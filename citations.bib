@article{ablart2017,
  title = {The How and Why behind a Multisensory Art Display},
  author = {Ablart, Damien and Velasco, Carlos and Vi, Chi Thanh and Gatti, Elia and Obrist, Marianna},
  year = {2017},
  month = oct,
  journal = {interactions},
  volume = {24},
  number = {6},
  pages = {38--43},
  issn = {10725520},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ablart2017.md;Human Computer Interaction/Multisensory Interfacing/Ablart et al., 2017 - The how and why behind a multisensory art display.pdf},
  url = {https://doi.org/10.1145/3137091}
}

@inproceedings{ablart2019,
  title = {Using {{Ultrasonic Mid-air Haptic Patterns}} in {{Multi-Modal User Experiences}}},
  booktitle = {2019 {{IEEE International Symposium}} on {{Haptic}}, {{Audio}} and {{Visual Environments}} and {{Games}} ({{HAVE}})},
  author = {Ablart, Damien and Frier, William and Limerick, Hannah and Georgiou, Orestis and Obrist, Marianna},
  year = {2019},
  month = oct,
  pages = {1--6},
  publisher = {{IEEE}},
  address = {{Subang Jaya, Malaysia}},
  urldate = {2020-10-03},
  abstract = {Ultrasonic mid-air tactile displays offer a unique combination of high spatial and temporal resolution and can stimulate a wide range of tactile frequencies. Leveraging those features, a new modulation technique producing spatially distributed tactile sensations has recently been introduced. This new approach, referred to as Spatiotemporal Modulation (STM), draws lines, curves and shapes on users' palm by moving a midair tactile point rapidly and repeatedly along the path. STM parameters and their impact on tactile perception are yet to be studied systematically. In this work, we first study how varying the draw frequency and the size of a simple shape affects the participants perception of texture and their emotional responses. In the second part of our study, we used the most salient tactile patterns of the first study to extend the results within a multimodal context. We found that tactile patterns' perception was consistent within both studies. We also found instances when the tactile patterns could alter the perception of the audio and visual stimuli. Finally, we discuss the benefits of our findings and conclude with implications for future work.},
  isbn = {978-1-72812-355-4},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ablart2019.md;Human Computer Interaction/Multisensory Interfacing/Ablart et al., 2019 - Using Ultrasonic Mid-air Haptic Patterns in Multi-Modal User Experiences.pdf},
  url = {https://doi.org/10.1109/HAVE.2019.8920969}
}

@article{aceti2013,
  title = {Not {{Here Not There}}},
  editor = {Aceti, Lanfranco},
  year = {2013},
  journal = {Leonardo},
  volume = {19},
  number = {2},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/aceti2013.md;Human Computer Interaction/Augmented Reality/2013 - Not Here Not There.pdf}
}

@misc{adl2022,
  title = {Extremists, {{Far Right Figures Exploit Recent Changes}} to {{Twitter}} {\textbar} {{ADL}}},
  author = {ADL},
  year = {2022},
  month = dec,
  journal = {Anti-Defamation League},
  url = {https://archive.today/Lz1ec},
  urldate = {2022-12-11},
  langid = {english},
  file = {../../../../../Zotero/storage/R9AZXARG/extremists-far-right-figures-exploit-recent-changes-twitter.html}
}

@misc{aftershokz2020,
  title = {Aftershockz {{Aeropex}}},
  author = {Aftershokz},
  year = {2020},
  journal = {AfterShokz},
  url = {https://aftershokz.co.uk/products/aeropex},
  urldate = {2020-05-25},
  abstract = {Listen to music through bone vibration with these contemporary Aftershokz Aeropex headphones. The open ear design and bone conduction technology lets you hear external sounds, such as traffic, during use, and the Enhanced Audio feature ensures deeper bass and less vibration. These Aftershokz Aeropex headphones are lightweight for comfortable all-day wearing and can be used during workouts and runs in the rain with an IP67 waterproof rating.},
  langid = {english},
  file = {../../../../../Zotero/storage/7DNSJP4C/aeropex.html}
}

@article{alkiviadou2019,
  title = {Hate Speech on Social Media Networks: Towards a Regulatory Framework?},
  shorttitle = {Hate Speech on Social Media Networks},
  author = {Alkiviadou, Natalie},
  year = {2019},
  month = jan,
  journal = {Information \& Communications Technology Law},
  volume = {28},
  number = {1},
  pages = {19--35},
  issn = {1360-0834, 1469-8404},
  urldate = {2022-12-11},
  abstract = {Social networks serve as effective platforms in which users' ideas can be spread in an easy and efficient manner. However, those ideas can be hateful and harmful, some of which may even amount to hate speech. YouTube, Facebook and Twitter have internal regulatory policies in relation to hate speech and have signed a Code of Conduct on the regulation of illegal hate speech with the European Commission. This paper looks at the issue of tackling hate speech on social networks and argues that, notwithstanding the weaknesses of internal policies and their implementation, their existence, as facilitated by the Code of Conduct, serves as a light at the end of the Internet hate tunnel where issues of multiple jurisdictions as well as technological realities, such as mirror sites and more, have resulted in the task of online regulation being more than a daunting one.},
  langid = {english},
  file = {Politics/Marxism/Alkiviadou, 2019 - Hate speech on social media networks.pdf},
  url = {https://doi.org/10.1080/13600834.2018.1494417}
}

@inproceedings{altosaar2019,
  title = {Physically {{Colliding}} with {{Music}}: {{Full-body Interactions}} with an {{Audio-only Virtual Reality Interface}}},
  shorttitle = {Physically {{Colliding}} with {{Music}}},
  booktitle = {Proceedings of the {{Thirteenth International Conference}} on {{Tangible}}, {{Embedded}}, and {{Embodied Interaction}}  - {{TEI}} '19},
  author = {Altosaar, Raul and Tindale, Adam and Doyle, Judith},
  year = {2019},
  pages = {553--557},
  publisher = {{ACM Press}},
  address = {{Tempe, Arizona, USA}},
  urldate = {2020-01-10},
  abstract = {A Very Real Looper (AVRL) is an audio-only virtual reality (VR) interface inside of which a performer triggers and controls music through full-body movement. Contrary to how musical interfaces in VR are normally used, a performer using AVRL is not disconnected from their surrounding environment through immersion, nor is their body restrained by a head-mounted display. Rather, AVRL utilizes two VR sensors and the Unity game engine to map virtual musical sounds onto physical objects in the real world. These objects help the performer locate the sounds. Using two handheld VR controllers, these sounds can be triggered, looped, acoustically affected, or repositioned in space. AVRL thus combines the affordances of the physical world and a VR system with the reconfigurability of a game engine. This integration results in an expansive and augmented performance environment that facilitates full-body musical interactions.},
  isbn = {978-1-4503-6196-5},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/altosaar2019.md;Human Computer Interaction/Virtual Reality/Altosaar et al., 2019 - Physically Colliding with Music.pdf},
  url = {https://doi.org/10.1145/3294109.3301256}
}

@misc{apple2020,
  title = {{{ARKit}}},
  author = {Apple},
  year = {2020},
  journal = {ARKit},
  url = {https://developer.apple.com/augmented-reality/arkit/},
  urldate = {2020-05-25},
  abstract = {Take advantage of the latest advances in ARKit to create incredible augmented reality experiences for Apple platforms.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/apple2020.md;../../../../../Zotero/storage/RN5UG5LG/arkit.html}
}

@misc{apple2020a,
  title = {App {{Clips}}},
  author = {{Apple}},
  year = {2020},
  journal = {Apple Developer},
  url = {https://developer.apple.com/app-clips/},
  urldate = {2020-10-02},
  abstract = {App Clips are a great way for users to quickly access and experience what your app has to offer.},
  langid = {english},
  file = {../../../../../Zotero/storage/37WZ3946/app-clips.html}
}

@phdthesis{armstrong2006,
  title = {An {{Enactive Approach}} to {{Digital Musical Instrument Design}}},
  author = {Armstrong, Newton},
  year = {2006},
  langid = {english},
  school = {Princeton University},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/armstrong2006.md;Arts & Humanities/Computational Art/Armstrong, 2006 - An Enactive Approach to Digital Musical Instrument Design.pdf}
}

@inproceedings{arslan2022,
  title = {Vibrating Shapes : {{Design}} and Evolution of a Spatial Augmented Reality Interface for Actuated Instruments},
  booktitle = {{{NIME}} 2022},
  author = {Arslan, Cagan and Berthaut, Florent and Beuchey, Anthony and Cambourian, Paul and Pat{\'e}, Arthur},
  year = {2022},
  month = jun
}

@misc{att2019,
  title = {{{AT}}\&{{T Brings Magic Leap One}} to {{Flagship Stores Next Week}}},
  author = {AT\&T},
  year = {2019},
  journal = {AT\&T},
  url = {https://about.att.com/story/2019/magic_leap.html},
  urldate = {2022-12-13},
  abstract = {The Magic Leap One wearable computer will offer an immersive experience like never before.},
  langid = {american},
  file = {../../../../../Zotero/storage/D6SZJGYN/magic_leap.html}
}

@article{azuma1997,
  title = {A {{Survey}} of {{Augmented Reality}}},
  author = {Azuma, Ronald},
  year = {1997},
  journal = {Presence: Teleoperators and Virtual Environments},
  volume = {6},
  number = {4},
  pages = {355--385},
  abstract = {This paper surveys the field of Augmented Reality, in which 3-D virtual objects are integrated into a 3-D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment and military applications that have been explored. This paper describes the characteristics of Augmented Reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective Augmented Reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using Augmented Reality.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/azuma1997.md;Human Computer Interaction/Augmented Reality/Azuma, 1997 - A Survey of Augmented Reality.pdf},
  url = {https://doi.org/10.1162/pres.1997.6.4.355}
}

@article{azuma2001,
  title = {Recent Advances in Augmented Reality},
  author = {Azuma, Ronald and Baillot, Yohan and Behringer, R and Feiner, Steven and Julier, S and MacIntyre, Blair},
  year = {2001},
  month = nov,
  journal = {IEEE Computer Graphics and Applications},
  volume = {21},
  number = {6},
  pages = {34--47},
  issn = {02721716},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/azuma2001.md;Human Computer Interaction/Augmented Reality/Azuma et al., 2001 - Recent advances in augmented reality.pdf},
  url = {https://doi.org/10.1109/38.963459}
}

@inproceedings{badawy2018,
  title = {Analyzing the {{Digital Traces}} of {{Political Manipulation}}: {{The}} 2016 {{Russian Interference Twitter Campaign}}},
  shorttitle = {Analyzing the {{Digital Traces}} of {{Political Manipulation}}},
  booktitle = {2018 {{IEEE}}/{{ACM International Conference}} on {{Advances}} in {{Social Networks Analysis}} and {{Mining}} ({{ASONAM}})},
  author = {Badawy, Adam and Ferrara, Emilio and Lerman, Kristina},
  year = {2018},
  month = aug,
  pages = {258--265},
  issn = {2473-991X},
  abstract = {Until recently, social media was seen to promote democratic discourse on social and political issues. However, this powerful communication platform has come under scrutiny for allowing hostile actors to exploit online discussions in an attempt to manipulate public opinion. A case in point is the ongoing U.S. Congress investigation of Russian interference in the 2016 U.S. election campaign, with Russia accused of, among other things, using trolls (malicious accounts created for the purpose of manipulation) and bots (automated accounts) to spread misinformation and politically biased information. In this study, we explore the effects of this manipulation campaign, taking a closer look at users who re-shared the posts produced on Twitter by the Russian troll accounts publicly disclosed by U.S. Congress investigation. We collected a dataset with over 43 million elections-related posts shared on Twitter between September 16 and November 9, 2016 by about 5.7 million distinct users. This dataset includes accounts associated with the identified Russian trolls. We use label propagation to infer the users' ideology based on the news sources they shared, to classify a large number of them as liberal or conservative with precision and recall above 90\%. Conservatives retweeted Russian trolls significantly more often than liberals and produced 36 times more tweets. Additionally, most of the troll content originated in, and was shared by users from Southern states. Using state-of-the-art bot detection techniques, we estimated that about 4.9\% and 6.2\% of liberal and conservative users respectively were bots. Text analysis on the content shared by trolls reveals that they had a mostly conservative, pro-Trump agenda. Although an ideologically broad swath of Twitter users were exposed to Russian trolls in the period leading up to the 2016 U.S. Presidential election, it was mainly conservatives who helped amplify their message.},
  keywords = {Bots,Interference,Media,Misinformation,Russian trolls,Social media manipulation,Text analysis,Tools,Twitter,Voting},
  file = {Politics/Marxism/Badawy et al., 2018 - Analyzing the Digital Traces of Political Manipulation.pdf;../../../../../Zotero/storage/66GDWK9I/stamp.html},
  url = {https://doi.org/10.1109/ASONAM.2018.8508646}
}

@article{bailey2017,
  title = {Online {{Feminist Pedagogy}}: {{A New Doorway}} into {{Our Brick-and-Mortar Classrooms}}?},
  shorttitle = {Online {{Feminist Pedagogy}}},
  author = {Bailey, Cathryn},
  year = {2017},
  journal = {Feminist Teacher},
  volume = {27},
  number = {2-3},
  eprint = {10.5406/femteacher.27.2-3.0253},
  eprinttype = {jstor},
  pages = {253},
  issn = {08824843},
  urldate = {2021-09-08},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/bailey2017.md;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/Online Feminist Pedagogy A New Doorway into Our Brick-and-Mortar Classrooms.md;Pedagogy/Bailey, 2017 - Online Feminist Pedagogy.pdf},
  url = {https://doi.org/10.5406/femteacher.27.2-3.0253}
}

@article{baldassi2018,
  title = {Challenges and {{New Directions}} in {{Augmented Reality}}, {{Computer Security}}, and {{Neuroscience}} -- {{Part}} 1: {{Risks}} to {{Sensation}} and {{Perception}}},
  shorttitle = {Challenges and {{New Directions}} in {{Augmented Reality}}, {{Computer Security}}, and {{Neuroscience}} -- {{Part}} 1},
  author = {Baldassi, Stefano and Kohno, Tadayoshi and Roesner, Franziska and Tian, Moqian},
  year = {2018},
  month = jun,
  journal = {arXiv:1806.10557 [cs]},
  eprint = {1806.10557},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1806.10557},
  urldate = {2020-05-25},
  abstract = {Rapidly advancing AR technologies are in a unique position to directly mediate between the human brain and the physical world. Though this tight coupling presents tremendous opportunities for human augmentation, it also presents new risks due to potential adversaries, including AR applications or devices themselves, as well as bugs or accidents. In this paper, we begin exploring potential risks to the human brain from augmented reality. Our initial focus is on sensory and perceptual risks (e.g., accidentally or maliciously induced visual adaptations, motion-induced blindness, and photosensitive epilepsy), but similar risks may span both lower- and higher-level human brain functions, including cognition, memory, and decision-making. Though they have not yet manifested in practice in early-generation AR technologies, we believe that such risks are uniquely dangerous in AR due to the richness and depth with which it interacts with a user's experience of the physical world. We propose a framework, based in computer security threat modeling, to conceptually and experimentally evaluate such risks. The ultimate goal of our work is to aid AR technology developers, researchers, and neuroscientists to consider these issues before AR technologies are widely deployed and become targets for real adversaries. By considering and addressing these issues now, we can help ensure that future AR technologies can meet their full, positive potential.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/baldassi2018.md;Human Computer Interaction/Augmented Reality/Baldassi et al., 2018 - Challenges and New Directions in Augmented Reality, Computer Security, and.pdf;../../../../../Zotero/storage/773269IN/1806.html}
}

@article{baran1964,
  title = {On Distributed Communications Networks},
  author = {Baran, Paul},
  year = {1964},
  journal = {IEEE transactions on Communications Systems},
  volume = {12},
  number = {1},
  pages = {1--9},
  publisher = {{IEEE}},
  file = {Human Computer Interaction/Complex Systems/Baran, 1964 - On distributed communications networks.pdf}
}

@article{barde2016,
  title = {Attention {{Redirection Using Binaurally Spatialised Cues Delivered Over}} a {{Bone Conduction Headset}}},
  author = {Barde, Amit and Ward, Matt and Helton, William S. and Billinghurst, Mark and Lee, Gun},
  year = {2016},
  month = sep,
  journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  volume = {60},
  number = {1},
  pages = {1534--1538},
  issn = {1541-9312},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/barde2016.md;Human Computer Interaction/Augmented Reality/Barde et al., 2016 - Attention Redirection Using Binaurally Spatialised Cues Delivered Over a Bone.pdf},
  url = {https://doi.org/10.1177/1541931213601352}
}

@phdthesis{barde2018,
  title = {Design {{Considerations}} for a {{Wearable}}, {{Bi-Modal Interface}}},
  author = {Barde, Amit},
  year = {2018},
  school = {University of Canterbury},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/barde2018.md;Human Computer Interaction/Multisensory Interfacing/Barde, 2018 - Design Considerations for a Wearable, Bi-Modal Interface.pdf}
}

@inproceedings{barde2020,
  title = {The Use of Spatialised Auditory and Visual Cues for Target Acqusition in a Search Task},
  booktitle = {Audio Engineering Society Conference: 2020 {{AES}} International Conference on Audio for Virtual and Augmented Reality},
  author = {Barde, Amit and Ward, Matt and Lindeman, Robert and Billinghurst, Mark},
  year = {2020},
  month = aug,
  url = {http://www.aes.org/e-lib/browse.cfm?elib=20875},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/barde2020.md}
}

@inproceedings{barrett2020,
  title = {Deepening Presence: {{Probing}} the Hidden Artefacts of Everyday Soundscapes},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Barrett, Natasha},
  year = {2020},
  series = {{{AM}} '20},
  pages = {77--84},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {Sound penetrates our outdoor spaces. Much of it we ignore amidst our fast passage from place to place, its qualities may be too quiet or fleeting to pay heed to above the bustle of our own thoughts, or we may experience the sounds as an annoyance. Manoeuvring our listening to be excited by its features is not so easy.This paper presents new artistic research that probes the hidden artefacts of everyday soundscapes - the sounds and details which we ignore or fail to engage - and draws them into a new audible reality. The work focuses on the affordances of spatial information in a novel combination of art and technology: site-specific composition and the ways of listening established by Schaeffer and his successors are combined with the technology of beam-forming from high resolution (Eigenmike) Ambisonics recordings, Ambisonics sound-field synthesis and the deployment of a new prototype loudspeaker. Underlying the artistic and scientific research is the hypothesis that spatially distributed information offers new opportunities to explore, isolate and musically develop features of interest, and that composition should address the same degree of spatiality as the real landscape. The work is part of the 'Reconfiguring the Landscape' project investigating how 3-D electroacoustic composition and sound-art can incite a new awareness of outdoor sound environments.},
  isbn = {978-1-4503-7563-4},
  keywords = {acoustic ecology,acoustics,composition,feature extraction,higher-order ambisonics,loudspeaker technology,sonification,soundscapes},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/barrett2020.md;Arts & Humanities/Computational Art/Barrett, 2020 - Deepening presence.pdf},
  url = {https://doi.org/10.1145/3411109.3411120}
}

@incollection{bassett2015,
  title = {Not {{Now}}? {{Feminism}}, {{Technology}}, {{Postdigital}}},
  booktitle = {Postdigital {{Aesthetics}}},
  author = {Bassett, Caroline},
  editor = {Berry, David and Dieter, Michael},
  year = {2015},
  pages = {136--150},
  publisher = {{Palgrave Macmillan UK}},
  address = {{London}},
  isbn = {978-1-349-49378-4 978-1-137-43720-4},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/bassett2015.md;Arts & Humanities/Media Studies/Bassett, 2015 - Not Now.pdf}
}

@article{battaglia2003,
  title = {Bayesian Integration of Visual and Auditory Signals for Spatial Localization},
  author = {Battaglia, Peter W. and Jacobs, Robert A. and Aslin, Richard N.},
  year = {2003},
  month = jul,
  journal = {Journal of the Optical Society of America A},
  volume = {20},
  number = {7},
  pages = {1391},
  issn = {1084-7529, 1520-8532},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/battaglia2003.md;Cognitive Science/Multisensory Integration/Battaglia et al., 2003 - Bayesian integration of visual and auditory signals for spatial localization.pdf},
  url = {https://doi.org/10.1364/JOSAA.20.001391}
}

@article{bayle2007,
  title = {Space, and More},
  author = {Bayle, Fran{\c c}ois},
  year = {2007},
  month = dec,
  journal = {Organised Sound},
  volume = {12},
  number = {3},
  pages = {241--249},
  issn = {1469-8153, 1355-7718},
  urldate = {2020-02-11},
  abstract = {Among the questions regularly put to me, those that recur most often touch upon three aspects, three things to consider that are, truth to tell, unending within the domain of organised sounds. Those questions that take the lead are usually concerned with space {\textendash} the representation of space as well as the production of space. Then come those that deal with listening, active or passive. Last are those relating to tools for making and for listening. Together, these approaches run through the stages that are very natural in position problematics: where, when, how, for whom, why? I would like, in formulating these repeated questions once more, to make myself re-orientate them in such a way to show that by bringing to bear forty years of experience, I have tried to reply to them as much through practice as through theory, putting forward the idea of a family of operational concepts linked together through the perceptual radical `acous': acousmatic, acousmonium, acousmographe, acousmath{\`e}que.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/bayle2007.md;Arts & Humanities/Computational Art/Bayle, 2007 - Space, and more.pdf},
  url = {https://doi.org/10.1017/S1355771807001872}
}

@book{beck2020,
  title = {Technocrats of the Imagination: Art, Technology, and the Military-Industrial Avant-Garde},
  shorttitle = {Technocrats of the Imagination},
  author = {Beck, John and Bishop, Ryan},
  year = {2020},
  publisher = {{Duke University Press Books}},
  address = {{Durham}},
  abstract = {"TECHNOCRATS OF THE IMAGINATION traces the rise of collaborative art and technology labs in the U.S. from WWII to the present. Ryan Bishop and John Beck reveal the intertwined histories of the avant-garde art movement and the military-industrial complex, showing how radical pedagogical practices traveled from Germany's Bauhaus movement to the U.S. art world and interacted with government-funded military research and development in university laboratories. During the 1960s both media labs and studio labs leaned heavily on methods of interdisciplinary collaboration and the power of American modernity to model new modes of social organization. The book's chapters take up MIT's Center for Art, Science, and Technology, Bell Labs's E.A.T. (Experiments in Art and Technology) Salon, and Los Angeles Museum of Art's Art + Technology Program. Their interconnected history illuminates how much of contemporary media culture and aesthetics depends on the historical relationship between military, corporate, and university actors. In light of revived interest in Black Mountain College and other 1960s art and technology labs, this book draws important connections between the contemporary art world and the militarized lab model of research that has dominated the sciences since the 1950s. The authors situate the rise of collaborative art and technology projects in the 1960s within John Dewey's ideology of scientific democracy, showing how leading thinkers from the Bauhaus movement in Germany immigrated to the U.S. and brought with them a Deweyan model for collaborative and interdisciplinary art and technology research. Over the course of the decade, the U.S. government increased funding to scientific research at university and private laboratories. Beck and Bishop investigate how various art and technology projects incorporated the collaborative and innovative interdisciplinarity of the avant-garde art movement with the corporate funding structure driven by the U.S. government's military and technoscientific interests. Finally, the authors consider the legacy of 1960s art and technology projects. During the 1970s and 80s, defense R\&D funding was less motivated by a Cold War corporate state, and was instead restructured according to an entrepreneurial and neoliberal model. At the same time, funding in the art world also became increasingly financialized and globalized. Today's art and technology work happens collaboratively not because of an intellectual commitment to interdisciplinarity, but because of the precarity of the contemporary labor market. This book will interest students and scholars in art history and theory, media studies, history of technology, American studies, cultural studies, and critical university studies"--},
  isbn = {978-1-4780-0595-7 978-1-4780-0660-2},
  langid = {english},
  lccn = {NX180.T4 B43 2020},
  keywords = {20th century,Arts,Experimental methods,History,Military-industrial complex,Technology and the arts,United States},
  file = {Arts & Humanities/Aesthetics/Beck and Bishop, 2020 - Technocrats of the imagination.pdf}
}

@inproceedings{bederson1995,
  title = {Audio Augmented Reality: A Prototype Automated Tour Guide},
  shorttitle = {Audio Augmented Reality},
  booktitle = {Conference Companion on {{Human}} Factors in Computing Systems  - {{CHI}} '95},
  author = {Bederson, Benjamin B.},
  year = {1995},
  pages = {210--211},
  publisher = {{ACM Press}},
  address = {{Denver, Colorado, United States}},
  urldate = {2021-04-08},
  abstract = {Augmented reality (or computer augmented environments as it is sometimes called) uses computers to enhance the richness of the real world. It differs from virtual reality in that it doesn't attempt to replace the real world. Our prototype automated tour guide superimposes audio on the world based on where a user is located. We propose this technique for use as an automated tour guide in museums and expect it will enhance the social aspects of museum visits, compared to taped tour guides.},
  isbn = {978-0-89791-755-1},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/bederson1995.md;Human Computer Interaction/Augmented Reality/Bederson, 1995 - Audio augmented reality.pdf},
  url = {https://doi.org/10.1145/223355.223526}
}

@article{berkhout1993,
  title = {Acoustic Control by Wave Field Synthesis},
  author = {Berkhout, A. J. and {de Vries}, D. and Vogel, P.},
  year = {1993},
  month = may,
  journal = {The Journal of the Acoustical Society of America},
  volume = {93},
  number = {5},
  pages = {2764--2778},
  issn = {0001-4966},
  urldate = {2022-12-19},
  langid = {english},
  file = {Human Computer Interaction/Audio Interfacing/Berkhout et al., 1993 - Acoustic control by wave field synthesis.pdf},
  url = {https://doi.org/10.1121/1.405852}
}

@article{bermejo2017,
  title = {A Survey on Haptic Technologies for Mobile Augmented Reality},
  author = {Bermejo, Carlos and Hui, Pan},
  year = {2017},
  month = sep,
  journal = {arXiv:1709.00698 [cs]},
  eprint = {1709.00698},
  primaryclass = {cs},
  urldate = {2020-01-10},
  abstract = {Augmented Reality (AR) and Mobile Augmented Reality (MAR) applications have gained much research and industry attention these days. The mobile nature of MAR applications limits users' interaction capabilities such as inputs, and haptic feedbacks. This survey reviews current research issues in the area of human computer interaction for MAR and haptic devices. The survey first presents human sensing capabilities and their applicability in AR applications. We classify haptic devices into two groups according to the triggered sense: cutaneous/tactile: touch, active surfaces, and mid-air; kinesthetic: manipulandum, grasp, and exoskeleton. Due to the mobile capabilities of MAR applications, we mainly focus our study on wearable haptic devices for each category and their AR possibilities. To conclude, we discuss the future paths that haptic feedbacks should follow for MAR applications and their challenges.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {â›” No DOI found,Computer Science - Human-Computer Interaction},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/bermejo2017.md;Human Computer Interaction/Augmented Reality/Bermejo and Hui, 2017 - A survey on haptic technologies for mobile augmented reality.pdf},
  url = {https://doi.org/10.48550/arXiv.1709.00698}
}

@book{berry2011,
  title = {The Philosophy of Software: Code and Mediation in the Digital Age},
  shorttitle = {The Philosophy of Software},
  author = {Berry, David},
  year = {2011},
  publisher = {{Palgrave Macmillan}},
  address = {{Houndmills, Basingstoke, Hampshire; New York}},
  url = {http://site.ebrary.com/id/10462131},
  urldate = {2020-01-10},
  abstract = {This book is a critical introduction to code and software that develops an understanding of its social and philosophical implications in the digital age. Written specifically for people interested in the subject from a non-technical background, the book provides a lively and interesting analysis of these new media forms.},
  isbn = {9780230306479 9781283067690 9786613067692},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/berry2011.md;Arts & Humanities/Media Studies/Berry, 2011 - The philosophy of software.pdf;Arts & Humanities/Media Studies/Berry, 2011 - The philosophy of software2.pdf}
}

@incollection{berry2015,
  title = {Thinking {{Postdigital Aesthetics}}: {{Art}}, {{Computation}} and {{Design}}},
  shorttitle = {Thinking {{Postdigital Aesthetics}}},
  booktitle = {Postdigital {{Aesthetics}}},
  author = {Berry, David M. and Dieter, Michael},
  editor = {Berry, David and Dieter, Michael},
  year = {2015},
  pages = {1--11},
  publisher = {{Palgrave Macmillan UK}},
  address = {{London}},
  url = {https://doi.org/10.1057/9781137437204_1},
  urldate = {2020-09-21},
  isbn = {978-1-349-49378-4 978-1-137-43720-4},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/berry2015.md;Arts & Humanities/Media Studies/Berry and Dieter, 2015 - Thinking Postdigital Aesthetics.pdf}
}

@inproceedings{berthaut2014,
  title = {Scenography of Immersive Virtual Musical Instruments},
  booktitle = {2014 {{IEEE VR Workshop}}: {{Sonic Interaction}} in {{Virtual Environments}} ({{SIVE}})},
  author = {Berthaut, Florent and Zappi, Victor and Mazzanti, Dario},
  year = {2014},
  month = mar,
  pages = {19--24},
  abstract = {Immersive Virtual Musical Instruments (IVMIs) can be considered as the meeting between Music Technology and Virtual Reality. Being both musical instruments and elements of Virtual Environments, IVMIs require a transversal approach from their designers, in particular when the final aim is to play them in front of an audience, as part of a scenography. In this paper, we combine the main constraints of musical performances and Virtual Reality applications into a set of dimensions, meant to extensively describe IVMIs stage setups. A number of existing stage setups are then classified using these dimensions, explaining how they were used to showcase live virtual performances and discussing their scenographic level.},
  keywords = {Aerospace electronics,audience's experience,Electronic mail,Immersive virtual musical instruments,Instruments,scenography,Stereo image processing,Three-dimensional displays,virtual reality,Virtual reality,Visualization},
  file = {Human Computer Interaction/Virtual Reality/Berthaut et al., 2014 - Scenography of immersive virtual musical instruments.pdf},
  url = {https://doi.org/10.1109/SIVE.2014.7006285}
}

@inproceedings{berthaut2016,
  title = {{{ControllAR}}: {{Appropriation}} of {{Visual Feedback}} on {{Control Surfaces}}},
  shorttitle = {{{ControllAR}}},
  booktitle = {Proceedings of the 2016 {{ACM}} on {{Interactive Surfaces}} and {{Spaces}} - {{ISS}} '16},
  author = {Berthaut, Florent and Jones, Alex},
  year = {2016},
  pages = {271--277},
  publisher = {{ACM Press}},
  address = {{Niagara Falls, Ontario, Canada}},
  urldate = {2020-05-27},
  abstract = {Despite the development of touchscreens, many expert systems for working with digital multimedia content, such as in music composition and performance, video editing or visual performance, still rely on control surfaces. This can be due to the accuracy and appropriateness of their sensors, the haptic feedback that they offer, and most importantly the way they can be adapted to the specific subset of gestures and tasks that users need to perform. On the other hand, visual feedback on controllers remains limited and/or fixed, preventing similar personalizing. In this paper, we propose ControllAR, a novel system that facilitates the appropriation of rich visual feedback on control surfaces through remixing of graphical user interfaces and augmented reality display. We then use our system to study current and potential appropriation of visual feedback in the case of digital musical instruments and derive guidelines for designers and developers.},
  isbn = {978-1-4503-4248-3},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/berthaut2016.md;Human Computer Interaction/Augmented Reality/Berthaut and Jones, 2016 - ControllAR.pdf},
  url = {https://doi.org/10.1145/2992154.2992170}
}

@inproceedings{berthaut2016a,
  title = {{{BOEUF}}: {{A Unified Framework}} for {{Modeling}} and {{Designing Digital Orchestras}}},
  shorttitle = {{{BOEUF}}},
  booktitle = {Music, {{Mind}}, and {{Embodiment}}},
  author = {Berthaut, Florent and Dahl, Luke},
  editor = {{Kronland-Martinet}, Richard and Aramaki, Mitsuko and Ystad, S{\o}lvi},
  year = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {153--166},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {Orchestras of Digital Musical Instruments (DMIs) enable new musical collaboration possibilities, extending those of acoustic and electric orchestras. However the creation and development of these orchestras remain constrained. In fact, each new musical collaboration system or orchestra piece relies on a fixed number of musicians, a fixed set of instruments (often only one), and a fixed subset of possible modes of collaboration.},
  isbn = {978-3-319-46282-0},
  langid = {english},
  keywords = {Boeuf,Collaboration,Collaborative music,Digital musical instrument,Digital orchestra,DMI,Framework,NIME,Orchestra},
  file = {Human Computer Interaction/Augmented Reality/Berthaut and Dahl, 2016 - BOEUF.pdf},
  url = {https://doi.org/10.1007/978-3-319-46282-0_10}
}

@inproceedings{berthaut2022,
  title = {The {{Effect}} of {{Visualisation Level}} and {{Situational Visibility}} in {{Co-located Digital Musical Ensembles}}},
  booktitle = {International {{Conference}} on {{New Interfaces}} for {{Musical Expression}}},
  author = {Berthaut, Florent and Dahl, Luke},
  year = {2022},
  month = jun,
  urldate = {2023-01-23},
  abstract = {Digital Musical Instruments (DMIs) offer new opportunities for collaboration, such as exchanging sounds or sharing controls between musicians. However, in the context of spontaneous and heterogeneous orchestras, such as jam sessions, collective music-making may become challenging due to the diversity and complexity of the DMIs and the musicians' unfamiliarity with the others' instruments. In particular, the potential lack of visibility into each musician's respective contribution to the sound they hear, i.e. who is playing what, might impede their capacity to play together. In this paper, we propose to augment each instrument in a digital orchestra with visual feedback extracted in real-time from the instrument's activity, in order to increase this awareness. We present the results of a user study in which we investigate the influence of visualisation level and situational visibility during short improvisations by groups of three musicians. Our results suggest that internal visualisations of all instruments displayed close to each musician's instrument provide the best awareness.},
  langid = {english},
  file = {Human Computer Interaction/Augmented Reality/Berthaut and Dahl, 2022 - The Effect of Visualisation Level and Situational Visibility in Co-located.pdf},
  url = {https://doi.org/10.21428/92fbeb44.9d974714}
}

@misc{berweck2012,
  title = {It {{Worked Yesterday}}},
  author = {Berweck, Sebastian},
  year = {2012},
  url = {http://eprints.hud.ac.uk/id/eprint/17540/1/sberweckfinalthesis.pdf},
  urldate = {2018-04-10},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/berweck2012.md;Arts & Humanities/Media Studies/Berweck, 2012 - It Worked Yesterday.pdf}
}

@inproceedings{bilbow2020,
  title = {Impact on Human Perception and Expression, Using Augmented Reality Technology as a Medium for Computational Art},
  booktitle = {Internal {{Research Proposal}}},
  author = {Bilbow, Sam},
  year = {2020},
  month = jan,
  publisher = {{Zenodo}},
  urldate = {2022-12-10},
  abstract = {This research proposal develops multi-sensory AR technology as a novel method to address the current visual bias in AR development, through the question: What impact do multi-sensory AR experiences have on human perception and expression in participatory installation art? I outline contemporary literature that discusses the possibility for multi-sensory AR, as well as examples of installations that utilise non-visual modes of perceptual mediation. I will use an iterative design process to create my own multi- sensory AR instruments, which will be used in an installation. Through individual and group studies of the instrument and installation respectively, I aim to answer the question through a combination of rigorous survey-based quantitative data analysis, as well as a grounded theory approach to qualitatively analyse interview feedback. The findings would culminate in a thesis paper exploring the impact of augmented reality technology on user perception and expression, and the creation of a software tool that could be used as a research platform and framework for creating multi- sensory AR experiences that are immersive for both artist and audience.},
  langid = {english},
  keywords = {{augmented reality, music technology, sonic art, installation, instrumentality}},
  file = {Human Computer Interaction/Augmented Reality/Bilbow, 2020 - Impact on human perception and expression, using augmented reality technology.pdf},
  url = {https://doi.org/10.5281/zenodo.7421529}
}

@misc{bilbow2020a,
  title = {Area{\textasciitilde} 360{\textdegree} Video / Ambisonics Documentation},
  author = {Bilbow, Sam},
  year = {2020},
  month = jul,
  address = {{Brighton, UK}},
  url = {https://www.youtube.com/watch?v=SPd-f2EXuIQ},
  urldate = {2022-12-14}
}

@inproceedings{bilbow2021,
  title = {The {{Value}} of {{Sound}} within a {{Multisensory Approach}} to {{AR}} in the {{Arts}}},
  booktitle = {Proceedings of the {{Multisensory Augmented Reality Workshop}}},
  author = {Bilbow, Sam and Kiefer, Chris and Chevalier, C{\'e}cile},
  year = {2021},
  pages = {8},
  publisher = {{Interact}},
  address = {{Italy}},
  abstract = {We explore the potential of sound within broader multisensory augmented reality, and its value in creating coherent, immersive and embodied experiences in computational art. We demonstrate this practically through accounts of the authors experiences in creating two pieces. Looking at the wider place of AR in the arts, we argue that DIY approaches to augmented reality are essential for creative work, and we speculate on how art can contribute to future theory, technologies and practice in the field.},
  langid = {english},
  file = {Human Computer Interaction/Augmented Reality/Bilbow et al., 2021 - The Value of Sound within a Multisensory Approach to AR in the Arts.pdf},
  url = {https://doi.org/10.5281/zenodo.7421488}
}

@article{bilbow2021a,
  title = {The Area{\textasciitilde} System: {{Exploring}} Real and Virtual Environments through Gestural Ambisonics and Audio Augmented Reality},
  author = {Bilbow, Sam},
  year = {2021},
  month = feb,
  journal = {Sonic Scope: New Approaches to Audiovisual Culture},
  volume = {2},
  file = {Human Computer Interaction/Augmented Reality/Bilbow, 2021 - The area~ system.pdf},
  url = {https://doi.org/10.21428/66f840a4.b74711a8}
}

@inproceedings{bilbow2021b,
  title = {Developing {{Multisensory Augmented Reality As A Medium For Computational Artists}}},
  booktitle = {Proceedings of the {{Fifteenth International Conference}} on {{Tangible}}, {{Embedded}}, and {{Embodied Interaction}}},
  author = {Bilbow, Sam},
  year = {2021},
  month = feb,
  pages = {1--7},
  publisher = {{ACM}},
  address = {{Salzburg Austria}},
  urldate = {2021-03-05},
  abstract = {This paper resituates multisensory augmented reality (MSAR) as an artistic medium for the creation of interactive and expressive works by computational artists. If an AR system can be thought of as one that combines real and virtual processes, is interactive in real-time, and is registered in three dimensions; why do we witness the majority of AR applications utilising primarily visual displays of information? In this paper, I propose a practice-led compositional approach for developing `MSAR Experiences', arguing that, as an medium that combines real and virtual multisensory processes, it must be explored with a multisensory approach. The paper further outlines the study methods that I will use to evaluate the developed experiences. The outcome of this project is the practice-led method as well as MSAR hardware, software and experiences that are developed and evaluated.},
  isbn = {978-1-4503-8213-7},
  langid = {english},
  file = {Human Computer Interaction/Augmented Reality/Bilbow, 2021 - Developing Multisensory Augmented Reality As A Medium For Computational Artists.pdf},
  url = {https://doi.org/10.1145/3430524.3443690}
}

@inproceedings{bilbow2022,
  title = {Evaluating Polaris{\textasciitilde} - {{An Audiovisual Augmented Reality Experience Built}} on {{Open-Source Hardware}} and {{Software}}},
  booktitle = {{{NIME}} 2022},
  author = {Bilbow, Sam},
  year = {2022},
  month = jun,
  publisher = {{New Interfaces for Musical Expression PubPub}},
  address = {{The University of Auckland, New Zealand}},
  urldate = {2022-09-27},
  abstract = {Augmented reality (AR) is increasingly being envisaged as a process of perceptual mediation or modulation, not only as a system that combines aligned and interactive virtual objects with a real environment. Within artistic practice, this reconceptualisation has led to a medium that emphasises this multisensory integration of virtual processes, leading to expressive, narrative-driven, and thought-provoking AR experiences. This paper outlines the development and evaluation of the polaris{\textasciitilde} experience. polaris{\textasciitilde} is built using a set of open-source hardware and software components that can be used to create privacy-respecting and cost-effective audiovisual AR experiences. Its wearable component is comprised of the open-source Project North Star AR headset and a pair of bone conduction headphones, providing simultaneous real and virtual visual and auditory elements. These elements are spatially aligned using Unity and PureData to the real space that they appear in and can be gesturally interacted with in a way that fosters artistic and musical expression. In order to evaluate the polaris{\textasciitilde}, 10 participants were recruited, who spent approximately 30 minutes each in the AR scene and were interviewed about their experience. Using grounded theory, the author extracted coded remarks from the transcriptions of these studies, that were then sorted into the categories of Sentiment, Learning, Adoption, Expression, and Immersion. In evaluating polaris{\textasciitilde} it was found that the experience engaged participants fruitfully, with many noting their ability to express themselves audiovisually in creative ways. The experience and the framework the author used to create it is available in a Github respository.},
  langid = {english},
  file = {Human Computer Interaction/Augmented Reality/Bilbow, 2022 - Evaluating polaris~ - An Audiovisual Augmented Reality Experience Built on.pdf},
  url = {https://doi.org/10.21428/92fbeb44.8abb9ce6}
}

@misc{bilbow2022a,
  title = {Polygons{\textasciitilde} {{AR Performance}} @ {{The ACCA}} ({{HD}} Clip)},
  author = {Bilbow, Sam},
  year = {2022},
  month = dec,
  publisher = {{Attenborough Centre for the Creative Arts}},
  address = {{Falmer, University of Sussex}},
  url = {https://www.youtube.com/watch?v=clSs3gHHnfc},
  urldate = {2022-12-13}
}

@misc{bilbow2022b,
  title = {Polygons{\textasciitilde} {{AR Performance}}  @ {{The Rosehill}}},
  author = {Bilbow, Sam},
  year = {2022},
  month = apr,
  publisher = {{The Rosehill}},
  address = {{Brighton, UK}},
  url = {https://www.youtube.com/watch?v=9IErsDvhXjM},
  urldate = {2022-12-13}
}

@misc{bilbow2022c,
  title = {Evaluating Polaris{\textasciitilde} - {{User Study Scene Demonstration}}},
  author = {Bilbow, Sam},
  year = {2022},
  month = oct,
  publisher = {{Sussex Humanities Lab}},
  address = {{University of Sussex, UK}},
  url = {https://www.youtube.com/watch?v=lCBgMs8ULj0},
  urldate = {2022-12-14}
}

@article{bilbow2023,
  title = {Mixed {{Realities}} as {{NIMEs}}},
  author = {Bilbow, Sam and Wang, Yichen},
  year = {2023},
  month = may,
  journal = {Workshop Proceedings, New Interfaces for Musical Expression Conference, Mexico City, Mexico},
  publisher = {{Zenodo}},
  urldate = {2024-01-29},
  abstract = {Inspired by recent XR workshops by colleagues, collaborators, and researchers, as well as recent advances in compositional and performative ecosystems this workshop aims to bring together practitioners specifically interested in augmented and mixed reality applications in music and the sonic arts. These projects have been run parallel to the current theoretical and practical trend of challenging the prevalent, ocularcentric view of MR technologies, which in turn has been necessary in carving out a space for applying MR as a medium for artistic expression through NIMEs.},
  copyright = {Creative Commons Attribution 4.0 International, Open Access},
  keywords = {Human-Computer Interaction,Mixed Reality,Musical Creativity},
  url = {https://doi.org/10.5281/ZENODO.8026943}
}

@phdthesis{bilbow2024,
  type = {Ph.{{D}}. {{Music Technologies}}},
  title = {Material, {{Embodied}}, and {{Spatial Relations}} in {{Augmented Reality}}: {{An Exploration}} of {{AR}} as a {{Medium}} for {{Musical Composition}} and {{Performance}}},
  shorttitle = {Material, {{Embodied}}, and {{Spatial Relations}} in {{Augmented Reality}}},
  author = {Bilbow, Sam},
  year = {2024},
  month = feb,
  address = {{Brighton, UK}},
  url = {https://doi.org/10779/uos.25205423.v1},
  abstract = {It has been thirty years since the original definition of augmented reality (AR) as a technology used to `augment the visual field of a user with information necessary in the performance of tasks'. In this first instance, it was developed with the purpose to `improve the efficiency and quality of human workers in their performance of manufacturing activities' (Caudell and Mizell, 1992). Alongside subsequent decades of funding from the U.S. military-industrial complex (MIC), we have also seen the uptake and reappropriation of AR in creative fields, such as computational art, performance, design, and entertainment - these works often proposing do-it-yourself (DIY) and open-source approaches to their design. Despite these developments, AR within sound-driven forms of art have been relatively under-explored. If an AR system can be thought of as one that can combine real and virtual multisensory processes, is interactive in real-time, and is registered in three dimensions (Azuma, 1997); why do we, thirty years on, witness the paradigmatic form of AR still being heavily biased (Billinghurst et al., 2015) towards it being a method of visual information overlay? Standing in stark contrast to the currently unfolding and hyper-commercialised view of AR {\textendash} as defined by the corporate `Metaverse' {\textendash} this thesis resituates AR as an artistic medium for the creation of interactive and expressive works by musicians and sound artists. It is guided primarily by the questions: `What are AR's affordances as an artistic medium, what is the resultant experience for participants and audiences (or `immersants') in these experiences, and what might a future of AR digital music instruments look, sound, and feel like?' To address these questions, this practice-based research takes a DIY Approach to Sound ARt, arguing that, as an mediumthat combines real and virtual multisensory processes, it must explored with a sensory-process agnostic approach {\textendash} that is, to approach AR as more than mere visual-information overlay, instead as `real-time computationally mediated perception' (Chevalier and Kiefer, 2020). This has involved making and hacking technology as a necessary aesthetic and political stance against commercial AR technologies in their typical form. Three sound augmented reality art (ARt) experiences are outlined, and embody the majority of the practical contribution of this thesis: area{\textasciitilde}, polaris{\textasciitilde}, and polygons{\textasciitilde}. In discussing the results of these three study chapters, theoretical propositions are made: `augmented materiality', `augmented embodiment', and `augmented space', that have implications for the use of AR as a sonic medium. Moreover, out of the iterated design of the AR experiences, their study, evaluation, and discussion, three `design guidelines' for those in the field interested in reproducing or developing similar sound ARt have been developed: Designing for Rich AR Experience, Consideration of the AR Instrument, and Role of the Virtual in the AR Environment.},
  langid = {english},
  school = {University of Sussex}
}

@article{billinghurst2006,
  title = {Research {{Directions}} in {{Handheld AR}}},
  author = {Billinghurst, Mark and Henrysson, Anders},
  year = {2006},
  month = jan,
  journal = {International Journal of Virtual Reality},
  volume = {5},
  number = {2},
  pages = {51--58},
  issn = {1081-1451},
  urldate = {2021-04-17},
  abstract = {Handheld mobile devices are an exciting new platform for Augmented Reality (AR). Mobile phones and PDAs have the potential to provide AR experiences to hundreds of millions of consumers. However, before widespread use can occur there are some obstacles that must be overcome. In particular, developers must consider the hardware and software capabilities of mobile devices and how these can be used to provide an effective AR experience. They must also develop AR interaction metaphors suitable for handheld AR. In this paper we review current and previous research in the field, provide design guidelines and outline future research directions.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/billinghurst2006.md;Human Computer Interaction/Augmented Reality/Billinghurst and Henrysson, 2006 - Research Directions in Handheld AR.pdf},
  url = {https://doi.org/10.20870/IJVR.2006.5.2.2690}
}

@article{billinghurst2015,
  title = {A {{Survey}} of {{Augmented Reality}}},
  author = {Billinghurst, Mark and Clark, Adrian and Lee, Gun},
  year = {2015},
  journal = {Foundations and Trends{\textregistered} in Human{\textendash}Computer Interaction},
  volume = {8},
  number = {2-3},
  pages = {73--227},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/billinghurst2015.md;Human Computer Interaction/Augmented Reality/Billinghurst et al., 2015 - A Survey of Augmented Reality2.pdf},
  url = {https://doi.org/10.1561/1100000049}
}

@book{bimber2005,
  title = {Spatial {{Augmented Reality}}: {{Merging Real}} and {{Virtual Worlds}}},
  shorttitle = {Spatial {{Augmented Reality}}},
  author = {Bimber, Oliver and Raskar, Ramesh},
  year = {2005},
  month = aug,
  publisher = {{A K Peters, Ltd.}},
  address = {{MA, United States}},
  url = {https://www.taylorfrancis.com/books/9781439864944},
  urldate = {2020-01-10},
  isbn = {978-0-429-10850-1},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/bimber2005.md;Human Computer Interaction/Augmented Reality/Bimber and Raskar, 2005 - Spatial Augmented Reality.pdf}
}

@inproceedings{bisig2020,
  title = {Sounding Feet},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Bisig, Daniel and Palacio, Pablo},
  year = {2020},
  series = {{{AM}} '20},
  pages = {222--228},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {The project emphSounding Feet explores the creative possibilities of interactively controlling sound synthesis through pressure sensitive shoe inlays that can monitor minute body movements. The project is motivated by the authors' own experience of working with interactive technologies in the context of dance. This experience has led to the desire to more closely relate the sensing capabilities of an interactive system to a dancer's own body awareness which prominently involve aspects of inner perception. The outcome of this project demonstrates that such an approach can help to establish interactive musical scenarios for dance that are not only more intuitive to work with for dancers but that also offer new possibilities for composers to tap into aspects of the dancers' expressivity that are normally hidden for an audience.},
  isbn = {978-1-4503-7563-4},
  keywords = {body awareness,dance and technology,movement sonification,wearable interface},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/bisig2020.md;Arts & Humanities/Computational Art/Bisig and Palacio, 2020 - Sounding feet.pdf},
  url = {https://doi.org/10.1145/3411109.3411112}
}

@incollection{blake2009,
  title = {Recording Practices and the Role of the Producer},
  booktitle = {The {{Cambridge Companion}} to {{Recorded Music}}},
  author = {Blake, Andrew},
  editor = {Cook, Nicholas and Clarke, Eric and {Leech-Wilkinson}, Daniel and Rink, John},
  year = {2009},
  pages = {36--53},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  url = {https://www.cambridge.org/core/product/identifier/CBO9781139002684A013/type/book_part},
  urldate = {2019-05-15},
  isbn = {978-1-139-00268-4},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/blake2009.md}
}

@article{blauert1969,
  title = {Sound {{Localization}} in the {{Median Plane}}},
  author = {Blauert, Jens},
  year = {1969},
  journal = {Acustica},
  volume = {22},
  number = {1969/70},
  pages = {9},
  abstract = {Psychoacoustic measurements with observers who were stimulated at both ears with identical narrow band signals yielded the following results: The sound sensations of the observers were localized in the median plane. The direction of the sound sensation is a function of frequency only and does not depend on the angle of incidence.},
  langid = {english},
  file = {Human Computer Interaction/Audio Interfacing/Blauert, 1969 - Sound Localization in the Median Plane.pdf}
}

@book{blauert1996,
  title = {Spatial {{Hearing}}: {{The Psychophysics}} of {{Human Sound Localization}}},
  shorttitle = {Spatial {{Hearing}}},
  author = {Blauert, Jens},
  year = {1996},
  month = oct,
  edition = {2},
  publisher = {{The MIT Press}},
  urldate = {2022-12-19},
  abstract = {The field of spatial hearing has exploded in the decade or so since Jens Blauert's classic work on acoustics was first published in English. This revised edition adds a new chapter that describes developments in such areas as auditory virtual reality (an important field of application that is based mainly on the physics of spatial hearing), binaural technology (modeling speech enhancement by binaural hearing), and spatial sound-field mapping. The chapter also includes recent research on the precedence effect that provides clear experimental evidence that cognition plays a significant role in spatial hearing. The remaining four chapters in this comprehensive reference cover auditory research procedures and psychometric methods, spatial hearing with one sound source, spatial hearing with multiple sound sources and in enclosed spaces, and progress and trends from 1972 (the first German edition) to 1983 (the first English edition){\textemdash}work that includes research on the physics of the external ear, and the application of signal processing theory to modeling the spatial hearing process. There is an extensive bibliography of more than 900 items.},
  isbn = {978-0-262-26868-4},
  langid = {english},
  file = {Human Computer Interaction/Audio Interfacing/Blauert, 1996 - Spatial Hearing.pdf},
  url = {https://doi.org/10.7551/mitpress/6391.001.0001}
}

@incollection{blum2012,
  title = {What's around {{Me}}? {{Spatialized Audio Augmented Reality}} for {{Blind Users}} with a {{Smartphone}}},
  shorttitle = {What's around {{Me}}?},
  booktitle = {Mobile and {{Ubiquitous Systems}}: {{Computing}}, {{Networking}}, and {{Services}}},
  author = {Blum, Jeffrey R. and Bouchard, Mathieu and Cooperstock, Jeremy R.},
  editor = {Puiatti, Alessandro and Gu, Tao},
  year = {2012},
  volume = {104},
  pages = {49--62},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  url = {https://doi.org/10.1007/978-3-642-30973-1_5},
  urldate = {2020-01-10},
  abstract = {Numerous projects have investigated assistive navigation technologies for the blind community, tackling challenges ranging from interface design to sensory substitution. However, none of these have successfully integrated what we consider to be the three factors necessary for a widely deployable system that delivers a rich experience of one's environment: implementation on a commodity device, use of a preexisting worldwide point of interest (POI) database, and a means of rendering the environment that is superior to a naive playback of spoken text. Our ``In Situ Audio Services'' (ISAS) application responds to these needs, allowing users to explore an urban area without necessarily having a particular destination in mind. We describe the technical aspects of its implementation, user requirements, interface design, safety concerns, POI data source issues, and further requirements to make the system practical on a wider basis. Initial qualitative feedback from blind users is also discussed.},
  isbn = {978-3-642-30972-4 978-3-642-30973-1},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/blum2012.md;Human Computer Interaction/Augmented Reality/Blum et al., 2012 - Whatâ€™s around Me.pdf}
}

@misc{boesel2013,
  title = {Origins of the {{Augmented Subject}}},
  author = {Boesel, Whitney Erin and Rey, {\relax PJ}},
  year = {2013},
  month = jan,
  url = {https://thesocietypages.org/cyborgology/2013/01/15/origins-of-the-augmented-subject/}
}

@article{bohil2011,
  title = {Virtual Reality in Neuroscience Research and Therapy},
  author = {Bohil, Corey J. and Alicea, Bradly and Biocca, Frank A.},
  year = {2011},
  month = dec,
  journal = {Nature Reviews Neuroscience},
  volume = {12},
  number = {12},
  pages = {752--762},
  issn = {1471-003X, 1471-0048},
  urldate = {2020-05-25},
  abstract = {Virtual reality (VR) environments are increasingly being used by neuroscientists to simulate natural events and social interactions. VR creates interactive, multimodal sensory stimuli that offer unique advantages over other approaches to neuroscientific research and applications. VR's compatibility with imaging technologies such as functional MRI allows researchers to present multimodal stimuli with a high degree of ecological validity and control while recording changes in brain activity. Therapists, too, stand to gain from progress in VR technology, which provides a high degree of control over the therapeutic experience. Here we review the latest advances in VR technology and its applications in neuroscience research.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/bohil2011.md;Human Computer Interaction/Virtual Reality/Bohil et al., 2011 - Virtual reality in neuroscience research and therapy.pdf},
  url = {https://doi.org/10.1038/nrn3122}
}

@article{bolter2013,
  title = {Media Studies, Mobile Augmented Reality, and Interaction Design},
  author = {Bolter, Jay David and Engberg, Maria and MacIntyre, Blair},
  year = {2013},
  pages = {10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/bolter2013.md;Human Computer Interaction/Augmented Reality/Bolter et al., 2013 - Media studies, mobile augmented reality, and interaction design.pdf}
}

@misc{bonarjee2022,
  title = {The {{Embodiment Hackathon}}},
  author = {Bonarjee, Dominique Savitri and Tonn, Sissel Marie and Bilbow, Sam and Giles, Emilie and Reus, Jonathan Chaim},
  year = {2022},
  month = apr,
  url = {https://dominiquebb.com/embodiment-hackathon/},
  urldate = {2022-12-12},
  abstract = {University of Sussex: 30/04 {\textendash} 01/05/2022 The idea to organize an embodiment hackathon, combining embodiment hacks, along with the prototyping and experimental electronics you'd expect a{\dots}},
  langid = {english},
  file = {../../../../../Zotero/storage/VTQ4A3HL/embodiment-hackathon.html}
}

@book{bourriaud2009,
  title = {Relational Aesthetics},
  author = {Bourriaud, Nicolas},
  year = {2009},
  series = {Documents Sur l'art},
  edition = {Nachdr.},
  publisher = {{Presses du r{\'e}el}},
  address = {{Dijon}},
  isbn = {978-2-84066-060-6},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/bourriaud2009.md;Arts & Humanities/Aesthetics/Bourriaud, 2009 - Relational aesthetics.pdf}
}

@misc{brandon2018,
  title = {Hidden {{Motive}}},
  author = {Brandon, Amy},
  year = {2018},
  address = {{TENOR 2018 - International Conference on Technologies for Music Notation \& Representation}},
  url = {https://www.youtube.com/watch?v=g9CS-wPR0xM},
  urldate = {2022-11-09}
}

@article{brandon2018a,
  title = {Hidden {{Motive}}: On the Development of Interactive Graphic Scores for {{AR}} and {{VR}}},
  author = {Brandon, Amy},
  year = {2018},
  journal = {The Association of Canadian Women Composers (ACWC)},
  number = {Fall / Winter 2018},
  pages = {19--28},
  url = {https://drive.google.com/file/d/1QOnobr2oF8P9TfGj9wzQK_Wg9dbP2MVY/view},
  file = {Human Computer Interaction/Augmented Reality/Brandon, 2018 - Hidden Motive.pdf}
}

@incollection{brandon2023,
  title = {Augmented Reality Guitars: {{Extended}} Instruments and Notation for a 21st-Century Practice},
  booktitle = {21st {{Century Guitar}}: {{Evolutions}} and {{Augmentations}}},
  author = {Brandon, Amy},
  year = {2023},
  month = jan,
  publisher = {{Bloomsbury Academic}},
  url = {https://www.bloomsbury.com/uk/21st-century-guitar-9781501373305/},
  isbn = {978-1-5013-7330-5},
  file = {Human Computer Interaction/Augmented Reality/Brandon, 2023 - Augmented reality guitars.pdf}
}

@article{brooks1996,
  title = {The {{Computer Scientist}} as {{Toolsmith II}}},
  author = {Brooks, Fred},
  year = {1996},
  journal = {Communications of the ACM},
  volume = {39},
  number = {3},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/brooks1996.md;Human Computer Interaction/Miscellaneous/Brooks, 1996 - The Computer Scientist as Toolsmith II.pdf}
}

@inproceedings{brooks2020,
  title = {Trigeminal-Based {{Temperature Illusions}}},
  booktitle = {{{CHI}} '20: {{Proceedings}} of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Brooks, Jas and Nagels, Steven and Lopes, Pedro},
  year = {2020},
  abstract = {We explore a temperature illusion that uses low-powered electronics and enables the miniaturization of simple warm and cool sensations. Our illusion relies on the properties of certain scents, such as the coolness of mint or hotness of peppers. These odors trigger not only the olfactory bulb, but also the nose's trigeminal nerve, which has receptors that respond to both temperature and chemicals. To exploit this, we engineered a wearable device based on micropumps and an atomizer that emits up to three custom-made ``thermal'' scents directly to the user's nose. Breathing in these scents causes the user to feel warmer or cooler. We demonstrate how our device renders warmth and cooling sensations in virtual experiences. Participants rated VR experiences with our trigeminal stimulants as significantly warmer or cooler than the baseline conditions. Lastly, we believe this offers an alternative to thermal feedback devices, which unfortunately rely on power-hungry heat-lamps or Peltier-elements.},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/brooks2020.md;Human Computer Interaction/Virtual Reality/Brooks et al., 2020 - Trigeminal-based Temperature Illusions.pdf},
  url = {https://doi.org/10.1145/3313831.3376806}
}

@inproceedings{brown2020,
  title = {Was That Me? {{Exploring}} the Effects of Error in Gestural Digital Musical Instruments},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Brown, Dom and Nash, Chris and Mitchell, Thomas J.},
  year = {2020},
  series = {{{AM}} '20},
  pages = {168--174},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {Traditional Western musical instruments have evolved to be robust and predictable, responding consistently to the same player actions with the same musical response. Consequently, errors occurring in a performance scenario are typically attributed to the performer and thus a hallmark of musical accomplishment is a flawless musical rendition. Digital musical instruments often increase the potential for a second type of error as a result of technological failure within one or more components of the instrument. Gestural instruments using machine learning can be particularly susceptible to these types of error as recognition accuracy often falls short of 100\%, making errors a familiar feature of gestural music performances. In this paper we refer to these technology-related errors as system errors, which can be difficult for players and audiences to disambiguate from performer errors. We conduct a pilot study in which participants repeat a note selection task in the presence of simulated system errors. The results suggest that, for the gestural music system under study, controlled increases in system error correspond to an increase in the occurrence and severity of performer error. Furthermore, we find the system errors reduce a performer's sense of control and result in the instrument being perceived as less accurate and less responsive.},
  isbn = {978-1-4503-7563-4},
  keywords = {augmented reality,game audio,musicology,sonic interaction design,sonification,sound art,spatial audio,virtual reality},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/brown2020.md;Arts & Humanities/Computational Art/Brown et al., 2020 - Was that me.pdf},
  url = {https://doi.org/10.1145/3411109.3411137}
}

@article{brustein2018,
  title = {Magic {{Leap}} Is {{Bidding}} on an {{Army Combat Contract}}},
  author = {Brustein, Joshua},
  year = {2018},
  month = sep,
  journal = {Bloomberg.com},
  url = {https://archive.today/2UVT1},
  urldate = {2022-11-08},
  abstract = {Microsoft has also expressed interest in providing augmented reality equipment for the battlefield},
  langid = {english},
  keywords = {Augmented Reality,business,Construction,cybersecurity,Football,Government,Military,Software,Startups,technology},
  file = {../../../../../Zotero/storage/IHTDR33S/magic-leap-is-bidding-on-an-army-combat-contract.html}
}

@article{burdea1996,
  title = {Multimodal {{Virtual Reality}}: {{Input-Output Devices}}, {{System Integration}}, and {{Human Factors}}},
  author = {Burdea, Grigore and Coiffet, Paul},
  year = {1996},
  url = {http://ti.rutgers.edu/publications/papers/1996_ijhci.pdf},
  urldate = {2020-05-28},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/burdea1996.md;Human Computer Interaction/Virtual Reality/Burdea and Coiffet, 1996 - Multimodal Virtual Reality.pdf}
}

@incollection{burnham1968,
  title = {System {{Esthetics}}},
  booktitle = {Artforum},
  author = {Burnham, Jack},
  year = {1968},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/burnham1968.md;Arts & Humanities/Aesthetics/Burnham, 1968 - System Esthetics.pdf}
}

@article{cadoz2014,
  title = {Tangibility, {{Presence}}, {{Materiality}}, {{Reality}} in {{Artistic Creation}} with {{Digital Technology}}},
  author = {Cadoz, Claude and Luciani, Annie and Villeneuve, Jerome and Kontogeorgakopoulos, Alexandros and Zannos, Iannis},
  year = {2014},
  pages = {9},
  abstract = {The democratization of Computer Arts and Computer Music has, due to dematerialization (virtualization) consequence of digital technologies, considerably widened the boundaries of creativity. As we are now entering a second phase that has been labeled ``post-digital'', we are called to reconcile this openness with notions such as embodiment, presence, enaction and tangibility. These notions are in our view inherently linked to creativity. Here we outline some approaches to this problem under development within the ``European Art-ScienceTechnology Network'' (EASTN1). Several areas of artistic creation are represented (Music, Animation, Multisensory Arts, Architecture, Fine Arts, Graphic communication, etc.). A main objective of this network is to establish common grounds through collaborative reflection and work on the above notions, using the concept of tangibility as a focal point. In this paper we describe several different approaches to the tangibility, in relation to concepts such as reality, materiality, objectivity, presence, concreteness, etc. and their antonyms. Our objective is to open a debate on tangibility, in the belief that it has a strong unifying potential but is also at the same time presents challenging and difficult to define. Here we present some initial thoughts on this topic in a first effort to bring together the approaches that arise from the different practices and projects developed within the partner institutions involved in the EASTN network.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/cadoz2014.md;Philosophy/Materiality/Cadoz et al., 2014 - Tangibility, Presence, Materiality, Reality in Artistic Creation with Digital.pdf}
}

@phdthesis{callahan1983,
  type = {Master of {{Science}}},
  title = {A 3-{{D}} Display Head-Set for Personalized Computing},
  author = {Callahan, Mark},
  year = {1983},
  address = {{Massachusetts Institute of Technology}},
  url = {http://hdl.handle.net/1721.1/71348},
  school = {Massachusetts Institute of Technology},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/callahan1983.md;Human Computer Interaction/Augmented Reality/Callahan, 1983 - A 3-D display head-set for personalized computing.pdf}
}

@misc{camci2021,
  title = {{{XRMI}} 2021: {{Audio Mostly}} 2021 {{Workshop}} on {{XR Musical Instruments}}},
  author = {{\c C}amc{\i}, An{\i}l and Berthaut, Florent and {\c C}a{\u g}an, Arslan},
  year = {2021},
  url = {https://easychair.org/cfp/XRMI2021},
  urldate = {2022-12-22},
  file = {../../../../../Zotero/storage/TINEBAWQ/XRMI2021.html}
}

@article{candy2018,
  title = {Practice-{{Based Research}} in the {{Creative Arts}}: {{Foundations}} and {{Futures}} from the {{Front Line}}},
  shorttitle = {Practice-{{Based Research}} in the {{Creative Arts}}},
  author = {Candy, Linda and Edmonds, Ernest},
  year = {2018},
  month = feb,
  journal = {Leonardo},
  volume = {51},
  number = {1},
  pages = {63--69},
  issn = {0024-094X, 1530-9282},
  urldate = {2020-06-11},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/candy2018.md;Arts & Humanities/Computational Art/Candy and Edmonds, 2018 - Practice-Based Research in the Creative Arts.pdf},
  url = {https://doi.org/10.1162/LEON_a_01471}
}

@incollection{caramiaux2010,
  title = {Towards a {{Gesture-Sound Cross-Modal Analysis}}},
  booktitle = {Gesture in {{Embodied Communication}} and {{Human-Computer Interaction}}},
  author = {Caramiaux, Baptiste and Bevilacqua, Fr{\'e}d{\'e}ric and Schnell, Norbert},
  year = {2010},
  volume = {5934},
  pages = {158--170},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  url = {https://doi.org/10.1007/978-3-642-12553-9_14},
  urldate = {2020-05-26},
  abstract = {This article reports on the exploration of a method based on canonical correlation analysis (CCA) for the analysis of the relationship between gesture and sound in the context of music performance and listening. This method is a first step in the design of an analysis tool for gesture-sound relationships. In this exploration we used motion capture data recorded from subjects performing free hand movements while listening to short sound examples. We assume that even though the relationship between gesture and sound might be more complex, at least part of it can be revealed and quantified by linear multivariate regression applied to the motion capture data and audio descriptors extracted from the sound examples. After outlining the theoretical background, the article shows how the method allows for pertinent reasoning about the relationship between gesture and sound by analysing the data sets recorded from multiple and individual subjects.},
  isbn = {978-3-642-12552-2 978-3-642-12553-9},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/caramiaux2010.md;Arts & Humanities/Computational Art/Caramiaux et al., 2010 - Towards a Gesture-Sound Cross-Modal Analysis.pdf}
}

@article{cardew1961,
  title = {Notation: {{Interpretation}}, Etc.},
  author = {Cardew, Cornelius},
  year = {1961},
  journal = {Tempo, New Series},
  number = {58},
  eprint = {944250},
  eprinttype = {jstor},
  pages = {21--33},
  url = {http://www.jstor.org/stable/944250},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/cardew1961.md;Arts & Humanities/Musicology/Cardew, 1961 - Notation.pdf}
}

@inproceedings{caudell1992,
  title = {Augmented Reality: An Application of Heads-up Display Technology to Manual Manufacturing Processes},
  shorttitle = {Augmented Reality},
  booktitle = {Proceedings of the {{Twenty-Fifth Hawaii International Conference}} on {{System Sciences}}},
  author = {Caudell, Thomas and Mizell, David},
  year = {1992},
  pages = {659-669 vol.2},
  publisher = {{IEEE}},
  address = {{Kauai, HI, USA}},
  urldate = {2020-02-13},
  abstract = {We describe the design and prototyping steps we have taken toward the implementation of a heads-up, see-through, head-mounted display (HUDSET). Combined with head position sensing and a real world registration system, this technology allows a computer-produced diagram to be superimposed and stabilized on a specific position on a real-world object. Successful development of the HUDset technology will enable cost reductions and efficiency improvements in many of the human-involved operations in aircraft manufacturing, by eliminating templates, formboard diagrams, and other masking devices.},
  isbn = {978-0-8186-2420-9},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/caudell1992.md;Human Computer Interaction/Augmented Reality/Caudell and Mizell, 1992 - Augmented reality.pdf},
  url = {https://doi.org/10.1109/HICSS.1992.183317}
}

@misc{ccdh2022,
  title = {The {{Musk Bump}}: {{Quantifying}} the Rise in Hate Speech under {{Elon Musk}}},
  shorttitle = {The {{Musk Bump}}},
  author = {CCDH},
  year = {2022},
  month = dec,
  journal = {Center for Countering Digital Hate},
  url = {https://archive.today/FJJfd},
  urldate = {2022-12-11},
  abstract = {Since his formal takeover of Twitter on October 27, Elon Musk has repeatedly promised to clamp down on hate speech while taking unilateral policy decisions, such as reinstating abusive accounts, that encourage the spread of [{\dots}]},
  langid = {british},
  file = {../../../../../Zotero/storage/JDXVLA53/the-musk-bump-quantifying-the-rise-in-hate-speech-under-elon-musk.html}
}

@inproceedings{cecchinato2017,
  title = {Always {{On}}(Line)?: {{User Experience}} of {{Smartwatches}} and Their {{Role}} within {{Multi-Device Ecologies}}},
  shorttitle = {Always {{On}}(Line)?},
  booktitle = {Proceedings of the 2017 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Cecchinato, Marta E. and Cox, Anna L. and Bird, Jon},
  year = {2017},
  month = may,
  pages = {3557--3568},
  publisher = {{ACM}},
  address = {{Denver Colorado USA}},
  urldate = {2020-05-25},
  abstract = {Users have access to a growing ecosystem of devices (desktop, mobile and wearable) that can deliver notifications and help people to stay in contact. Smartwatches are gaining popularity, yet little is known about the user experience and their impact on our increasingly always online culture. We report on a qualitative study with existing users on their everyday use of smartwatches to understand both the added value and the challenges of being constantly connected at the wrist. Our findings show that users see a large benefit in receiving notifications on their wrist, especially in terms of helping manage expectations of availability. Moreover, we find that response rates after viewing a notification on a smartwatch change based on the other devices available: laptops prompt quicker replies than smartphones. Finally, there are still many costs associated with using smartwatches, thus we make a series of design recommendations to improve the user experience of smartwatches.},
  isbn = {978-1-4503-4655-9},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/cecchinato2017.md;Human Computer Interaction/User Experience Design/Cecchinato et al., 2017 - Always On(line).pdf},
  url = {https://doi.org/10.1145/3025453.3025538}
}

@book{chalmers2022,
  title = {Reality+: Virtual Worlds and the Problem of Philosophy},
  shorttitle = {Reality+},
  author = {Chalmers, David John},
  year = {2022},
  publisher = {{Allen Lane, an imprint of Penguin Books}},
  address = {{London}},
  url = {https://www.penguin.co.uk/books/306905/reality-by-chalmers-david-j/9780241320716},
  abstract = {"A leading philosopher takes a mind-bending journey through virtual worlds, illuminating the nature of reality and our place within it. Virtual reality is genuine reality. That's the central thesis of Reality+. In a highly original work of "technophilosophy," David J. Chalmers argues that virtual worlds generated by computers are not second-class worlds. We can live a meaningful life in virtual reality. We may even be living in a computer simulation already-and if we are, that's not so bad. What is reality, anyway? How do we know there's an external world? What's the relation between mind and body? How can we lead a good life? Is there a god? In Reality+, Chalmers conducts a grand tour of philosophy, using virtual worlds to illuminate all of these questions and to provide new answers to many of them. Studded with illustrations that bring philosophical issues to life, Reality+ is a major statement that will shape discussion of philosophy and technology for years to come"--},
  isbn = {978-0-241-32071-6},
  langid = {english},
  file = {Human Computer Interaction/Mixed Reality/Chalmers, 2022 - Reality+.pdf}
}

@book{charmaz2006,
  title = {Constructing Grounded Theory},
  author = {Charmaz, Kathy},
  year = {2006},
  publisher = {{Sage Publications}},
  address = {{London ; Thousand Oaks, Calif}},
  isbn = {978-0-7619-7352-2 978-0-7619-7353-9},
  langid = {english},
  lccn = {H61.24 .C45 2006},
  keywords = {Grounded theory,Research Methodology,Social sciences},
  file = {Research Methods/Grounded Theory/Charmaz, 2006 - Constructing grounded theory.pdf}
}

@inproceedings{chatzidimitris2016,
  title = {{{SoundPacman}}: {{Audio}} Augmented Reality in Location-Based Games},
  shorttitle = {{{SoundPacman}}},
  booktitle = {2016 18th {{Mediterranean Electrotechnical Conference}} ({{MELECON}})},
  author = {Chatzidimitris, Thomas and Gavalas, Damianos and Michael, Despina},
  year = {2016},
  month = apr,
  pages = {1--6},
  publisher = {{IEEE}},
  address = {{Lemesos, Cyprus}},
  urldate = {2020-02-13},
  abstract = {Sound design has received little attention in location-based games research. Typically, existing prototypes heavily rely on visual information with sound only having a marginal role in the game design and development process. This paper investigates the role of sound as primary interface for conveying game information and creating engaging gaming experiences. As a case study, we present SoundPacman, a prototype location-based game, wherein players experience the game space with the use of 3D sounds, which augment the physical environment. Preliminary tests utilizing EEG analysis provide evidence that sound augmentation may significantly contribute towards enhancing the immersion levels of players.},
  isbn = {978-1-5090-0058-6},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/chatzidimitris2016.md;Human Computer Interaction/Augmented Reality/Chatzidimitris et al., 2016 - SoundPacman.pdf},
  url = {https://doi.org/10.1109/MELCON.2016.7495414}
}

@phdthesis{chevalier2016,
  title = {Remembering to {{Remember}}: {{A Practice-based Study}} in {{Digital Re-appropriation}} and {{Bodily Perception}}},
  author = {Chevalier, C{\'e}cile},
  year = {2016},
  url = {https://sro.sussex.ac.uk/id/eprint/65574/},
  abstract = {Through the evolution of digital media technology, social networks and more recently Web 3.0 (e.g. Cloud-based) technologies, culture and memory is being transformed, both in relation to how memories are represented, and how they may be engaged with or re-accessed.},
  langid = {english},
  school = {University of Sussex},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/chevalier2016.md;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/Remembering to Remember A Practice-based Study in Digital Re-appropriation and Bodily Perception.md;Arts & Humanities/Computational Art/Chevalier, 2016 - Remembering to Remember.pdf}
}

@misc{chevalier2017,
  title = {The {{Forum}} for {{Immersive Augmented Reality Instruments}}},
  author = {Chevalier, C{\'e}cile and Kiefer, Chris},
  year = {2017},
  month = jul,
  url = {http://www.emutelab.org/blog/arimi},
  urldate = {2022-12-12},
  file = {../../../../../Zotero/storage/DMFINDUP/arimi3.html}
}

@inproceedings{chevalier2018,
  title = {Listening {{Mirrors}}: {{Prototyping}} for a {{Hybrid Audio Augmented Reality Installation}}},
  booktitle = {{{ICLI}} 2018, 4th {{International Conference}} on {{Live Interfaces}}. {{Inspiration}}, {{Performance}}, {{Emancipation}}.},
  author = {Chevalier, C{\'e}cile and Kiefer, Chris},
  editor = {{Jos{\'e} Alberto Gomes} and {Miguel Carvalhais} and {Rui Penha}},
  year = {2018},
  pages = {241},
  address = {{Porto, Portugal}},
  url = {https://sro.sussex.ac.uk/id/eprint/74980/},
  urldate = {2021-04-30},
  abstract = {We introduce ongoing developments of Listening Mirrors, a sound art instal-lation and live interface for musician and non-musician alike. The piece, in its construction and interaction design, investigates ways in which collective sonic expression can be made possi-ble using Audio Augmented Reality technology (AAR) and acoustic mirrors, whilst asking how such environments promote collective sonic expression.},
  isbn = {978-989-746-170-5},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/chevalier2018.md;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/Listening Mirrors Prototyping for a Hybrid Audio Augmented Reality Installation.md;Human Computer Interaction/Augmented Reality/Chevalier and Kiefer, 2018 - Listening Mirrors.pdf}
}

@misc{chevalier2019,
  title = {Listening {{Mirrors}} 2.0 at the {{Sussex Humanities Lab}}},
  author = {Chevalier, C{\'e}cile and Kiefer, Chris},
  year = {2019},
  url = {http://listeningmirrors.net/},
  urldate = {2022-12-13},
  file = {../../../../../Zotero/storage/ZMETLRIA/listeningmirrors.net.html}
}

@article{chevalier2020,
  title = {What {{Does Augmented Reality Mean}} as a {{Medium}} of {{Expression}} for {{Computational Artists}}?},
  author = {Chevalier, C{\'e}cile and Kiefer, Chris},
  year = {2020},
  month = may,
  journal = {Leonardo},
  volume = {53},
  number = {3},
  pages = {263--267},
  issn = {0024-094X, 1530-9282},
  urldate = {2021-04-28},
  abstract = {As augmented reality (AR) quickly evolves with new technological practice, there is a growing need to question and reevaluate its potential as a medium for creative expression. The authors discuss AR within computational art, framed within AR as a medium, AR aesthetics and applications. The Forum for Augmented Reality Immersive Instruments (ARImI), a two-day event on AR, highlights both possibilities and fundamental concerns for continuing artworks in this field, including visual bias, sensory modalities, interactivity and performativity. The authors offer a new AR definition as real-time computationally mediated perception.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/chevalier2020.md;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/What Does Augmented Reality Mean as a Medium of Expression for Computational Artists.md;Human Computer Interaction/Augmented Reality/Chevalier and Kiefer, 2020 - What Does Augmented Reality Mean as a Medium of Expression for Computational.pdf},
  url = {https://doi.org/10.1162/leon_a_01740}
}

@article{chng2017,
  title = {Shift-{{Life Interactive Art}}: {{Mixed-Reality Artificial Ecosystem Simulation}}},
  shorttitle = {Shift-{{Life Interactive Art}}},
  author = {Ch'ng, Eugene and Harrison, Dew and Moore, Samantha},
  year = {2017},
  month = may,
  journal = {Presence: Teleoperators and Virtual Environments},
  volume = {26},
  number = {2},
  pages = {157--181},
  issn = {1054-7460, 1531-3263},
  urldate = {2020-05-27},
  abstract = {This article presents a detailed design, development and implementation of a Mixed Reality Art-Science collaboration project which was exhibited during Darwin's bicentenary exhibition at Shrewsbury, England. As an artist-led project the concerns of the artist were paramount, and this article presents Shift-Life as part of an on-going exploration into the parallels between the non-linear human thinking process and computation using semantic association to link items into ideas, and ideas into holistic concepts. Our art explores perceptions and states of mind as we move our attention between the simulated world of the computer and the real-world we inhabit, which means that any viewer engagement is participatory rather than passive. From a Mixed Reality point of view, the lead author intends to explore the convergence of the physical and virtual, therefore the formalization of the Mixed Reality system, focusing on the integration of artificial life, ecology, physical sensors and participant interaction through an interface of physical props. It is common for digital media artists to allow viewers to activate a work either through a computer screen via direct keyboard or mouse manipulation, or through immersive means to activate their work, for ``Shift-Life'' the artist was concerned with a direct ``relational'' approach where viewers would intuitively engage with the installation's everyday objects, and with each other, to fully experience the piece. The Mixed Reality system is mediated via physical environmental sensors, which affect the virtual environment and autonomous agents, which in turn reacts and is expressed as virtual pixels projected onto a physical surface. The tangible hands-on interface proved to be instinctive, attractive and informative on many levels, delivering a good example of collaboration between the Arts and Science.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/chng2017.md;Human Computer Interaction/Augmented Reality/Châ€™ng et al., 2017 - Shift-Life Interactive Art.pdf},
  url = {https://doi.org/10.1162/PRES_a_00291}
}

@article{clark1998,
  title = {The {{Extended Mind}}},
  author = {Clark, A. and Chalmers, D.},
  year = {1998},
  month = jan,
  journal = {Analysis},
  volume = {58},
  number = {1},
  pages = {7--19},
  issn = {0003-2638, 1467-8284},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/clark1998.md;Philosophy/Extended Cognition/Clark and Chalmers, 1998 - The Extended Mind.pdf},
  url = {https://doi.org/10.1093/analys/58.1.7}
}

@article{clark1999,
  title = {An Embodied Cognitive Science?},
  author = {Clark, Andy},
  year = {1999},
  month = sep,
  journal = {Trends in Cognitive Sciences},
  volume = {3},
  number = {9},
  pages = {345--351},
  issn = {13646613},
  urldate = {2022-09-12},
  langid = {english},
  file = {Philosophy/Extended Cognition/Clark, 1999 - An embodied cognitive science.pdf},
  url = {https://doi.org/10.1016/S1364-6613(99)01361-3}
}

@book{clark2001,
  title = {Being There: Putting Brain, Body, and World Together Again},
  shorttitle = {Being There},
  author = {Clark, Andy},
  year = {2001},
  series = {A {{Bradford}} Book},
  edition = {1. paperback ed},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass.}},
  isbn = {978-0-262-53156-6 978-0-262-03240-7},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/clark2001.md}
}

@inproceedings{cohen1993,
  title = {Augmented Audio Reality: Telepresence/{{VR}} Hybrid Acoustic Environments},
  shorttitle = {Augmented Audio Reality},
  booktitle = {Proceedings of 1993 2nd {{IEEE International Workshop}} on {{Robot}} and {{Human Communication}}},
  author = {Cohen, M. and Aoki, S. and Koizumi, N.},
  year = {1993},
  month = nov,
  pages = {361--364},
  abstract = {Augmented audio reality consists of hybrid presentations in which computer-generated sounds are overlayed on top of more directly acquired audio signals. We are exploring the alignability of binaural signals with artificially spatialized sources, synthesized by convolving monaural signals with left/right pairs of directional transfer functions. We use MAW (multidimensional audio windows), a NeXT-based system, as a binaural directional mixing console. Since the rearrangement of a dynamic map is used to dynamically select transfer functions, a user may specify the virtual location of a sound source, throwing the source into perceptual space, using exocentric graphical control to drive egocentric auditory display. As a concept demonstration, we muted a telephone, and then used MAW to spatialize a ringing signal at its location, putting the sonic image of the phone into the office environment. By juxtaposing and mixing 'real' and 'synthetic' audio transmissions, we are exploring the relationship between acoustic telepresence and VR presentations: telepresence manifests as the actual configuration of sources in a sound field, as perceivable by a dummyhead; VR is the perception yielded by filtering of virtual sources with respect to virtual sinks. We have conducted an experiment testing the usefulness of such a hybrid.{$<>$}},
  keywords = {acoustic telepresence,Acoustic testing,audio-visual systems,augmented audio reality,binaural directional mixing console,binaural signal alignability,computer-generated sounds,convolving monaural signals,directional transfer functions,egocentric auditory display,exocentric graphical control,Humans,Laboratories,Layout,left/right pairs,MAW,multidimensional audio windows,NeXT-based system,Robots,Signal synthesis,Switches,telecontrol,Telephony,transfer function dynamic selection,Transfer functions,virtual location,virtual reality,Virtual reality,VR hybrid acoustic environments},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/cohen1993.md;Human Computer Interaction/Augmented Reality/Cohen et al., 1993 - Augmented audio reality.pdf},
  url = {https://doi.org/10.1109/ROMAN.1993.367692}
}

@inproceedings{collins2011,
  title = {Making Gamers Cry: Mirror Neurons and Embodied Interaction with Game Sound},
  shorttitle = {Making Gamers Cry},
  booktitle = {Proceedings of the 6th {{Audio Mostly Conference}} on {{A Conference}} on {{Interaction}} with {{Sound}} - {{AM}} '11},
  author = {Collins, Karen},
  year = {2011},
  pages = {39--46},
  publisher = {{ACM Press}},
  address = {{Coimbra, Portugal}},
  urldate = {2021-06-11},
  abstract = {In this paper, I draw on an embodied cognition approach to describe how sound mediates our identification with and empathy for video game characters. This identification is discussed in terms of mirror neurons and body schema, drawing on theoretical and empirical research to explore ways in which identity is created from our embodied interaction with sound. I conclude by suggesting ways in which sound designers and composers can use this information to create more empathy and identification between players and their game characters.},
  isbn = {978-1-4503-1081-9},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/collins2011.md;Arts & Humanities/Media Studies/Collins, 2011 - Making gamers cry.pdf},
  url = {https://doi.org/10.1145/2095667.2095673}
}

@book{collins2013,
  title = {Playing with Sound: A Theory of Interacting with Sound and Music in Video Games},
  shorttitle = {Playing with Sound},
  author = {Collins, Karen},
  year = {2013},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  isbn = {978-0-262-01867-8},
  langid = {english},
  lccn = {QA76.76.I59 C653 2013},
  keywords = {Interactive multimedia,Video games},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/collins2013.md;Arts & Humanities/Media Studies/Collins, 2013 - Playing with sound.pdf}
}

@misc{combinereality2020,
  title = {Portable {{Project Northstar Rig}}},
  shorttitle = {{{CombineReality}} on {{Twitter}}},
  author = {Combine Reality},
  year = {2020},
  month = apr,
  journal = {Twitter},
  url = {https://twitter.com/CombineReality/status/1252638433870143488},
  urldate = {2020-05-26},
  langid = {english},
  file = {../../../../../Zotero/storage/FMSPZNZD/1252638433870143488.html}
}

@incollection{concannon1990,
  title = {Cut and {{Paste}}: {{Collage}} and the {{Art}} of {{Sound}}},
  booktitle = {Sound by {{Artists}}},
  author = {Concannon, Kevin},
  year = {1990},
  publisher = {{Art Metropole}},
  address = {{Walter Phillips Gallery}},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/concannon1990.md;Arts & Humanities/Musicology/Concannon, 1990 - Cut and Paste.pdf}
}

@misc{constanzo2015,
  title = {Tool: Karma{\textasciitilde} (Sampler/Looper External) {\textbar} {{Cycling}} '74},
  shorttitle = {Tool},
  author = {Constanzo, Rodrigo},
  year = {2015},
  month = may,
  url = {https://cycling74.com/tools/karma-samplerlooper-external},
  urldate = {2020-05-26},
  abstract = {karma{\textasciitilde} is a looper/sampler external for Max.},
  langid = {english},
  file = {../../../../../Zotero/storage/QI82CXG8/karma-samplerlooper-external.html}
}

@misc{cornford2016,
  title = {Review of {{Wolgang Ernst}}'s {{Sonic Time Machines}}},
  author = {Cornford, Stephen},
  year = {2016},
  month = oct,
  journal = {Theory, Culture \& Society},
  url = {https://www.theoryculturesociety.org/review-wolgang-ernsts-sonic-time-machines-stephen-cornford/},
  urldate = {2018-04-10},
  abstract = {Review of Wolgang Ernst, Sonic Time Machines (Amsterdam University Press, 2016), 184 pages, {\texteuro}79.00. ~ Reviewed by Stephen Cornford ~ Book details: http://en.aup.nl/books/9789089649492-sonic-time-machines.html ~ ~ ~ ~ Sonic Time Machines is Wolfgang Ernst's first book to be published directly in},
  langid = {american},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/cornford2016.md}
}

@article{correia2020,
  title = {Affordances and {{Constraints}} in {{Interactive Audio}} / {{Visual Systems}}},
  author = {Correia, Nuno and Masu, Raul},
  year = {2020},
  month = apr,
  journal = {EAI Endorsed Transactions on Creative Technologies},
  volume = {7},
  number = {23},
  pages = {164000},
  issn = {2409-9708},
  urldate = {2020-05-25},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/correia2020.md;Human Computer Interaction/Multisensory Interfacing/Correia and Masu, 2020 - Affordances and Constraints in Interactive Audio - Visual Systems.pdf},
  url = {https://doi.org/10.4108/eai.23-4-2020.164000}
}

@incollection{cramer2015,
  title = {What {{Is}} '{{Post-digital}}'?},
  booktitle = {Postdigital {{Aesthetics}}},
  author = {Cramer, Florian},
  year = {2015},
  pages = {12--26},
  publisher = {{Palgrave Macmillan UK}},
  address = {{London}},
  url = {https://doi.org/10.1057/9781137437204_1},
  isbn = {978-1-349-49378-4 978-1-137-43720-4},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/cramer2015.md;Arts & Humanities/Media Studies/Cramer, 2015 - What Is 'Post-digital'.pdf}
}

@article{critchley2004,
  title = {Neural Systems Supporting Interoceptive Awareness},
  author = {Critchley, Hugo D and Wiens, Stefan and Rotshtein, Pia and {\"O}hman, Arne and Dolan, Raymond J},
  year = {2004},
  month = feb,
  journal = {Nature Neuroscience},
  volume = {7},
  number = {2},
  pages = {189--195},
  issn = {1097-6256, 1546-1726},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/critchley2004.md;Cognitive Science/Interoception/Critchley et al., 2004 - Neural systems supporting interoceptive awareness.pdf},
  url = {https://doi.org/10.1038/nn1176}
}

@incollection{cutler2000,
  title = {Plunderphonics},
  booktitle = {Music, Electronic Media, and Culture},
  author = {Cutler, Chris},
  editor = {Simon, Emmerson},
  year = {2000},
  publisher = {{Ashgate}},
  address = {{Aldershot ; Burlington, USA}},
  isbn = {978-0-7546-0109-8},
  lccn = {ML1380 .M86 2000},
  keywords = {20th century,Electronic music,History and criticism,Music,Music and technology},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/cutler2000.md;Arts & Humanities/Musicology/Cutler, 2000 - Plunderphonics.pdf}
}

@misc{cycling742020,
  title = {Max {{MSP}}},
  shorttitle = {What Is {{Max}}?},
  author = {Cycling'74},
  year = {2020},
  url = {https://cycling74.com/products/max},
  urldate = {2020-05-25},
  abstract = {Max is an infinitely flexible place to create interactive media software. With in-depth tools for audio, graphics, interaction, and communication, Max is an environment to explore and develop your own ideas.},
  langid = {english},
  file = {../../../../../Zotero/storage/I9NPEJPU/max.html}
}

@article{das2017,
  title = {Music {{Everywhere}} {\textendash} {{Augmented Reality Piano Improvisation Learning System}}},
  author = {Das, Shantanu and Glickman, Seth and Hsiao, Fu Yen and Lee, Byunghwan},
  year = {2017},
  pages = {2},
  abstract = {This paper describes the design and implementation of an augmented reality (AR) piano learning tool that uses a Microsoft HoloLens and a MIDI-over-Bluetooth-enabled electric piano. The tool presents a unique visual interface{\textemdash}a ``mirror key overlay'' approach{\textemdash}fitted for the AR environment, and opens up the possibility of on-instrument learning experiences. The curriculum focuses on teaching improvisation in blues, rock, jazz and classical genres. Users at the piano engage with interactive lessons, watch virtual hand demonstrations, see and hear example improvisations, and play their own solos and accompaniment along with AR-projected virtual musicians. The tool aims to be entertaining yet also effective in teaching core musical concepts.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/das2017.md;Human Computer Interaction/Augmented Reality/Das et al., 2017 - Music Everywhere â€“ Augmented Reality Piano Improvisation Learning System.pdf}
}

@incollection{davies2004,
  title = {Virtual {{Space}}},
  booktitle = {Space: {{In Science}}, {{Art}}, and {{Society}}},
  author = {Davies, Char},
  editor = {Penz, Fran{\c c}ois and Radick, Gregory and Howell, Robert},
  year = {2004},
  pages = {69--104},
  publisher = {{Cambridge University Press}},
  isbn = {978-0-521-82376-0},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/davies2004.md}
}

@incollection{deacon2023,
  title = {Spatial {{Design Considerations}} for {{Interactive Audio}} in {{Virtual Reality}}},
  booktitle = {Sonic {{Interactions}} in {{Virtual Environments}}},
  author = {Deacon, Thomas and Barthet, Mathieu},
  editor = {Geronazzo, Michele and Serafin, Stefania},
  year = {2023},
  pages = {181--217},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  urldate = {2024-01-29},
  abstract = {Abstract             Space is a fundamental feature of virtual reality (VR) systems, and more generally, human experience. Space is a place where we can produce and transform ideas and act to create meaning. It is also an information container. When working with sound and space interactions, making VR systems becomes a fundamentally interdisciplinary endeavour. To support the design of future systems, designers need an understanding of spatial design decisions that impact audio practitioners' processes and communication. This chapter proposes a typology of VR interactive audio systems, focusing on their function and the role of space in their design. Spatial categories are proposed to be able to analyse the role of space within existing interactive audio VR products. Based on the spatial design considerations explored in this chapter, a series of implications for design are offered that future research can exploit.},
  isbn = {978-3-031-04020-7 978-3-031-04021-4},
  langid = {english},
  file = {Human Computer Interaction/Virtual Reality/Deacon and Barthet, 2023 - Spatial Design Considerations for Interactive Audio in Virtual Reality.pdf},
  url = {https://doi.org/10.1007/978-3-031-04021-4_6}
}

@book{decerteau1984,
  title = {The Practice of Everyday Life},
  author = {{de Certeau}, Michel},
  year = {1984},
  publisher = {{University of California Press}},
  address = {{Berkeley, Calif.}},
  isbn = {978-0-520-23699-8},
  langid = {english}
}

@article{dedomenico2019,
  title = {Complexity {{Explained}}},
  author = {De Domenico, Manlio and Sayama, Hiroki},
  year = {2019},
  urldate = {2022-08-03},
  abstract = {Booklet of the Complexity Explained project},
  copyright = {CC-By Attribution 4.0 International},
  url = {https://doi.org/10.17605/OSF.IO/TQGNW}
}

@article{deguzman2020,
  title = {Security and {{Privacy Approaches}} in {{Mixed Reality}}: {{A Literature Survey}}},
  shorttitle = {Security and {{Privacy Approaches}} in {{Mixed Reality}}},
  author = {{de Guzman}, Jaybie A. and Thilakarathna, Kanchana and Seneviratne, Aruna},
  year = {2020},
  month = jan,
  journal = {ACM Computing Surveys},
  volume = {52},
  number = {6},
  pages = {1--37},
  issn = {0360-0300, 1557-7341},
  urldate = {2020-05-25},
  abstract = {Mixed reality (MR) technology development is now gaining momentum due to advances in computer vision, sensor fusion, and realistic display technologies. With most of the research and development focused on delivering the promise of MR, there is only barely a few working on the privacy and security implications of this technology. This survey paper aims to put in to light these risks, and to look into the latest security and privacy work on MR. Specifically, we list and review the different protection approaches that have been proposed to ensure user and data security and privacy in MR. We extend the scope to include work on related technologies such as augmented reality (AR), virtual reality (VR), and human-computer interaction (HCI) as crucial components, if not the origins, of MR, as well as numerous related work from the larger area of mobile devices, wearables, and Internet-of-Things (IoT). We highlight the lack of investigation, implementation, and evaluation of data protection approaches in MR. Further challenges and directions on MR security and privacy are also discussed.},
  langid = {english},
  keywords = {Computer Science - Computers and Society,Computer Science - Cryptography and Security,Computer Science - Human-Computer Interaction},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/deguzman2020.md;Human Computer Interaction/Mixed Reality/de Guzman et al., 2020 - Security and Privacy Approaches in Mixed Reality.pdf},
  url = {https://doi.org/10.1145/3359626}
}

@article{dejesus2022,
  title = {Play-to-{{Earn}}: {{A Qualitative Analysis}} of the {{Experiences}} and {{Challenges Faced By Axie Infinity Online Gamers Amidst}} the {{COVID-19 Pandemic}}},
  shorttitle = {Play-to-{{Earn}}},
  author = {De Jesus, Shealtielle Blaise and Austria, Daphne and Marcelo, Daniela Raine and Ocampo, Ceejay and Tibudan, April Joyce and Jhoselle, Tus},
  year = {2022},
  journal = {International Journal of Psychology and Counseling},
  volume = {12},
  number = {1},
  urldate = {2022-09-12},
  abstract = {One of the most in-demand and divisive of these new games that allow players to collect tradeable crypto currencies is the Axie Infinity. Non-employed, along with the students, are finding it difficult to find stable employment since this pandemic brought many setbacks to employed and more particularly to unemployed students. This study explores the lived experiences, challenges, and coping mechanisms of Axie Infinity Players amidst the pandemic. The study employed the Interpretative Phenomenological Analysis with 20 participants. The following conclusions were drawn based on the study's findings: (1 )For the most part, playing Axie Infinity is not as easy as it looks. (2) Most of the Axie Infinity players are students and it takes a lot of their time playing Axie Infinity that most of their time is spent playing instead of resting and studying just to reach their quota for that day. (3)Axie Infinity is both a blessing and stress. The Axie Infinity play-to-earn game is described as a blessing because it became the number one source of income of the participants despite being amid this pandemic. It also became their source of stress because it adds pressure, tension, and strain to their lives as both a player and a student. (4) Axie Infinity players need a strong support system in their psychological, spiritual, emotional, and physical aspects to withstand the situation of lacking sleep and rest, the pressure of the need to reach the quota, slow internet connection, judgments of the people that surround them, and not being able to focus in both playing and studying. (5) Finally, Axie Infinity players value themselves by coping with negative experiences and challenges they have been through.},
  copyright = {Creative Commons Attribution 4.0 International},
  langid = {english},
  keywords = {{160801 Applied Sociology, Program Evaluation and Social Impact Assessment},160804 Rural Sociology,160808 Sociology and Social Studies of Science and Technology,160809 Sociology of Education,160810 Urban Sociology and Community Studies,160899 Sociology not elsewhere classified,170102 Developmental Psychology and Ageing,170103 Educational Psychology,170105 Gender Psychology,{170106 Health, Clinical and Counselling Psychology},170113 Social and Community Psychology,170114 Sport and Exercise Psychology,170199 Psychology not elsewhere classified,179999 Psychology and Cognitive Sciences not elsewhere classified,Applied Psychology,Clinical Psychology,Developmental and Educational Psychology,FOS: Psychology,FOS: Sociology,{Personality, Social and Criminal Psychology},Sociology},
  file = {Human Computer Interaction/Metaverse/De Jesus et al., 2022 - Play-to-Earn.pdf},
  url = {https://doi.org/10.6084/M9.FIGSHARE.18856454.V1}
}

@article{delanda2015,
  title = {The {{New Materiality}}: {{The New Materiality}}},
  shorttitle = {The {{New Materiality}}},
  author = {DeLanda, Manuel},
  year = {2015},
  month = sep,
  journal = {Architectural Design},
  volume = {85},
  number = {5},
  pages = {16--21},
  issn = {00038504},
  urldate = {2020-02-11},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/delanda2015.md;Philosophy/Materiality/DeLanda, 2015 - The New Materiality.pdf},
  url = {https://doi.org/10.1002/ad.1948}
}

@misc{delaney2017,
  title = {Atau {{Tanaka}}'s {{EMG Music Performance}} at {{Meta Gesture Music Concert}}, {{London}} 2017},
  shorttitle = {English},
  author = {Delaney, Martin},
  year = {2017},
  month = mar,
  url = {https://commons.wikimedia.org/wiki/Category:Electronic_musical_instruments#/media/File:Atau_Tanaka_-_Myogram.jpg},
  urldate = {2022-12-12},
  copyright = {CC-BY-SA 4.0 International},
  file = {../../../../../Zotero/storage/ZI8954EU/CategoryElectronic_musical_instruments.html}
}

@book{deleuze1988,
  title = {A Thousand Plateaus: Capitalism and Schizophrenia},
  shorttitle = {A Thousand Plateaus},
  author = {Deleuze, Gilles and Guattari, F{\'e}lix},
  year = {1988},
  publisher = {{Athlone Press}},
  address = {{London}},
  isbn = {978-0-485-12058-5 978-0-485-11335-8},
  lccn = {B77 .D413x 1988},
  keywords = {Philosophy},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/deleuze1988.md}
}

@article{delic2022,
  title = {Profiling the {{Potential Risks}} and {{Benefits}} of {{Emerging}} ``{{Play}} to {{Earn}}'' {{Games}}: A {{Qualitative Analysis}} of {{Players}}' {{Experiences}} with {{Axie Infinity}}},
  shorttitle = {Profiling the {{Potential Risks}} and {{Benefits}} of {{Emerging}} ``{{Play}} to {{Earn}}'' {{Games}}},
  author = {Delic, Amelia J. and Delfabbro, Paul H.},
  year = {2022},
  month = aug,
  journal = {International Journal of Mental Health and Addiction},
  issn = {1557-1874, 1557-1882},
  urldate = {2022-09-12},
  abstract = {The invention of blockchain technology, coupled with the growing interest in cryptocurrencies, has given rise to a new form of monetised gaming known as ``Play to Earn'' (PTE). ``Axie Infinity'' (AI) is currently the most popular PTE game, occupying a large portion of the online gaming market. In this paper, we profile the risks and benefits of PTE gaming, with a specific focus on AI. Qualitative data in the form of online chat threads was evaluated via a Thematic Analysis (TA) approach. The analysis revealed a number of themes including the dominance of extrinsically motivated gameplay in conjunction with negative appraisals of game quality, the benefits and costs of play, and the potential for PTE scholarship models to be associated with exploitation. The results did, however, indicate awareness of potential consumer risks. The findings have implications for informing consumer education, regulation, as well as areas of focus in future quantitative research.},
  langid = {english},
  file = {Human Computer Interaction/Metaverse/Delic and Delfabbro, 2022 - Profiling the Potential Risks and Benefits of Emerging â€œPlay to Earnâ€ Games.pdf},
  url = {https://doi.org/10.1007/s11469-022-00894-y}
}

@article{demetriou2018,
  title = {`{{Imagineering}}' Mixed Reality ({{MR}}) Immersive Experiences in the Postdigital Revolution: Innovation, c},
  author = {Demetriou, Panayiota A},
  year = {2018},
  journal = {nternational Journal of Performance Arts and DigitalMedia,},
  volume = {14},
  number = {2},
  pages = {19},
  abstract = {At the frontiers of our technoculture and experience economy, artist-researchers as catalytic agents become Imagineers and entrepreneurs of themselves. Arts are quantified in expectations of extending forms of communication with people and our environments, by creating humanistic ways of interfacing with machines. Within the experience economy the term `immersion' is overused trending towards VR, which has troubled many researchers and practitioners across disciplines. Drawing on perspectives from performance studies, digital humanities, and human-computer interaction (HCI), this paper reviews the role of XR-enabling technologies, beyond VR, in designing immersive experiences, and their integration into performance practices. It discusses the shift of the artist's role in imagineering new resources and new ways of working to immerse audiences, and it evaluates this in a postdigital context. It discusses how immersion operates, and critiques components necessary to create affective environments in terms of audience engagement, agency, participation, involvement, presence, embodiment and interaction. The article discusses how performance as a lab can act as a method of inquiry by bringing the anthropological, performative and theatrical perspectives; and the ethics of to testing immersive-enabling technologies and/or experiences within the context of live performances.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/demetriou2018.md;Human Computer Interaction/Mixed Reality/Demetriou, 2018 - â€˜Imagineeringâ€™ mixed reality (MR) immersive experiences in the postdigital.pdf}
}

@inproceedings{denning2014,
  title = {In Situ with Bystanders of Augmented Reality Glasses: Perspectives on Recording and Privacy-Mediating Technologies},
  shorttitle = {In Situ with Bystanders of Augmented Reality Glasses},
  booktitle = {Proceedings of the 32nd Annual {{ACM}} Conference on {{Human}} Factors in Computing Systems - {{CHI}} '14},
  author = {Denning, Tamara and Dehlawi, Zakariya and Kohno, Tadayoshi},
  year = {2014},
  pages = {2377--2386},
  publisher = {{ACM Press}},
  address = {{Toronto, Ontario, Canada}},
  urldate = {2020-05-25},
  abstract = {Augmented reality (AR) devices are poised to enter the market. It is unclear how the properties of these devices will affect individuals' privacy. In this study, we investigate the privacy perspectives of individuals when they are bystanders around AR devices. We conducted 12 field sessions in caf{\'e}s and interviewed 31 bystanders regarding their reactions to a co-located AR device. Participants were predominantly split between having indifferent and negative reactions to the device. Participants who expressed that AR devices change the bystander experience attributed this difference to subtleness, ease of recording, and the technology's lack of prevalence. Additionally, participants surfaced a variety of factors that make recording more or less acceptable, including what they are doing when the recording is being taken. Participants expressed interest in being asked permission before being recorded and in recording-blocking devices. We use the interview results to guide an exploration of design directions for privacymediating technologies.},
  isbn = {978-1-4503-2473-1},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/denning2014.md;Human Computer Interaction/Augmented Reality/Denning et al., 2014 - In situ with bystanders of augmented reality glasses.pdf},
  url = {https://doi.org/10.1145/2556288.2557352}
}

@inproceedings{desjardins2018,
  title = {Revealing {{Tensions}} in {{Autobiographical Design}} in {{HCI}}},
  booktitle = {Proceedings of the 2018 on {{Designing Interactive Systems Conference}} 2018 - {{DIS}} '18},
  author = {Desjardins, Audrey and Ball, Aubree},
  year = {2018},
  pages = {753--764},
  publisher = {{ACM Press}},
  address = {{Hong Kong, China}},
  urldate = {2020-03-17},
  abstract = {While self-usage has long been regarded as a questionable approach in human-computer interaction (HCI) research, recent projects have shown the successful use of autobiographical design as a method to investigate long-term and intimate relations between people and technologies in everyday life. In an effort to continue the development of methodological best practices, we need to acknowledge with more nuance the tensions that arise in use. In this paper, we articulate such tensions by examining two first-hand accounts of using autobiographical design and four autobiographical design projects of other HCI researchers. Our findings address: genuine needs, design participation, intimacy, reflexivity, and authorial voice. Our contribution is constituted of critical insights into the complexities of using autobiographical design and recommendations for researchers interested in using this method.},
  isbn = {978-1-4503-5198-0},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/desjardins2018.md;Research Methods/Autobiographical Design/Desjardins and Ball, 2018 - Revealing Tensions in Autobiographical Design in HCI.pdf},
  url = {https://doi.org/10.1145/3196709.3196781}
}

@book{dewey1934,
  title = {Art as {{Experience}}},
  author = {Dewey, John},
  year = {1934},
  publisher = {{Capricorn Books}},
  address = {{New York}}
}

@article{dey2018,
  title = {A {{Systematic Review}} of 10 {{Years}} of {{Augmented Reality Usability Studies}}: 2005 to 2014},
  shorttitle = {A {{Systematic Review}} of 10 {{Years}} of {{Augmented Reality Usability Studies}}},
  author = {Dey, Arindam and Billinghurst, Mark and Lindeman, Robert W. and Swan, J. Edward},
  year = {2018},
  month = apr,
  journal = {Frontiers in Robotics and AI},
  volume = {5},
  pages = {37},
  issn = {2296-9144},
  urldate = {2020-10-02},
  abstract = {Augmented Reality (AR) interfaces have been studied extensively over the last few decades, with a growing number of user-based experiments. In this paper, we systematically review 10 years of the most influential AR user studies, from 2005 to 2014. A total of 291 papers with 369 individual user studies have been reviewed and classified based on their application areas. The primary contribution of the review is to present the broad landscape of user-based AR research, and to provide a high-level view of how that landscape has changed. We summarize the high-level contributions from each category of papers, and present examples of the most influential user studies. We also identify areas where there have been few user studies, and opportunities for future research. Among other things, we find that there is a growing trend toward handheld AR user studies, and that most studies are conducted in laboratory settings and do not involve pilot testing. This research will be useful for AR researchers who want to follow best practices in designing their own AR user studies.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/dey2018.md;Human Computer Interaction/Augmented Reality/Dey et al., 2018 - A Systematic Review of 10 Years of Augmented Reality Usability Studies.pdf},
  url = {https://doi.org/10.3389/frobt.2018.00037}
}

@incollection{dieter2015,
  title = {Dark {{Patterns}}: {{Interface Design}}, {{Augmentation}} and {{Crisis}}},
  shorttitle = {Dark {{Patterns}}},
  booktitle = {Postdigital {{Aesthetics}}},
  author = {Dieter, Michael},
  editor = {Berry, David and Dieter, Michael},
  year = {2015},
  pages = {163--178},
  publisher = {{Palgrave Macmillan UK}},
  address = {{London}},
  url = {https://doi.org/10.1057/9781137437204_13},
  urldate = {2020-09-21},
  isbn = {978-1-349-49378-4 978-1-137-43720-4},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/dieter2015.md;Arts & Humanities/Media Studies/Dieter, 2015 - Dark Patterns.pdf}
}

@article{discipio2003,
  title = {'{{Sound}} Is the Interface': From Interactive to Ecosystemic Signal Processing},
  shorttitle = {`{{Sound}} Is the Interface'},
  author = {Di Scipio, Agostino},
  year = {2003},
  month = dec,
  journal = {Organised Sound},
  volume = {8},
  number = {3},
  pages = {269--277},
  issn = {1355-7718, 1469-8153},
  urldate = {2020-01-10},
  abstract = {This paper takes a systemic perspective on interactive signal processing and introduces the author's               Audible Eco-Systemic Interface               (AESI) project. It starts with a discussion of the paradigm of `interaction' in existing computer music and live electronics approaches, and develops following bio-cybernetic principles such as `system/ambience coupling', `noise', and `self-organisation'. Central to the paper is an understanding of `interaction' as a network of interdependencies among system components, and as a means for dynamical behaviour to emerge upon the contact of an autonomous system (e.g. a DSP unit) with the external environment (room or else hosting the performance). The author describes the design philosophy in his current work with the AESI (whose DSP component was implemented as a signal patch in K               YMA               5.2), touching on compositional implications (not only live electronics situations, but also sound installations).},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/discipio2003.md;Arts & Humanities/Computational Art/Di Scipio, 2003 - 'Sound is the interface'.pdf},
  url = {https://doi.org/10.1017/S1355771803000244}
}

@book{dourish2004,
  title = {Where the Action Is: The Foundations of Embodied Interaction},
  shorttitle = {Where the Action Is},
  author = {Dourish, Paul},
  year = {2004},
  series = {A {{Bradford}} Book},
  edition = {1. MIT Press paperback ed},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass.}},
  isbn = {978-0-262-54178-7},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/dourish2004.md;Philosophy/Extended Cognition/Dourish, 2004 - Where the action is.pdf}
}

@article{dupreez2008,
  title = {({{Im}}){{Materiality}} - {{On}} the {{Immateriality}} of {{Art}}},
  author = {Du Preez, Amanda},
  year = {2008},
  journal = {Image \& Text: a Journal for Design},
  volume = {2008},
  number = {14},
  pages = {30--41},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/dupreez2008.md;Philosophy/Materiality/Du Preez, 2008 - (Im)Materiality - On the Immateriality of Art.pdf}
}

@book{durlach1995,
  title = {Virtual {{Reality}}: {{Scientific}} and {{Technological Challenges}}},
  shorttitle = {Virtual {{Reality}}},
  author = {Durlach, Nathaniel and Mavor, Anne},
  year = {1995},
  month = dec,
  publisher = {{National Academies Press}},
  address = {{Washington, D.C.}},
  url = {http://www.nap.edu/catalog/4761},
  urldate = {2020-01-10},
  isbn = {978-0-309-05135-4},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/durlach1995.md;Human Computer Interaction/Virtual Reality/Durlach and Mavor, 1995 - Virtual Reality.pdf}
}

@book{earnshaw2020,
  title = {Technology, {{Design}} and the {{Arts}} - {{Opportunities}} and {{Challenges}}},
  editor = {Earnshaw, Rae and Liggett, Susan and Excell, Peter and Thalmann, Daniel},
  year = {2020},
  series = {Springer {{Series}} on {{Cultural Computing}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  url = {https://doi.org/10.1007/978-3-030-42097-0},
  urldate = {2020-09-22},
  isbn = {978-3-030-42096-3 978-3-030-42097-0},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/earnshaw2020.md;Arts & Humanities/Computational Art/Earnshaw et al., 2020 - Technology, Design and the Arts - Opportunities and Challenges.pdf}
}

@article{edmonds2010,
  title = {The {{Art}} of {{Interaction}}},
  author = {Edmonds, Ernest},
  year = {2010},
  month = dec,
  journal = {Digital Creativity},
  volume = {21},
  number = {4},
  pages = {257--264},
  issn = {1462-6268, 1744-3806},
  urldate = {2020-06-11},
  abstract = {Interactive art has become much more common as a result of the many ways in which the computer and the Internet have facilitated it. Issues relating to human{\textendash} computer interaction (HCI) are as important to interactive art making as issues relating to the colours of paint are to painting. It is not that HCI and art necessarily share goals. It is just that much of the knowledge of HCI and its methods can contribute to interactive art making. This paper reviews recent work that looks at these issues in the art context. In interactive digital art, the artist is concerned with how the artwork behaves, how the audience interacts with it and, ultimately, in participant experience and their degree of engagement. The paper looks at these issues and brings together a collection of research results and art practice experiences that together help to illuminate this significant new and expanding area. In particular, it is suggested that this work points towards a much needed critical language that can be used to describe, compare and discuss interactive digital art.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/edmonds2010.md;Arts & Humanities/Computational Art/Edmonds, 2010 - The Art of Interaction.pdf},
  url = {https://doi.org/10.1080/14626268.2010.556347}
}

@article{edmonds2017,
  title = {Systems Theory, Systems Art and the Computer: {{Ernest Edmonds}} Interviewed by {{Francesca Franco}}},
  shorttitle = {Systems Theory, Systems Art and the Computer},
  author = {Edmonds, Ernest and Franco, Francesca},
  year = {2017},
  month = apr,
  journal = {Interdisciplinary Science Reviews},
  volume = {42},
  number = {1-2},
  pages = {169--179},
  issn = {0308-0188, 1743-2790},
  urldate = {2020-06-11},
  abstract = {This interview with Edmonds, conducted by Franco in 2016, explores how Systems art, Systems Theory, and his personal relationships with artists such as Malcolm Hughes, Kenneth Martin and Edward Ihnatowicz influenced his art practice.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/edmonds2017.md;Arts & Humanities/Computational Art/Edmonds and Franco, 2017 - Systems theory, systems art and the computer.pdf},
  url = {https://doi.org/10.1080/03080188.2017.1297158}
}

@article{edmonds2018,
  title = {Algorithmic {{Art Machines}}},
  author = {Edmonds, Ernest},
  year = {2018},
  month = jan,
  journal = {Arts},
  volume = {7},
  number = {1},
  pages = {3},
  issn = {2076-0752},
  urldate = {2020-06-11},
  abstract = {The article reviews the author's personal development in relation to art made by algorithmic machines and discusses both the nature of such systems and the future implications for art.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/edmonds2018.md;Arts & Humanities/Computational Art/Edmonds, 2018 - Algorithmic Art Machines.pdf},
  url = {https://doi.org/10.3390/arts7010003}
}

@inproceedings{elblaus2020,
  title = {Utruchirp: {{An}} Impulse Response Measurement and Auralisation Tool Developed for Artistic Practice},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Elblaus, Ludvig and Eckel, Gerhard},
  year = {2020},
  series = {{{AM}} '20},
  pages = {61--68},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {This paper presents the utruchirp software, a tool for measuring impulse responses and modelling room acoustics in real time through auralisation based on convolution using those responses. utruchirp is the result of concerns and needs emerging from the authors' ongoing artistic practice, exploring room scale acoustic feedback as material for live performance, installations, and fixed media pieces as utrumque.The paper provides the technical and, more importantly, the artistic details of the development of utruchirp and its features, highlighting those that are the direct result of insights from artistic work: Monitoring of all stages of measuring and signal processing, auralisations of the measurements from within the measurement process, and integrated round trip delay estimation. Finally, it points out future directions and features that are to be explored next, with an invitation for collaborative efforts, aiming to bring the sensibilities of musical instruments to our measurement tools.},
  isbn = {978-1-4503-7563-4},
  keywords = {acoustics,composition,convolution,electroacoustic music,feedback,impulse response measurement,room modelling},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/elblaus2020.md;Arts & Humanities/Computational Art/Elblaus and Eckel, 2020 - Utruchirp.pdf},
  url = {https://doi.org/10.1145/3411109.3411140}
}

@inproceedings{elblaus2020a,
  title = {Acoustic Modelling as a Strategy for Composing Site-Specific Music},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Elblaus, Ludvig and Eckel, Gerhard},
  year = {2020},
  series = {{{AM}} '20},
  pages = {69--76},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {This paper describes two site-specific musical compositions, focusing on how modelling was used in their respective composition processes. Primarily, the acoustics of the sites were modelled to aid in the preparation and composition of the pieces. From this we propose the general use of modelling as a way to work with the concept of site. But the idea of formulating a model is also applicable more widely in the work described and this is discussed with the two pieces as starting points.Both pieces use acoustic room scale feedback as their only source of sound, so the impact of the room, speakers and microphones used is immense. The first piece, Rundg{\aa}ng, is a commission for the GRM Acousmonium. The second piece, Clockwork, is a public installation that will also be the site of a performance, combining the installation with live interventions. Clockwork will also employ modelling as a component of the piece itself, and include a remote performer and a remote audience. We suggest that there are possibilities to employ compositional strategies to embrace these kinds of hybrid presence situations by composing for many vantage points.},
  isbn = {978-1-4503-7563-4},
  keywords = {acoustics,composition,electroacoustic music,feedback,modelling,presence,room impulse response,site specificity},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/elblaus2020a.md;Arts & Humanities/Computational Art/Elblaus and Eckel, 2020 - Acoustic modelling as a strategy for composing site-specific music.pdf},
  url = {https://doi.org/10.1145/3411109.3411141}
}

@misc{eliasson2020,
  title = {Wunderkammer},
  author = {Eliasson, Olafur},
  year = {2020},
  url = {https://olafureliasson.net/},
  urldate = {2020-05-25},
  abstract = {Official website of Olafur Eliasson and his studio: Studio Olafur Eliasson},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/eliasson2020.md;../../../../../Zotero/storage/8JBQEWC8/olafureliasson.net.html}
}

@article{emmerson1998,
  title = {Aural Landscape: Musical Space},
  shorttitle = {Aural Landscape},
  author = {Emmerson, Simon},
  year = {1998},
  month = aug,
  journal = {Organised Sound},
  volume = {3},
  number = {2},
  pages = {135--140},
  issn = {1355-7718, 1469-8153},
  urldate = {2020-02-11},
  abstract = {This paper seeks to examine how sound in general (and electroacoustic music in particular) can evoke a sense of being and place which may be strongly related to our visual experience. The auditory system has evolved to seek the reasons for the soundfield it encounters and this property cannot meaningfully be ignored by composers in this medium. The acousmatic condition stimulates and enhances this response. The science of acoustics cannot any longer alone explain sound phenomena and requires psychological and ecological dimensions. The idea of the `frame' is developed from large-scale to small-scale soundfields: `landscape', `arena' and `stage' are seen to be flexible components of this approach to composition. The paper concludes that a mature relationship of audio and visual art forms requires a greater acknowledgement of these attributes of sound.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/emmerson1998.md;Arts & Humanities/Computational Art/Emmerson, 1998 - Aural landscape.pdf},
  url = {https://doi.org/10.1017/S1355771898002064}
}

@incollection{emmerson2015,
  title = {Local/{{Field}} and {{Beyond The Scale}} of {{Spaces}}},
  booktitle = {Kompositionen F{\"u}r H{\"o}rbaren {{RaumDie}} Fr{\"u}he Elektroakustische {{Musik}} Und Ihre {{Kontexte}}},
  author = {Emmerson, Simon},
  year = {2015},
  edition = {1. Aufl.},
  publisher = {{transcript Verlag}},
  address = {{Bielefeld}},
  url = {https://www.degruyter.com/view/books/9783839430767/9783839430767-001/9783839430767-001.xml},
  urldate = {2020-02-11},
  isbn = {978-3-8394-3076-7},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/emmerson2015.md}
}

@article{engberg2014,
  title = {Cultural Expression in Augmented and Mixed Reality},
  author = {Engberg, Maria and Bolter, Jay David},
  year = {2014},
  month = feb,
  journal = {Convergence: The International Journal of Research into New Media Technologies},
  volume = {20},
  number = {1},
  pages = {3--9},
  issn = {1354-8565, 1748-7382},
  urldate = {2020-10-27},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/engberg2014.md;Human Computer Interaction/Augmented Reality/Engberg and Bolter, 2014 - Cultural expression in augmented and mixed reality.pdf},
  url = {https://doi.org/10.1177/1354856513516250}
}

@article{engberg2014a,
  title = {Polyaesthetic Sights and Sounds:},
  author = {Engberg, Maria},
  year = {2014},
  volume = {4},
  number = {1},
  pages = {20},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/engberg2014a.md;Arts & Humanities/Aesthetics/Engberg, 2014 - Polyaesthetic sights and sounds.pdf}
}

@misc{eno2018,
  title = {Bloom: {{Open Space}}},
  author = {Eno, Brian and Chilvers, Peter},
  year = {2018},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/eno2018.md}
}

@book{ernst2016,
  title = {Sonic Time Machines: Explicit Sound, Sirenic Voices, and Implicit Sonicity},
  shorttitle = {Sonic Time Machines},
  author = {Ernst, Wolfgang},
  year = {2016},
  series = {Recursions: Theories of Media, Materiality, and Cultural Techniques},
  publisher = {{Amsterdam University Press}},
  address = {{Amsterdam}},
  isbn = {978-90-8964-949-2},
  keywords = {Music,Philosophy and aesthetics,Sound (Philosophy),Sound in mass media},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ernst2016.md}
}

@misc{espressif2020,
  title = {{{ESP32}}},
  author = {Espressif},
  year = {2020},
  url = {https://www.espressif.com/en/products/socs/esp32/overview},
  urldate = {2020-05-25},
  file = {../../../../../Zotero/storage/YJAA9S5C/overview.html}
}

@article{essl2006,
  title = {An Enactive Approach to the Design of New Tangible Musical Instruments},
  author = {Essl, Georg and O'Modhrain, Sile},
  year = {2006},
  month = dec,
  journal = {Organised Sound},
  volume = {11},
  number = {3},
  pages = {285--296},
  issn = {1355-7718, 1469-8153},
  urldate = {2021-04-28},
  abstract = {In this paper, we propose a theoretical framework for the design of tangible interfaces for musical expression. The main insight for the proposed approach is the importance and utility of familiar sensorimotor experiences for the creation of engaging and playable new musical instruments. In particular, we suggest exploiting the commonalities between different natural interactions by varying the auditory response or tactile details of the instrument within certain limits. Using this principle, devices for classes of sounds such as coarse grain collision interactions or friction interactions can be designed. The designs we propose retain the familiar tactile aspect of the interaction so that the performer can take advantage of tacit knowledge gained through experiences with such phenomena in the real world.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/essl2006.md;Arts & Humanities/Computational Art/Essl and O'Modhrain, 2006 - An enactive approach to the design of new tangible musical instruments.pdf},
  url = {https://doi.org/10.1017/S135577180600152X}
}

@misc{everyrealm2022,
  title = {Fantasy {{Islands}}},
  author = {Everyrealm},
  year = {2022},
  journal = {Everyrealm: Fantasy Islands},
  url = {https://everyrealm.com/fantasy-islands},
  urldate = {2022-12-13},
  abstract = {Fantasy Islands is the first-ever master-planned premier island community in the metaverse (comprised of NFT land in The Sandbox and 100 unique private islands)},
  langid = {english},
  file = {../../../../../Zotero/storage/4489MBBK/fantasy-islands.html}
}

@misc{fatemi2022,
  title = {The {{Metaverse Will Radically Change Content Creation Forever}}},
  author = {Fatemi, Falon},
  year = {2022},
  journal = {Forbes},
  url = {https://archive.today/K9Ve8},
  urldate = {2022-09-12},
  abstract = {Although the metaverse promises to touch nearly every person in our society, there's one demographic that will almost certainly see disproportionately strong disruption: creators.},
  langid = {english},
  file = {../../../../../Zotero/storage/ECEPIZ4Q/the-metaverse-will-radically-change-content-creation-forever.html}
}

@incollection{fazi2016,
  title = {Computational {{Aesthetics}}},
  booktitle = {A {{Companion}} to {{Digital Art}}},
  author = {Fazi, M Beatrice and Fuller, Matthew},
  editor = {Paul, Christiane},
  year = {2016},
  publisher = {{John Wiley \& Sons}},
  url = {https://monoskop.org/images/f/f1/Fazi_M_Beatrice_Fuller_Matthew_2016_Computational_Aesthetics.pdf},
  urldate = {2020-06-11},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/fazi2016.md;Arts & Humanities/Aesthetics/Fazi and Fuller, 2016 - Computational Aesthetics.pdf}
}

@article{feiner1993,
  title = {Knowledge-Based Augmented Reality},
  author = {Feiner, Steven and Macintyre, Blair and Seligmann, Dor{\'e}e},
  year = {1993},
  month = jul,
  journal = {Communications of the ACM},
  volume = {36},
  number = {7},
  pages = {53--62},
  issn = {0001-0782, 1557-7317},
  urldate = {2021-02-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/feiner1993.md;Human Computer Interaction/Augmented Reality/Feiner et al., 1993 - Knowledge-based augmented reality.pdf},
  url = {https://doi.org/10.1145/159544.159587}
}

@misc{feiner1993a,
  type = {Archive},
  title = {Knowledge-Based {{Augmented Reality}} for {{Maintenance Assistance}}},
  author = {Feiner, Steven and MacIntyre, Blair and Seligmann, Dor{\'e}e},
  year = {1993},
  journal = {Knowledge-based Augmented Reality for Maintenance Assistance},
  url = {https://graphics.cs.columbia.edu/projects/karma/karma.html},
  urldate = {2022-12-13},
  file = {../../../../../Zotero/storage/5U7IVG2H/karma.html}
}

@article{feiner1997,
  title = {A {{Touring Machine}}: {{Prototyping 3D Mobile Augmented Reality Systems}} for {{Exploring}} the {{Urban Environment}}},
  author = {Feiner, Steven and MacIntyre, Blair and H{\"o}llerer, Tobias and Webster, Anthony},
  year = {1997},
  journal = {Personal Technologies},
  volume = {1},
  pages = {8},
  abstract = {We describe a prototype system that combines together the overlaid 3D graphics of augmented reality with the untethered freedom of mobile computing. The goal is to explore how these two technologies might together make possible wearable computer systems that can support users in their everyday interactions with the world. We introduce an application that presents information about our university's campus, using a head-tracked, see-through, headworn, 3D display, and an untracked, opaque, handheld, 2D display with stylus and trackpad. We provide an illustrated explanation of how our prototype is used, and describe our rationale behind designing its software infrastructure and selecting the hardware on which it runs.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/feiner1997.md;Human Computer Interaction/Augmented Reality/Feiner et al., 1997 - A Touring Machine.pdf},
  url = {https://doi.org/10.1007/BF01682023}
}

@article{feingold1995,
  title = {{{OU}}: {{Interactivity}} as {{Divination}} as {{Vending Machine}}},
  shorttitle = {{{OU}}},
  author = {Feingold, Ken},
  year = {1995},
  journal = {Leonardo},
  volume = {28},
  number = {5},
  eprint = {1576224},
  eprinttype = {jstor},
  pages = {399},
  issn = {0024094X},
  urldate = {2019-08-17},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/feingold1995.md;Human Computer Interaction/Augmented Reality/Feingold, 1995 - OU.pdf},
  url = {https://doi.org/10.2307/1576224}
}

@book{fetterman2010,
  title = {Ethnography: Step-by-Step},
  shorttitle = {Ethnography},
  author = {Fetterman, David M.},
  year = {2010},
  series = {Applied Social Research Methods Series},
  edition = {3rd ed},
  number = {17},
  publisher = {{SAGE}},
  address = {{Los Angeles}},
  isbn = {978-1-4129-5045-9},
  langid = {english},
  lccn = {GN345 .F47 2010},
  keywords = {Ethnology,Methodology},
  file = {Research Methods/Autoethnography/Fetterman, 2010 - Ethnography.pdf}
}

@article{francis2019,
  title = {Undergraduate Student Perceptions of Assessment and Feedback Practice: Fostering Agency and Dialogue},
  shorttitle = {Undergraduate Student Perceptions of Assessment and Feedback Practice},
  author = {Francis, Robert A. and Millington, James D.A. and Cederl{\"o}f, Gustav},
  year = {2019},
  month = oct,
  journal = {Journal of Geography in Higher Education},
  volume = {43},
  number = {4},
  pages = {468--485},
  issn = {0309-8265, 1466-1845},
  urldate = {2021-09-13},
  abstract = {Assessment and feedback practices sit at the heart of education and the student experience. This paper reports on undergraduate perceptions of assessment and feedback in the Department of Geography at King's College London, UK. Twenty-eight first and second-year students across six focus groups provided comments on their understanding of feedback, their feedback experiences, and what they felt could be improved. It was clear that students desired feedback that would help them improve summative performance, but were unsure of how best to use it and consequently had high expectations that led to dissatisfaction. Particular concern was expressed about marking and feedback consistency, and the inherent variation in practice they experienced. Many comments indicated a lack of student agency, which may reflect the power relations that students find themselves in within their community of practice. Finding ways of fostering agency and improving dialogue over perceptions and expectations are suggested to be important steps in improving assessment and feedback practice, and student satisfaction.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/francis2019.md;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/Undergraduate student perceptions of assessment and feedback practice fostering agency and dialogue.md;Pedagogy/Francis et al., 2019 - Undergraduate student perceptions of assessment and feedback practice.pdf},
  url = {https://doi.org/10.1080/03098265.2019.1660867}
}

@misc{frank2022,
  title = {Metaverse Real Estate Sales Top \$500 Million, and Are Projected to Double This Year},
  author = {Frank, Robert},
  year = {2022},
  journal = {CNBC},
  url = {https://archive.today/pDqMq},
  urldate = {2022-09-12},
  abstract = {A rush of investors is pouring into the new virtual land craze, hoping to get in on the ground floor of the next digital Manhattan or Monaco.},
  langid = {english},
  file = {../../../../../Zotero/storage/G3X9JMPB/metaverse-real-estate-sales-top-500-million-metametric-solutions-says.html}
}

@techreport{franziskaroesner2020,
  title = {Mixed {{Reality}}: {{Security Privacy}} and {{Safety}}},
  editor = {{Franziska Roesner} and Kohno, Tadayoshi},
  year = {2020},
  institution = {{University of Washington}},
  url = {https://ar-sec.cs.washington.edu/files/MixedReality_SecurityPrivacySafety_Summit2019.pdf},
  urldate = {2020-05-25},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/franziskaroesner2020.md;Human Computer Interaction/Mixed Reality/2020 - Mixed Reality.pdf}
}

@book{frith1996,
  title = {Performing Rites: On the Value of Popular Music},
  shorttitle = {Performing Rites},
  author = {Frith, Simon},
  year = {1996},
  publisher = {{Harvard University Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-674-66195-0},
  langid = {english},
  lccn = {ML3795 .F738 1996},
  keywords = {History and criticism,Music,Philosophy and aesthetics,Popular music,Social aspects},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/frith1996.md;Arts & Humanities/Musicology/Frith, 1996 - Performing rites.pdf}
}

@article{fruend2001,
  title = {The {{Augmented Reality Personal Digital Assistant}}},
  author = {Fruend, Juergen and Geiger, Christian and Grafe, Michael and Kleinjohann, Bernd and Institut, Heinz-Nixdorf},
  year = {2001},
  pages = {3},
  abstract = {This short paper describes a German research project on mobile augmented reality. The idea is to develop a framework that provides AR-services for the consumer market using a personal digital assistant.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/fruend2001.md;Human Computer Interaction/Augmented Reality/Fruend et al., 2001 - The Augmented Reality Personal Digital Assistant.pdf}
}

@book{fuchs2014,
  title = {Social Media: A Critical Introduction},
  shorttitle = {Social Media},
  author = {Fuchs, Christian},
  year = {2014},
  publisher = {{SAGE}},
  address = {{Los Angeles}},
  abstract = {"Now more than ever, we need to understand social media - the good as well as the bad. We need critical knowledge that helps us to navigate the controversies and contradictions of this complex digital media landscape. Only then can we make informed judgments about what's happening in our media world, and why. Showing the reader how to ask the right kinds of questions about social media, Christian Fuchs takes us on a journey across social media, delving deep into case studies on Google, Facebook, Twitter, WikiLeaks and Wikipedia. The result lays bare the structures and power relations at the heart of our media landscape." -- Publisher's description},
  isbn = {978-1-4462-5730-2 978-1-4462-5731-9},
  langid = {english},
  lccn = {HM742 .F84 2014},
  keywords = {Social media},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/fuchs2014.md;Arts & Humanities/Media Studies/Fuchs, 2014 - Social media.pdf}
}

@misc{gach2022,
  title = {Crypto {{Gaming}} '{{Landlords}}' {{Upset They Can}}'t {{Keep Exploiting All The Players Quitting}}},
  author = {Gach, Ethan},
  year = {2022},
  journal = {Kotaku Australia},
  url = {https://archive.today/509s0},
  urldate = {2022-09-12},
  abstract = {Axie Infinity is the crypto-backed Pok{\'e}mon clone in which cute little creatures that double as NFTs battle for fun and...},
  langid = {australian},
  file = {../../../../../Zotero/storage/WHARJ8UR/crypto-gaming-landlords-upset-they-cant-keep-exploiting-all-the-players-quitting.html}
}

@book{gallagher2017,
  title = {Enactivist Interventions: Rethinking the Mind},
  shorttitle = {Enactivist Interventions},
  author = {Gallagher, Shaun},
  year = {2017},
  edition = {First edition},
  publisher = {{Oxford University Press}},
  address = {{Oxford New York}},
  abstract = {Enactivist Interventions' is an interdisciplinary work that explores how theories of embodied cognition illuminate many aspects of the mind, including intentionality, representation, the affect, perception, action and free will, higher-order cognition, and intersubjectivity. Gallagher argues for a rethinking of the concept of mind, drawing on pragmatism, phenomenology and cognitive science. Enactivism is presented as a philosophy of nature that has significant methodological and theoretical implications for the scientific investigation of the mind. Gallagher argues that, like the basic phenomena of perception and action, sophisticated cognitive phenomena like reflection, imagining, and mathematical reasoning are best explained in terms of an affordance-based skilled coping. He offers an account of the continuity that runs between basic action, affectivity, and a rationality that in every case remains embodied. Gallagher's analysis also addresses recent predictive models of brain function and outlines an alternative, enactivist interpretation that emphasizes the close coupling of brain, body and environment rather than a strong boundary that isolates the brain in its internal processes. The extensive relational dynamics that integrates the brain with the extra-neural body opens into an environment that is physical, social and cultural and that recycles back into the enactive process. Cognitive processes are in-the-world rather than in-the-head; they are situated in affordance spaces defined across evolutionary, developmental and individual histories, and are constrained by affective processes and normative dimensions of social and cultural practices--},
  isbn = {978-0-19-879432-5},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/gallagher2017.md;Philosophy/Extended Cognition/Gallagher, 2017 - Enactivist interventions.pdf}
}

@book{gamma1995,
  title = {Design Patterns: Elements of Reusable Object-Oriented Software},
  shorttitle = {Design Patterns},
  editor = {Gamma, Erich},
  year = {1995},
  series = {Addison-{{Wesley}} Professional Computing Series},
  publisher = {{Addison-Wesley}},
  address = {{Reading, Mass}},
  isbn = {978-0-201-63361-0},
  lccn = {QA76.64 .D47 1995},
  keywords = {Computer software,Object-oriented programming (Computer science),Reusability,Software patterns},
  file = {Human Computer Interaction/Software Engineering/Gamma, 1995 - Design patterns.pdf}
}

@phdthesis{gamper2014,
  title = {Enabling Technologies for Audio Augmented Reality Systems},
  author = {Gamper, Hannes},
  year = {2014},
  abstract = {Audio augmented reality (AAR) refers to technology that embeds computer-generated auditory content into a user's real acoustic environment. An AAR system has specific requirements that set it apart from regular human--computer interfaces: an audio playback system to allow the simultaneous perception of real and virtual sounds; motion tracking to enable interactivity and location-awareness; the design and implementation of auditory display to deliver AAR content; and spatial rendering to display spatialised AAR content. This thesis presents a series of studies on enabling technologies to meet these requirements.},
  langid = {english},
  school = {Aalto University},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/gamper2014.md;Human Computer Interaction/Augmented Reality/Gamper, 2014 - Enabling technologies for audio augmented reality systems.pdf}
}

@book{geroimenko2014,
  title = {Augmented {{Reality Art}}: {{From}} an {{Emerging Technology}} to a {{Novel Creative Medium}}},
  shorttitle = {Augmented {{Reality Art}}},
  editor = {Geroimenko, Vladimir},
  year = {2014},
  series = {Springer {{Series}} on {{Cultural Computing}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  url = {https://doi.org/10.1007/978-3-319-06203-7},
  urldate = {2020-09-22},
  isbn = {978-3-319-06202-0 978-3-319-06203-7},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/geroimenko2014.md;Human Computer Interaction/Augmented Reality/Geroimenko, 2014 - Augmented Reality Art.pdf}
}

@book{geroimenko2018,
  title = {Augmented {{Reality Art}}},
  editor = {Geroimenko, Vladimir},
  year = {2018},
  series = {Springer {{Series}} on {{Cultural Computing}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  url = {https://doi.org/10.1007/978-3-319-69932-5},
  urldate = {2020-09-22},
  isbn = {978-3-319-69931-8 978-3-319-69932-5},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/geroimenko2018.md;Human Computer Interaction/Augmented Reality/Geroimenko, 2018 - Augmented Reality Art.pdf}
}

@book{geronazzo2023,
  title = {Sonic {{Interactions}} in {{Virtual Environments}}},
  author = {Geronazzo, Michele and Serafin, Stefania},
  year = {2023},
  publisher = {{Springer Nature}},
  url = {https://doi.org/10.1007/978-3-031-04021-4}
}

@article{gerzon1973,
  title = {Periphony: {{With-Height Sound Reproduction}}},
  author = {Gerzon, Michael},
  year = {1973},
  journal = {Journal of The Audio Engeneering Society},
  volume = {21},
  number = {1},
  pages = {2--10},
  url = {http://www.aes.org/e-lib/browse.cfm?elib=2012},
  urldate = {2020-07-22},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/gerzon1973.md;Human Computer Interaction/Audio Interfacing/Gerzon, 1973 - Periphony.pdf}
}

@article{gibson2014,
  title = {The {{Ecological Approach}} to {{Visual Perception}}},
  author = {Gibson, James J},
  year = {2014},
  pages = {347},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/gibson2014.md;Cognitive Science/Visual Psychology/Gibson, 2014 - The Ecological Approach to Visual Perception.pdf}
}

@book{giddens1984,
  title = {The Constitution of Society: Outline of the Theory of Structuration},
  shorttitle = {The Constitution of Society},
  author = {Giddens, Anthony},
  year = {1984},
  publisher = {{University of California Press}},
  address = {{Berkeley}},
  isbn = {978-0-520-05292-5},
  lccn = {HM24 .G4465 1984},
  keywords = {Political sociology,Social institutions,Social structure,Sociology},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/giddens1984.md}
}

@book{glaser1967,
  title = {The Discovery of Grounded Theory: Strategies for Qualitative Research},
  shorttitle = {The Discovery of Grounded Theory},
  author = {Glaser, Barney G. and Strauss, Anselm L.},
  year = {1967},
  publisher = {{Aldine Transaction}},
  address = {{New Brunswick}},
  langid = {english}
}

@incollection{godoy2006,
  title = {Playing ``{{Air Instruments}}'': {{Mimicry}} of {{Sound-Producing Gestures}} by {{Novices}} and {{Experts}}},
  shorttitle = {Playing ``{{Air Instruments}}''},
  booktitle = {Gesture in {{Human-Computer Interaction}} and {{Simulation}}},
  author = {God{\o}y, Rolf Inge and Haga, Egil and Jensenius, Alexander Refsum},
  editor = {Gibet, Sylvie and Courty, Nicolas and Kamp, Jean-Fran{\c c}ois},
  year = {2006},
  volume = {3881},
  pages = {256--267},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  url = {https://doi.org/10.1007/11678816_29},
  urldate = {2020-05-26},
  abstract = {Both musicians and non-musicians can often be seen making sound-producing gestures in the air without touching any real instruments. Such ''air playing'' can be regarded as an expression of how people perceive and imagine music, and studying the relationships between these gestures and sound might contribute to our knowledge of how gestures help structure our experience of music.},
  isbn = {978-3-540-32624-3 978-3-540-32625-0},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/godoy2006.md;Arts & Humanities/Computational Art/GodÃ¸y et al., 2006 - Playing â€œAir Instrumentsâ€.pdf}
}

@article{gomez2020,
  title = {Fragility of a Multilayer Network of Intranational Supply Chains},
  author = {Gomez, Michael and Garcia, Susana and Rajtmajer, Sarah and Grady, Caitlin and Mejia, Alfonso},
  year = {2020},
  month = dec,
  journal = {Applied Network Science},
  volume = {5},
  number = {1},
  pages = {71},
  issn = {2364-8228},
  urldate = {2022-12-11},
  abstract = {Supply chains enable the flow of goods and services within economic systems. When mapped for the entire economy and geographic locations of a country, supply chains form a spatial web of interactions among suppliers and buyers. One way to characterize supply chains is through multiregional input-output linkages. Using a multiregional input-output dataset, we build the multilayer network of supply chains in the United States. Together with a network cascade model, the multilayer network is used to explore the propagation of economic shocks along intranational supply chains. We find that the effect of economic shocks, measured using the avalanche size or total number of collapsed nodes, varies widely depending on the geographic location and economic sector of origin of a shock. The response of the supply chains to shocks reveals a threshold-like behavior. Below a certain failure or fragility level, the avalanche size increases relatively quickly for any node in the network. Based on this result, we find that the most fragile regions tend to be located in the central United States, which are regions that tend to specialize in food production and manufacturing. The most fragile layers are chemical and pharmaceutical products, services and food-related products, which are all sectors that have been disrupted by the Coronavirus Disease 2019 (COVID-19) pandemic in the United States. The fragility risk, measured by the intersection of the fragility level of a node and its exposure to shocks, varies across regions and sectors. This suggests that interventions aiming to make the supply-chain network more robust to shocks are likely needed at multiple levels of network aggregation.},
  langid = {english},
  file = {Politics/Marxism/Gomez et al., 2020 - Fragility of a multilayer network of intranational supply chains.pdf},
  url = {https://doi.org/10.1007/s41109-020-00310-1}
}

@misc{google2020,
  title = {{{ARCore}}},
  author = {Google},
  year = {2020},
  journal = {ARCore},
  url = {https://developers.google.com/ar},
  urldate = {2020-05-25},
  abstract = {With ARCore, build new augmented reality experiences that seamlessly blend the digital and physical worlds. Transform the way people play, shop, learn, create, and experience the world together{\textemdash}at Google scale.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/google2020.md;../../../../../Zotero/storage/YTYX7MTZ/ar.html}
}

@misc{gordijn2017,
  title = {Concrete {{Storm}}, {{Studio Drift}}},
  author = {Gordijn, Lonneke and Nauta, Ralph},
  year = {2017},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/gordijn2017.md}
}

@misc{gottschalk2017,
  title = {Move {{Over}}, {{Virtual Reality}}{\textemdash}a {{New Artistic Medium Is}} about to {{Emerge}}},
  author = {Gottschalk, Molly},
  year = {2017},
  month = mar,
  journal = {Artsy},
  url = {https://archive.today/d3Iuc},
  urldate = {2020-05-27},
  abstract = {This week at The Armory Show, a new technology-driven medium, mixed reality, makes its debut courtesy of Studio Drift and Microsoft's HoloLens.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/gottschalk2017.md;../../../../../Zotero/storage/RFCTUW5Z/artsy-editorial-move-virtual-reality-new-artistic-medium-emerge.html}
}

@article{gould2014,
  title = {Invisible Visualities: {{Augmented}} Reality Art and the Contemporary Media Ecology},
  shorttitle = {Invisible Visualities},
  author = {Gould, Amanda Starling},
  year = {2014},
  month = feb,
  journal = {Convergence: The International Journal of Research into New Media Technologies},
  volume = {20},
  number = {1},
  pages = {25--32},
  issn = {1354-8565, 1748-7382},
  urldate = {2020-05-27},
  abstract = {Augmented reality (AR) art is a form of artistic expression that complicates traditional notions of the visual arts. A visual AR artist trades in what we might call invisible visualities. In this essay, I consider the questions why does AR art matter as a cultural form of expression? and what does AR art contribute to contemporary technoliterary theoretical discourse? by putting several recent AR artworks into dialogue with some of today's most important literary-media theorists.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/gould2014.md;Human Computer Interaction/Augmented Reality/Gould, 2014 - Invisible visualities.pdf},
  url = {https://doi.org/10.1177/1354856513514332}
}

@article{graham2013,
  title = {Augmented Reality in Urban Places: Contested Content and the Duplicity of Code: {{{\emph{Augmented}}}}{\emph{ Reality in Urban Places}}},
  shorttitle = {Augmented Reality in Urban Places},
  author = {Graham, Mark and Zook, Matthew and Boulton, Andrew},
  year = {2013},
  month = jul,
  journal = {Transactions of the Institute of British Geographers},
  volume = {38},
  number = {3},
  pages = {464--479},
  issn = {00202754},
  urldate = {2020-02-07},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/graham2013.md;Human Computer Interaction/Augmented Reality/Graham et al., 2013 - Augmented reality in urban places.pdf},
  url = {https://doi.org/10.1111/j.1475-5661.2012.00539.x}
}

@inproceedings{graham2019,
  title = {Composing Spatial Soundscapes Using Acoustic Metasurfaces},
  booktitle = {Proceedings of the 14th {{International Audio Mostly Conference}}: {{A Journey}} in {{Sound}}},
  author = {Graham, Thomas J. and Magnusson, Thor and Rajguru, Chinmay and Yazdan, Arash Pour and Jacobs, Alex and Memoli, Gianluca},
  year = {2019},
  month = sep,
  pages = {103--110},
  publisher = {{ACM}},
  address = {{Nottingham United Kingdom}},
  urldate = {2020-09-19},
  abstract = {In this work, we explore the use of acoustic metamaterials in delivering spatially significant acoustic experiences. In particular, we discuss a user study run in a space where a dedicated composition is played through a metamaterial "prism". Results show users perceive sound to be louder in the direction determined by the metamaterial, depending on its frequency. This demonstrates how an acoustic metamaterial prism, in combination with an electronic composer, may be used to deliver different sound messages to different parts of an audience, even with a single speaker. We underpin our conclusions with user observations and heuristic considerations on possible application scenarios.},
  isbn = {978-1-4503-7297-8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/graham2019.md;Arts & Humanities/Computational Art/Graham et al., 2019 - Composing spatial soundscapes using acoustic metasurfaces.pdf},
  url = {https://doi.org/10.1145/3356590.3356607}
}

@inproceedings{grasset2008,
  title = {Art and {{Mixed Reality}}: {{New Technology}} for {{Seamless Merging Between Virtual}} and {{Real}}},
  booktitle = {{{DAC}} 2007},
  author = {Grasset, Rapha{\"e}l and Woods, Eric and Billinghurst, Mark},
  year = {2007},
  pages = {10},
  abstract = {Mixed Reality (MR) describes new technology that intrinsically supports the mixing between the real world with the virtual world. In this paper, we present different interactive Mixed Reality experiences we have been developing that explore the artistic applications of the technology. We discuss our approach, the knowledge we have gained and review issues raised by these diverse experiences. Finally, we introduce some initial design guidelines to help others to develop their own interactive Mixed Reality artistic creations.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/grasset2008.md;Human Computer Interaction/Augmented Reality/Grasset et al., 2007 - Art and Mixed Reality.pdf}
}

@misc{green2010,
  title = {Cardboard {{Cutout}} in Perfomance at {{Dialogues Festival}}, {{Inspace}}, {{Edinburgh}} in 2010},
  author = {Green, Owen},
  year = {2010},
  url = {http://owengreen.net/wp-content/uploads/2015/08/box-1024x846.png},
  langid = {english}
}

@article{green2011,
  title = {Agility and {{Playfulness}}: {{Technology}} and Skill in the Performance Ecosystem},
  shorttitle = {Agility and {{Playfulness}}},
  author = {Green, Owen},
  year = {2011},
  month = aug,
  journal = {Organised Sound},
  volume = {16},
  number = {2},
  pages = {134--144},
  issn = {1355-7718, 1469-8153},
  urldate = {2022-08-22},
  abstract = {Whilst it is common in much discourse around contemporary musical practices to emphasise the differences between digital and acoustic ways of making music, Simon Waters' discussion of the Performance Ecosystem as an analytic perspective argues instead for a heightened sense of continuity (Waters 2007). This article lends support to this argument by developing an ecosystemically situated account of our relationships with technology and processes of skill formation. It is argued that this sense of continuity is justified, but that where differences of experiences do arise these are not, as sometimes supposed, an essential characteristic of digital technologies. On the basis that much of our skill formation consists of tacit knowledge, it is suggested that further discussion on how particular circumstances and skills arise would be revealing. Two possible headings for such discussion are suggested in the form of `Agility' and `Playfulness'.},
  langid = {english},
  file = {Arts & Humanities/Computational Art/Green, 2011 - Agility and Playfulness.pdf},
  url = {https://doi.org/10.1017/S1355771811000082}
}

@techreport{grubb2022,
  type = {Call-{{In Application}}},
  title = {Whitehaven {{Decision}} and {{Inspector}}'s {{Report}}},
  author = {DLUHC},
  year = {2022},
  month = dec,
  number = {APP/H0900/V/21/3271069},
  pages = {419},
  address = {{Whitehaven, Cumbria, UK}},
  institution = {{Department for Levelling Up, Housing \& Communities}},
  url = {https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1122625/22-12-07_Whitehaven_-_Decision_Letter_and_IR.pdf},
  urldate = {2022-12-11},
  collaborator = {Grubb, Michael and Barrett, John},
  file = {Politics/Marxism/DLUHC, 2022 - Whitehaven Decision and Inspector's Report.pdf}
}

@book{guerin1936,
  title = {Fascism and {{Big Business}}},
  author = {Guerin, Daniel},
  translator = {Merrill, Frances and Merrill, Mason},
  year = {1973},
  publisher = {{Pathfinder Press}},
  address = {{Canada}},
  urldate = {2022-12-19},
  isbn = {978-0-87348-878-5},
  file = {Politics/Marxism/Guerin, 1973 - Fascism and Big Business.pdf}
}

@incollection{gunzel2019,
  title = {What {{Do They Represent}}? {{Computer Games}} as {{Spatial Concepts}}},
  booktitle = {Ludotopia: {{Spaces}}, {{Places}} and {{Territories}} in {{Computer Games}}},
  author = {G{\"u}nzel, Stephan},
  editor = {Aarseth, Espen and G{\"u}nzel, Stephan},
  year = {2019},
  month = sep,
  series = {Edition {{Medienwissenschaft}}},
  edition = {1},
  volume = {63},
  publisher = {{transcript Verlag}},
  address = {{Bielefeld, Germany}},
  urldate = {2022-09-30},
  abstract = {Where do computer games {\guillemotright}happen{\guillemotleft}? The articles collected in this pioneering volume explore the categories of {\guillemotright}space{\guillemotleft}, {\guillemotright}place{\guillemotleft} and {\guillemotright}territory{\guillemotleft} featuring in most general theories of space to lay the groundwork for the study of spatiality in games. Shifting the focus away from earlier debates on, e.g., the narrative nature of games, this collection proposes, instead, that thorough attention be given to the tension between experienced spaces and narrated places as well as to the mapping of both of these.},
  isbn = {978-3-8376-4730-3 978-3-8394-4730-7},
  langid = {english},
  file = {Philosophy/Space/GÃ¼nzel, 2019 - What Do They Represent.pdf},
  url = {https://doi.org/10.14361/9783839447307}
}

@article{gupta2018,
  title = {On the Use of Closed-Back Headphones for Active Hear-through Equalization in Augmented Reality Applications},
  author = {Gupta, Rishabh and Ranjan, Rishabh and He, Jianjun and Gan, Woon-Seng},
  year = {2018},
  pages = {12},
  abstract = {Augmented Reality (AR) audio refers to techniques where virtual sounds are superimposed with real sounds to produce immersive digital content. Headphones are widely used in consumer devices for playback of virtual sounds. However, for AR audio, an important step is to make sure that headphones allow external sounds to pass through naturally. To achieve this, a technique called Hear-Through (HT) processing is commonly employed to reproduce the incoming real sound by playing back processed version of it. In this context, open-back and headphones and closed in-ear headphones have been employed for HT processing. Closed-back headphones provide strong isolation unlike open-back headphones and do not have fittings issue as well as modified ear canal resonance effect found in closed in-ear headphones. In this paper, an investigation of HT design using closed-back circumaural headphones equipped with two pairs of microphones was conducted. An adaptive filtering algorithm was used to derive the ideal equalization filter. To alleviate the direction dependency of the ideal equalization filter and simplify HT filter design, two simplified equalization filters were also introduced. Experiments with objective evaluation using spectral difference and subjective evaluation on both timbre and spatial performance were conducted. These experimental results indicate a close match of the ideal equalized signal with the reference signal in open ear listening, which is slightly degraded in the simplified equalization filters, but outperforms the default ambient hear-through mode in the commercial headphones.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/gupta2018.md;Human Computer Interaction/Augmented Reality/Gupta et al., 2018 - On the use of closed-back headphones for active hear-through equalization in.pdf}
}

@inproceedings{guzman-serrano2019,
  title = {Where {{There Are Flies}}, {{Media Art You}}'ll {{Find}}: {{Digital}} ({{Im}})Materiality, {{Artistic Medium}}, and {{Media Art Decay}}},
  shorttitle = {Where {{There Are Flies}}, {{Media Art You}}'ll {{Find}}},
  booktitle = {Proceedings of the 9th {{International Conference}} on {{Digital}} and {{Interactive Arts}}},
  author = {{Guzman-Serrano}, Rodrigo},
  year = {2019},
  month = oct,
  pages = {1--7},
  publisher = {{ACM}},
  address = {{Braga Portugal}},
  urldate = {2020-06-11},
  abstract = {The digital revolution has already left its footprint in the cultural industry by not only introducing new aesthetics and art forms, but also by crucially transforming the practices of museums, libraries, archives, and cultural institutions in general. However, although most museums rely on the use of digital technologies in one way or another, few actively collect and preserve media and digital art. This apparent contradiction has not only endangered the future availability of specific artworks but it has also impeded the proper contextualization and historicization of media art.},
  isbn = {978-1-4503-7250-3},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/guzman-serrano2019.md;Philosophy/Materiality/Guzman-Serrano, 2019 - Where There Are Flies, Media Art You'll Find.pdf},
  url = {https://doi.org/10.1145/3359852.3359903}
}

@inproceedings{hafidh2013,
  title = {F-{{Glove}}: {{A}} Glove with Force-Audio Sensory Substitution System for Diabetic Patients},
  shorttitle = {F-{{Glove}}},
  booktitle = {2013 {{IEEE International Symposium}} on {{Haptic Audio Visual Environments}} and {{Games}} ({{HAVE}})},
  author = {Hafidh, Basim and Osman, Hussein Al and Alowaidi, Majed and {El-Saddik}, Abdulmotaleb and Liu, Xiaoping P.},
  year = {2013},
  month = oct,
  pages = {34--38},
  publisher = {{IEEE}},
  address = {{Istanbul, Turkey}},
  urldate = {2020-10-03},
  abstract = {Some diabetic patients experience difficulties in modulating the grip force magnitude when they manipulate objects using their hands. This difficulty is caused by the sensory loss at the fingertips that impairs the feedback loop between the brain and the aforementioned sensors. In this paper, we present a sensory substitution system called ``F-Glove'', which is aimed at helping diabetic patients to manipulate objects more efficiently by using appropriate forces. This is achieved by substituting the force felt at the fingertips when grip an object with an audio feedback displayed through the earphones of a mobile phone. The patient wears a glove integrated with pressure sensors mounted on the fingertips, and the sensors' pressure signals are conditioned and wirelessly transmitted to a mobile phone interface to display an audio with a volume linearly proportional to the pressure applied by the fingers of patients.},
  isbn = {978-1-4799-0849-3 978-1-4799-0848-6},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hafidh2013.md;Human Computer Interaction/Multisensory Interfacing/Hafidh et al., 2013 - F-Glove.pdf},
  url = {https://doi.org/10.1109/HAVE.2013.6679607}
}

@inproceedings{hashizume2018,
  title = {Trans-Scale {{Playground}}: {{An Immersive Visual Telexistence System}} for {{Human Adaptation}}},
  shorttitle = {Trans-Scale {{Playground}}},
  booktitle = {The 31st {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology Adjunct Proceedings}}},
  author = {Hashizume, Satoshi and Ishii, Akira and Suzuki, Kenta and Takazawa, Kazuki and Ochiai, Yoichi},
  year = {2018},
  pages = {66--68},
  publisher = {{ACM}},
  address = {{Berlin Germany}},
  urldate = {2021-05-15},
  abstract = {In this paper, we present a novel telexistence system and design methods for telexistence studies to explore spatialscale deconstruction. There have been studies on the experience of dwarf-sized or giant-sized telepresence have been conducted over a period of many years. In this study, we discuss the scale of movements, image transformation, technical components of telepresence robots, and user experiences of telexistence-based spatial transformations. We implemented two types of telepresence robots with an omnidirectional stereo camera setup for a spatial trans-scale experience, wheeled robots, and quadcopters. These telepresence robots provide users with a trans-scale experience for a distance ranging from 15 cm to 30 m. We conducted user studies for different camera positions on robots and for different image transformation method.},
  isbn = {978-1-4503-5949-8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hashizume2018.md;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/Trans-scale Playground An Immersive Visual Telexistence System for Human Adaptation.md;Human Computer Interaction/Augmented Reality/Hashizume et al., 2018 - Trans-scale Playground.pdf},
  url = {https://doi.org/10.1145/3266037.3266103}
}

@article{hayes2011,
  title = {Vibrotactile {{Feedback-Assisted Performance}}},
  author = {Hayes, Lauren},
  year = {2011},
  pages = {4},
  abstract = {When performing digital music it is important to be able to acquire a comparable level of sensitivity and control to what can be achieved with acoustic instruments. By examining the links between sound and touch, new compositional and performance strategies start to emerge for performers using digital instruments1. These involve technological implementations utilizing the haptic2 information channels, oâ†µering insight into how our tacit knowledge of the physical world can be introduced to the digital domain, enforcing the view that sound is a `species of touch' [14].},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hayes2011.md;Human Computer Interaction/Augmented Reality/Hayes, 2011 - Vibrotactile Feedback-Assisted Performance.pdf}
}

@inproceedings{hayes2018,
  title = {Live {{Electronic Music Performance}}: {{Embodied}} and {{Enactive Approaches}}},
  shorttitle = {Live {{Electronic Music Performance}}},
  booktitle = {Proceedings of the 5th {{International Conference}} on {{Movement}} and {{Computing}}},
  author = {Hayes, Lauren},
  year = {2018},
  month = jun,
  pages = {1--3},
  publisher = {{ACM}},
  address = {{Genoa Italy}},
  urldate = {2020-06-15},
  abstract = {Mini Savior Opt. (2017) is a twenty-five minute live electronic performance which demonstrates an enactive and embodied approach to interactive and improvisational music systems. The piece was formed out of a playful exploration of my most recent hybrid analogue/digital performance system. An excessive number of components mutually affect each other through an ecological network of sound analysis and digital signal processing (DSP). Engaging with different parts of the instrument through tangible and haptic controllers, I bring a sense of immediacy into my hands: the slightest movement may trigger a drastic change in sound, which in turn may activate other processes within the network. Through the physical struggle, the performer, vulnerable to the fragile instabilities that have been potentialised, attempts to navigate the performance space.},
  isbn = {978-1-4503-6504-8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hayes2018.md;Arts & Humanities/Computational Art/Hayes, 2018 - Live Electronic Music Performance.pdf},
  url = {https://doi.org/10.1145/3212721.3212891}
}

@article{hayes2019,
  title = {Beyond {{Skill Acquisition}}: {{Improvisation}}, {{Interdisciplinarity}}, and {{Enactive Music Cognition}}},
  shorttitle = {Beyond {{Skill Acquisition}}},
  author = {Hayes, Lauren},
  year = {2019},
  month = sep,
  journal = {Contemporary Music Review},
  volume = {38},
  number = {5},
  pages = {446--462},
  issn = {0749-4467, 1477-2256},
  urldate = {2022-08-24},
  langid = {english},
  file = {Arts & Humanities/Computational Art/Hayes, 2019 - Beyond Skill Acquisition.pdf},
  url = {https://doi.org/10.1080/07494467.2019.1684059}
}

@article{hennion1983,
  title = {The Production of Success: An Anti-Musicology of the Pop Song},
  shorttitle = {The Production of Success},
  author = {Hennion, Antoine},
  year = {1983},
  month = jan,
  journal = {Popular Music},
  volume = {3},
  pages = {159},
  issn = {0261-1430, 1474-0095},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hennion1983.md}
}

@article{hesmondhalgh1998,
  title = {The {{British Dance Music Industry}}: {{A Case Study}} of {{Independent Cultural Production}}},
  shorttitle = {The {{British Dance Music Industry}}},
  author = {Hesmondhalgh, David},
  year = {1998},
  month = jun,
  journal = {The British Journal of Sociology},
  volume = {49},
  number = {2},
  eprint = {591311},
  eprinttype = {jstor},
  pages = {234},
  issn = {00071315},
  urldate = {2020-01-10},
  abstract = {This article analyses the British dance music industry and assesses claims that it offers a powerful alternative to the 'mainstream' music business. Two unusual features of the sector are identified. Whereas the recording industry as a whole is marked by concentration and centralization, the UK dance music industry is relatively decentralized and is made up of large numbers of 'independent' companies. Reasons for the success of small, local companies are offered, in particular the emphasis amongst dance audiences on genre, rather than on performer identity; and the low promotional costs enabled by negative press coverage of 'acid house' in the late 1980s. But the article argues that a number of features of the British dance music industry work against a view of the sector as a radical challenge to prevailing cultural-industry practices. These are as follows: firstly, the reliance of dance music companies on crossover hits and compilation albums; secondly, close ties between the independents and corporate partners; and thirdly, the pressures placed upon small companies to follow the standard ways of dealing with risk in the recording industry- in particular, the development of a star system.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hesmondhalgh1998.md;Arts & Humanities/Musicology/Hesmondhalgh, 1998 - The British Dance Music Industry.pdf},
  url = {https://doi.org/10.2307/591311}
}

@book{holland2019,
  title = {New {{Directions}} in {{Music}} and {{Human-Computer Interaction}}},
  editor = {Holland, Simon and Mudd, Tom and {Wilkie-McKenna}, Katie and McPherson, Andrew and Wanderley, Marcelo M.},
  year = {2019},
  series = {Springer {{Series}} on {{Cultural Computing}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  url = {https://doi.org/10.1007/978-3-319-92069-6},
  urldate = {2020-09-22},
  isbn = {978-3-319-92068-9 978-3-319-92069-6},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/holland2019.md;Arts & Humanities/Computational Art/Holland et al., 2019 - New Directions in Music and Human-Computer Interaction.pdf}
}

@incollection{hollerer2004,
  title = {Mobile {{Augmented Reality}}},
  booktitle = {Telegeoinformatics: {{Location-Based Computing}} and {{Services}}},
  author = {H{\"o}llerer, T. and Feiner, S.},
  year = {2004},
  month = mar,
  edition = {1},
  publisher = {{CRC Press}},
  url = {https://www.taylorfrancis.com/books/9780203501078},
  urldate = {2020-01-10},
  isbn = {978-0-203-50107-8},
  langid = {english},
  file = {../../../../../../../../C\:\\Users\\Sam Bilbow\\OneDrive\\Literature\\Human Computer Interaction\\Augmented Reality\\HÃ¶llerer and Feiner, 2004 - Mobile Augmented Reality.pdf;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hollerer2004.md}
}

@article{holloway-attaway2014,
  title = {Performing Materialities: {{Exploring}} Mixed Media Reality and {{{\emph{Moby-Dick}}}}},
  shorttitle = {Performing Materialities},
  author = {{Holloway-Attaway}, Lissa},
  year = {2014},
  month = feb,
  journal = {Convergence: The International Journal of Research into New Media Technologies},
  volume = {20},
  number = {1},
  pages = {55--68},
  issn = {1354-8565, 1748-7382},
  urldate = {2020-05-27},
  abstract = {In my research, I explore mixed reality applications developed to engage and sustain collaborative and participatory digital narratives. In particular, I provide a theoretical context for a collaborative research project, The (re-)Mapping Moby Project, to illustrate how augmented reality tools and social media applications are used to sustain a critical/creative reading of Herman Melville's 1851 work Moby-Dick through participatory, performative, and locative digital practices. I address how both `texts' and `bodies' assume ontological properties through interfaces and responses that foreground affect, and I demonstrate methods to map locative and narrative shifts as they move from print to digital forms.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/holloway-attaway2014.md;Human Computer Interaction/Augmented Reality/Holloway-Attaway, 2014 - Performing materialities.pdf},
  url = {https://doi.org/10.1177/1354856513514337}
}

@book{hooks1994,
  title = {Teaching to {{Transgress}}},
  author = {Hooks, Bell},
  year = {1994},
  publisher = {{Taylor \& Francis Group}},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Fleeting Notes/Teaching to Transgress.md;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hooks1994.md;Pedagogy/Hooks, 1994 - Teaching to Transgress.pdf}
}

@incollection{hovhannisyan2019,
  title = {Enacting {{Virtual Reality}}: {{The Philosophy}} and {{Cognitive Science}} of {{Optimal Virtual Experience}}},
  shorttitle = {Enacting {{Virtual Reality}}},
  booktitle = {Augmented {{Cognition}}},
  author = {Hovhannisyan, Garri and Henson, Anna and Sood, Suraj},
  editor = {Schmorrow, Dylan D. and Fidopiastis, Cali M.},
  year = {2019},
  volume = {11580},
  pages = {225--255},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  url = {https://doi.org/10.1007/978-3-030-22419-6_17},
  urldate = {2022-08-18},
  abstract = {The standard approach to immersive virtual reality (VR) is arguably ``object-centric'' in that it aims to design physically realistic virtual experiences. This article deems the object-centric approach both philosophically and theoretically problematic and builds up to an alternative, ``action-predicated'' approach, whose aim is to simulate virtual experiences with a primary emphasis on pragmatic functionality instead. Section 1 lays out the rationale of the article and provides an outline for its general structure. Section 2 illustrates the nature of the problem being tackled and articulates a philosophically motivated critique, demonstrating the necessary limitations of the standard approach, as well as the need for an alternative. Section 3 draws on the enactive approach to cognitive science and begins the formulation of such an alternative. Section 4 completes the turn toward an action-predicated approach and argues, in particular, for a flow-based conception of immersive VR experience. Section 5 systematically discusses the methodological implications of the theoretical merits of this article by examining a design probe, Wake, conducted on participants (N = 25) in a mixed reality (MR) setting. Finally, Section 6 constitutes the conclusion of this article, wherein its philosophical, theoretical, and methodological efforts, as well as possible avenues for future research, are briefly noted.},
  isbn = {978-3-030-22418-9 978-3-030-22419-6},
  langid = {english},
  file = {Human Computer Interaction/Virtual Reality/Hovhannisyan et al., 2019 - Enacting Virtual Reality.pdf}
}

@misc{htc2020,
  title = {{{VIVE}}},
  author = {HTC},
  year = {2020},
  url = {https://www.vive.com/uk/product/},
  urldate = {2020-07-12},
  abstract = {Whether it's for gaming or business, discover the ideal VIVE device for you, and learn more about what features should be included in a high-end VR solution.},
  file = {../../../../../Zotero/storage/6UNN9RA9/product.html}
}

@book{huber2013,
  title = {Modern {{Recording Techniques}}},
  author = {Huber, David Miles and Runstein, Robert E.},
  year = {2013},
  month = aug,
  publisher = {{CRC Press}},
  abstract = {As the most popular and authoritative guide to recording Modern Recording Techniques provides everything you need to master the tools and day to day practice of music recording and production. From room acoustics and running a session to mic placement and designing a studio Modern Recording Techniques will give you a really good grounding in the theory and industry practice. Expanded to include the latest digital audio technology the 7th edition now includes sections on podcasting, new surround sound formats and HD and audio.If you are just starting out or looking for a step up in industry, Modern Recording Techniques provides an in depth excellent read- the must have book},
  isbn = {978-1-136-11782-4},
  langid = {english},
  keywords = {Computers / Digital Media / Audio,Music / General,Music / Recording \& Reproduction,Technology \& Engineering / Acoustics \& Sound,TECHNOLOGY \& ENGINEERING / Mechanical},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/huber2013.md}
}

@book{hugill2018,
  title = {The {{Digital Musician}}},
  author = {Hugill, Andrew},
  year = {2018},
  edition = {Third edition},
  publisher = {{Routledge}},
  address = {{New York ; London}},
  isbn = {978-0-203-70421-9},
  langid = {english},
  lccn = {ML3876},
  keywords = {Computer music,History and criticism,Instruction and study,Music,Philosophy and aesthetics},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hugill2018.md;Arts & Humanities/Computational Art/Hugill, 2018 - The Digital Musician.pdf}
}

@article{hutmacher2019,
  title = {Why {{Is There So Much More Research}} on {{Vision Than}} on {{Any Other Sensory Modality}}?},
  author = {Hutmacher, Fabian},
  year = {2019},
  month = oct,
  journal = {Frontiers in Psychology},
  volume = {10},
  pages = {2246},
  issn = {1664-1078},
  urldate = {2020-05-26},
  abstract = {Why is there so much more research on vision than on any other sensory modality? There is a seemingly easy answer to this question: It is because vision is our most important and most complex sense. Although there are arguments in favor of this explanation, it can be challenged in two ways: by showing that the arguments regarding the importance and complexity of vision are debatable and by demonstrating that there are other aspects that need to be taken into account. Here, I argue that the explanation is debatable, as there are various ways of defining ``importance'' and ``complexity'' and, as there is no clear consensus that vision is indeed the most important and most complex of our senses. Hence, I propose two additional explanations: According to the methodological-structural explanation, there is more research on vision because the available, present-day technology is better suited for studying vision than for studying other modalities {\textendash} an advantage which most likely is the result of an initial bias toward vision, which reinforces itself. Possible reasons for such an initial bias are discussed. The cultural explanation emphasizes that the dominance of the visual is not an unchangeable constant, but rather the result of the way our societies are designed and thus heavily influenced by human decision-making. As it turns out, there is no universal hierarchy of the senses, but great historical and cross-cultural variation. Realizing that the dominance of the visual is socially and culturally reinforced and not simply a law of nature, gives us the opportunity to take a step back and to think about the kind of sensory environments we want to create and about the kinds of theories that need to be developed in research.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hutmacher2019.md;Cognitive Science/Multisensory Integration/Hutmacher, 2019 - Why Is There So Much More Research on Vision Than on Any Other Sensory Modality.pdf},
  url = {https://doi.org/10.3389/fpsyg.2019.02246}
}

@book{hutto2017,
  title = {Evolving Enactivism: Basic Minds Meet Content},
  shorttitle = {Evolving Enactivism},
  author = {Hutto, Daniel D. and Myin, Erik},
  year = {2017},
  publisher = {{MIT Press}},
  address = {{Cambridge, Massachusetts}},
  isbn = {978-0-262-03611-5},
  lccn = {BD418.3 .H88 2017},
  keywords = {Act (Philosophy),Cognitive science,Content (Psychology),Intentionalism,Intentionality (Philosophy),Mental representation,Phenomenology,Philosophy of mind},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hutto2017.md}
}

@book{hutto2017a,
  title = {Radicalizing Enactivism: Basic Minds without Content},
  shorttitle = {Radicalizing Enactivism},
  author = {Hutto, Daniel D and Myin, Erik and {MIT Press}},
  year = {2017},
  publisher = {{MIT Press}},
  address = {{Cambridge, Massachusetts; London}},
  isbn = {978-0-262-01854-8 978-0-262-53464-2},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/hutto2017a.md}
}

@inproceedings{iber2019,
  title = {Auditory {{Augmented Reality}} for {{Cyber Physical Production Systems}}},
  booktitle = {Proceedings of the 14th {{International Audio Mostly Conference}}: {{A Journey}} in {{Sound}}},
  author = {Iber, Michael and Lechner, Patrik and Jandl, Christian and Mader, Manuel and Reichmann, Michael},
  year = {2019},
  month = sep,
  pages = {53--60},
  publisher = {{ACM}},
  address = {{Nottingham United Kingdom}},
  urldate = {2020-09-19},
  abstract = {We describe a proof-of-concept approach on the sonification of estimated operation states of 3D printing processes. The results of this study form the basis for the development of an ``intelligent'' noise protection headphone as part of Cyber Physical Production Systems, which provides auditorily augmented information to machine operators and enables radio communication between them. Further application areas are implementations in control rooms (equipped with multichannel loudspeaker systems) and utilization for training purposes. The focus of our research lies on situation-specific acoustic processing of conditioned machine sounds and operation related data with high information content, considering the often highly auditorily influenced working knowledge of skilled workers. As a proof-of-concept the data stream of error probability estimations regarding partly manipulated 3D printing processes was mapped to three sonification models, giving evidence about momentary operation states. The neural network applied indicates a high accuracy ({$>$}93\%) concerning error estimation distinguishing between normal and manipulated operation states. None of the manipulated states could be identified by listening. An auditory augmentation, respectively sonification of these error estimations provides a considerable benefit to process monitoring.},
  isbn = {978-1-4503-7297-8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/iber2019.md;Human Computer Interaction/Augmented Reality/Iber et al., 2019 - Auditory Augmented Reality for Cyber Physical Production Systems.pdf},
  url = {https://doi.org/10.1145/3356590.3356600}
}

@misc{ircam2014,
  title = {Leap {{Motion}} Skeletal Tracking in {{Max}}},
  author = {IRCAM},
  year = {2014},
  month = nov,
  journal = {Sound Music Movement Interaction - ISMM},
  url = {http://ismm.ircam.fr/leapmotion/},
  urldate = {2020-05-25},
  abstract = {We~developed a new object for using the Leap Motion in Max, based on~the Leap~Motion SDK V2~Skeletal Tracking~Beta.},
  langid = {english},
  file = {../../../../../Zotero/storage/RVSX4FD7/leapmotion.html}
}

@article{isaak2018,
  title = {User {{Data Privacy}}: {{Facebook}}, {{Cambridge Analytica}}, and {{Privacy Protection}}},
  shorttitle = {User {{Data Privacy}}},
  author = {Isaak, Jim and Hanna, Mina J.},
  year = {2018},
  month = aug,
  journal = {Computer},
  volume = {51},
  number = {8},
  pages = {56--59},
  issn = {1558-0814},
  abstract = {With the revelation that Facebook handed over personally identifiable information of more than 87 million users to Cambridge Analytica, it is now imperative that comprehensive privacy policy laws be developed. Technologists, researchers, and innovators should meaningfully contribute to the development of these policies.},
  keywords = {Cambridge Analytica,cybercrime,data privacy,data security,Facebook,Internet/Web technologies,online security,personally identifiable information,PII,privacy,privacy protection,security,social media,The Policy Corner,user data privacy},
  file = {Human Computer Interaction/Security & Privacy/Isaak and Hanna, 2018 - User Data Privacy.pdf;../../../../../Zotero/storage/ZUITMA7X/stamp.html},
  url = {https://doi.org/10.1109/MC.2018.3191268}
}

@inproceedings{jarvis2020,
  title = {Composing in Spacetime with Rainbows: {{Spatial}} Metacomposition in the Real World},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Jarvis, Robert and Verhagen, Darrin},
  year = {2020},
  series = {{{AM}} '20},
  pages = {175--182},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {There exists a long tradition of incorporating acoustic space as a creative parameter in musical composition and performance. This creative potential has been extended by way of modern sensing and computing technology which allows the position of the listener to act as an input to interactive musical works in immersive, digital environments. Furthermore, the sophistication of sensing technology has reached a point where barriers to implementing these digital interactive musical systems in the physical world are dissolving.In this research we have set out to understand what new modes of artistic performance might be enabled by these interactive spatial musical systems, and what the analysis of these systems can tell us about the compositional principles of arranging musical elements in space as well as time.We have applied a practice-based approach, leveraging processes of software development, composition, and performance to create a complete system for composing and performing what we refer to as spatial metacompositions. The system is tested at scale in the realisation of a musical work based upon the path of a sailplane in flight.Analysis of the work and the supporting system leads us to suggest opportunities exist for extending existing intermodal composition theory through the analysis of audiovisual renderings of performed spatial works. We also point to unique challenges posed by spatial arrangement, such as effective strategies for structuring musical notes in three dimensions as to produce strong harmonic movement.Beyond enabling new modes of artistic expression, the understanding garnered from these musical structures may help inform a more generalisable approach to non-linear composition, leveraging virtual representations of musical space that respond to arbitrary input data.},
  isbn = {978-1-4503-7563-4},
  keywords = {composition,flight,metacomposition,music,music technology,musical performance,performing arts,sonification},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/jarvis2020.md;Arts & Humanities/Computational Art/Jarvis and Verhagen, 2020 - Composing in spacetime with rainbows.pdf},
  url = {https://doi.org/10.1145/3411109.3411136}
}

@article{johnson2017,
  title = {{{VRMin}}: {{Using Mixed Reality}} to {{Augment}} the {{Theremin}} for {{Musical Tutoring}}},
  author = {Johnson, David and Tzanetakis, George},
  year = {2017},
  pages = {6},
  abstract = {The recent resurgence of Virtual Reality (VR) technologies provide new platforms for augmenting traditional music instruments. Instrument augmentation is a common approach for designing new interfaces for musical expression, as shown through hyperinstrument research. New visual affordances present in VR give designers new methods for augmenting instruments to extend not only their expressivity, but also their capabilities for computer assisted tutoring. In this work, we present VRMin, a mobile Mixed Reality (MR) application for augmenting a physical theremin, with an immersive virtual environment (VE), for real time computer assisted tutoring. We augment a physical theremin with 3D visual cues to indicate correct hand positioning for performing given notes and volumes. The physical theremin acts as a domain specific controller for the resulting MR environment. The initial effectiveness of this approach is measured by analyzing a performer's hand position while training with and without the VRMin. We also evaluate the usability of the interface using heuristic evaluation based on a newly proposed set of guidelines designed for VR musical environments.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/johnson2017.md;Human Computer Interaction/Virtual Reality/Johnson and Tzanetakis, 2017 - VRMin.pdf}
}

@article{julier2000,
  title = {{{BARS}}: {{Battlefield Augmented Reality System}}},
  author = {Julier, Simon and Baillot, Yohan and Lanzagorta, Marco and Brown, Dennis and Rosenblum, Lawrence},
  year = {2000},
  pages = {8},
  abstract = {Many future military operations are expected to occur in urban environments. These complex, 3D battlefields are extremely demanding and introduce many challenges to the dismounted warfighter. These include limited visibility, lack of familiarity with the environment, sniper threats, concealment of enemy forces, ineffective communications, and a general problem of locating and identifying enemy and friendly forces. Better situational awareness is required for effective operation in the urban environment.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/julier2000.md;Human Computer Interaction/Augmented Reality/Julier et al., 2000 - BARS.pdf}
}

@article{jung2011,
  title = {Form and {{Materiality}} in {{Interaction Design}}: {{A New Approach}} to {{HCI}}},
  author = {Jung, Heekyoung and Stolterman, Erik},
  year = {2011},
  pages = {10},
  abstract = {This paper is motivated by the increasing significance of form in design and use of interactive artifacts. The objective of this paper is to conceptualize what we mean by form in the context of interaction design and HCI research and how we can approach it in regard to emerging type of digital materiality. To do this, we first examine conceptual dimensions of form in interactive artifacts through the lens of three existing perspectives with their respective focus on: material, meaning, and making. We then apply these perspectives in our analysis of specific forms of interactive artifacts. Based on this analysis, we suggest a model of four different types of forms: the cognitive, embodied, expressive, and exploratory forms. Reflecting on this model, we propose form-driven interaction design research with its epistemological and methodological implications.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/jung2011.md;Philosophy/Materiality/Jung and Stolterman, 2011 - Form and Materiality in Interaction Design.pdf}
}

@inproceedings{jung2011a,
  title = {Material Probe: Exploring Materiality of Digital Artifacts},
  shorttitle = {Material Probe},
  booktitle = {Proceedings of the Fifth International Conference on {{Tangible}}, Embedded, and Embodied Interaction - {{TEI}} '11},
  author = {Jung, Heekyoung and Stolterman, Erik},
  year = {2011},
  pages = {153},
  publisher = {{ACM Press}},
  address = {{Funchal, Portugal}},
  urldate = {2020-05-25},
  abstract = {We present an approach for exploring materiality of digital artifacts by suggesting a study method{\textemdash}material probe. The purpose with the method is to understand how people perceive material qualities of artifacts and to discuss how designers could intentionally and methodologically include such non-functional user desires related to material qualities in the design of digital artifacts. The study procedure and results from preliminary studies are described with their implications for future work.},
  isbn = {978-1-4503-0478-8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/jung2011a.md;Philosophy/Materiality/Jung and Stolterman, 2011 - Material probe.pdf},
  url = {https://doi.org/10.1145/1935701.1935731}
}

@inproceedings{jung2012,
  title = {Digital Form and Materiality: Propositions for a New Approach to Interaction Design Research},
  shorttitle = {Digital Form and Materiality},
  booktitle = {Proceedings of the 7th {{Nordic Conference}} on {{Human-Computer Interaction Making Sense Through Design}} - {{NordiCHI}} '12},
  author = {Jung, Heekyoung and Stolterman, Erik},
  year = {2012},
  pages = {645},
  publisher = {{ACM Press}},
  address = {{Copenhagen, Denmark}},
  urldate = {2020-05-25},
  abstract = {Advanced information and interaction technology pervades everyday life, introducing new forms and meanings of computer applications beyond desktop computers{\textemdash}from varying types of digital devices to interactive fashion and architecture. Motivated by the notion of digital technology as a material for interaction design, this research aims to develop a theoretical foundation to create and critique digital artifacts in the context of interaction design and HCI research. Specifically we conceptualize digital form and materiality as two reciprocal aspects of digital artifact based on the perspectives from relevant disciplines including design, arts, craft, material culture and philosophy of technology. The conceptualization emphasizes the process of making, personal meanings, and socio-cultural values of digital artifacts, constructing a new theoretical framework for exploratory and critical research approaches. In the end we discuss a proposal for form-driven interaction design research as a new approach to HCI with its focus on form and materiality aspects of digital artifacts based on the reflection on our theoretical propositions.},
  isbn = {978-1-4503-1482-4},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/jung2012.md;Philosophy/Materiality/Jung and Stolterman, 2012 - Digital form and materiality.pdf},
  url = {https://doi.org/10.1145/2399016.2399115}
}

@misc{jurgenson2011,
  title = {Digital {{Dualism}} versus {{Augmented Reality}} - {{Cyborgology}}},
  author = {Jurgenson, Nathan},
  year = {2011},
  month = feb,
  url = {https://thesocietypages.org/cyborgology/2011/02/24/digital-dualism-versus-augmented-reality/},
  urldate = {2022-12-22},
  abstract = {The Society Pages (TSP) is an open-access social science project headquartered in the Department of Sociology at the University of Minnesota},
  langid = {english},
  file = {../../../../../Zotero/storage/F6ISLUVR/digital-dualism-versus-augmented-reality.html}
}

@inproceedings{kalkusch2002,
  title = {Structured Visual Markers for Indoor Pathfinding},
  booktitle = {The {{First IEEE International Workshop Agumented Reality Toolkit}},},
  author = {Kalkusch, M. and Lidy, T. and Knapp, N. and Reitmayr, G. and Kaufmann, H. and Schmalstieg, D.},
  year = {2002},
  pages = {8},
  publisher = {{IEEE}},
  address = {{Darmstadt, Germany}},
  urldate = {2021-04-09},
  abstract = {We present a mobile augmented reality (AR) system to guide a user through an unfamiliar building to a destination room. The system presents a world-registered wire frame model of the building labeled with directional information in a see-through heads-up display, and a three-dimensional world-in-miniature (WIM) map on a wrist-worn pad that also acts as an input device. Tracking is done using a combination of wall-mounted ARToolkit markers observed by a head-mounted camera, and an inertial tracker. To allow coverage of arbitrarily large areas with a limited set of markers, a structured marker re-use scheme based on graph coloring has been developed.},
  isbn = {978-0-7803-7680-9},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kalkusch2002.md;Human Computer Interaction/Augmented Reality/Kalkusch et al., 2002 - Structured visual markers for indoor pathfinding.pdf},
  url = {https://doi.org/10.1109/ART.2002.1107018}
}

@misc{kane2022,
  title = {Metaverse {{Meltdown}}: {{Top Metaverse Lands Lose}} 91\% {{Value}}},
  shorttitle = {Metaverse {{Meltdown}}},
  author = {Kane, Ian},
  year = {2022},
  month = aug,
  journal = {DappRadar},
  url = {https://archive.today/bcG3n},
  urldate = {2022-09-12},
  abstract = {The land may be virtual, but the pain is real},
  langid = {english},
  file = {../../../../../Zotero/storage/68MYRV7U/metaverse-meltdown-top-metaverse-lands-lose-91-value.html}
}

@article{kania2006,
  title = {Making {{Tracks}}: {{The Ontology}} of {{Rock Music}}},
  shorttitle = {Making {{Tracks}}},
  author = {Kania, Andrew},
  year = {2006},
  month = sep,
  journal = {Journal of Aesthetics and Art Criticism},
  volume = {64},
  number = {4},
  pages = {401--414},
  issn = {0021-8529, 1542-6245},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kania2006.md;Arts & Humanities/Musicology/Kania, 2006 - Making Tracks.pdf},
  url = {https://doi.org/10.1111/j.1540-594X.2006.00219.x}
}

@inproceedings{karunanayaka2021,
  title = {Multisensory {{Augmented Reality}}},
  booktitle = {Human-{{Computer Interaction}} {\textendash} {{INTERACT}} 2021},
  author = {Karunanayaka, Kasun and Nijholt, Anton and Halloluwa, Thilina and Ranasinghe, Nimesha and Wickramasinghe, Manjusri and Vyas, Dhaval},
  editor = {Ardito, Carmelo and Lanzilotti, Rosa and Malizia, Alessio and Petrie, Helen and Piccinno, Antonio and Desolda, Giuseppe and Inkpen, Kori},
  year = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {558--563},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {Multisensory augmented reality enables content developers to generate more realistic, sensory rich user experiences. Applications and research related to multisensory augmented reality expands through several areas such as education, medicine, human-machine interactions, human-food interactions, marketing, and neuroscience. Aim of this workshop is to gather researchers and industry representatives who are involved in multisensory augmented reality research to discuss the current state-of-the-art in the field, define future research directions, form new collaborations, and come up with future publication plans. We believe that this workshop would enhance the participants' experience of the Interact 2021 and encourage more participants to attend the main conference.},
  isbn = {978-3-030-85607-6},
  langid = {english},
  keywords = {HCI,Multimodal interfaces,Multisensory augmented reality,Multisensory internet,Multisensory user experiences},
  url = {https://doi.org/10.1007/978-3-030-85607-6_77}
}

@inproceedings{kato1999,
  title = {Marker Tracking and {{HMD}} Calibration for a Video-Based Augmented Reality Conferencing System},
  booktitle = {Proceedings 2nd {{IEEE}} and {{ACM International Workshop}} on {{Augmented Reality}} ({{IWAR}}'99)},
  author = {Kato, H. and Billinghurst, M.},
  year = {1999},
  pages = {85--94},
  publisher = {{IEEE Comput. Soc}},
  address = {{San Francisco, CA, USA}},
  urldate = {2021-04-17},
  abstract = {We describe an augmented reality conferencing system which uses the overlay of virtual images on the real world. Remote collaborators are represented on Virtual Monitors which can be freely positioned about a user in space. Users can collaboratively view and interact with virtual objects using a shared virtual whiteboard. This is possible through precise virtual image registration using fast and accurate computer vision techniques and HMD calibration. We propose a method for tracking fiducial markers and a calibration method for optical see-through HMD based on the marker tracking.},
  isbn = {978-0-7695-0359-2},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kato1999.md;Human Computer Interaction/Augmented Reality/Kato and Billinghurst, 1999 - Marker tracking and HMD calibration for a video-based augmented reality.pdf},
  url = {https://doi.org/10.1109/IWAR.1999.803809}
}

@article{kendall2010,
  title = {Spatial {{Perception}} and {{Cognition}} in {{Multichannel Audio}} for {{Electroacoustic Music}}},
  author = {Kendall, Gary S.},
  year = {2010},
  month = dec,
  journal = {Organised Sound},
  volume = {15},
  number = {03},
  pages = {228--238},
  issn = {1355-7718, 1469-8153},
  urldate = {2020-02-12},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kendall2010.md;Arts & Humanities/Computational Art/Kendall, 2010 - Spatial Perception and Cognition in Multichannel Audio for Electroacoustic Music.pdf},
  url = {https://doi.org/10.1017/S1355771810000336}
}

@article{kendall2010a,
  title = {Meaning in {{Electroacoustic Music}} and the {{Everyday Mind}}},
  author = {Kendall, Gary S.},
  year = {2010},
  month = apr,
  journal = {Organised Sound},
  volume = {15},
  number = {01},
  pages = {63},
  issn = {1355-7718, 1469-8153},
  urldate = {2020-02-12},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kendall2010a.md;Arts & Humanities/Computational Art/Kendall, 2010 - Meaning in Electroacoustic Music and the Everyday Mind.pdf},
  url = {https://doi.org/10.1017/S1355771809990276}
}

@article{kendall2011,
  title = {Why {{Things Don}}'t {{Work}}: {{What}} You Need to Know about Spatial Audio},
  author = {Kendall, Gary S},
  year = {2011},
  pages = {4},
  abstract = {Composers engaged in the sonic arts have frequently found themselves attempting to use spatial audio in ways that didn't work as intended. Maybe more than any other facet of technological music, mastering spatial audio seems to involve a learning process in which one slowly discovers the things that work and those that don't. The purpose of this paper is to foster understanding of spatial audio through examples of practical problems. These problems reveal some general misconceptions about spatial hearing that explain why things go wrong. A particular lesson to be gleaned from this discussion is that there is no silver bullet for solving spatial audio problems, and every situation needs to be understood in its proper context.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kendall2011.md;Arts & Humanities/Computational Art/Kendall, 2011 - Why Things Don't Work.pdf}
}

@misc{kentish2020,
  title = {Murmurations over {{Brighton}} Pier at Sunset},
  author = {Kentish, Rhys},
  year = {2020},
  month = jan,
  url = {https://unsplash.com/photos/ExhIp8DuHD8},
  urldate = {2022-12-12},
  langid = {american},
  file = {../../../../../Zotero/storage/6PVPYYSD/ExhIp8DuHD8.html}
}

@inproceedings{kern2020,
  title = {The Influence of Mood Induction by Music or a Soundscape on Presence and Emotions in a Virtual Reality Park Scenario},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Kern, Angelika C. and Ellermeier, Wolfgang and Jost, Lina},
  year = {2020},
  series = {{{AM}} '20},
  pages = {233--236},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {Music and background sound are often used in virtual realities for creating an emotional atmosphere. The present study investigates how music or an ambient soundscape influence presence, the feeling of "being there", as well as positive and negative affect. Fifty-one subjects participated, taking a stroll through a virtual park presented via a head-mounted display while they were walking on a treadmill. Sound was varied within subjects in four audio conditions: In a randomized sequence, participants experienced silence, a nature soundscape and music of positive or negative valence. In addition, time of day (daytime vs. nighttime walk) in the virtual environment was varied between subjects. Afterwards they were asked to rate their experience of presence and the positive and negative affect experienced. Results indicated that replaying any kind of sound lead to higher presence ratings compared to no sound at all, but there was no difference between playing a soundscape or music. Background music, however, tended to induce the expected emotions, though somewhat dependent on the musical pieces chosen. Further studies might evaluate whether it is possible to induce emotions through positive or negative (non-musical) soundscapes as well.},
  isbn = {978-1-4503-7563-4},
  keywords = {emotion,music,presence,soundscape,virtual reality},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kern2020.md;Arts & Humanities/Computational Art/Kern et al., 2020 - The influence of mood induction by music or a soundscape on presence and.pdf},
  url = {https://doi.org/10.1145/3411109.3411129}
}

@article{kerruish2019,
  title = {Arranging Sensations: Smell and Taste in Augmented and Virtual Reality},
  shorttitle = {Arranging Sensations},
  author = {Kerruish, Erika},
  year = {2019},
  month = jan,
  journal = {The Senses and Society},
  volume = {14},
  number = {1},
  pages = {31--45},
  issn = {1745-8927, 1745-8935},
  urldate = {2021-05-14},
  abstract = {The development of digital taste and smell underscores the importance of cultural dimensions of bodily perception in augmented reality (AR) and virtual reality (VR) devices. This can be seen in Vocktail and Season Traveller, two digital devices incorporating taste and smell. Vocktail is an AR technology that augments the experience of drinking water, or even air, through the electrical stimulation of tastebuds and the manipulation of color and smell. Season Traveller is a VR game in which the user moves through four seasonal landscapes. It uses wind, odor, and temperature in addition to the more standard audio-visual displays. The cultural dimensions of these devices can be examined using phenomenological terms. They instigate perceptual circuits, and call on and create sedimented habits. Although VR and AR are often thought of in terms of their similitude to reality, understanding Vocktail and Season Traveller this way illustrates the world-creating dimension of multisensory devices. These technologies structure and shift thresholds of taste and smell, reworking past perceptual styles and habits to develop new perceptual experiences. In so doing, Season Traveller and Vocktail throw to the fore questions about the conditions according to which people exercise their senses in digitally dominated environments.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kerruish2019.md;Human Computer Interaction/Augmented Reality/Kerruish, 2019 - Arranging sensations.pdf},
  url = {https://doi.org/10.1080/17458927.2018.1556952}
}

@misc{kershner1980,
  type = {Science {{Fiction}}},
  title = {The {{Empire Strikes Back}}},
  author = {Kershner, Irvin},
  year = {1980},
  publisher = {{20th Century Fox}}
}

@phdthesis{kiefer2012,
  title = {Multiparametric {{Interfaces For Fine-Grained Control}} of {{Digital Music}}},
  author = {Kiefer, Chris},
  year = {2012},
  langid = {english},
  school = {University of Sussex},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kiefer2012.md;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/Multiparametric Interfaces For Fine-Grained Control of Digital Music.md;Arts & Humanities/Computational Art/Kiefer, 2012 - Multiparametric Interfaces For Fine-Grained Control of Digital Music.pdf}
}

@inproceedings{kiefer2018,
  title = {Towards New Modes of Collective Musical Expression through Audio Augmented Reality},
  booktitle = {Proceedings of the {{International Conference}} on {{New Interfaces}} for {{Musical Expression}}},
  author = {Kiefer, Chris and Chevalier, C{\'e}cile},
  year = {2018},
  month = jun,
  pages = {25--28},
  address = {{Virginia, USA}},
  abstract = {We investigate how audio augmented reality can engender new collective modes of musical expression in the context of a sound art installation, Listening Mirrors, exploring the creation of interactive sound environments for musicians and non-musicians alike. Listening Mirrors is designed to incorporate physical objects and computational systems for altering the acoustic environment, to enhance collective listening and challenge traditional musician-instrument performance. At a formative stage in exploring audio AR technology, we conducted an audience experience study investigating questions around the potential of audio AR in creating sound installation environments for collective musical expression. We collected interview evidence about the participants' experience and analysed the data with using a grounded theory approach. The results demonstrated that the technology has the potential to create immersive spaces where an audience can feel safe to experiment musically, and showed how AR can intervene in sound perception to instrumentalise an environment. The results also revealed caveats about the use of audio AR, mainly centred on social inhibition and seamlessness of experience, and finding a balance between mediated worlds to create space for interplay between the two.},
  keywords = {augmented reality,collective musical expression,mobile music making,sound art installation},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kiefer2018.md;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/Towards new modes of collective musical expression through audio augmented reality.md;Human Computer Interaction/Augmented Reality/Kiefer and Chevalier, 2018 - Towards new modes of collective musical expression through audio augmented.pdf},
  url = {https://doi.org/10.5281/zenodo.1302661}
}

@article{kiefer2019,
  title = {Sample-Level Sound Synthesis with Recurrent Neural Networks and Conceptors},
  author = {Kiefer, Chris},
  year = {2019},
  journal = {PeerJ Computer Science},
  volume = {5},
  pages = {e205},
  issn = {2376-5992},
  urldate = {2020-01-10},
  abstract = {Conceptors are a recent development in the field of reservoir computing; they can be used to influence the dynamics of recurrent neural networks (RNNs), enabling generation of arbitrary patterns based on training data. Conceptors allow interpolation and extrapolation between patterns, and also provide a system of boolean logic for combining patterns together. Generation and manipulation of arbitrary patterns using conceptors has significant potential as a sound synthesis method for applications in computer music but has yet to be explored. Conceptors are untested with the generation of multi-timbre audio patterns, and little testing has been done on scalability to longer patterns required for audio. A novel method of sound synthesis based on conceptors is introduced. Conceptular Synthesis is based on granular synthesis; sets of conceptors are trained to recall varying patterns from a single RNN, then a runtime mechanism switches between them, generating short patterns which are recombined into a longer sound. The quality of sound resynthesis using this technique is experimentally evaluated. Conceptor models are shown to resynthesise audio with a comparable quality to a close equivalent technique using echo state networks with stored patterns and output feedback. Conceptor models are also shown to excel in their malleability and potential for creative sound manipulation, in comparison to echo state network models which tend to fail when the same manipulations are applied. Examples are given demonstrating creative sonic possibilities, by exploiting conceptor pattern morphing, boolean conceptor logic and manipulation of RNN dynamics.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kiefer2019.md;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/Sample-level sound synthesis with recurrent neural networks and conceptors.md;Arts & Humanities/Computational Art/Kiefer, 2019 - Sample-level sound synthesis with recurrent neural networks and conceptors.pdf},
  url = {https://doi.org/10.7717/peerj-cs.205}
}

@inproceedings{kiefer2020,
  title = {Shaping the Behaviour of Feedback Instruments with Complexity-Controlled Gain Dynamics},
  booktitle = {{{NIME}} 2020},
  author = {Kiefer, Chris and Overholt, Dan and Eldridge, Alice},
  year = {2020},
  pages = {6},
  publisher = {{New Interfaces for Musical Expression}},
  address = {{Birmingham, UK}},
  abstract = {Feedback instruments offer radical new ways of engaging with instrument design and musicianship. They are defined by recurrent circulation of signals through the instrument, which give the instrument `a life of its own' and a 'stimulating uncontrollability'. Arguably, the most interesting musical behaviour in these instruments happens when their dynamic complexity is maximised, without falling into saturating feedback. It is often challenging to keep the instrument in this zone; this research looks at algorithmic ways to manage the behaviour of feedback loops in order to make feedback instruments more playable and musical; to expand the `sweet spot'. We propose a solution that manages gain dynamics based on measurement of complexity, using a realtime implementation of the Effort to Compress algorithm. The system was evaluated with four musicians, all who have different variations of string-based feedback instruments, following an autobiographical design approach. Qualitative feedback was gathered, showing that the system was successful in modifying the behaviour of these instruments to allow easier access to edge transition zones, sometimes at the expense of losing some of the more compelling dynamics of the instruments. Basic efficacy of the system is evidenced by descriptive audio analysis. This paper is accompanied by a dataset of sounds collected during the study, and open source software that was written to support the research.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kiefer2020.md;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/Shaping the behaviour of feedback instruments with complexity-controlled gain dynamics.md;Arts & Humanities/Computational Art/Kiefer et al., 2020 - Shaping the behaviour of feedback instruments with complexity-controlled gain.pdf},
  url = {https://doi.org/10.5281/zenodo.4813406}
}

@article{kim2018,
  title = {Revisiting {{Trends}} in {{Augmented Reality Research}}: {{A Review}} of the 2nd {{Decade}} of {{ISMAR}} (2008{\textendash}2017)},
  shorttitle = {Revisiting {{Trends}} in {{Augmented Reality Research}}},
  author = {Kim, Kangsoo and Billinghurst, Mark and Bruder, Gerd and Duh, Henry Been-Lirn and Welch, Gregory F.},
  year = {2018},
  month = nov,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {24},
  number = {11},
  pages = {2947--2962},
  issn = {1077-2626, 1941-0506, 2160-9306},
  urldate = {2020-02-07},
  abstract = {In 2008, Zhou et al. presented a survey paper summarizing the previous ten years of ISMAR publications, which provided invaluable insights into the research challenges and trends associated with that time period. Ten years later, we review the research that has been presented at ISMAR conferences since the survey of Zhou et al., at a time when both academia and the AR industry are enjoying dramatic technological changes. Here we consider the research results and trends of the last decade of ISMAR by carefully reviewing the ISMAR publications from the period of 2008{\textendash}2017, in the context of the first ten years. The numbers of papers for different research topics and their impacts by citations were analyzed while reviewing them{\textemdash}which reveals that there is a sharp increase in AR evaluation and rendering research. Based on this review we offer some observations related to potential future research areas or trends, which could be helpful to AR researchers and industry members looking ahead.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kim2018.md;Human Computer Interaction/Augmented Reality/Kim et al., 2018 - Revisiting Trends in Augmented Reality Research.pdf},
  url = {https://doi.org/10.1109/TVCG.2018.2868591}
}

@article{kirchhoff2015,
  title = {Extended {{Cognition}} \& the {{Causal-Constitutive Fallacy}}: {{In Search}} for a {{Diachronic}} and {{Dynamical Conception}} of {{Constitution}}},
  shorttitle = {Extended {{Cognition}} \& the {{Causal-Constitutive Fallacy}}},
  author = {Kirchhoff, Michael D.},
  year = {2015},
  month = mar,
  journal = {Philosophy and Phenomenological Research},
  volume = {90},
  number = {2},
  pages = {320--360},
  issn = {00318205},
  urldate = {2021-06-14},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kirchhoff2015.md;Philosophy/Extended Cognition/Kirchhoff, 2015 - Extended Cognition & the Causal-Constitutive Fallacy.pdf},
  url = {https://doi.org/10.1111/phpr.12039}
}

@article{kirchhoff2020,
  title = {Attuning to the {{World}}: {{The Diachronic Constitution}} of the {{Extended Conscious Mind}}},
  shorttitle = {Attuning to the {{World}}},
  author = {Kirchhoff, Michael D. and Kiverstein, Julian},
  year = {2020},
  month = aug,
  journal = {Frontiers in Psychology},
  volume = {11},
  pages = {1966},
  issn = {1664-1078},
  urldate = {2021-06-14},
  abstract = {It is a near consensus among materialist philosophers of mind that consciousness must somehow be constituted by internal neural processes, even if we remain unsure quite how this works. Even friends of the extended mind theory have argued that when it comes to the material substrate of conscious experience, the boundary of skin and skull is likely to prove somehow to be privileged. Such arguments have, however, typically conceived of the constitution of consciousness in synchronic terms, making a firm separation between proximate mechanisms and their ultimate causes. We argue that the processes involved in the constitution of some conscious experiences are diachronic, not synchronic. We focus on what we call phenomenal attunement in this paper{\textemdash}the feeling of being at home in a familiar, culturally constructed environment. Such a feeling is missing in cases of culture shock. Phenomenal attunement is a structure of our conscious experience of the world that is ubiquitous and taken for granted. We will argue that it is constituted by cycles of embodied and world-involving engagement whose dynamics are constrained by cultural practices. Thus, it follows that an essential structure of the conscious mind, the absence of which profoundly transforms conscious experience, is extended.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kirchhoff2020.md;Philosophy/Extended Cognition/Kirchhoff and Kiverstein, 2020 - Attuning to the World.pdf},
  url = {https://doi.org/10.3389/fpsyg.2020.01966}
}

@article{klopfer2008,
  title = {Environmental {{Detectives}}{\textemdash}the Development of an Augmented Reality Platform for Environmental Simulations},
  author = {Klopfer, Eric and Squire, Kurt},
  year = {2008},
  month = apr,
  journal = {Educational Technology Research and Development},
  volume = {56},
  number = {2},
  pages = {203--228},
  issn = {1042-1629, 1556-6501},
  urldate = {2020-02-07},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/klopfer2008.md;Human Computer Interaction/Augmented Reality/Klopfer and Squire, 2008 - Environmental Detectivesâ€”the development of an augmented reality platform for.pdf},
  url = {https://doi.org/10.1007/s11423-007-9037-6}
}

@article{knight2016,
  title = {A {{Companion}} to {{Public Art}}},
  author = {Knight, Cher Krause},
  year = {2016},
  pages = {514},
  langid = {english},
  keywords = {â“ Multiple DOI},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/knight2016.md;Arts & Humanities/Computational Art/Knight, 2016 - A Companion to Public Art.pdf},
  url = {https://doi.org/10.1002/9781118475331}
}

@incollection{krueger1991,
  title = {Artificial Reality: {{Past}} and Future},
  booktitle = {Virtual {{Reality}} : {{Theory}}, {{Practice}}, and {{Promise}}},
  author = {Krueger, Myron W.},
  editor = {Helsel, Sandra K. and Roth, Judith Paris},
  year = {1991},
  publisher = {{Meckler, Westport}},
  isbn = {978-0-88736-728-1},
  keywords = {â›” No DOI found},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/krueger1991.md}
}

@book{kwastek2013,
  title = {Aesthetics of {{Interaction}} in {{Digital Art}}},
  author = {Kwastek, Katja},
  year = {2013},
  publisher = {{MIT Press}},
  isbn = {0-262-31722-2},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/kwastek2013a.md}
}

@book{landy2007,
  title = {Understanding the Art of Sound Organization},
  author = {Landy, Leigh},
  year = {2007},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-12292-4},
  langid = {english},
  lccn = {ML1380 .L28 2007},
  keywords = {Computer music,Electro-acoustics,Electronic music,History and criticism},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/landy2007.md;Arts & Humanities/Computational Art/Landy, 2007 - Understanding the art of sound organization.pdf}
}

@inproceedings{larrieux2022,
  title = {Augmented {{Objects}} as {{Portals}} into {{Virtual Worlds}}:{{Using Audio}} to {{Create Immersive Experiences}} in {{Extended Realities}}},
  shorttitle = {Augmented {{Objects}} as {{Portals}} into {{Virtual Worlds}}},
  booktitle = {Proceedings of the 17th {{International Audio Mostly Conference}}},
  author = {Larrieux, Eric and Speziali, Stella},
  year = {2022},
  month = oct,
  series = {{{AM}} '22},
  pages = {44--51},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  urldate = {2022-12-22},
  abstract = {Building on a long history of the integration of new technology into the arts, in this research we set out to develop and evaluate new methods for creating immersive, audio-centric artworks in a Mixed Reality (MR) context. We employ multiple levels of spatial audio, both within the room as well as the umbrellas that participants navigate the space with, in order to provide a 6 degree of freedom immersive experience. Furthermore, we use dynamic projection mapping, again both throughout the global environment, and on the umbrellas, to create immersive experiences. This allows the umbrellas to function as so-called Augmented Objects that facilitate the composition and navigation of Responsive Sonic Environments, thus encouraging participants to examine their own perceptions of reality while incorporating them into the larger artistic installation. Additionally, we explore the creation of Spatial Metacompositions, navigable environments that function as performance spaces for the participants who interact with them. Finally, we present the technical foundations necessary to create such systems and discuss techniques to effectively employ them in one's artistic practice.},
  isbn = {978-1-4503-9701-8},
  keywords = {ambisonics,Augmented objects,digital augmentation,embedded systems.,extended reality,immersion,interactive sonic art,mixed reality,projection mapping,responsive sonic environments,spatial audio,spatial augmented reality,spatial metacompositions},
  file = {Human Computer Interaction/Augmented Reality/Larrieux and Speziali, 2022 - Augmented Objects as Portals into Virtual Worlds.pdf},
  url = {https://doi.org/10.1145/3561212.3561243}
}

@book{latour2003,
  title = {Science in Action: How to Follow Scientists and Engineers through Society},
  shorttitle = {Science in Action},
  author = {Latour, Bruno},
  year = {2003},
  edition = {11. print},
  publisher = {{Harvard Univ. Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-674-79291-3},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/latour2003.md}
}

@book{latour2007,
  title = {Reassembling the Social: An Introduction to {{Actor-Network-Theory}}},
  shorttitle = {Reassembling the Social},
  author = {Latour, Bruno},
  year = {2007},
  series = {Clarendon Lectures in Management Studies},
  publisher = {{Oxford Univ. Press}},
  address = {{Oxford}},
  isbn = {978-0-19-925605-1 978-0-19-925604-4},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/latour2007.md}
}

@inproceedings{lawton2020,
  title = {Nature Soundscapes: {{An}} Audio Augmented Reality Experience},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Lawton, Mark and Cunningham, Stuart and Convery, Ian},
  year = {2020},
  series = {{{AM}} '20},
  pages = {85--92},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {Augmented Reality (AR) has developed to be a popular and exciting technology domain, gaining notable public interest from 2009 to the present day. AR applications have traditionally focused upon paradigms that are visually led. In this paper, we document an Audio Augmented Reality (AAR) project, which considers soundscapes and how they might be transformed via the application of music and sound technologies. This work is concerned with the augmentation of nature soundscapes and explores how this may be used to enhance public understanding of the natural world. At present, we are concerned with the augmentation of spaces with biophony. Two examples of acoustic augmented reality are described: an initial pilot study to investigate the feasibility of the approach and an installation at the Timber International Forest Festival 2019. A technical description of each is provided alongside our own reflection and participant feedback, garnered from a soundwalk inspired approach to evaluation by audiences at the festival.},
  isbn = {978-1-4503-7563-4},
  keywords = {augmented reality,nature,soundscapes},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/lawton2020.md;Human Computer Interaction/Augmented Reality/Lawton et al., 2020 - Nature soundscapes.pdf},
  url = {https://doi.org/10.1145/3411109.3411142}
}

@misc{leapmotion2015,
  title = {Touch {{Everything}} {\textendash} {{Leap Motion Gallery}}},
  author = {Leap Motion},
  year = {2015},
  url = {https://gallery.leapmotion.com/touch-everything/},
  urldate = {2020-07-22},
  file = {../../../../../Zotero/storage/5VZLZEDL/touch-everything.html}
}

@misc{leapmotion2016,
  title = {{{HTC Vive Setup}}},
  author = {Leap Motion},
  year = {2016},
  journal = {Leap Motion Developer},
  url = {https://archive.today/GQtAH},
  urldate = {2020-07-22},
  abstract = {The VR Developer Kit is available only from the  Leap Motion web store . This setup guide will get you started in minutes.   \_},
  langid = {american},
  file = {../../../../../Zotero/storage/JIZAGSF7/vive.html}
}

@misc{leapmotion2017,
  title = {Geco {{MIDI}} {\textendash} {{Leap Motion Gallery}}},
  author = {Leap Motion},
  year = {2017},
  url = {https://archive.today/3M1PX},
  urldate = {2020-07-22},
  file = {../../../../../Zotero/storage/KKLCMS4S/geco-midi.html}
}

@misc{leapmotion2018,
  title = {Project {{North Star}}},
  author = {Leap Motion},
  year = {2018},
  journal = {Leap Motion Developer},
  url = {https://developer.leapmotion.com/northstar},
  urldate = {2020-05-25},
  langid = {american},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/leapmotion2018.md;../../../../../Zotero/storage/7LB5G435/northstar.html}
}

@misc{leddy2021,
  title = {Dewey's {{Aesthetics}}},
  author = {Leddy, Tom and Puolakka, Kalle},
  year = {2021},
  journal = {The Stanford Encyclopedia of Philosophy},
  url = {https://archive.today/0BPFI},
  urldate = {2022-09-12},
  abstract = {John Dewey is, with Charles Sanders Peirce and William James, one ofthe leading early figures of the school of American Pragmatists. Hehas also had a great deal of influence in aesthetics and thephilosophy of art. His work Art as Experience (1934) isregarded by many as one of the most important contributions to thisarea in the twentieth century. The work is especially well-known forits full-blown treatment of aesthetic experience., Critical of attempts to limit aesthetic experience solely to thedomain of fine art, Art as Experience has had a highinfluence on trends in aesthetic research, which have sought tobroaden the scope of the field from the traditional arts to popularculture (Shusterman 1992, 2nd edition 2000), the naturalenvironment (Berleant 1997), and the everyday (Kupfer 1983, Saito2007, Stroud 2011, Leddy 2012). The work is also often seen as a keypart of Dewey's general late philosophical project, mostsystematically developed in Experience and Nature (1925), ofrethinking experience along naturalist lines as an interaction betweenthe organism and its environment as opposed to a discrete sensory unitsuch as stimulus, impression, idea, or sense-datum. Instead ofinvestigating how our senses are in touch with reality and whetherthey represent it correctly{\textemdash}which Dewey takes to be the frame ofmodern epistemology{\textemdash}Dewey's starting point, building onhis reading of Darwin's theory of evolution, is to look at theways in which experience is formed as a part of natural processes towhich the human being is fundamentally tied. For Dewey, aestheticexperience is the highest form of this interaction. It is the phasewhen, in Dewey's often used words, the interaction between theorganism and the environment reaches a stage of fulfillment. AlreadyExperience and Nature includes a chapter on aesthetics thethemes of which Dewey went on to develop in much greater depth anddetail in Art as Experience some ten years later. Due to thehigh value that Dewey places on aesthetic experience, Art asExperience has even been regarded as the culminating work ofDewey's late philosophical thinking (Alexander 2013).},
  collaborator = {Zalta, Edward N.},
  file = {../../../../../Zotero/storage/JRKUCIAW/dewey-aesthetics.html}
}

@misc{ledesma2021,
  title = {Axie {{Infinity Finds Ready Players}} in {{Hyperinflation-Racked Venezuela}}},
  author = {Ledesma, Lyllah},
  year = {2021},
  month = nov,
  url = {https://archive.today/4MtIu},
  urldate = {2022-09-12},
  abstract = {As they have in the Philippines, some players are making enough money to feed their families.},
  langid = {english}
}

@misc{lee2020,
  title = {A {{Conceptual Model}} of {{Immersive Experience}} in {{Extended Reality}}},
  author = {Lee, Hyunkook},
  year = {2020},
  month = sep,
  publisher = {{PsyArXiv}},
  urldate = {2022-12-22},
  abstract = {The term immersion or immersive is popularly used when describing and evaluating technologies in the area of extended reality (i.e., virtual/augmented/mixed reality). Much research been conducted on immersion over the last few decades. However, there is still a lack of consistency in how the term is defined in the literature. Presence and involvement are other prominent concepts studied in the field of extended reality. However, there is currently no consensus on their relationship with immersion among researchers. This paper first discusses different dimensions of immersion as well as those of presence and involvement, aiming to resolve potential confusion around the terms and synthesise a relationship among them. From this, a new conceptual model of immersive experience for future studies in extended reality is proposed. The model defines physical presence, social/self presence and involvement as the main high-level attributes that collectively lead to an immersive experience. Each pair of the three attributes shares a common lower-level attribute of sensory, narrative or task/motor engagement, which is an initial step towards the higher-level experience. Plausibility, interactivity and interestingness are defined as the main properties of immersive system and content, each of which is biased by a subjective factor: internal reference, skills/knowledge and personal preference, respectively.},
  langid = {american},
  keywords = {Cognitive Neuroscience,Cognitive Psychology,Conceptual model,Experience,Extended Reality,Immersion,Immersive,Involvement,Neuroscience,Perception,Presence,Social and Behavioral Sciences},
  file = {Human Computer Interaction/Augmented Reality/Lee, 2020 - A Conceptual Model of Immersive Experience in Extended Reality.pdf},
  url = {https://doi.org/10.31234/osf.io/sefkh}
}

@book{lefebvre1991,
  title = {The Production of Space},
  author = {Lefebvre, Henri},
  year = {1991},
  publisher = {{Blackwell}},
  address = {{Oxford, OX, UK ; Cambridge, Mass., USA}},
  isbn = {978-0-631-14048-1},
  langid = {english},
  lccn = {BD621 .L4813 1991},
  keywords = {Space and time},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/lefebvre1991.md;Philosophy/Space/Lefebvre, 1991 - The production of space.pdf}
}

@article{lidji2007,
  title = {Spatial Associations for Musical Stimuli: {{A}} Piano in the Head?},
  shorttitle = {Spatial Associations for Musical Stimuli},
  author = {Lidji, Pascale and Kolinsky, R{\'e}gine and Lochy, Aliette and Morais, Jos{\'e}},
  year = {2007},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {33},
  number = {5},
  pages = {1189--1207},
  issn = {1939-1277, 0096-1523},
  urldate = {2020-05-26},
  abstract = {This study was aimed at examining whether pitch height and pitch change are mentally represented along spatial axes. A series of experiments explored, for isolated tones and 2-note intervals, the occurrence of effects analogous to the spatial numerical association of response codes (SNARC) effect. Response device orientation (horizontal vs. vertical), task, and musical expertise of the participants were manipulated. The pitch of isolated tones triggered the automatic activation of a vertical axis independently of musical expertise, but the contour of melodic intervals did not. By contrast, automatic associations with the horizontal axis seemed linked to music training for pitch and, to a lower extent, for intervals. These results, discussed in the light of studies on number representation, provide a new example of the effects of musical expertise on music cognition.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/lidji2007.md;Cognitive Science/Psychophysics/Lidji et al., 2007 - Spatial associations for musical stimuli.pdf},
  url = {https://doi.org/10.1037/0096-1523.33.5.1189}
}

@misc{lightform2020,
  title = {Lightform: {{Design Tools}} for {{Projection}}},
  shorttitle = {Lightform},
  author = {{Lightform}},
  year = {2020},
  journal = {Lightform},
  url = {https://lightform.com/},
  urldate = {2020-10-03},
  abstract = {Introducing the next generation of Lightform. LF2 is the first AR projector, and provides everything you need to make magic with light. LFC Kit can be used to go big with your own projector. It's like LF1, but more flexible and faster.},
  langid = {american},
  file = {../../../../../Zotero/storage/MAAJJZXK/lightform.com.html}
}

@inproceedings{lin2020,
  title = {{{ARchitect}}: {{Building Interactive Virtual Experiences}} from {{Physical Affordances}} by {{Bringing Human-in-the-Loop}}},
  shorttitle = {{{ARchitect}}},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lin, Chuan-en and Cheng, Ta Ying and Ma, Xiaojuan},
  year = {2020},
  month = apr,
  pages = {1--13},
  publisher = {{ACM}},
  address = {{Honolulu HI USA}},
  urldate = {2020-09-19},
  abstract = {Automatic generation of Virtual Reality (VR) worlds which adapt to physical environments have been proposed to enable safe walking in VR. However, such techniques mainly focus on the avoidance of physical objects as obstacles and overlook their interaction affordances as passive haptics. Current VR experiences involving interaction with physical objects in surroundings still require verbal instruction from an assisting partner. We present ARchitect, a proof-of-concept prototype that allows flexible customization of a VR experience with human-in-the-loop. ARchitect brings in an assistant to map physical objects to virtual proxies of matching affordances using Augmented Reality (AR). In a within-subjects study (9 user pairs) comparing ARchitect to a baseline condition, assistants and players experienced decreased workload and players showed increased VR presence and trust in the assistant. Finally, we defined design guidelines of ARchitect for future designers and implemented three demonstrative experiences.},
  isbn = {978-1-4503-6708-0},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/lin2020.md;Human Computer Interaction/Augmented Reality/Lin et al., 2020 - ARchitect.pdf},
  url = {https://doi.org/10.1145/3313831.3376614}
}

@inproceedings{lindeman2007,
  title = {A Classification Scheme for Multi-Sensory Augmented Reality},
  booktitle = {Proceedings of the 2007 {{ACM}} Symposium on {{Virtual}} Reality Software and Technology  - {{VRST}} '07},
  author = {Lindeman, Robert W. and Noma, Haruo},
  year = {2007},
  pages = {175},
  publisher = {{ACM Press}},
  address = {{Newport Beach, California}},
  urldate = {2020-01-10},
  abstract = {We present a new classification framework for describing augmented reality (AR) applications based on where the mixing of real and computer-generated stimuli takes place. In addition to "classical" visual AR techniques, such as optical-see-through and video-see-through AR, our framework encompasses AR directed at the other senses as well. This "axis of mixing location" is a continuum ranging from the physical environment to the human brain. There are advantages and disadvantages of mixing at different points along the continuum, and while there is no "best" location, we present sample usage scenarios that illustrate the expressiveness of this classification approach.},
  isbn = {978-1-59593-863-3},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/lindeman2007.md;Human Computer Interaction/Augmented Reality/Lindeman and Noma, 2007 - A classification scheme for multi-sensory augmented reality.pdf},
  url = {https://doi.org/10.1145/1315184.1315216}
}

@inproceedings{lindeman2008,
  title = {An {{Empirical Study}} of {{Hear-Through Augmented Reality}}: {{Using Bone Conduction}} to {{Deliver Spatialized Audio}}},
  shorttitle = {An {{Empirical Study}} of {{Hear-Through Augmented Reality}}},
  booktitle = {2008 {{IEEE Virtual Reality Conference}}},
  author = {Lindeman, Robert W. and Noma, Haruo and {de Barros}, Paulo Goncalves},
  year = {2008},
  pages = {35--42},
  publisher = {{IEEE}},
  address = {{Reno, NV, USA}},
  urldate = {2020-05-25},
  abstract = {Augmented reality (AR) is the mixing of computer-generated stimuli with real-world stimuli. In this paper, we present results from a controlled, empirical study comparing three ways of delivering spatialized audio for AR applications: a speaker array, headphones, and a bone-conduction headset. Analogous to optical-see-through AR in the visual domain, Hear-Through AR allows users to receive computer-generated audio using the bone-conduction headset, and real-world audio using their unoccluded ears. Our results show that subjects achieved the best accuracy using a speaker array physically located around the listener when stationary sounds were played, but that there was no difference in accuracy between the speaker array and the bone-conduction device for sounds that were moving, and that both devices outperformed standard headphones for moving sounds. Subjective comments by subjects following the experiment support this performance data.},
  isbn = {978-1-4244-1971-5},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/lindeman2008.md;Human Computer Interaction/Augmented Reality/Lindeman et al., 2008 - An Empirical Study of Hear-Through Augmented Reality.pdf},
  url = {https://doi.org/10.1109/VR.2008.4480747}
}

@article{litovsky1998,
  title = {The {{Precedence Effect}}},
  author = {Litovsky, Ruth Y and Colburn, H Steven and Yost, William A and Guzman, Sandra J},
  year = {1998},
  pages = {23},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/litovsky1998.md;Cognitive Science/Psychophysics/Litovsky et al., 1998 - The Precedence Effect.pdf},
  url = {https://doi.org/10.1121/1.427914}
}

@inproceedings{lopes2017,
  title = {Providing {{Haptics}} to {{Walls}} \& {{Heavy Objects}} in {{Virtual Reality}} by {{Means}} of {{Electrical Muscle Stimulation}}},
  booktitle = {Proceedings of the 2017 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lopes, Pedro and You, Sijing and Cheng, Lung-Pan and Marwecki, Sebastian and Baudisch, Patrick},
  year = {2017},
  month = may,
  pages = {1471--1482},
  publisher = {{ACM}},
  address = {{Denver Colorado USA}},
  urldate = {2020-05-25},
  abstract = {We explore how to add haptics to walls and other heavy objects in virtual reality. When a user tries to push such an object, our system actuates the user's shoulder, arm, and wrist muscles by means of electrical muscle stimulation, creating a counter force that pulls the user's arm backwards. Our device accomplishes this in a wearable form factor.},
  isbn = {978-1-4503-4655-9},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/lopes2017.md;Human Computer Interaction/Multisensory Interfacing/Lopes et al., 2017 - Providing Haptics to Walls & Heavy Objects in Virtual Reality by Means of.pdf},
  url = {https://doi.org/10.1145/3025453.3025600}
}

@inproceedings{lopes2018,
  title = {Adding {{Force Feedback}} to {{Mixed Reality Experiences}} and {{Games}} Using {{Electrical Muscle Stimulation}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}  - {{CHI}} '18},
  author = {Lopes, Pedro and You, Sijing and Ion, Alexandra and Baudisch, Patrick},
  year = {2018},
  pages = {1--13},
  publisher = {{ACM Press}},
  address = {{Montreal QC, Canada}},
  urldate = {2020-05-25},
  abstract = {We present a mobile system that enhances mixed reality experiences and games with force feedback by means of electrical muscle stimulation (EMS). The benefit of our approach is that it adds physical forces while keeping the users' hands free to interact unencumbered{\textemdash}not only with virtual objects, but also with physical objects, such as props and appliances. We demonstrate how this supports three classes of applications along the mixed-reality continuum: (1) entirely virtual objects, such as furniture with EMS friction when pushed or an EMS-based catapult game. (2) Virtual objects augmented via passive props with EMSconstraints, such as a light control panel made tangible by means of a physical cup or a balance-the-marble game with an actuated tray. (3) Augmented appliances with virtual behaviors, such as a physical thermostat dial with EMSdetents or an escape-room that repurposes lamps as levers with detents. We present a user-study in which participants rated the EMS-feedback as significantly more realistic than a no-EMS baseline.},
  isbn = {978-1-4503-5620-6},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/lopes2018.md;Human Computer Interaction/Multisensory Interfacing/Lopes et al., 2018 - Adding Force Feedback to Mixed Reality Experiences and Games using Electrical.pdf},
  url = {https://doi.org/10.1145/3173574.3174020}
}

@inproceedings{lucero2019,
  title = {A {{Sample}} of {{One}}: {{First-Person Research Methods}} in {{HCI}}},
  shorttitle = {A {{Sample}} of {{One}}},
  booktitle = {Companion {{Publication}} of the 2019 on {{Designing Interactive Systems Conference}} 2019 {{Companion}} - {{DIS}} '19 {{Companion}}},
  author = {Lucero, Andr{\'e}s and Desjardins, Audrey and Neustaedter, Carman and H{\"o}{\"o}k, Kristina and Hassenzahl, Marc and Cecchinato, Marta E.},
  year = {2019},
  pages = {385--388},
  publisher = {{ACM Press}},
  address = {{San Diego, CA, USA}},
  urldate = {2020-03-17},
  abstract = {First-person research (i.e., research that involves data collection and experiences from the researcher themselves) continues to become a viable addition and, possibly even, alternative to more traditional HCI methods. While we have seen the benefits of using methods such as autoethnography, autobiographical design, and autoethnographical research through design, we also see the need to further explore, define, and investigate the practices, techniques, tactics, and implications of first-person research in HCI. To address this, this one-day workshop aims to bring together a community of researchers, designers, and practitioners who are interested in exploring and reimagining research in HCI and interaction design, with an emphasis on first-person methods.},
  isbn = {978-1-4503-6270-2},
  langid = {english},
  file = {Research Methods/Autobiographical Design/Lucero et al., 2019 - A Sample of One.pdf},
  url = {https://doi.org/10.1145/3301019.3319996}
}

@inproceedings{macintyre2001,
  title = {Augmented Reality as a New Media Experience},
  booktitle = {Proceedings {{IEEE}} and {{ACM International Symposium}} on {{Augmented Reality}}},
  author = {MacIntyre, Blair and Bolter, J.D. and Moreno, E. and Hannigan, B.},
  year = {2001},
  pages = {197--206},
  publisher = {{IEEE Comput. Soc}},
  address = {{New York, NY, USA}},
  urldate = {2020-10-27},
  abstract = {In this paper we discuss our work on applying media theory to the creation of narrative augmented reality (AR) experiences. We summarize the concepts of remediation and media forms as they relate to our work, argue for their importance to the development of a new medium such as AR, and present two example AR experiences we have designed using these conceptual tools. In particular, we focus on leveraging the interaction between the physical and virtual world, remediating existing media (film, stage and interactive CD-ROM), and building on the cultural expectations of our users.},
  isbn = {978-0-7695-1375-1},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/macintyre2001.md;Human Computer Interaction/Augmented Reality/MacIntyre et al., 2001 - Augmented reality as a new media experience.pdf},
  url = {https://doi.org/10.1109/ISAR.2001.970538}
}

@article{mackay1996,
  title = {Augmenting {{Reality}}: {{A}} New Paradigm for Interacting with Computers},
  author = {Mackay, Wendy E},
  year = {1996},
  journal = {La Recherche},
  volume = {285},
  number = {L'ordinateur au doigt et {\`a} l'{\oe}il},
  pages = {9},
  url = {https://www.larecherche.fr/parution/mensuel-285},
  abstract = {A revolution in computer interface design is changing the way we think about computers. Rather than typing on a keyboard and watching a television monitor, Augmented Reality lets people use familiar, everyday objects in ordinary ways. The difference is that these objects also provide a link into a computer network. Doctors can examine patients while viewing superimposed medical images; children can program their own LEGO constructions; and construction engineers can use ordinary paper engineering drawings to make live video connections to colleagues far away. Rather than immersing people in an artifically-created virtual world, the goal is to augment everyday objects in the physical world by enhancing them with a wealth of digital information and communication capabilities.},
  langid = {english},
  keywords = {â›” No DOI found},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/mackay1996.md;Human Computer Interaction/Augmented Reality/Mackay, 1996 - Augmenting Reality.pdf}
}

@book{madinger2000,
  title = {Eight Arms to Hold You: The Solo {{Beatles}} Compendium},
  shorttitle = {Eight Arms to Hold You},
  author = {Madinger, Chip and Easter, Mark},
  year = {2000},
  publisher = {{44.1 Productions}},
  address = {{Chesterfield, Missouri}},
  isbn = {978-0-615-11724-9},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/madinger2000.md}
}

@inproceedings{maggioni2017,
  title = {Measuring the Added Value of Haptic Feedback},
  booktitle = {2017 {{Ninth International Conference}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})},
  author = {Maggioni, Emanuela and Agostinelli, Erika and Obrist, Marianna},
  year = {2017},
  month = may,
  pages = {1--6},
  publisher = {{IEEE}},
  address = {{Erfurt, Germany}},
  urldate = {2020-05-25},
  abstract = {While there is an increased appreciation for integrating haptic feedback with audio-visual content, there is still a lack of understanding of how to quantify the added value of touch for a user's experience (UX) of multimedia content. Here we focus on three main concepts to measure this added value: UX, emotions, and expectations. We present a case study measuring the added value of haptic feedback for a standardized set of audio-visual content (i.e., short video clips), comparing two haptic stimulation modalities (i.e., mid-air vs. vibro-tactile stimuli). Our findings demonstrate that UX of hapticallyenhanced audio-visual content is perceived as a more pleasant, unpredictable, and creative experience. The users' overall liking increases together with a positive change of the users' expectations, independently from the haptic stimulation modality. We discuss how our approach provides the foundation for future work on developing a measurement model to predict the added value of haptic feedback for users' experiences within and beyond the multimedia context.},
  isbn = {978-1-5386-4024-1},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/maggioni2017.md;Human Computer Interaction/Multisensory Interfacing/Maggioni et al., 2017 - Measuring the added value of haptic feedback.pdf},
  url = {https://doi.org/10.1109/QoMEX.2017.7965670}
}

@article{maggioni2019,
  title = {{{OWidgets}}: {{A}} Toolkit to Enable Smell-Based Experience Design},
  shorttitle = {{{OWidgets}}},
  author = {Maggioni, Emanuela and Cobden, Robert and Obrist, Marianna},
  year = {2019},
  month = oct,
  journal = {International Journal of Human-Computer Studies},
  volume = {130},
  pages = {248--260},
  issn = {10715819},
  urldate = {2020-10-03},
  abstract = {Interactive technologies are transforming the ways in which people experience, interact and share information. Advances in technology have made it possible to generate real and virtual environments with breath-taking graphics and high-fidelity audio. However, without stimulating the other senses such as touch and smell, and even taste in some cases, such experiences feel hollow and fictitious; they lack realism. One of the main stumbling blocks for progress towards creating truly compelling multisensory experiences is the lack of appropriate tools and guidance for designing beyond audio-visual applications. Here we focus particularly on the sense of smell and how smell-based design can be enabled to create novel user experiences. We present a design toolkit for smell (i.e., OWidgets). The toolkit consists of a graphical user interface and the underlying software framework. The framework uses two main components: a Mapper and Scheduler facilitating the device-independent replication of olfactory experiences. We discuss how our toolkit reduces the complexity of designing with smell and enables a creative exploration based on specific design features. We conclude by reflecting on future directions to extend the toolkit and integrate it into the wider audio-visual ecosystem.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/maggioni2019.md;Human Computer Interaction/Multisensory Interfacing/Maggioni et al., 2019 - OWidgets.pdf},
  url = {https://doi.org/10.1016/j.ijhcs.2019.06.014}
}

@misc{magicleap2018,
  title = {Magic {{Leap}} 1},
  author = {Magic Leap},
  year = {2018},
  url = {https://www.magicleap.com/magic-leap-1},
  urldate = {2020-05-25},
  abstract = {Step aside VR and smartphone AR. Magic Leap 1 is a wearable spatial computer that brings the physical and digital worlds together as one.},
  langid = {american},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/magicleap2018.md;../../../../../Zotero/storage/56CBS9SS/magic-leap-1.html}
}

@article{magnusson2009,
  title = {Of {{Epistemic Tools}}: Musical Instruments as Cognitive Extensions},
  shorttitle = {Of {{Epistemic Tools}}},
  author = {Magnusson, Thor},
  year = {2009},
  month = aug,
  journal = {Organised Sound},
  volume = {14},
  number = {2},
  pages = {168--176},
  issn = {1355-7718, 1469-8153},
  urldate = {2020-05-26},
  abstract = {This paper explores the differences in the design and performance of acoustic and new digital musical instruments, arguing that with the latter there is an increased encapsulation of musical theory. The point of departure is the phenomenology of musical instruments, which leads to the exploration of designed artefacts as extensions of human cognition {\textendash} as scaffolding onto which we delegate parts of our cognitive processes. The paper succinctly emphasises the pronounced epistemic dimension of digital instruments when compared to acoustic instruments. Through the analysis of material epistemologies it is possible to describe the digital instrument as an               epistemic tool               : a designed tool with such a high degree of symbolic pertinence that it becomes a system of knowledge and thinking in its own terms. In conclusion, the paper rounds up the phenomenological and epistemological arguments, and points at issues in the design of digital musical instruments that are germane due to their strong aesthetic implications for musical culture.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/magnusson2009.md;Arts & Humanities/Computational Art/Magnusson, 2009 - Of Epistemic Tools.pdf},
  url = {https://doi.org/10.1017/S1355771809000272}
}

@phdthesis{magnusson2009a,
  title = {Epistemic {{Tools}}: {{The Phenomenology}} of {{Digital Musical Instruments}}},
  author = {Magnusson, Thor},
  year = {2009},
  url = {https://sro.sussex.ac.uk/id/eprint/83540/1/Magnusson%2C%20Thor%282%29.pdf},
  urldate = {2020-12-15},
  school = {University of Sussex},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/magnusson2009a.md;Arts & Humanities/Computational Art/Magnusson, 2009 - Epistemic Tools.pdf}
}

@book{magnusson2019,
  title = {Sonic Writing: Technologies of Material, Symbolic and Signal Inscriptions},
  shorttitle = {Sonic Writing},
  author = {Magnusson, Thor},
  year = {2019},
  publisher = {{Bloomsbury Academic}},
  address = {{New York, NY}},
  isbn = {978-1-5013-1385-1 978-1-5013-1386-8 978-1-5013-1389-9},
  lccn = {ML3800 .M23776 2019},
  keywords = {Music,Musical instruments,Musical notation,Philosophy and aesthetics,Recording and reproducing Philosophy,Sound},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/magnusson2019.md}
}

@article{magnusson2021,
  title = {The Migration of Musical Instruments: {{On}} the Socio-Technological Conditions of Musical Evolution},
  shorttitle = {The Migration of Musical Instruments},
  author = {Magnusson, Thor},
  year = {2021},
  month = mar,
  journal = {Journal of New Music Research},
  volume = {50},
  number = {2},
  pages = {175--183},
  issn = {0929-8215, 1744-5027},
  urldate = {2021-06-10},
  abstract = {Music technologies reflect the most advanced human technologies in most historical periods. Examples range from 40 thousand years old bone flutes found in caves in the Swabian Jura, through ancient Greek water organs or medieval Arabic musical automata, to today's electronic and digital instruments with deep learning. Music technologies incorporate the musical ideas of a time and place and they disseminate those ideas when adopted by other musical cultures. This article explores how contemporary music technologies are culturally conditioned and applies the concept of ethno-organology to describe the nature of migration of instruments between musical cultures.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/magnusson2021.md;Arts & Humanities/Computational Art/Magnusson, 2021 - The migration of musical instruments.pdf},
  url = {https://doi.org/10.1080/09298215.2021.1907420}
}

@techreport{mann1994,
  title = {Mediated Reality},
  author = {Mann, Steve},
  year = {1994},
  number = {MIT-ML Percom TR-260},
  pages = {21},
  institution = {{University of Toronto}},
  url = {https://citeseerx.ist.psu.edu/pdf/80513721f052262668b4a3e43fcffeefc956de75},
  urldate = {2021-02-10},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/mann1994.md;Human Computer Interaction/Augmented Reality/Mann, 1994 - Mediated reality.pdf}
}

@inproceedings{mann2018,
  title = {All {{Reality}}: {{Values}}, Taxonomy, and Continuum, for {{Virtual}}, {{Augmented}}, {{eXtended}}/{{MiXed}} ({{X}}), {{Mediated}} ({{X}},{{Y}}), and {{Multimediated Reality}}/{{Intelligence}}},
  booktitle = {Roceedings of the {{AWE}} 2018 {{Conference}}},
  author = {Mann, Steve and Havens, John C and Iorio, Jay and Yuan, Yu and Furness, Tom},
  year = {2018},
  pages = {10},
  address = {{Santa Clara, CA, USA}},
  abstract = {Humans are creating a world of eXtended/Artificial Reality/Intelligence (AR, AI, XR, XI or EI), that in many ways is hypocritical, e.g. where cars and buildings are always ``allowed'' to ``wear'' cameras, but humans sometimes aren't, and where machines sense our every movement, yet we can't even understand how they work. We're constructing a system of values that gives more rights and less responsibilities to AI (Artificial Intelligence) than to HI (Humanistic Intelligence). Whereas it is becoming common to separate the notions of IRL (In Real Life) and ``Augmented'' or ``Virtual'' Reality (AR, VR) into completely disparate realms with clearly delineated boundaries, we propose here the notion of ``All Reality'' to more holistically represent the links between these soon-to-be-outdated culturally accepted norms of various levels of consciousness. Inclusive in the notion of ``All Reality'' is also the idea of ``ethically aligned reality'', recognizing values-based biases, cultural norms, and applied ethics of the creators of technology.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/mann2018.md;Human Computer Interaction/Augmented Reality/Mann et al., 2018 - All Reality.pdf},
  url = {https://doi.org/10.48550/arXiv.1804.08386}
}

@inproceedings{mann2018a,
  title = {Phenomenological {{Augmented Reality}} with the {{Sequential Wave Imprinting Machine}} ({{SWIM}})},
  booktitle = {2018 {{IEEE Games}}, {{Entertainment}}, {{Media Conference}} ({{GEM}})},
  author = {Mann, Steve},
  year = {2018},
  pages = {1--9},
  publisher = {{IEEE}},
  address = {{Galway}},
  urldate = {2021-05-20},
  abstract = {SWIM (Sequential Wave Imprinting Machine) is an invention that makes for visual art as well as scientific discovery of otherwise invisible physical phenomenology around us, such as sound waves, radio waves, etc.. It uses multimediated reality (sensing, computation, and display) to turn phenomena such as interference patterns between multiple sound sources, into pictures ``painted'' by nature itself (rather than from computer graphics). This gives us a glimpse into the nature of the real world arouond us, i.e. phenomena arising from physics (natural philosophy).},
  isbn = {978-1-5386-6304-2},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/mann2018a.md;Human Computer Interaction/Augmented Reality/Mann, 2018 - Phenomenological Augmented Reality with the Sequential Wave Imprinting Machine.pdf},
  url = {https://doi.org/10.1109/GEM.2018.8516502}
}

@book{manovich2001,
  title = {The Language of New Media},
  author = {Manovich, Lev},
  year = {2001},
  series = {Leonardo},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass.}},
  isbn = {978-0-262-63255-3 978-0-262-13374-6},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/manovich2001.md;Arts & Humanities/Media Studies/Manovich, 2001 - The language of new media.pdf}
}

@article{manovich2006,
  title = {The Poetics of Augmented Space},
  author = {Manovich, Lev},
  year = {2006},
  month = jun,
  journal = {Visual Communication},
  volume = {5},
  number = {2},
  pages = {219--240},
  issn = {1470-3572, 1741-3214},
  urldate = {2020-05-24},
  abstract = {This article discusses how people experience spatial forms when they are filled in with dynamic and rich multimedia information; spaces such as shopping or entertainment areas or other spaces where various information can be accessed wirelessly. The author calls such spaces `augmented space': the physical space overlaid with dynamically changing information, multimedia in form and localized for each user. The article asks whether this form becomes irrelevant and `invisible' or if people end up with a new experience in which the spatial and information layers are equally important. The author also discusses the general dynamic between spatial form and information and how this might function differently in today's computer culture. Throughout the article, augmentation is reconceptualized as an idea and cultural and aesthetic practice rather than as technology. Various practices in professional and vernacular architecture and built environments, cinema, 20th-century art and media art are discussed in terms of augmentation.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/manovich2006.md;Human Computer Interaction/Augmented Reality/Manovich, 2006 - The poetics of augmented space.pdf},
  url = {https://doi.org/10.1177/1470357206065527}
}

@misc{marr2022,
  title = {How {{To Buy Land}} \& {{Real Estate In The Metaverse}}},
  author = {Marr, Bernard},
  year = {2022},
  journal = {Forbes},
  url = {https://www.forbes.com/sites/bernardmarr/2022/03/23/how-to-buy-land--real-estate-in-the-metaverse/},
  urldate = {2022-09-12},
  abstract = {We are quickly heading towards the age of the metaverse {\textendash} connected, persistent virtual realities where we will live digital lives alongside our real lives. Increasingly we will use these spaces to work, play, socialize and learn.},
  langid = {english},
  file = {../../../../../Zotero/storage/TJJV2XX7/how-to-buy-land--real-estate-in-the-metaverse.html}
}

@article{martin2017,
  title = {Percussionist-{{Centred Design}} for {{Touchscreen Digital Musical Instruments}}},
  author = {Martin, Charles P.},
  year = {2017},
  month = mar,
  journal = {Contemporary Music Review},
  volume = {36},
  number = {1-2},
  pages = {64--85},
  issn = {0749-4467, 1477-2256},
  urldate = {2020-05-26},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/martin2017.md;Arts & Humanities/Computational Art/Martin, 2017 - Percussionist-Centred Design for Touchscreen Digital Musical Instruments.pdf},
  url = {https://doi.org/10.1080/07494467.2017.1370794}
}

@article{martina2001,
  title = {Raumsoziologie},
  author = {Martina, L{\"o}w},
  year = {2001},
  journal = {Frankfurt am Main: Suhrkamp},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/martina2001.md}
}

@inproceedings{martinezplasencia2014,
  title = {Through the Combining Glass},
  booktitle = {Proceedings of the 27th Annual {{ACM}} Symposium on {{User}} Interface Software and Technology},
  author = {Martinez Plasencia, Diego and Berthaut, Florent and Karnik, Abhijit and Subramanian, Sriram},
  year = {2014},
  month = oct,
  series = {{{UIST}} '14},
  pages = {341--350},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  urldate = {2023-01-24},
  abstract = {Reflective optical combiners like beam splitters and two way mirrors are used in AR to overlap digital contents on the users' hands or bodies. Augmentations are usually unidirectional, either reflecting virtual contents on the user's body (Situated Augmented Reality) or augmenting user's reflections with digital contents (AR mirrors). But many other novel possibilities remain unexplored. For example, users' hands, reflected inside a museum AR cabinet, can allow visitors to interact with the artifacts exhibited. Projecting on the user's hands as their reflection cuts through the objects can be used to reveal objects' internals. Augmentations from both sides are blended by the combiner, so they are consistently seen by any number of users, independently of their location or, even, the side of the combiner through which they are looking. This paper explores the potential of optical combiners to merge the space in front and behind them. We present this design space, identify novel augmentations/interaction opportunities and explore the design space using three prototypes.},
  isbn = {978-1-4503-3069-5},
  keywords = {augmented reality,multi-user,optical combiners},
  file = {Human Computer Interaction/Augmented Reality/Martinez Plasencia et al., 2014 - Through the combining glass.pdf},
  url = {https://doi.org/10.1145/2642918.2647351}
}

@inproceedings{mathew2019,
  title = {Spread of {{Hate Speech}} in {{Online Social Media}}},
  booktitle = {Proceedings of the 10th {{ACM Conference}} on {{Web Science}}},
  author = {Mathew, Binny and Dutt, Ritam and Goyal, Pawan and Mukherjee, Animesh},
  year = {2019},
  month = jun,
  pages = {173--182},
  publisher = {{ACM}},
  address = {{Boston Massachusetts USA}},
  urldate = {2022-12-11},
  abstract = {Hate speech is considered to be one of the major issues currently plaguing the online social media. With online hate speech culminating in gruesome scenarios like the Rohingya genocide in Myanmar, anti-Muslim mob violence in Sri Lanka, and the Pittsburgh synagogue shooting, there is a dire need to understand the dynamics of user interaction that facilitate the spread of such hateful content. In this paper, we perform the first study that looks into the diffusion dynamics of the posts made by hateful and non-hateful users on Gab1. We collect a massive dataset of 341K users with 21M posts and investigate the diffusion of the posts generated by hateful and non-hateful users. We observe that the content generated by the hateful users tend to spread faster, farther and reach a much wider audience as compared to the content generated by normal users. We further analyze the hateful and non-hateful users on the basis of their account and network characteristics. An important finding is that the hateful users are far more densely connected among themselves. Overall, our study provides the first cross-sectional view of how hateful users diffuse hate content in online social media.},
  isbn = {978-1-4503-6202-3},
  langid = {english},
  file = {Politics/Marxism/Mathew et al., 2019 - Spread of Hate Speech in Online Social Media.pdf},
  url = {https://doi.org/10.1145/3292522.3326034}
}

@misc{matsuda2009,
  title = {The {{Pusher}} / {{The Entertainment}}},
  author = {Matsuda, Keiichi},
  year = {2009},
  month = oct,
  url = {https://www.youtube.com/watch?v=396pkbio3DE},
  urldate = {2022-11-01}
}

@misc{matsuda2010,
  title = {Augmented (Hyper){{Reality}}: {{Domestic Robocop}}},
  shorttitle = {Augmented (Hyper){{Reality}}},
  author = {Matsuda, Keiichi},
  year = {2010},
  month = jan,
  url = {https://www.youtube.com/watch?v=fSfKlCmYcLc},
  urldate = {2022-11-01}
}

@misc{matsuda2016,
  title = {{{HYPER-REALITY}}},
  author = {Matsuda, Keiichi},
  year = {2016},
  month = may,
  url = {https://www.youtube.com/watch?v=YJg02ivYzSs},
  urldate = {2022-11-01}
}

@misc{matsuda2019,
  title = {Merger},
  author = {Matsuda, Keiichi},
  year = {2019},
  month = jan,
  url = {https://www.youtube.com/watch?v=SqW2dEkiD-Y},
  urldate = {2022-11-01}
}

@article{mcalpine1999,
  title = {Making {{Music}} with {{Algorithms}}: {{A Case-Study System}}},
  author = {McAlpine, Kenneth and Miranda, Eduardo and Hoggar, Stuart},
  year = {1999},
  journal = {Computer Music Journal},
  volume = {23},
  number = {2},
  eprint = {3680733},
  eprinttype = {jstor},
  pages = {19--30},
  url = {http://www.jstor.org/stable/3680733},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/mcalpine1999.md;Arts & Humanities/Computational Art/McAlpine et al., 1999 - Making Music with Algorithms.pdf}
}

@misc{mcarthur2019,
  title = {Sonic {{Explorations}} with the {{IKO}}},
  author = {McArthur, Angela},
  year = {2019},
  journal = {IEM Residency},
  url = {http://iem-residency.angelamcarthur.com/},
  urldate = {2022-12-19},
  langid = {british},
  file = {../../../../../Zotero/storage/5PGEG3QZ/iem-residency.angelamcarthur.com.html}
}

@inproceedings{mcduff2017,
  title = {Pulse and Vital Sign Measurement in Mixed Reality Using a {{HoloLens}}},
  booktitle = {Proceedings of the 23rd {{ACM Symposium}} on {{Virtual Reality Software}} and {{Technology}}},
  author = {McDuff, Daniel and Hurter, Christophe and {Gonzalez-Franco}, Mar},
  year = {2017},
  month = nov,
  pages = {1--9},
  publisher = {{ACM}},
  address = {{Gothenburg Sweden}},
  urldate = {2020-05-25},
  abstract = {Cardiography, quantitative measurement of the functioning of the heart, traditionally requires customized obtrusive contact sensors. Using new methods photoplethysmography and ballistocardiography signals can be captured using ubiquitous sensors, such as webcams and accelerometers. However, these signals are not visible to the unaided eye. We present Cardiolens - a mixed reality system that enables real-time, hands-free measurement and visualization of blood ow and vital signs from multiple people. e system combines a front-facing webcam, imaging ballistocardiography, and remote imaging photoplethysmography methods for recovering pulse signals. A heads up display allows users to view their own heart rate whenever they are wearing the device and the heart rate and heart rate variability of another person simply by looking at them. Cardiolens provides the wearer with a new way to understand physiological signals and has applications in human-computer interaction and in the study of social psychology.},
  isbn = {978-1-4503-5548-3},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/mcduff2017.md;Cognitive Science/Interoception/McDuff et al., 2017 - Pulse and vital sign measurement in mixed reality using a HoloLens.pdf},
  url = {https://doi.org/10.1145/3139131.3139134}
}

@book{mcquillan2022,
  title = {Resisting {{AI}}: An Anti-Fascist Approach to Artificial Intelligence},
  shorttitle = {Resisting {{AI}}},
  author = {McQuillan, Dan},
  year = {2022},
  publisher = {{Bristol University Press}},
  address = {{Bristol}},
  isbn = {978-1-5292-1349-2 978-1-5292-1350-8},
  langid = {english},
  file = {Human Computer Interaction/Artificial Intelligence/McQuillan, 2022 - Resisting AI.pdf}
}

@inproceedings{melchior2005,
  title = {Authoring and User Interaction for the Production of Wave Field Synthesis Content in an Augmented Reality System},
  booktitle = {Fourth {{IEEE}} and {{ACM International Symposium}} on {{Mixed}} and {{Augmented Reality}} ({{ISMAR}}'05)},
  author = {Melchior, F. and Laubach, T. and {de Vries}, D.},
  year = {2005},
  pages = {48--51},
  publisher = {{IEEE}},
  address = {{Vienna, Austria}},
  urldate = {2020-01-10},
  abstract = {Wave field synthesis (WFS) enables the accurate reproduction of a sound field for a large listening area with correct characteristics for each listener position. An exact perspective on the synthesized wave field is provided for every listener. Therefore, WFS-technology is ideally suited to be combined with augmented reality systems, where every user perceives his own visual perspective of a given scene. This paper presents a concept for authoring and user interaction for the production of wave field synthesis content in an augmented reality system. Also, the implementation of a prototype WFS-AR System based on ARToolkit is explained.},
  isbn = {978-0-7695-2459-7},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/melchior2005.md;Human Computer Interaction/Augmented Reality/Melchior et al., 2005 - Authoring and user interaction for the production of wave field synthesis.pdf},
  url = {https://doi.org/10.1109/ISMAR.2005.20}
}

@incollection{men2023,
  title = {Supporting {{Sonic Interaction}} in {{Creative}}, {{Shared Virtual Environments}}},
  booktitle = {Sonic {{Interactions}} in {{Virtual Environments}}},
  author = {Men, Liang and {Bryan-Kinns}, Nick},
  editor = {Geronazzo, Michele and Serafin, Stefania},
  year = {2023},
  pages = {237--267},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  urldate = {2024-01-29},
  abstract = {Abstract             This chapter examines user experience design for collaborative music making in shared virtual environments (SVEs). Whilst SVEs have been extensively researched for many application domains including education, entertainment, work and training, there is limited research on the creative aspects. This results in many unanswered design questions such as how to design the user experience without being detrimental to the creative output, and how to design spatial configurations to support both individual creativity and collaboration. Here, we explore multi-modal approaches to supporting creativity in collaborative music making in SVEs. We outline an SVE, LeMo, which allows two people to create music collaboratively. We then present two studies; the first explores how free-form visual 3D annotations instead of spoken communication can support collaborative composition processes and human{\textendash}human interaction. Five classes of use of annotation were identified in the study, three of which are particularly relevant to the future design of sonic interactions in virtual environments. The second study used a modified version of LeMo to test the support for a creative collaboration of two different spatial audio settings, which according to the results, changed participants' behaviour and affected their collaboration. Finally, design implications for the auditory design of SVEs focusing on supporting creative collaboration are given.},
  isbn = {978-3-031-04020-7 978-3-031-04021-4},
  langid = {english},
  file = {Human Computer Interaction/Virtual Reality/Men and Bryan-Kinns, 2023 - Supporting Sonic Interaction in Creative, Shared Virtual Environments.pdf},
  url = {https://doi.org/10.1007/978-3-031-04021-4_8}
}

@inproceedings{mendonca2020,
  title = {Surround Sound Spreads Visual Attention and Increases Cognitive Effort in Immersive Media Reproductions},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Mendon{\c c}a, Catarina and Korshunova, Victoria},
  year = {2020},
  series = {{{AM}} '20},
  pages = {16--21},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {The goal of this study was to explore the effects of different spatial sound configurations on visual attention and cognitive effort in an immersive environment. For that purpose, different groups of people were exposed to the same immersive video, but with different soundtrack conditions: mono, stereo, 5.1 and 7.4.1. The different sound conditions consisted of different artistic adaptations of the same soundtrack. During the visualization of the video, participants wore an eye-tracking device and were asked to perform a counting task. Gaze direction and pupil dilation metrics were obtained, as measures of attention and cognitive effort. Results demonstrate that the conditions 5.1 and 7.4.1 were associated with larger distributions of the visual attention, with subjects spending more time gazing at task-irrelevant areas on the screen. The sound condition which led to more concentrated attention on the task-relevant area was mono. The wider the spatial sound configuration, the greater the gaze distribution. Conditions 7.4.1 and 5.1 were also associated with larger pupil dilations than the mono and stereo conditions, showing that these conditions might lead to increased cognitive demand and therefore increased task difficulty. We conclude that sound design should be carefully planned to prevent visual distraction. More surrounding spatialized sounds may lead to more distraction and more difficulty in following audiovisual contents than less distributed sounds. We propose that sound spatialization and soundtrack design should be adapted to the audiovisual content and the task at hand, varying in immersiveness accordingly.},
  isbn = {978-1-4503-7563-4},
  keywords = {attention,audiovisual,difficulty,perception,pupil dilation,sound design,spatial audio,virtual reality},
  file = {../../../../../../../../C\:\\Users\\Sam Bilbow\\OneDrive\\Literature\\Human Computer Interaction\\Augmented Reality\\MendonÃ§a and Korshunova, 2020 - Surround sound spreads visual attention and increases cognitive effort in.pdf;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/mendonca2020.md},
  url = {https://doi.org/10.1145/3411109.3411118}
}

@book{merleau-ponty1945,
  title = {Phenomenology of {{Perception}}},
  author = {{Merleau-Ponty}, Maurice},
  year = {1945},
  publisher = {{Routledge}}
}

@book{merleau-ponty1968,
  title = {The Visible and the Invisible: {{Followed}} by Working Notes},
  author = {{Merleau-Ponty}, Maurice},
  year = {1968},
  publisher = {{Northwestern University Press}}
}

@article{merrifield1993,
  title = {Place and {{Space}}: {{A Lefebvrian Reconciliation}}},
  shorttitle = {Place and {{Space}}},
  author = {Merrifield, Andrew},
  year = {1993},
  journal = {Transactions of the Institute of British Geographers},
  volume = {18},
  number = {4},
  eprint = {622564},
  eprinttype = {jstor},
  pages = {516},
  issn = {00202754},
  urldate = {2022-09-12},
  langid = {english},
  file = {Philosophy/Space/Merrifield, 1993 - Place and Space.pdf},
  url = {https://doi.org/10.2307/622564}
}

@inproceedings{metatla2016,
  title = {Tap the {{ShapeTones}}: {{Exploring}} the {{Effects}} of {{Crossmodal Congruence}} in an {{Audio-Visual Interface}}},
  shorttitle = {Tap the {{ShapeTones}}},
  booktitle = {Proceedings of the 2016 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Metatla, Oussama and Correia, Nuno N. and Martin, Fiore and {Bryan-Kinns}, Nick and Stockman, Tony},
  year = {2016},
  month = may,
  pages = {1055--1066},
  publisher = {{ACM}},
  address = {{San Jose California USA}},
  urldate = {2020-05-25},
  abstract = {There is growing interest in the application of crossmodal perception to interface design. However, most research has focused on task performance measures and often ignored user experience and engagement. We present an examination of crossmodal congruence in terms of performance and engagement in the context of a memory task of audio, visual, and audio-visual stimuli. Participants in a first study showed improved performance when using a visual congruent mapping that was cancelled by the addition of audio to the baseline conditions, and a subjective preference for the audio-visual stimulus that was not reflected in the objective data. Based on these findings, we designed an audio-visual memory game to examine the effects of crossmodal congruence on user experience and engagement. Results showed higher engagement levels with congruent displays with some reported preference for potential challenge and enjoyment that an incongruent display may support, particularly for increased task complexity.},
  isbn = {978-1-4503-3362-7},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/metatla2016.md;Human Computer Interaction/Multisensory Interfacing/Metatla et al., 2016 - Tap the ShapeTones.pdf},
  url = {https://doi.org/10.1145/2858036.2858456}
}

@misc{microsoft2019,
  title = {Microsoft {{HoloLens}}},
  author = {Microsoft},
  year = {2019},
  journal = {Microsoft HoloLens 2},
  url = {https://www.microsoft.com/en-us/hololens},
  urldate = {2020-05-25},
  abstract = {Introducing HoloLens 2, an untethered mixed reality headset that's designed to help you solve real business problems today using intelligent apps and solutions.},
  langid = {american},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/microsoft2019.md;../../../../../Zotero/storage/QXFBA8XE/hololens.html}
}

@misc{microsoft2021,
  title = {U.{{S}}. {{Army}} to Use {{HoloLens}} Technology in High-Tech Headsets for Soldiers},
  author = {Microsoft},
  year = {2021},
  month = jun,
  journal = {Microsoft Transform},
  url = {https://news.microsoft.com/transform/u-s-army-to-use-hololens-technology-in-high-tech-headsets-for-soldiers/},
  urldate = {2022-12-13},
  abstract = {Microsoft will soon produce thousands of mixed-reality headsets for U.S. Army soldiers.},
  langid = {american},
  file = {../../../../../Zotero/storage/KXQVUFUY/u-s-army-to-use-hololens-technology-in-high-tech-headsets-for-soldiers.html}
}

@misc{microsoft2022,
  title = {Microsoft {{Hololens}} 2 {{Development}}},
  author = {Microsoft},
  year = {2022},
  url = {https://www.microsoft.com/en-us/hololens/developers},
  urldate = {2022-12-13},
  abstract = {Build mixed reality apps for Microsoft HoloLens. Start developing for the first untethered holographic computer and find new ways to create and collaborate.},
  langid = {american},
  file = {../../../../../Zotero/storage/E9DSB8YV/developers.html}
}

@article{mieville1998,
  title = {The Conspiracy of Architecture: {{Notes}} on a Modern Anxiety},
  author = {Mi{\'e}ville, China},
  year = {1998},
  journal = {Historical Materialism},
  volume = {2},
  number = {1},
  pages = {1--32},
  file = {Philosophy/Space/MiÃ©ville, 1998 - The conspiracy of architecture.pdf},
  url = {https://doi.org/10.1163/156920698100414176}
}

@article{milgram1994,
  title = {A {{Taxonomy}} of {{Mixed Reality Visual Displays}}},
  author = {Milgram, Paul and Kishino, Fumio},
  year = {1994},
  month = dec,
  journal = {IEICE Transactions on Information and Systems},
  volume = {E77-D},
  number = {12},
  pages = {8},
  url = {https://search.ieice.org/bin/summary.php?id=e77-d_12_1321},
  abstract = {Mixed Reality (MR) visual displays, a particular subset of Virtual Reality (VR) related technologies, involve the merging of real and virtual worlds somewhere along the 'virtuality continuum' which connects completely real environments to completely virtual ones. Augmented Reality (AR), probably the best known of these, refers to all cases in which the display of an otherwise real environment is augmented by means of virtual (computer graphic) objects. The converse case on the virtuality continuum is therefore Augmented Virtuality (AV). Six classes of hybrid MR display environments are identified. However quite different groupings are possible and this demonstrates the need for an efficient taxonomy, or classification framework, according to which essential differences can be identified. An approximately three-dimensional taxonomy is proposed comprising the following dimensions: extent of world knowledge, reproduction fidelity, and extent of presence metaphor.},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/milgram1994.md;Human Computer Interaction/Augmented Reality/Milgram and Kishino, 1994 - A Taxonomy of Mixed Reality Visual Displays.pdf}
}

@incollection{misker2010,
  title = {Authoring {{Immersive Mixed Reality Experiences}}},
  booktitle = {The {{Engineering}} of {{Mixed Reality Systems}}},
  author = {Misker, Jan M.V. and {van der Ster}, Jelle},
  editor = {Dubois, Emmanuel and Gray, Philip and Nigay, Laurence},
  year = {2010},
  pages = {275--291},
  publisher = {{Springer London}},
  address = {{London}},
  url = {https://doi.org/10.1007/978-1-84882-733-2_14},
  urldate = {2020-05-27},
  abstract = {Creating a mixed reality experience is a complicated endeavour. From our practice as a media lab in the artistic domain we found that engineering is `only' a first step in creating a mixed reality experience. Designing the appearance and directing the user experience are equally important for creating an engaging, immersive experience. We found that mixed reality artworks provide a very good test bed for studying these topics. This chapter details three steps required for authoring mixed reality experiences: engineering, designing and directing. We will describe a platform (VGE) for creating mixed reality environments that incorporates these steps. A case study (EI4) is presented in which this platform was used to not only engineer the system, but in which an artist was given the freedom to explore the artistic merits of mixed reality as an artistic medium, which involved areas such as the look and feel, multimodal experience and interaction, immersion as a subjective emotion and game play scenarios.},
  isbn = {978-1-84882-732-5 978-1-84882-733-2},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/misker2010.md;Human Computer Interaction/Augmented Reality/Misker and van der Ster, 2010 - Authoring Immersive Mixed Reality Experiences.pdf}
}

@book{monbiot2022,
  title = {Regenesis: Feeding the World without Devouring the Planet},
  shorttitle = {Regenesis},
  author = {Monbiot, George},
  year = {2022},
  publisher = {{Allen Lane}},
  address = {{London, UK}},
  abstract = {"What if there were a way to stop climate change and end global hunger at the same time? The way we feed ourselves is destroying the planet, and a collection of crises have brought the global food supply to its breaking point. But it doesn't have to be this way. With technology that already exists, we could sustainably provide everyone on the planet with a healthy diet. By cultivating hydrogen-eating bacteria, deep-rooted plants, and much richer communities of insects--coupled with existing technology to reduce our dependence on meat--we can dramatically reduce our carbon footprint, solve world hunger, and halt the sixth extinction at the same time. George Monbiot is an internationally renowned climate activist, widely known for bringing bold, creative thinking to the climate and ecological crises facing our planet. Now, he turns his attention to the global food system to offer a reimagining of the way we feed ourselves on a scale to fit the urgency of the problems we face."--},
  isbn = {978-0-7352-4039-1 978-0-241-44764-2},
  lccn = {HD9000.5 .M655 2022},
  keywords = {Agriculture durable,Alimentation,Aspect de l'environnement,Diet,Environmental aspects,Food industry and trade,Food security,Food supply,S{\'e}curit{\'e} alimentaire,Sustainable agriculture},
  annotation = {OCLC: on1251913057}
}

@book{moorefield2010,
  title = {The Producer as Composer: Shaping the Sounds of Popular Music},
  shorttitle = {The Producer as Composer},
  author = {Moorefield, Virgil},
  year = {2010},
  edition = {1st MIT Press pbk. ed},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-51405-7},
  lccn = {ML3470 .M66 2010},
  keywords = {{Analysis, appreciation},Popular music,Production and direction History,Sound recordings},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/moorefield2010.md}
}

@article{mori2017,
  title = {A Survey of Diminished Reality: {{Techniques}} for Visually Concealing, Eliminating, and Seeing through Real Objects},
  shorttitle = {A Survey of Diminished Reality},
  author = {Mori, Shohei and Ikeda, Sei and Saito, Hideo},
  year = {2017},
  month = dec,
  journal = {IPSJ Transactions on Computer Vision and Applications},
  volume = {9},
  number = {1},
  pages = {17},
  issn = {1882-6695},
  urldate = {2021-02-12},
  abstract = {In this paper, we review diminished reality (DR) studies that visually remove, hide, and see through real objects from the real world. We systematically analyze and classify publications and present a technology map as a reference for future research. We also discuss future directions, including multimodal diminished reality. We believe that this paper will be useful mainly for students who are interested in DR, beginning DR researchers, and teachers who introduce DR in their classes.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/mori2017.md;Human Computer Interaction/Augmented Reality/Mori et al., 2017 - A survey of diminished reality.pdf},
  url = {https://doi.org/10.1186/s41074-017-0028-1}
}

@book{murchison2010,
  title = {Ethnography Essentials: Designing, Conducting, and Presenting Your Research},
  shorttitle = {Ethnography Essentials},
  author = {Murchison, Julian M.},
  year = {2010},
  series = {Research Methods for the Social Sciences},
  edition = {1st ed},
  publisher = {{Jossey-Bass}},
  address = {{San Francisco}},
  isbn = {978-0-470-34389-0},
  langid = {english},
  lccn = {GN345 .M87 2010},
  keywords = {Ethnology,Methodology},
  file = {Research Methods/Autoethnography/Murchison, 2010 - Ethnography essentials.pdf}
}

@misc{musgrave1975,
  title = {Orfeo {{II}}: {{An Improvisation}} on a {{Theme}}},
  author = {Musgrave, Thea},
  year = {1975},
  journal = {Music Sales Classical},
  url = {http://www.musicsalesclassical.com/composer/work/8436},
  urldate = {2018-04-13},
  copyright = {Music Sales Classical},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/musgrave1975.md;../../../../../Zotero/storage/48K8ZPMX/8436.html}
}

@misc{musgrave1975a,
  title = {Orfeo {{I}}},
  author = {Musgrave, Thea},
  year = {1975},
  journal = {Music Sales Classical},
  url = {http://www.musicsalesclassical.com/composer/work/8432},
  urldate = {2018-04-13},
  copyright = {Music Sales Classical},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/musgrave1975a.md;../../../../../Zotero/storage/Q65CPZ7B/8432.html}
}

@misc{musgrave1987,
  title = {Narcissus},
  author = {Musgrave, Thea},
  year = {1987},
  journal = {Music Sales Classical},
  url = {http://www.musicsalesclassical.com/composer/work/11633},
  urldate = {2018-04-13},
  copyright = {Music Sales Classical},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/musgrave1987.md;../../../../../Zotero/storage/CWP6SYDJ/11633.html}
}

@misc{musgrave1993,
  title = {Orfeo {{III}}},
  author = {Musgrave, Thea},
  year = {1993},
  journal = {Music Sales Classical},
  url = {http://www.musicsalesclassical.com/composer/work/1098/8437#},
  urldate = {2018-04-13},
  copyright = {Music Sales Classical},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/musgrave1993.md;../../../../../Zotero/storage/YVKTMIL5/8437.html}
}

@article{nagel2005,
  title = {Beyond Sensory Substitution{\textemdash}Learning the Sixth Sense},
  author = {Nagel, Saskia K and Carl, Christine and Kringe, Tobias and M{\"a}rtin, Robert and K{\"o}nig, Peter},
  year = {2005},
  month = dec,
  journal = {Journal of Neural Engineering},
  volume = {2},
  number = {4},
  pages = {R13-R26},
  issn = {1741-2560, 1741-2552},
  urldate = {2020-10-03},
  abstract = {Rapid advances in neuroscience have sparked numerous efforts to study the neural correlate of consciousness. Prominent subjects include higher sensory area, distributed assemblies bound by synchronization of neuronal activity and neurons in specific cortical laminae. In contrast, it has been suggested that the quality of sensory awareness is determined by systematic change of afferent signals resulting from behaviour and knowledge thereof. Support for such skill-based theories of perception is provided by experiments on sensory substitution. Here, we pursue this line of thought and create new sensorimotor contingencies and, hence, a new quality of perception. Adult subjects received orientation information, obtained by a magnetic compass, via vibrotactile stimulation around the waist. After six weeks of training we evaluated integration of the new input by a battery of tests. The results indicate that the sensory information provided by the belt (1) is processed and boosts performance, (2) if inconsistent with other sensory signals leads to variable performance, (3) does interact with the vestibular nystagmus and (4) in half of the experimental subjects leads to qualitative changes of sensory experience. These data support the hypothesis that new sensorimotor contingencies can be learned and integrated into behaviour and affect perceptual experience.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/nagel2005.md;Cognitive Science/Multisensory Integration/Nagel et al., 2005 - Beyond sensory substitutionâ€”learning the sixth sense.pdf},
  url = {https://doi.org/10.1088/1741-2560/2/4/R02}
}

@inproceedings{naimark1991,
  title = {Elements of Real-Space Imaging: A Proposed Taxonomy},
  shorttitle = {Elements of Real-Space Imaging},
  booktitle = {Electronic {{Imaging}} '91, {{San Jose}},{{CA}}},
  author = {Naimark, Michael},
  editor = {Merritt, John O. and Fisher, Scott S.},
  year = {1991},
  month = aug,
  pages = {169--179},
  address = {{San Jose, CA}},
  urldate = {2021-02-12},
  abstract = {Along with the marriage of motion pictures and computers has come an increasing interest in making images appear to have a greater degree of realness or presence, which I call "realspace imaging." Such topics as high definition television, 3D, fisheye lenses, surrogate travel, arid "cyberspace" reflect such interest. These topics are usually piled together and are unparsable, with the implicit assumptions that "the more resolution, the more presence" and "the more presence, the better." This paper proposes a taxonomy of the elements of realspace imaging. The taxonomy is organized around six sections: 1) monoscopic imaging, 2) stereoscopic imaging, 3) multiscopic imaging, 4) panoramics, 5) surrogate travel, and 6) realtime imaging.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/naimark1991.md;Human Computer Interaction/Augmented Reality/Naimark, 1991 - Elements of real-space imaging.pdf},
  url = {https://doi.org/10.1117/12.46305}
}

@inproceedings{narumi2011,
  title = {Augmented Reality Flavors: Gustatory Display Based on Edible Marker and Cross-Modal Interaction},
  shorttitle = {Augmented Reality Flavors},
  booktitle = {Proceedings of the 2011 Annual Conference on {{Human}} Factors in Computing Systems - {{CHI}} '11},
  author = {Narumi, Takuji and Nishizaka, Shinya and Kajinami, Takashi and Tanikawa, Tomohiro and Hirose, Michitaka},
  year = {2011},
  pages = {93},
  publisher = {{ACM Press}},
  address = {{Vancouver, BC, Canada}},
  urldate = {2020-01-10},
  abstract = {The main contribution of this paper is to realize computer generated augmented flavors and establish a method to integrate gustatory information into computer human interactions. There are several reasons for the scarcity of research on gustatory information. One reason is that taste sensations are affected by a number of factors, such as vision, olfaction and memories. This produces a complex cognition mechanism for a user's gustatory sensation, and makes it difficult to build up a gustatory display which produces a specific taste on demand.},
  isbn = {978-1-4503-0228-9},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/narumi2011.md;Human Computer Interaction/Multisensory Interfacing/Narumi et al., 2011 - Augmented reality flavors.pdf},
  url = {https://doi.org/10.1145/1978942.1978957}
}

@article{navarro2021,
  title = {Why {{Asian Countries}} Are {{Controlling}} the {{Pandemic Better Than}} the {{United States}} and {{Western Europe}}},
  author = {Navarro, Vicente},
  year = {2021},
  month = apr,
  journal = {International Journal of Health Services},
  volume = {51},
  number = {2},
  pages = {261--264},
  issn = {0020-7314, 1541-4469},
  urldate = {2022-12-11},
  abstract = {The coronavirus pandemic has shed light on the detrimental impact of neoliberal policies on public health and well-being and as a result, there have been calls for increases in public spending to rectify the lack of public health services. However, neoliberal right-wing parties have dismissed such calls, pointing instead to Asian countries as examples in successfully controlling the pandemic without high public health spending, attributing this to the entrepreneurial orientation of their governments, as opposed to their public services. This article refutes this idea, instead charting the reasons that Asian countries have better controlled the pandemic including prior experience of pandemics, cultural factors, and various successful public health policies. The article concludes by looking at the example of Trump and demonstrating the inadequacies of the business model for dealing with the coronavirus pandemic.},
  langid = {english},
  file = {Politics/Marxism/Navarro, 2021 - Why Asian Countries are Controlling the Pandemic Better Than the United States.pdf},
  url = {https://doi.org/10.1177/0020731421999930}
}

@incollection{ndalianis2003,
  title = {Architectures of the {{Senses}}: {{Neobaroque Entertainment Spectacles}}},
  booktitle = {Rethinking Media Change: The Aesthetics of Transition},
  author = {Ndalianis, Angela},
  year = {2003},
  series = {Media in Transition},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-20146-9},
  lccn = {P90 .R38 2003},
  keywords = {History,Mass media},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ndalianis2003.md;Arts & Humanities/Aesthetics/Ndalianis, 2003 - Architectures of the Senses.pdf}
}

@book{negus2009,
  title = {Popular Music in Theory: An Introduction},
  shorttitle = {Popular Music in Theory},
  author = {Negus, Keith},
  year = {2009},
  edition = {Reprinted},
  publisher = {{Polity Press}},
  address = {{Cambridge}},
  isbn = {978-0-7456-1318-5 978-0-7456-1317-8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/negus2009.md}
}

@inproceedings{neustaedter2012,
  title = {Autobiographical Design in {{HCI}} Research: Designing and Learning through Use-It-Yourself},
  booktitle = {{{DIS}} '12: {{Proceedings}} of the {{Designing Interactive Systems Conference}}},
  author = {Neustaedter, Carman and Sengers, Phoebe},
  year = {2012},
  pages = {10},
  address = {{Newcastle Upon Tyne, United Kingdom}},
  abstract = {Designing a system with yourself as a target user and evaluating the design through your own self-usage is commonly considered a questionable approach in HCI research. Perhaps for this reason, HCI research including extensive self-usage of a design is underdocumented. Yet such self-usage does happen and many researchers have found great value in the lessons learned from it. Our goal in this paper is to bring these hidden practices to light and offer guidelines for how HCI researchers can usefully engage in what we term `autobiographical design'{\textemdash}design research drawing on extensive, genuine usage by those creating or building a system. Through interviews with HCI experts who have engaged in variations of autobiographical design, we draw out the possibilities and limitations of autobiographical design methods and lay out best practices for its use as an HCI research method.},
  langid = {english},
  file = {Research Methods/Autobiographical Design/Neustaedter and Sengers, 2012 - Autobiographical design in HCI research.pdf},
  url = {https://doi.org/10.1145/2317956.2318034}
}

@inproceedings{nishida2019,
  title = {Egocentric {{Smaller-person Experience}} through a {{Change}} in {{Visual Perspective}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Nishida, Jun and Matsuda, Soichiro and Oki, Mika and Takatori, Hikaru and Sato, Kosuke and Suzuki, Kenji},
  year = {2019},
  month = may,
  pages = {1--12},
  publisher = {{ACM}},
  address = {{Glasgow Scotland Uk}},
  urldate = {2021-05-15},
  isbn = {978-1-4503-5970-2},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/nishida2019.md;Human Computer Interaction/Augmented Reality/Nishida et al., 2019 - Egocentric Smaller-person Experience through a Change in Visual Perspective.pdf},
  url = {https://doi.org/10.1145/3290605.3300926}
}

@inproceedings{nishida2020,
  title = {{{HandMorph}}: A {{Passive Exoskeleton}} That {{Miniaturizes Grasp}}},
  shorttitle = {{{HandMorph}}},
  booktitle = {Proceedings of the 33rd {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Nishida, Jun and Matsuda, Soichiro and Matsui, Hiroshi and Teng, Shan-Yuan and Liu, Ziwei and Suzuki, Kenji and Lopes, Pedro},
  year = {2020},
  month = oct,
  pages = {565--578},
  publisher = {{ACM}},
  address = {{Virtual Event USA}},
  urldate = {2021-05-15},
  abstract = {We engineered an exoskeleton, which we call HandMorph, that approximates the experience of having a smaller grasp\- ing range. It uses mechanical links to transmit motion from the wearer's fingers to a smaller hand with five anatomically correct fingers. The result is that HandMorph miniaturizes a wearer's grasping range while transmitting haptic feedback.},
  isbn = {978-1-4503-7514-6},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/nishida2020.md;Human Computer Interaction/Multisensory Interfacing/Nishida et al., 2020 - HandMorph.pdf},
  url = {https://doi.org/10.1145/3379337.3415875}
}

@book{noe2004,
  title = {Action in Perception},
  author = {No{\"e}, Alva},
  year = {2004},
  series = {Representation and Mind},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-14088-1},
  lccn = {B828.45 .N64 2004},
  keywords = {Act (Philosophy),Perception (Philosophy)},
  file = {Philosophy/Extended Cognition/NoÃ«, 2004 - Action in perception.pdf}
}

@misc{noe2009,
  type = {Psychological {{Drama}}},
  title = {Enter the {{Void}}},
  author = {No{\'e}, Gaspar},
  year = {2009},
  publisher = {{Wild Bunch Distribution}},
  langid = {english}
}

@inproceedings{normand2012,
  title = {A New Typology of Augmented Reality Applications},
  booktitle = {Proceedings of the 3rd {{Augmented Human International Conference}} on - {{AH}} '12},
  author = {Normand, Jean-Marie and Servi{\`e}res, Myriam and Moreau, Guillaume},
  year = {2012},
  pages = {1--8},
  publisher = {{ACM Press}},
  address = {{Meg\&\#232;ve, France}},
  urldate = {2020-02-07},
  abstract = {In recent years Augmented Reality (AR) has become more and more popular, especially since the availability of mobile devices, such as smartphones or tablets, brought AR into our everyday life. Although the AR community has not yet agreed on a formal definition of AR, some work focused on proposing classifications of existing AR methods or applications. Such applications cover a wide variety of technologies, devices and goals, consequently existing taxonomies rely on multiple classification criteria that try to take into account AR applications diversity. In this paper we review existing taxonomies of augmented reality applications and we propose our own, which is based on (1) the number of degrees of freedom required by the application, as well as on (2) the visualization mode used, (3) the temporal base of the displayed content and (4) the rendering modalities used in the application. Our taxonomy covers location-based services as well as more traditional visionbased AR applications. Although AR is mainly based on the visual sense, other rendering modalities are also covered by the same degree-of-freedom criterion in our classification.},
  isbn = {978-1-4503-1077-2},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/normand2012.md;Human Computer Interaction/Augmented Reality/Normand et al., 2012 - A new typology of augmented reality applications.pdf},
  url = {https://doi.org/10.1145/2160125.2160143}
}

@misc{notion2020,
  title = {Notion {\textendash} {{The}} All-in-One Workspace for Your Notes, Tasks, Wikis, and Databases.},
  author = {Notion},
  year = {2020},
  journal = {Notion},
  url = {https://www.notion.so},
  urldate = {2020-05-25},
  abstract = {A new tool that blends your everyday work apps into one. It's the all-in-one workspace for you and your team},
  langid = {english},
  file = {../../../../../Zotero/storage/DXNI86HI/www.notion.so.html}
}

@misc{nreal2020,
  title = {{{nReal Light}}},
  author = {{nReal}},
  year = {2020},
  url = {https://nreal.ai/product/},
  urldate = {2020-10-01},
  file = {../../../../../Zotero/storage/FPP375TI/product.html}
}

@article{nystrom2011,
  title = {Textons and the {{Propagation}} of {{Space}} in {{Acousmatic Music}}},
  author = {Nystr{\"o}m, Erik},
  year = {2011},
  month = apr,
  journal = {Organised Sound},
  volume = {16},
  number = {1},
  pages = {14--26},
  issn = {1355-7718, 1469-8153},
  urldate = {2020-01-10},
  abstract = {The concepts introduced by Smalley in the context of space-form (2007) have firmly put acousmatic music on a discourse of spatial exploration, holding much potential for the developing of aesthetics in new directions. This article approaches space from the low level of musical structure, with a multi-dimensional attitude to space-form, exploring               spatial texture               , a concept introduced by Smalley to describe the temporal formations of space in spectromorphology (1997). Spatial articulation is investigated in the context of granular-oriented textures, proposing a micro-spatial, perceptual morphology {\textendash} the               texton               {\textendash} as an aesthetic approach to acousmatic music. This follows Albert Bregman's speculation regarding equivalents to visual perception in texture, where the theory of textons was first developed by the neuroscientist B{\'e}la Julesz.                          The article discusses acousmatic textons, in terms of intrinsic properties, the way they propagate in time, and how they organise in distributions to form spatial textures. The emergent macroscopic qualities of textonal formations are also reflected upon in the introduction of a group of textural states, where source-bonded spaces and abstract musical thinking coalesce.},
  langid = {english},
  file = {../../../../../../../../C\:\\Users\\Sam Bilbow\\OneDrive\\Literature\\Arts & Humanities\\Computational Art\\NystrÃ¶m, 2011 - Textons and the Propagation of Space in Acousmatic Music.pdf;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/nystrom2011.md},
  url = {https://doi.org/10.1017/S1355771810000397}
}

@phdthesis{nystrom2013,
  title = {Topology of {{Spatial Texture}} in the {{Acousmatic Medium}}},
  author = {Nystr{\"o}m, Erik},
  year = {2013},
  langid = {english},
  school = {City University London},
  file = {../../../../../../../../C\:\\Users\\Sam Bilbow\\OneDrive\\Literature\\Arts & Humanities\\Computational Art\\NystrÃ¶m, 2013 - Topology of Spatial Texture in the Acousmatic Medium.pdf;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/nystrom2013.md}
}

@article{nystrom2015,
  title = {Low-{{Level Topology}} of {{Spatial Texture}}},
  author = {Nystr{\"o}m, Erik},
  year = {2015},
  pages = {5},
  abstract = {Low-level topology of spatial texture is here introduced as the basis of an aesthetic principle of sonic texture and spatial structure in electroacoustic music. The term spatial texture is used to describe aggregate sound structures which have a perceived three-dimensional spatial presence, specifically meaning that they occupy several areas or a stretch of horizontal perspectival space1 whilst also having a dynamic behaviour in spectral space2. The word topology refers to properties, qualities and structural features which remain distinct to a texture despite continuous change or recurrent incarnations in different specific shapes throughout a work.3 Ultimately, topology of spatial texture may be thought of as the core principle behind an attitude to music which considers all elements of structure to be part of an elastic spatiotemporal sound fabric. Rather than conceiving a work as built from time-finite morphological `objects', this view emphasises processes of deformation, where any singular shapes may be seen as instances of textural topologies. The terminology presented here is intended as a contribution to discourse on spatiality in music, with special relevance to multichannel compositions.4 This article focuses on the low-level, internal, structure of a spatial texture.},
  langid = {english},
  file = {../../../../../../../../C\:\\Users\\Sam Bilbow\\OneDrive\\Literature\\Arts & Humanities\\Computational Art\\NystrÃ¶m, 2015 - Low-Level Topology of Spatial Texture.pdf;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/nystrom2015.md}
}

@inproceedings{obrist2014,
  title = {Temporal, Affective, and Embodied Characteristics of Taste Experiences: A Framework for Design},
  shorttitle = {Temporal, Affective, and Embodied Characteristics of Taste Experiences},
  booktitle = {Proceedings of the 32nd Annual {{ACM}} Conference on {{Human}} Factors in Computing Systems - {{CHI}} '14},
  author = {Obrist, Marianna and Comber, Rob and Subramanian, Sriram and {Piqueras-Fiszman}, Betina and Velasco, Carlos and Spence, Charles},
  year = {2014},
  pages = {2853--2862},
  publisher = {{ACM Press}},
  address = {{Toronto, Ontario, Canada}},
  urldate = {2020-05-25},
  abstract = {We present rich descriptions of taste experience through an analysis of the diachronic and synchronic experiences of each of the five basic taste qualities: sweet, sour, salt, bitter, and umami. Our findings, based on a combination of user experience evaluation techniques highlight three main themes: temporality, affective reactions, and embodiment. We present the taste characteristics as a framework for design and discuss each taste in order to elucidate the design qualities of individual taste experiences. These findings add a semantic understanding of taste experiences, their temporality enhanced through descriptions of the affective reactions and embodiment that the five basic tastes elicit. These findings are discussed on the basis of established psychological and behavioral phenomena, highlighting the potential for taste-enhanced design.},
  isbn = {978-1-4503-2473-1},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/obrist2014.md;Human Computer Interaction/Multisensory Interfacing/Obrist et al., 2014 - Temporal, affective, and embodied characteristics of taste experiences.pdf},
  url = {https://doi.org/10.1145/2556288.2557007}
}

@article{obrist2016,
  title = {Sensing the Future of {{HCI}}: Touch, Taste, and Smell User Interfaces},
  shorttitle = {Sensing the Future of {{HCI}}},
  author = {Obrist, Marianna and Velasco, Carlos and Vi, Chi and Ranasinghe, Nimesha and Israr, Ali and Cheok, Adrian and Spence, Charles and Gopalakrishnakone, Ponnampalam},
  year = {2016},
  month = aug,
  journal = {interactions},
  volume = {23},
  number = {5},
  pages = {40--49},
  issn = {10725520},
  urldate = {2020-05-25},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/obrist2016.md;Human Computer Interaction/Multisensory Interfacing/Obrist et al., 2016 - Sensing the future of HCI.pdf},
  url = {https://doi.org/10.1145/2973568}
}

@inproceedings{obrist2016a,
  title = {Touch, {{Taste}}, \& {{Smell User Interfaces}}: {{The Future}} of {{Multisensory HCI}}},
  shorttitle = {Touch, {{Taste}}, \& {{Smell User Interfaces}}},
  booktitle = {Proceedings of the 2016 {{CHI Conference Extended Abstracts}} on {{Human Factors}} in {{Computing Systems}}  - {{CHI EA}} '16},
  author = {Obrist, Marianna and Velasco, Carlos and Vi, Chi Thanh and Ranasinghe, Nimesha and Israr, Ali and Cheok, Adrian D. and Spence, Charles and Gopalakrishnakone, Ponnampalam},
  year = {2016},
  pages = {3285--3292},
  publisher = {{ACM Press}},
  address = {{San Jose, California, USA}},
  urldate = {2020-01-10},
  abstract = {The senses we call upon when interacting with technology are very restricted. We mostly rely on vision and audition, increasingly harnessing touch, whilst taste and smell remain largely underexploited. In spite of our current knowledge about sensory systems and sensory devices, the biggest stumbling block for progress concerns the need for a deeper understanding of people's multisensory experiences in HCI. It is essential to determine what tactile, gustatory, and olfactory experiences we can design for, and how we can meaningfully stimulate such experiences when interacting with technology. Importantly, we need to determine the contribution of the different senses along with their interactions in order to design more effective and engaging digital multisensory experiences. Finally, it is vital to understand what the limitations are that come into play when users need to monitor more than one sense at a time. The aim of this workshop is to deepen and expand the discussion on touch, taste, and smell within the CHI community and promote the relevance of multisensory experience design and research in HCI.},
  isbn = {978-1-4503-4082-3},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/obrist2016a.md;Human Computer Interaction/Multisensory Interfacing/Obrist et al., 2016 - Touch, Taste, & Smell User Interfaces.pdf},
  url = {https://doi.org/10.1145/2851581.2856462}
}

@inproceedings{obrist2017,
  title = {Mastering the {{Senses}} in {{HCI}}: {{Towards Multisensory Interfaces}}},
  shorttitle = {Mastering the {{Senses}} in {{HCI}}},
  booktitle = {Proceedings of the 12th {{Biannual Conference}} on {{Italian SIGCHI Chapter}} - {{CHItaly}} '17},
  author = {Obrist, Marianna},
  year = {2017},
  pages = {1--2},
  publisher = {{ACM Press}},
  address = {{Cagliari, Italy}},
  urldate = {2020-01-10},
  abstract = {With the proliferation of sensory technologies that do not only stimulate the sense of vision and hearing, but also our sense of touch, smell, and taste, we are confronted with the challenge of mastering those ``new'' senses in the design of interactive systems. To meaningfully design multisensory interfaces and enrich human-technology interactions we need to systematically investigate the technical, perceptual, and experiential parameters of sensory and multisensory stimulation. Here, I particularly focus on the study of tactile, gustatory, and olfactory experiences facilitated by the use of novel technologies (e.g., mid-air haptic devices, olfactory devices) and the combination of objective and subjective measures within sensory science, psychology, HCI, and user experience research.},
  isbn = {978-1-4503-5237-6},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/obrist2017.md;Human Computer Interaction/Multisensory Interfacing/Obrist, 2017 - Mastering the Senses in HCI.pdf},
  url = {https://doi.org/10.1145/3125571.3125603}
}

@article{obrist2017a,
  title = {Multisensory {{Experiences}} in {{HCI}}},
  author = {Obrist, Marianna and Gatti, Elia and Maggioni, Emanuela and Vi, Chi Thanh and Velasco, Carlos},
  year = {2017},
  month = apr,
  journal = {IEEE MultiMedia},
  volume = {24},
  number = {2},
  pages = {9--13},
  issn = {1070-986X},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/obrist2017a.md;Human Computer Interaction/Multisensory Interfacing/Obrist et al., 2017 - Multisensory Experiences in HCI.pdf},
  url = {https://doi.org/10.1109/MMUL.2017.33}
}

@misc{oculus2019,
  title = {Oculus {{Quest}}},
  author = {Oculus},
  year = {2019},
  url = {https://www.oculus.com/},
  urldate = {2020-07-12},
  abstract = {Defy reality and distance with Oculus. Our VR headsets connect people and redefine digital gaming and entertainment. Learn more about Rift, Rift S, Quest and Go.},
  langid = {english},
  file = {../../../../../Zotero/storage/87A4C3IR/www.oculus.com.html}
}

@misc{oculus2020,
  title = {Oculus {{Quest}} 2},
  shorttitle = {Oculus {{Quest}} 2},
  author = {Oculus},
  year = {2020},
  url = {https://www.oculus.com/quest-2/},
  urldate = {2020-10-01},
  abstract = {Oculus Quest 2 is our most advanced all-in-one VR system yet. Explore an expansive library of awe-inspiring games and immersive experiences with unparalleled freedom.},
  langid = {english},
  file = {../../../../../Zotero/storage/HPA26UYD/quest-2.html}
}

@inproceedings{odea2019,
  title = {Auditory {{Distraction}} in {{HCI}}: {{Towards}} a {{Framework}} for the {{Design}} of {{Hierarchically-Graded Auditory Notifications}}},
  shorttitle = {Auditory {{Distraction}} in {{HCI}}},
  booktitle = {Proceedings of the 14th {{International Audio Mostly Conference}}: {{A Journey}} in {{Sound}}},
  author = {O'Dea, Ronan and Jedir, Rokaia and Neff, Flaithri},
  year = {2019},
  month = sep,
  pages = {61--66},
  publisher = {{ACM}},
  address = {{Nottingham United Kingdom}},
  urldate = {2020-09-19},
  abstract = {This paper discusses hierarchical structure of auditory distractors based on two human perceptual systems responsible for distinct pre-attentive process:1. the auditory perceptual system and 2. the working memory (WM) system. Specifically, the authors propose accounting for WM function and capacity when designing auditory notifications for multimodal applications, due to interaction between certain auditory attention mechanisms and WM. A review of literature concerning WM disruption caused by auditory streams, as well as reference to relevant ISO (International Organization for Standardization) standards, is also presented.},
  isbn = {978-1-4503-7297-8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/odea2019.md;Arts & Humanities/Computational Art/O'Dea et al., 2019 - Auditory Distraction in HCI.pdf},
  url = {https://doi.org/10.1145/3356590.3356601}
}

@incollection{olsen2023,
  title = {Embodied and {{Sonic Interactions}} in {{Virtual Environments}}: {{Tactics}} and {{Exemplars}}},
  shorttitle = {Embodied and {{Sonic Interactions}} in {{Virtual Environments}}},
  booktitle = {Sonic {{Interactions}} in {{Virtual Environments}}},
  author = {Olsen, Sophus B{\'e}ne{\'e} and H{\o}eg, Emil Rosenlund and Erkut, Cumhur},
  editor = {Geronazzo, Michele and Serafin, Stefania},
  year = {2023},
  pages = {219--235},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  urldate = {2024-01-29},
  abstract = {Abstract             As the next generation of active video games (AVG) and virtual reality (VR) systems enter people's lives, designers may wrongly aim for an experience decoupled from bodies. However, both AVG and VR clearly afford opportunities to bring experiences, technologies, and users' physical and experiential bodies together, and to study and teach these open-ended relationships of enaction and meaning-making in the framework of embodied interaction. Without such a framework, an aesthetic pleasure, lasting satisfaction, and enjoyment would be impossible to achieve in designing sonic interactions in virtual environments (SIVE). In this chapter, we introduce this framework and focus on design exemplars that come from a soma design ideation workshop and balance rehabilitation. Within the field of physiotherapy, developing new conceptual interventions, with a more patient-centered approach, is still scarce but has huge potential for overcoming some of the challenges facing health care. We indicate how the tactics such as making space, subtle guidance, defamiliarization, and intimate correspondence have informed the exemplars, both in the workshop and also in our ongoing physiotherapy case. Implications for these tactics and design strategies for our design, as well as for general practitioners of SIVE are outlined.},
  isbn = {978-3-031-04020-7 978-3-031-04021-4},
  langid = {english},
  file = {Human Computer Interaction/Virtual Reality/Olsen et al., 2023 - Embodied and Sonic Interactions in Virtual Environments.pdf},
  url = {https://doi.org/10.1007/978-3-031-04021-4_7}
}

@inproceedings{onate2020,
  title = {Seeking for Spectral Manipulation of the Sound of Musical Instruments Using Metamaterials},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {O{\~n}ate, Carolina Espinoza and Arancibia, Alonso and Cartes, Gabriel and Beas, Claudio Falc{\'o}n},
  year = {2020},
  series = {{{AM}} '20},
  pages = {277--280},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {The sound of practically all traditional musical instruments is unique and depends on the collective behavior of various vibrators, each one with their own acoustic and mechanical properties. If we pluck a string of an acoustic guitar, a part of the wave is reflected by the sound box, and the other fraction of the elastic energy sets in motion the sound box surfaces. Thereby, the vibration of the surfaces (soundboard, ribs, back and sound hole), are the basis of the guitar sound production.In this work, we explore the effect of locally coupling tunable mechanical metamaterials to the soundboard of an acoustic guitar, in order to absorb specific ranges of frequencies and change its vibrational properties. We show the preliminary results of our research, which involves a mechano-acoustic characterization of tunable mechanical metamaterials and the analysis of the effect of applying them to an acoustic guitar when a string tuned to a convenient frequency is plucked. We observe that this simple mechanism is an alternative to manipulate the spectral properties of the sound signal produced by the instrument. Although the results are inaudible, they seem promising for future explorations of sound manipulation of musical instruments.},
  isbn = {978-1-4503-7563-4},
  keywords = {acoustic,musical instruments,new materials,sonic interaction design},
  file = {../../../../../../../../C\:\\Users\\Sam Bilbow\\OneDrive\\Literature\\Arts & Humanities\\Computational Art\\OÃ±ate et al., 2020 - Seeking for spectral manipulation of the sound of musical instruments using.pdf;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/onate2020.md},
  url = {https://doi.org/10.1145/3411109.3411127}
}

@article{ongwesojr.2022,
  title = {The {{Metaverse Has Bosses Too}}. {{Meet}} the `{{Managers}}' of {{Axie Infinity}}},
  author = {Ongweso Jr., Edward},
  year = {2022},
  month = apr,
  journal = {Vice},
  url = {https://archive.today/pQfjZ},
  urldate = {2022-09-12},
  abstract = {Managers in play-to-earn game Axie Infinity employ large teams of ``scholars'' who can't afford their own NFTs even as the game's economy spirals.},
  chapter = {Motherboard},
  langid = {english},
  keywords = {Crypto,Metaverse,Nfts,On the Clock,Play to Earn,Worldnews},
  file = {../../../../../Zotero/storage/CXEU2N4Y/the-metaverse-has-bosses-too-meet-the-managers-of-axie-infinity.html}
}

@misc{opensea2022,
  title = {The {{Sandbox}} - {{Collection}} on {{OpenSea}}},
  author = {OpenSea},
  year = {2022},
  journal = {OpenSea},
  url = {https://opensea.io/collection/sandbox},
  urldate = {2022-12-12},
  abstract = {The Sandbox is a community-driven platform where creators can monetize voxel assets and gaming experiences on the blockchain. The Sandbox metaverse comprises a map made up of 166,464 LANDS.  LAND owners can host contests and events, stake SAND to earn and customize assets, monetize assets and experiences, vote in the metaverse governance, play games that you or others create, and more! Trade the collection and keep your eyes peeled for future drops.},
  langid = {american}
}

@misc{opensea2022a,
  title = {{{OpenSea}}, the Largest {{NFT}} Marketplace},
  author = {OpenSea},
  year = {2022},
  journal = {OpenSea},
  url = {https://opensea.io/},
  urldate = {2022-12-12},
  abstract = {OpenSea is the world's first and largest web3 marketplace for NFTs and crypto collectibles. Browse, create, buy, sell, and auction NFTs using OpenSea today.},
  langid = {american},
  file = {../../../../../Zotero/storage/Z2R5FVAJ/opensea.io.html}
}

@article{ossaparra2015,
  title = {Engaging in Critically Reflective Teaching: From Theory to Practice in Pursuit of Transformative Learning},
  shorttitle = {Engaging in Critically Reflective Teaching},
  author = {Ossa Parra, Marcela and Guti{\'e}rrez, Roberto and Aldana, Mar{\'i}a Fernanda},
  year = {2015},
  month = jan,
  journal = {Reflective Practice},
  volume = {16},
  number = {1},
  pages = {16--30},
  issn = {1462-3943, 1470-1103},
  urldate = {2021-09-14},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ossaparra2015.md;Pedagogy/Ossa Parra et al., 2015 - Engaging in critically reflective teaching.pdf},
  url = {https://doi.org/10.1080/14623943.2014.944141}
}

@misc{oxfordreference2020,
  title = {Ocularcentrism},
  author = {Oxford Reference},
  year = {2020},
  journal = {Oxford Reference},
  url = {https://www.oxfordreference.com/view/10.1093/oi/authority.20110803100245338},
  urldate = {2020-05-25},
  abstract = {"ocularcentrism" published on  by null.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/oxfordreference2020.md;../../../../../Zotero/storage/KJKD38JW/authority.html}
}

@article{panciroli2018,
  title = {Educating about {{Art}} by {{Augmented Reality}}: {{New Didactic Mediation Perspectives}} at {{School}} and in {{Museums}}},
  shorttitle = {Educating about {{Art}} by {{Augmented Reality}}},
  author = {Panciroli, Chiara and Macauda, Anita and Russo, Veronica},
  year = {2018},
  month = mar,
  journal = {Proceedings},
  volume = {1},
  number = {9},
  pages = {1107},
  issn = {2504-3900},
  urldate = {2020-01-10},
  abstract = {Different national and international researches have stressed relevant aspects concerning the application of augmented reality in formal and non-formal educational contexts, especially at school and in museums. In fact, augmented reality plays a meaningful role in the relationship between technologies and didactic mediation; its applications are the prerequisite for an augmented learning, through the reproduction of specific scenarios which go beyond the pure theoretical dimension. More specifically the present contribution aims to set out an option for a reflection on the relationship between art education and augmented reality technologies from the didactic mediation point of view, with reference to a shared and collaborative construction of knowledge of artistic and cultural heritage.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/panciroli2018.md;Human Computer Interaction/Augmented Reality/Panciroli et al., 2018 - Educating about Art by Augmented Reality.pdf},
  url = {https://doi.org/10.3390/proceedings1091107}
}

@article{papagiannis2014,
  title = {Working towards Defining an Aesthetics of Augmented Reality: {{A}} Medium in Transition},
  shorttitle = {Working towards Defining an Aesthetics of Augmented Reality},
  author = {Papagiannis, Helen},
  year = {2014},
  month = feb,
  journal = {Convergence: The International Journal of Research into New Media Technologies},
  volume = {20},
  number = {1},
  pages = {33--40},
  issn = {1354-8565, 1748-7382},
  urldate = {2020-01-10},
  abstract = {The present is a critical time in augmented reality's (AR) definition, as a new medium with aesthetics and conventions just beginning to emerge. We are at a moment when we can look both to the future and to the past: still seeing the previous forms that are shaping AR as a medium while paving new paths, contributing to novel styles and tropes. This article will work toward defining an aesthetics of AR as a new medium in transition, discussing my work as both an artist and a researcher in AR.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/papagiannis2014.md;Human Computer Interaction/Augmented Reality/Papagiannis, 2014 - Working towards defining an aesthetics of augmented reality.pdf},
  url = {https://doi.org/10.1177/1354856513514333}
}

@incollection{papagiannis2017,
  title = {The {{Critical Role}} of {{Artists}} in {{Advancing Augmented Reality}}},
  booktitle = {The {{Next Step}}: {{Exponential Life}}},
  author = {Papagiannis, Helen},
  year = {2017},
  pages = {124--139},
  publisher = {{Turner Libros}},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/papagiannis2017.md;Human Computer Interaction/Augmented Reality/Papagiannis, 2017 - The Critical Role of Artists in Advancing Augmented Reality.pdf}
}

@misc{parikka2010,
  title = {What Is {{Media Archaeology}}?},
  shorttitle = {What Is {{Media Archaeology}}?},
  author = {Parikka, Jussi},
  year = {2010},
  month = oct,
  url = {http://mediacartographies.blogspot.com/2010/10/what-is-media-archaeology-beta.html},
  urldate = {2018-04-13},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/parikka2010.md}
}

@article{parikka2015,
  title = {Mutating {{Media Ecologies}}},
  author = {Parikka, Jussi},
  year = {2015},
  pages = {8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/parikka2015.md;Arts & Humanities/Media Studies/Parikka, 2015 - Mutating Media Ecologies.pdf}
}

@incollection{paul2015,
  title = {Genealogies of the {{New Aesthetic}}},
  booktitle = {Postdigital {{Aesthetics}}},
  author = {Paul, Christiane and Levy, Malcolm},
  editor = {Berry, David and Dieter, Michael},
  year = {2015},
  pages = {27--43},
  publisher = {{Palgrave Macmillan UK}},
  address = {{London}},
  isbn = {978-1-349-49378-4 978-1-137-43720-4},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/paul2015.md;Arts & Humanities/Media Studies/Paul and Levy, 2015 - Genealogies of the New Aesthetic.pdf}
}

@inproceedings{paul2015a,
  title = {From {{Immateriality}} to {{Neomateriality}}: {{Art}} and the {{Conditions}} of {{Digital Materiality}}},
  booktitle = {Proceedings of the 21st {{International Symposium}} on {{Electronic Art}}},
  author = {Paul, Christiane},
  year = {2015},
  pages = {4},
  address = {{Vancouver, BC, Canada}},
  abstract = {This paper explores the evolution of materialities in the context of art and digital technologies and proposes ``neomateriality'' as a current condition of material and objecthood. It traces the evolution from dematerialization and the immaterial to hypermateriality and neomateriality as a term capturing various disruptions that introduce new aesthetic paradigms. The concept of neomateriality strives to describe an objecthood that incorporates networked digital technologies, and embeds, processes, and reflects back the data of humans and the environment, or reveals its own coded materiality and the way in which digital processes see our world.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/paul2015a.md;Philosophy/Materiality/Paul, 2015 - From Immateriality to Neomateriality.pdf}
}

@incollection{paul2016,
  title = {Augmented {{Realities}}: {{Digital Art}} in the {{Public Sphere}}},
  shorttitle = {Augmented {{Realities}}},
  booktitle = {A {{Companion}} to {{Public Art}}},
  author = {Paul, Christiane},
  editor = {Knight, Cher Krause and Senie, Harriet F.},
  year = {2016},
  month = aug,
  edition = {1},
  pages = {205--225},
  publisher = {{Wiley}},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118475331.ch10},
  urldate = {2021-06-11},
  isbn = {978-1-118-47532-4 978-1-118-47533-1},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/University/Literature/Human Computer Interaction/Augmented Reality/Paul, 2016 - Augmented Realities2.pdf;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/paul2016.md}
}

@inproceedings{piekarski2001,
  title = {Tinmith-{{Metro}}: New Outdoor Techniques for Creating City Models with an Augmented Reality Wearable Computer},
  shorttitle = {Tinmith-{{Metro}}},
  booktitle = {Proceedings {{Fifth International Symposium}} on {{Wearable Computers}}},
  author = {Piekarski, W. and Thomas, B.H.},
  year = {2001},
  pages = {31--38},
  publisher = {{IEEE Comput. Soc}},
  address = {{Zurich, Switzerland}},
  urldate = {2021-04-14},
  abstract = {This paper presents new techniques for capturing and viewing on site 3D graphical models for large outdoor objects. Using an augmented reality wearable computer, we have developed a software system, known as TinmithMetro. Tinmith-Metro allows users to control a 3D constructive solid geometry modeller for building graphical objects of large physical artefacts, for example buildings, in the physical world. The 3D modeller is driven by a new user interface known as Tinmith-Hand, which allows the user to control the modeller using a set of pinch gloves and hand tracking. These techniques allow user to supply their AR renderers with models that would previously have to be captured with manual, time-consuming, and/or expensive methods.},
  isbn = {978-0-7695-1318-8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/piekarski2001.md;Human Computer Interaction/Augmented Reality/Piekarski and Thomas, 2001 - Tinmith-Metro.pdf},
  url = {https://doi.org/10.1109/ISWC.2001.962093}
}

@phdthesis{pirro2017,
  title = {Composing {{Interactions}}},
  author = {Pirr{\`o}, David},
  year = {2017},
  address = {{Austria}},
  langid = {english},
  school = {Institute of Electronic Music and Acoustics, University of Music and Performing Arts Graz},
  file = {../../../../../../../../C\:\\Users\\Sam Bilbow\\OneDrive\\Literature\\Arts & Humanities\\Computational Art\\PirrÃ², 2017 - Composing Interactions.pdf;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/pirro2017.md}
}

@book{price2011,
  title = {Mad at School: Rhetorics of Mental Disability and Academic Life},
  shorttitle = {Mad at School},
  author = {Price, Margaret},
  year = {2011},
  series = {Corporealities},
  publisher = {{University of Michigan Press}},
  address = {{Ann Arbor}},
  isbn = {978-0-472-07138-8 978-0-472-05138-0},
  lccn = {RC451.4.S7 P735 2011},
  keywords = {College students,College teachers,Communication,Education (Higher),Employment,Faculty,Mental health,Mentally Disabled Persons,Mentally ill,Personal Narratives,psychology,Stereotyping},
  file = {Pedagogy/Price, 2011 - Mad at school.pdf}
}

@book{pursell1972,
  title = {The {{Military-Industrial Complex}}},
  author = {Pursell, Carroll},
  year = {1972},
  month = feb,
  publisher = {{Harper \& Row}},
  isbn = {978-0-06-045296-4},
  langid = {english},
  file = {../../../../../Zotero/storage/569BXV2U/25205423.bib}
}

@article{puyat2021,
  title = {Axie {{Infinity}} and the Concept of Play-to-Earn},
  author = {Puyat, Maia},
  year = {2021},
  journal = {CNN Philippines},
  url = {https://www.cnnphilippines.com/life/culture/tech/2021/11/9/axie-infinity-play-to-earn-philippines.html},
  urldate = {2022-09-12},
  langid = {english},
  file = {../../../../../Zotero/storage/IBNIHCJ6/axie-infinity-play-to-earn-philippines.html}
}

@misc{quay2016,
  title = {Augmented {{Reality Musical Instrument}}},
  author = {Quay, Yago De},
  year = {2016},
  month = dec,
  url = {https://www.youtube.com/watch?v=11glZ3U1Txs},
  urldate = {2022-11-03}
}

@inproceedings{quinton2020,
  title = {Sonification of an Exoplanetary Atmosphere},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Quinton, Michael and McGregor, Iain and Benyon, David},
  year = {2020},
  series = {{{AM}} '20},
  pages = {191--198},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {This study investigates the effectiveness of user design methods to create a sonification for an astronomer who analyses exoplanet meteorological data situated in habitable zones. Requirements about the astronomer's work, the dataset and how to sonify it utilising Grounded Theory were identified. Parameter mapping sonification was used to represent effective transiting radii measurements through subtractive synthesis and spatialization. The design was considered to be effective, allowing the instantaneous identification of a water feature overlooked on a visual graph, even when noise within the dataset overlapped the source signal. The results suggest that multiple parameter mappings provide richer auditory stimuli and semantic qualities in order to allow an improved understanding of the dataset.},
  isbn = {978-1-4503-7563-4},
  keywords = {astronomy,exoplanet atmospheres,grounded theory,parameter mapping sonification,sonification,user centred design},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/quinton2020.md;Arts & Humanities/Computational Art/Quinton et al., 2020 - Sonification of an exoplanetary atmosphere.pdf},
  url = {https://doi.org/10.1145/3411109.3411117}
}

@article{ramo2012,
  title = {Digital {{Augmented Reality Audio Headset}}},
  author = {R{\"a}m{\"o}, Jussi and V{\"a}lim{\"a}ki, Vesa},
  year = {2012},
  journal = {Journal of Electrical and Computer Engineering},
  volume = {2012},
  pages = {1--13},
  issn = {2090-0147, 2090-0155},
  urldate = {2020-01-10},
  abstract = {Augmented reality audio (ARA) combines virtual sound sources with the real sonic environment of the user. An ARA system can be realized with a headset containing binaural microphones. Ideally, the ARA headset should be acoustically transparent, that is, it should not cause audible modification to the surrounding sound. A practical implementation of an ARA mixer requires a low-latency headphone reproduction system with additional equalization to compensate for the attenuation and the modified ear canal resonances caused by the headphones. This paper proposes digital IIR filters to realize the required equalization and evaluates a real-time prototype ARA system. Measurements show that the throughput latency of the digital prototype ARA system can be less than 1.4\,ms, which is sufficiently small in practice. When the direct and processed sounds are combined in the ear, a comb filtering effect is brought about and appears as notches in the frequency response. The comb filter effect in speech and music signals was studied in a listening test and it was found to be inaudible when the attenuation is 20\,dB. Insert ARA headphones have a sufficient attenuation at frequencies above about 1\,kHz. The proposed digital ARA system enables several immersive audio applications, such as a virtual audio tourist guide and audio teleconferencing.},
  langid = {english},
  file = {../../../../../../../../C\:\\Users\\Sam Bilbow\\OneDrive\\Literature\\Human Computer Interaction\\Augmented Reality\\RÃ¤mÃ¶ and VÃ¤limÃ¤ki, 2012 - Digital Augmented Reality Audio Headset.pdf;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ramo2012.md},
  url = {https://doi.org/10.1155/2012/457374}
}

@phdthesis{ranjan2016,
  title = {{{3D Audio Reproduction}}: {{Natural Augmented Reality Headset And Next Generation Entertainment System Using Wave Field Synthesis}}},
  author = {Ranjan, Rishabh},
  year = {2016},
  langid = {english},
  school = {Nanyang Technological University},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ranjan2016.md;Human Computer Interaction/Augmented Reality/Ranjan, 2016 - 3D Audio Reproduction.pdf}
}

@article{raskar1998,
  title = {Spatially {{Augmented Reality}}},
  author = {Raskar, Ramesh and Welch, Greg and Fuchs, Henry},
  year = {1998},
  month = sep,
  pages = {8},
  abstract = {To create an effective illusion of virtual objects coexisting with the real world, see-through HMD-based Augmented Reality techniques supplement the user's view with images of virtual objects. We introduce here a new paradigm, Spatially Augmented Reality (SAR), where virtual objects are rendered directly within or on the user's physical space.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/raskar1998.md;Human Computer Interaction/Augmented Reality/Raskar et al., 1998 - Spatially Augmented Reality.pdf}
}

@article{raskin2005,
  title = {Comments Are {{More Important}} than {{Code}}},
  author = {Raskin, Jef},
  year = {2005},
  month = mar,
  journal = {Queue},
  volume = {3},
  number = {2},
  pages = {64--65},
  issn = {1542-7730, 1542-7749},
  urldate = {2020-05-24},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/raskin2005.md;Arts & Humanities/Media Studies/Raskin, 2005 - Comments are More Important than Code.pdf},
  url = {https://doi.org/10.1145/1053331.1053354}
}

@misc{ray2018,
  title = {Brian {{Eno}} and {{Peter Chilvers}} Create `Quite Magical' Flower Garden of Sound in {{Amsterdam}} with `{{Bloom}}: {{Open Space}}' - {{Stories}}},
  author = {Ray, Susanna},
  year = {2018},
  month = feb,
  url = {https://archive.today/tRSVk},
  urldate = {2020-01-10},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ray2018.md;../../../../../Zotero/storage/6CWBQ7NR/brian-eno-peter-chilvers-create-quite-magical-flower-garden-sound-amsterdam-bloom-open-space.html}
}

@incollection{rhodes2018,
  title = {Augmented {{Reality}} in {{Art}}: {{Aesthetics}} and {{Material}} for {{Expression}}},
  shorttitle = {Augmented {{Reality}} in {{Art}}},
  booktitle = {Augmented {{Reality Art}}},
  author = {Rhodes, Geoffrey Alan},
  editor = {Geroimenko, Vladimir},
  year = {2018},
  pages = {163--172},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  url = {https://doi.org/10.1007/978-3-319-69932-5_7},
  urldate = {2020-05-25},
  isbn = {978-3-319-69931-8 978-3-319-69932-5},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/rhodes2018.md;Human Computer Interaction/Augmented Reality/Rhodes, 2018 - Augmented Reality in Art.pdf}
}

@article{riva2016,
  title = {Transforming {{Experience}}: {{The Potential}} of {{Augmented Reality}} and {{Virtual Reality}} for {{Enhancing Personal}} and {{Clinical Change}}},
  shorttitle = {Transforming {{Experience}}},
  author = {Riva, Giuseppe and Ba{\~n}os, Rosa M. and Botella, Cristina and Mantovani, Fabrizia and Gaggioli, Andrea},
  year = {2016},
  month = sep,
  journal = {Frontiers in Psychiatry},
  volume = {7},
  issn = {1664-0640},
  urldate = {2022-08-18},
  abstract = {During life, many personal changes occur. These include changing house, school, work, and even friends and partners. However, the daily experience shows clearly that, in some situations, subjects are unable to change even if they want to. The recent advances in psychology and neuroscience are now providing a better view of personal change, the change affecting our assumptive world: (a) the focus of personal change is reducing the distance between self and reality (conflict); (b) this reduction is achieved through (1) an intense focus on the particular experience creating the conflict or (2) an internal or external reorganization of this experience; (c) personal change requires a progression through a series of different stages that however happen in discontinuous and non-linear ways; and (d) clinical psychology is often used to facilitate personal change when subjects are unable to move forward. Starting from these premises, the aim of this paper is to review the potential of virtuality for enhancing the processes of personal and clinical change. First, the paper focuses on the two leading virtual technologies {\textendash} augmented reality (AR) and virtual reality (VR) {\textendash} exploring their current uses in behavioral health and the outcomes of the 28 available systematic reviews and meta-analyses. Then the paper discusses the added value provided by VR and AR in transforming our external experience by focusing on the high level of personal efficacy and self-reflectiveness generated by their sense of presence and emotional engagement. Finally, it outlines the potential future use of virtuality for transforming our inner experience by structuring, altering, and/ or replacing our bodily self-consciousness. The final outcome may be a new generation of transformative experiences that provide knowledge that is epistemically inaccessible to the individual until he or she has that experience, while at the same time transforming the individual's worldview.},
  langid = {english},
  file = {Human Computer Interaction/Mixed Reality/Riva et al., 2016 - Transforming Experience.pdf},
  url = {https://doi.org/10.3389/fpsyt.2016.00164}
}

@article{robinett1991,
  title = {A {{Computational Model}} for the {{Stereoscopic Optics}} of a {{Head-Mounted Display}}},
  author = {Robinett, Warren and Rolland, Jannick P},
  year = {1991},
  pages = {21},
  abstract = {For stereoscopic photography or telepresence, orthostereoscopy occurs when the perceived size, shape, and relative position of objects in the three-dimensional scene being viewed match those of the physical objects in front of the camera. In Virtual Reality, the simulated scene has no physical counterpart, so orthostereoscopy must be defined in this case as constancy, as the head moves around, of the perceived size, shape and relative positions of the simulated objects.},
  langid = {english},
  keywords = {â›” No DOI found},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/robinett1991.md;Human Computer Interaction/Augmented Reality/Robinett and Rolland, 1991 - A Computational Model for the Stereoscopic Optics of a Head-Mounted Display.pdf},
  url = {https://doi.org/10.1016/B978-0-12-227748-1.50013-5}
}

@article{robinett1992,
  title = {Synthetic Experience: {{A}} Proposed Taxonomy},
  author = {Robinett, Warren},
  year = {1992},
  month = jan,
  journal = {Presence: Teleoper. Virtual Environ.},
  volume = {1},
  number = {2},
  pages = {229--247},
  issn = {1054-7460},
  abstract = {A taxonomy is proposed to classify all varieties of technologically mediated experience. This includes virtual reality and teleoperation, and also earlier devices such as the microscope and telephone. The model of mediated interaction assumes a sensor-display link from the world to the human, and an action-actuator link going back from the human to the world, with the mediating technology transforming the transmitted experience in some way. The taxonomy is used to classify a number of example systems.Two taxonomies proposed earlier are compared with the ideas presented in this paper. Then the long-term prospects of this field are speculated on, ignoring constraints of cost, effort, or time to develop. Finally, the ultimate limits of synthetic experience are discussed, which derive from properties of the physical universe and the human neural apparatus.},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/robinett1992.md;Human Computer Interaction/Augmented Reality/Robinett, 1992 - Synthetic experience.pdf}
}

@misc{robinson2020,
  title = {A {{Hawk Calling Out To The Canyon}} -- {{An Augmented Harmonica}} \& {{Immersive Music Performance}}},
  author = {Robinson, Andrew},
  year = {2020},
  month = feb,
  url = {https://www.youtube.com/watch?v=VuaCJTPChvY},
  urldate = {2022-11-03}
}

@misc{rode2020,
  title = {{{SoundField}} by {{R{\O}DE Plugin}}},
  author = {R{\O}DE},
  year = {2020},
  url = {https://www.rode.com/soundfieldplugin},
  urldate = {2020-05-25},
  file = {../../../../../Zotero/storage/KISLRKDL/soundfieldplugin.html}
}

@inproceedings{rodger2020,
  title = {What {{Makes}} a {{Good Musical Instrument}}? {{A Matter}} of {{Processes}}, {{Ecologies}} and {{Specificities}}},
  booktitle = {Proceedings of the {{International Conference}} on {{New Interfaces}} for {{Musical Expression}}},
  author = {Rodger, Matthew and Stapleton, Paul and {van Walstijn}, Maarten and Ortiz, Miguel and Pardue, Laurel},
  year = {2020},
  pages = {6},
  address = {{Birmingham, UK}},
  abstract = {Understanding the question of what makes a good musical instrument raises several conceptual challenges. Researchers have regularly adopted tools from traditional HCI as a framework to address this issue, in which instrumental musical activities are taken to comprise a device and a user, and should be evaluated as such. We argue that this approach is not equipped to fully address the conceptual issues raised by this question. It is worth reflecting on what exactly an instrument is, and how instruments contribute toward meaningful musical experiences. Based on a theoretical framework that incorporates ideas from ecological psychology, enactivism, and phenomenology, we propose an alternative approach to studying musical instruments. According to this approach, instruments are better understood in terms of processes rather than as devices, while musicians are not users, but rather agents in musical ecologies. A consequence of this reframing is that any evaluations of instruments, if warranted, should align with the specificities of the relevant processes and ecologies concerned. We present an outline of this argument and conclude with a description of a current research project to illustrate how our approach can shape the design and performance of a musical instrument in-progress.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/rodger2020.md;Philosophy/Extended Cognition/Rodger et al., 2020 - What Makes a Good Musical Instrument.pdf}
}

@book{rodgers,
  title = {Pink {{Noises}}: {{Women}} on {{Electronic Music}} and {{Sound}}},
  author = {Rodgers, Tara},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/rodgers.md;Arts & Humanities/Computational Art/Rodgers, Pink Noises.pdf}
}

@article{rogers2021,
  title = {Sci-{{Fi Icon Neal Stephenson Finally Takes}} on {{Global Warming}}},
  author = {Rogers, Adam},
  year = {2021},
  journal = {Wired},
  issn = {1059-1028},
  url = {https://archive.today/AOqTa},
  urldate = {2022-09-12},
  abstract = {The renowned author says his genre should inspire solutions. In his new novel, 'Termination Shock,' he tackles our most existential crisis.},
  langid = {american},
  keywords = {climate change,longreads,magazine-29.11,science fiction},
  file = {../../../../../Zotero/storage/E8A88S2A/sci-fi-icon-neal-stephenson-global-warming.html}
}

@article{rolland2000,
  title = {Optical {{Versus Video See-Through Head-Mounted Displays}} in {{Medical Visualization}}},
  author = {Rolland, Jannick P. and Fuchs, Henry},
  year = {2000},
  month = jun,
  journal = {Presence: Teleoperators and Virtual Environments},
  volume = {9},
  number = {3},
  pages = {287--309},
  issn = {1054-7460},
  urldate = {2021-05-14},
  abstract = {We compare two technological approaches to augmented reality for 3-D medical visualization: optical and video see-through devices. We provide a context to discuss the technology by reviewing several medical applications of augmented-reality research efforts driven by real needs in the medical field, both in the United States and in Europe. We then discuss the issues for each approach, optical versus video, from both a technology and human-factor point of view. Finally, we point to potentially promising future developments of such devices including eye tracking and multifocus planes capabilities, as well as hybrid optical/video technology.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/rolland2000.md;Human Computer Interaction/Augmented Reality/Rolland and Fuchs, 2000 - Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization.pdf},
  url = {https://doi.org/10.1162/105474600566808}
}

@inproceedings{rompapas2020,
  title = {Project {{Esky}}: {{Enabling High Fidelity Augmented Reality}} on an {{Open Source Platform}}},
  booktitle = {{{ISS}} '20: {{Proceedings}} of the 2020 {{ACM International Conference}} on {{Interactive Surfaces}} and {{Spaces}}},
  author = {Rompapas, Damien Constantine and Quiros, Daniel Flores and Rodda, Charlton and Brown, Bryan Christopher and Zerkin, Noah Benjamin and Cassinelli, Alvaro},
  year = {2020},
  month = nov,
  address = {{Lisbon, Portugal}},
  urldate = {2020-10-14},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/rompapas2020.md;Human Computer Interaction/Augmented Reality/Rompapas et al., 2020 - Project Esky.pdf},
  url = {https://doi.org/10.1145/3380867.3426220}
}

@inproceedings{rosenberg1993,
  title = {Virtual Fixtures: {{Perceptual}} Tools for Telerobotic Manipulation},
  shorttitle = {Virtual Fixtures},
  booktitle = {Proceedings of {{IEEE Virtual Reality Annual International Symposium}}},
  author = {Rosenberg, Louis},
  year = {1993},
  pages = {76--82},
  publisher = {{IEEE}},
  address = {{Seattle, WA, USA}},
  urldate = {2020-01-16},
  isbn = {978-0-7803-1363-7},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/rosenberg1993.md;Human Computer Interaction/Augmented Reality/Rosenberg, 1993 - Virtual fixtures.pdf},
  url = {https://doi.org/10.1109/VRAIS.1993.380795}
}

@book{ross1999,
  title = {Digital Archaeology: Rescuing Neglected and Damaged Data Resources: A {{JISC}}/{{NPO}} Study with the {{Electronic Libraries}} ({{eLib}}) {{Programme}} on the Preservation of Electronic Materials},
  shorttitle = {Digital Archaeology},
  author = {Ross, Seamus and Gow, Ann},
  year = {1999},
  series = {Electronic Libraries Programme Studies {{P}}},
  number = {2},
  publisher = {{Library Information Technology Centre}},
  address = {{London}},
  isbn = {978-1-900508-51-3},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ross1999.md;Arts & Humanities/Media Studies/Ross and Gow, 1999 - Digital archaeology.pdf}
}

@article{ross2005,
  title = {New {{Media Arts Hybridity}}: {{The Vases}} ({{Dis}})Communicants {{Between Art}}, {{Affective Science}} and {{AR Technology}}},
  shorttitle = {New {{Media Arts Hybridity}}},
  author = {Ross, Christine},
  year = {2005},
  month = nov,
  journal = {Convergence: The International Journal of Research into New Media Technologies},
  volume = {11},
  number = {4},
  pages = {32--42},
  issn = {1354-8565, 1748-7382},
  urldate = {2020-02-07},
  abstract = {Following Annie Coombes's and Avtar Brah's (authors of Hybridity and its Discontents: Politics, Science, Culture, 2000) request that we not merely apply but in fact historicise hybridity, and arguing that the art and science explorations of new media art have produced some of the strongest new media hybridities to date, the author focuses on one of the important fields of investigation currently linking media art, science and technology: augmented reality or what should be called augmented perception of time and space. This aesthetic field of investigation has led to a reassessment of representation, one that is not without (1) sharing some of the fundamental concerns of current neuroscientific investigation of mental processes and (2) questioning the image/real continuum principle at the core of recent augmented reality technology research. The article examines media artist Bill Viola's The Passions series (2000{\textendash}2001) to contend that new media's original contribution to the practice of hybridity lies in the interaction that it both articulates and encourages with affective sciences, an interaction that redefines representation as an approximation, a facilitator {\textendash} a projection screen for complex mental processes.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ross2005.md;Human Computer Interaction/Augmented Reality/Ross, 2005 - New Media Arts Hybridity.pdf},
  url = {https://doi.org/10.1177//1354856505061051}
}

@book{rowlands2010,
  title = {The New Science of the Mind: From Extended Mind to Embodied Phenomenology},
  shorttitle = {The New Science of the Mind},
  author = {Rowlands, Mark},
  year = {2010},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-01455-7},
  langid = {english},
  lccn = {BF311 .R685 2010},
  keywords = {Cognitive science,Mental Processes,{Philosophy, Medical}},
  file = {Philosophy/Extended Cognition/Rowlands, 2010 - The new science of the mind.pdf}
}

@article{roy2016,
  title = {Inside Sonicity},
  author = {Roy, Elodie A.},
  year = {2016},
  month = jul,
  journal = {Sound Studies},
  volume = {2},
  number = {2},
  pages = {192--194},
  issn = {2055-1940},
  urldate = {2018-04-13},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/roy2016.md},
  url = {https://doi.org/10.1080/20551940.2016.1245990}
}

@article{rumsey2002,
  title = {Spatial {{Quality Evaluation}} for {{Reproduced Sound}}: {{Terminology}}, {{Meaning}}, and a {{Scene-Based Paradigm}}},
  author = {Rumsey, Francis},
  year = {2002},
  journal = {J. Audio Eng. Soc.},
  volume = {50},
  number = {9},
  pages = {16},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/rumsey2002.md;Arts & Humanities/Computational Art/Rumsey, 2002 - Spatial Quality Evaluation for Reproduced Sound.pdf}
}

@article{rusconi2006,
  title = {Spatial Representation of Pitch Height: The {{SMARC}} Effect},
  shorttitle = {Spatial Representation of Pitch Height},
  author = {Rusconi, Elena and Kwan, Bonnie and Giordano, Bruno and Umilta, Carlo and Butterworth, Brian},
  year = {2006},
  month = mar,
  journal = {Cognition},
  volume = {99},
  number = {2},
  pages = {113--129},
  issn = {00100277},
  urldate = {2020-05-26},
  abstract = {Through the preferential pairing of response positions to pitch, here we show that the internal representation of pitch height is spatial in nature and affects performance, especially in musically trained participants, when response alternatives are either vertically or horizontally aligned. The finding that our cognitive system maps pitch height onto an internal representation of space, which in turn affects motor performance even when this perceptual attribute is irrelevant to the task, extends previous studies on auditory perception and suggests an interesting analogy between music perception and mathematical cognition. Both the basic elements of mathematical cognition (i.e. numbers) and the basic elements of musical cognition (i.e. pitches), appear to be mapped onto a mental spatial representation in a way that affects motor performance.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/rusconi2006.md;Cognitive Science/Psychophysics/Rusconi et al., 2006 - Spatial representation of pitch height.pdf},
  url = {https://doi.org/10.1016/j.cognition.2005.01.004}
}

@article{ruth2019,
  title = {Secure {{Multi-User Content Sharing}} for {{Augmented Reality Applications}}},
  author = {Ruth, Kimberly and Kohno, Tadayoshi and Roesner, Franziska},
  year = {2019},
  pages = {19},
  abstract = {Augmented reality (AR), which overlays virtual content on top of the user's perception of the real world, has now begun to enter the consumer market. Besides smartphone platforms, early-stage head-mounted displays such as the Microsoft HoloLens are under active development. Many compelling uses of these technologies are multi-user: e.g., inperson collaborative tools, multiplayer gaming, and telepresence. While prior work on AR security and privacy has studied potential risks from AR applications, new risks will also arise among multiple human users. In this work, we explore the challenges that arise in designing secure and private content sharing for multi-user AR. We analyze representative application case studies and systematize design goals for security and functionality that a multi-user AR platform should support. We design an AR content sharing control module that achieves these goals and build a prototype implementation (ShareAR) for the HoloLens. This work builds foundations for secure and private multi-user AR interactions.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ruth2019.md;Human Computer Interaction/Augmented Reality/Ruth et al., 2019 - Secure Multi-User Content Sharing for Augmented Reality Applications.pdf}
}

@phdthesis{rutz2014,
  title = {Tracing the {{Compositional Process}}. {{Sound}} Art That Rewrites Its Own Past: Formation, Praxis and a Computer Framework},
  author = {Rutz, Hans Holger},
  year = {2014},
  url = {https://pearl.plymouth.ac.uk/bitstream/handle/10026.1/3116/2014rutz10254321phd.pdf?sequence=6&isAllowed=y},
  urldate = {2020-06-11},
  school = {Plymouth University},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/rutz2014.md;Arts & Humanities/Computational Art/Rutz, 2014 - Tracing the Compositional Process.pdf}
}

@article{rutz2016,
  title = {Agency and {{Algorithms}}},
  author = {Rutz, Hanns Holger},
  year = {2016},
  month = nov,
  journal = {Journal of Science and Technology of the Arts},
  volume = {8},
  number = {1},
  pages = {73},
  issn = {1646-9798},
  urldate = {2020-06-11},
  abstract = {Although the concept of algorithms has been established a long time ago, their current topicality indicates a shift in the discourse. Classical definitions based on logic seem to be inadequate to describe their aesthetic capabilities. New approaches stress their involvement in material practices as well as their incompleteness. Algorithmic aesthetics can no longer be tied to the static analysis of programs, but must take into account the dynamic and experimental nature of coding practices. It is suggested that the aesthetic objects thus produced articulate something that could be called algorithmicity or the space of algorithmic agency. This is the space or the medium {\textendash}following Luhmann's form/medium distinction {\textendash} where human and machine undergo mutual incursions. In the resulting coupled ``extimate'' writing process, human initiative and algorithmic speculation cannot be clearly divided out any longer. An observation is attempted of defining aspects of such a medium by drawing a trajectory across a number of sound pieces. The operation of exchange between form and medium I call reconfiguration and it is indicated by this trajectory.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/rutz2016.md;Arts & Humanities/Computational Art/Rutz, 2016 - Agency and Algorithms.pdf},
  url = {https://doi.org/10.7559/citarj.v8i1.223}
}

@article{ryan1991,
  title = {Some Remarks on Musical Instrument Design at {{STEIM}}},
  author = {Ryan, Joel},
  year = {1991},
  month = jan,
  journal = {Contemporary Music Review},
  volume = {6},
  number = {1},
  pages = {3--17},
  issn = {0749-4467, 1477-2256},
  urldate = {2022-08-18},
  langid = {english},
  file = {Human Computer Interaction/Audio Interfacing/Ryan, 1991 - Some remarks on musical instrument design at STEIM.pdf},
  url = {https://doi.org/10.1080/07494469100640021}
}

@book{salen2003,
  title = {Rules of Play: Game Design Fundamentals},
  shorttitle = {Rules of Play},
  author = {Salen, Katie and Zimmerman, Eric},
  year = {2003},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-24045-1},
  lccn = {QA76.76.C672 S25 2003},
  keywords = {Computer games,Design,Programming},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/salen2003.md}
}

@article{samanci2014,
  title = {Embodied Site-Specific Animation},
  author = {Samanci, Ozge},
  year = {2014},
  month = feb,
  journal = {Convergence: The International Journal of Research into New Media Technologies},
  volume = {20},
  number = {1},
  pages = {14--24},
  issn = {1354-8565, 1748-7382},
  urldate = {2020-05-27},
  abstract = {Embodied site-specific animation is one of the ways of expanding the conventions of animation and rethinking the animation medium in the digital context. On the air is an interactive installation based on embodied site-specific animation. Existing installations that are based on embodied site-specific animations rely on abstract visualizations and do not attempt to tell a story or portray characters. I am exploring the design strategies and new meaning-making opportunities that arise with the use of embodied site-specific animation for mixed reality art projects.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/samanci2014.md;Human Computer Interaction/Augmented Reality/Samanci, 2014 - Embodied site-specific animation.pdf},
  url = {https://doi.org/10.1177/1354856513514335}
}

@article{santini2020,
  title = {Composition as an {{Embodied Act}}: A {{Framework}} for the {{Gesture-based Creation}} of {{Augmented Reality Action Scores}}},
  author = {Santini, Giovanni},
  year = {2020},
  pages = {8},
  abstract = {In a context where Augmented Reality (AR) is rapidly spreading out as one of the most promising technologies, there is a great potential for applications addressing musical practices. This paper presents the development of a framework for creating AR gesture-based scores in the context of experimental instrumental composition. The notation system is made possible by GesturAR, an Augmented Reality software developed by the author: it allows one to draw trajectories of gestures directly on the real vibrating body. Those trajectories are visualized as lines moving in real-time with a predetermined speed. The user can also create an AR score (a sequence of trajectories) by arranging miniaturized trajectories representations on a timeline. The timeline is then processed and a set of events is created. This application paves the way to a new kind of notation: embodied interactive notation, characterized by a mimetic 4D representation of gesture, where the act of notation (performed by the composer during the compositional process) corresponds to the notated act (i.e., the action the interpreter is meant to produce during the performance).},
  langid = {english},
  keywords = {â›” No DOI found},
  file = {Human Computer Interaction/Augmented Reality/Santini, 2020 - Composition as an Embodied Act.pdf},
  url = {https://doi.org/10.5281/zenodo.3898853}
}

@inproceedings{santini2022,
  title = {Linear: {{A}} Multi-Device Augmented Reality Environment for Interactive Notation and Music Improvisation},
  booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation {\textendash} {{TENOR}}'2022},
  author = {Santini, Giovanni},
  editor = {Tiffon, Vincent and Bell, Jonathan and {de Paiva Santana}, Charles},
  year = {2022},
  pages = {37--43},
  publisher = {{PRISM Laboratory}},
  address = {{Marseille, France}},
  url = {https://tenor2022.prism.cnrs.fr/templates/ProceedingsTENOR2022.pdf},
  isbn = {979-10-97498-03-0},
  file = {Human Computer Interaction/Augmented Reality/Santini, 2022 - Linear.pdf}
}

@inproceedings{sardana2020,
  title = {Perception of Spatial Data Properties in an Immersive Multi-Layered Auditory Environment},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Sardana, Disha and Joo, Woohun and Bukvic, Ivica Ico and Earle, Gregory},
  year = {2020},
  series = {{{AM}} '20},
  pages = {30--37},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {We present a study of spatial sonification of multidimensional data using a spatial mask and an immersive high-density loudspeaker array. The study participants are asked to identify edges and perceived center of 2D shapes projected across the perimeter of an exocentric environment. The results show that the phase modulation technique results in less accurate user responses than the amplitude modulation or combined modulation techniques. No significant differences are found between stationary and mobile-user scenarios when comparing the angular miss distances of the perceived center of sonified shapes, but significant differences are identified in locating their left and top edges. Further research is warranted to determine why properties of some shapes are easier to pinpoint than others, and how sonification may be improved to minimize such discrepancies.},
  isbn = {978-1-4503-7563-4},
  keywords = {data sonification,immersive environments,perception,spatial audio},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/sardana2020.md;Arts & Humanities/Computational Art/Sardana et al., 2020 - Perception of spatial data properties in an immersive multi-layered auditory.pdf},
  url = {https://doi.org/10.1145/3411109.3411134}
}

@book{sathian2019,
  title = {Multisensory Perception: From Laboratory to Clinic},
  shorttitle = {Multisensory Perception},
  editor = {Sathian, K. and Ramachandran, V S},
  year = {2019},
  edition = {1},
  publisher = {{Elsevier}},
  address = {{San Deigo}},
  isbn = {978-0-12-812492-5},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/sathian2019.md;Cognitive Science/Multisensory Integration/Sathian and Ramachandran, 2019 - Multisensory perception.pdf}
}

@inproceedings{satoh2001,
  title = {A Hybrid Registration Method for Outdoor Augmented Reality},
  booktitle = {Proceedings {{IEEE}} and {{ACM International Symposium}} on {{Augmented Reality}}},
  author = {Satoh, K. and Anabuki, M. and Yamamoto, H. and Tamura, H.},
  year = {2001},
  pages = {67--76},
  publisher = {{IEEE Comput. Soc}},
  address = {{New York, NY, USA}},
  urldate = {2021-04-09},
  abstract = {In this paper, a registration method for outdoor wearable AR systems is described. Our approach is based on using a high precision gyroscope, which can measure 3DOF angle of head direction accurately, but with some drift error. We solved the drift problem with a vision-based drift compensation algorithm, which tracks natural features in the outdoor environment as landmarks from images captured by a camera on an HMD. This paper first describes the detail of the vision-based drift compensation method. Then, a calibration method for the orientation sensor is proposed. Finally, using results from an actual wearable AR system, a comparison of registration error with and without vision-based drift compensation demonstrates the feasibility of the proposed method.},
  isbn = {978-0-7695-1375-1},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/satoh2001.md;Human Computer Interaction/Augmented Reality/Satoh et al., 2001 - A hybrid registration method for outdoor augmented reality.pdf},
  url = {https://doi.org/10.1109/ISAR.2001.970516}
}

@inproceedings{schacher2006,
  title = {Ambisonics {{Spatialization Tools}} for {{Max}}/{{MSP}}},
  booktitle = {Proceedings of the 2006 {{International Computer Music Conference}}},
  author = {Schacher, Jan and Kocher, Philippe},
  year = {2006},
  volume = {2006},
  pages = {274--277},
  publisher = {{Michigan Publishing}},
  address = {{New Orleans, Louisiana, USA}},
  urldate = {2020-05-25},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/schacher2006.md;Human Computer Interaction/Audio Interfacing/Schacher and Kocher, 2006 - Ambisonics Spatialization Tools for Max-MSP.pdf},
  url = {https://doi.org/2027/spo.bbp2372.2006.057}
}

@article{schiavio2018,
  title = {{{4E Music Pedagogy}} and the {{Principles}} of {{Self-Organization}}},
  author = {Schiavio, Andrea and {van der Schyff}, Dylan},
  year = {2018},
  month = aug,
  journal = {Behavioral Sciences},
  volume = {8},
  number = {8},
  pages = {72},
  issn = {2076-328X},
  urldate = {2022-09-12},
  abstract = {Recent approaches in the cognitive and psychological sciences conceive of mind as an Embodied, Embedded, Extended, and Enactive (or 4E) phenomenon. While this has stimulated important discussions and debates across a vast array of disciplines, its principles, applications, and explanatory power have not yet been properly addressed in the domain of musical development. Accordingly, it remains unclear how the cognitive processes involved in the acquisition of musical skills might be understood through the lenses of this approach, and what this might offer for practical areas like music education. To begin filling this gap, the present contribution aims to explore central aspects of music pedagogy through the lenses of 4E cognitive science. By discussing cross-disciplinary research in music, pedagogy, psychology, and philosophy of mind, we will provide novel insights that may help inspire a richer understanding of what musical learning entails. In doing so, we will develop conceptual bridges between the notion of `autopoiesis' (the property of continuous self-regeneration that characterizes living systems) and the emergent dynamics contributing to the flourishing of one's musical life. This will reveal important continuities between a number of new teaching approaches and principles of self-organization. In conclusion, we will briefly consider how these conceptual tools align with recent work in interactive cognition and collective music pedagogy, promoting the close collaboration of musicians, pedagogues, and cognitive scientists.},
  langid = {english},
  file = {Philosophy/Extended Cognition/Schiavio and van der Schyff, 2018 - 4E Music Pedagogy and the Principles of Self-Organization.pdf},
  url = {https://doi.org/10.3390/bs8080072}
}

@book{schmidthorning2015,
  title = {Chasing Sound: Technology, Culture, and the Art of Studio Recording from {{Edison}} to the {{LP}}},
  shorttitle = {Chasing Sound},
  author = {Schmidt Horning, Susan},
  year = {2015},
  month = dec,
  series = {Studies in Industry and Society},
  isbn = {978-1-4214-1848-3},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/schmidthorning2015.md;Arts & Humanities/Musicology/Schmidt Horning, 2015 - Chasing sound.pdf}
}

@inproceedings{schraffenberger2015,
  title = {Sonically {{Tangible Objects}}},
  booktitle = {{{xCoAx}} 2015: {{Proceedings}} of the {{Third Conference}} on {{Computation}}, {{Communication}}, {{Aesthetics}} and {{X}}.},
  author = {Schraffenberger, Hanna and {van der Heide}, Edwin},
  year = {2015},
  pages = {233--248},
  address = {{Glasgow, Scotland}},
  url = {http://2015.xcoax.org/pdf/xcoax2015-Schraffenberger.pdf},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/schraffenberger2015.md;Human Computer Interaction/Augmented Reality/Schraffenberger and van der Heide, 2015 - Sonically Tangible Objects.pdf}
}

@inproceedings{schraffenberger2016,
  title = {Multimodal Augmented Reality: The Norm Rather than the Exception},
  shorttitle = {Multimodal Augmented Reality},
  booktitle = {Proceedings of the 2016 Workshop on {{Multimodal Virtual}} and {{Augmented Reality}} - {{MVAR}} '16},
  author = {Schraffenberger, Hanna and {van der Heide}, Edwin},
  year = {2016},
  pages = {1--6},
  publisher = {{ACM Press}},
  address = {{Tokyo, Japan}},
  urldate = {2020-01-10},
  abstract = {Augmented reality (AR) is commonly seen as a technology that overlays virtual imagery onto a participant's view of the world. In line with this, most AR research is focused on what we see. In this paper, we challenge this focus on vision and make a case for an experience-focused and modalitiesencompassing understanding of AR. We argue that multimodality in AR is the norm rather than the exception, as AR environments consist of both virtual content and our real, physical, multimodal world. We explore the role multimodal and non-visual aspects of our physical reality can play when creating AR scenarios and the possibilities and challenges that emerge when approaching AR from a modalitiesencompassing perspective.},
  isbn = {978-1-4503-4559-0},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/schraffenberger2016.md;Human Computer Interaction/Augmented Reality/Schraffenberger and van der Heide, 2016 - Multimodal augmented reality.pdf},
  url = {https://doi.org/10.1145/3001959.3001960}
}

@phdthesis{schraffenberger2018,
  title = {Arguably Augmented Reality: Relationships between the Virtual and the Real},
  shorttitle = {Arguably Augmented Reality},
  author = {Schraffenberger, Hanna},
  year = {2018},
  url = {http://www.creativecode.org/thesis/},
  langid = {english},
  school = {University of Leiden},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/schraffenberger2018.md;Human Computer Interaction/Augmented Reality/Schraffenberger, 2018 - Arguably augmented reality.pdf}
}

@incollection{seah2015,
  title = {Need for {{Touch}} in {{Human Space Exploration}}: {{Towards}} the {{Design}} of a {{Morphing Haptic Glove}} {\textendash} {{ExoSkin}}},
  shorttitle = {Need for {{Touch}} in {{Human Space Exploration}}},
  booktitle = {Human-{{Computer Interaction}} {\textendash} {{INTERACT}} 2015},
  author = {Seah, Sue Ann and Obrist, Marianna and Roudaut, Anne and Subramanian, Sriram},
  editor = {Abascal, Julio and Barbosa, Simone and Fetter, Mirko and Gross, Tom and Palanque, Philippe and Winckler, Marco},
  year = {2015},
  volume = {9299},
  pages = {18--36},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  url = {https://doi.org/10.1007/978-3-319-22723-8_3},
  urldate = {2020-05-25},
  abstract = {The spacesuit, particularly the spacesuit glove, creates a barrier between astronauts and their environment. Motivated by the vision of facilitating full-body immersion for effortless space exploration, it is necessary to understand the sensory needs of astronauts during extra-vehicular activities (EVAs). In this paper, we present the outcomes from a two-week field study performed at the Mars Desert Research Station, a facility where crews carry out Marssimulated missions. We used a combination of methods (a haptic logbook, technology probes, and interviews) to investigate user needs for haptic feedback in EVAs in order to inform the design of a haptic glove. Our results contradict the common belief that a haptic technology should always convey as much information as possible, but should rather offer a controllable transfer. Based on these findings, we identified two main design requirements to enhance haptic feedback through the glove: (i) transfer of the shape and pressure features of haptic information and (ii) control of the amount of haptic information. We present the implementation of these design requirements in the form of the concept and first prototype of ExoSkin. ExoSkin is a morphing haptic feedback layer that augments spacesuit gloves by controlling the transfer of haptic information from the outside world onto the astronauts' skin.},
  isbn = {978-3-319-22722-1 978-3-319-22723-8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/seah2015.md;Human Computer Interaction/Multisensory Interfacing/Seah et al., 2015 - Need for Touch in Human Space Exploration.pdf}
}

@misc{sennheiser2018,
  title = {Sennheiser {{AMBEO AR One Headphones}}},
  author = {Sennheiser},
  year = {2018},
  url = {https://en-uk.sennheiser.com/ambeo-application-armr},
  urldate = {2020-10-03},
  file = {../../../../../Zotero/storage/477B7K3N/shop.magicleap.com.html}
}

@article{serafin2016a,
  ids = {serafin2016},
  title = {Virtual {{Reality Musical Instruments}}: {{State}} of the {{Art}}, {{Design Principles}}, and {{Future Directions}}},
  shorttitle = {Virtual {{Reality Musical Instruments}}},
  author = {Serafin, Stefania and Erkut, Cumhur and Kojs, Juraj and Nilsson, Niels C. and Nordahl, Rolf},
  year = {2016},
  month = sep,
  journal = {Computer Music Journal},
  volume = {40},
  number = {3},
  pages = {22--40},
  issn = {0148-9267, 1531-5169},
  urldate = {2022-08-22},
  abstract = {The rapid development and availability of low-cost technologies have created a wide interest in virtual reality. In the field of computer music, the term ``virtual musical instruments'' has been used for a long time to describe software simulations, extensions of existing musical instruments, and ways to control them with new interfaces for musical expression. Virtual reality musical instruments (VRMIs) that include a simulated visual component delivered via a head-mounted display or other forms of immersive visualization have not yet received much attention. In this article, we present a field overview of VRMIs from the viewpoint of the performer. We propose nine design guidelines, describe evaluation methods, analyze case studies, and consider future challenges.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/serafin2016.md;Human Computer Interaction/Virtual Reality/Serafin et al., 2016 - Virtual Reality Musical Instruments.pdf;Human Computer Interaction/Virtual Reality/Serafin et al., 2016 - Virtual Reality Musical Instruments2.pdf},
  url = {https://doi.org/10.1162/COMJ_a_00372}
}

@incollection{serafin2023,
  title = {Audio in {{Multisensory Interactions}}: {{From Experiments}} to {{Experiences}}},
  shorttitle = {Audio in {{Multisensory Interactions}}},
  booktitle = {Sonic {{Interactions}} in {{Virtual Environments}}},
  author = {Serafin, Stefania},
  editor = {Geronazzo, Michele and Serafin, Stefania},
  year = {2023},
  pages = {305--318},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  urldate = {2024-01-29},
  abstract = {Abstract             In the real and virtual world, we usually experience sounds in combination with at least an additional modality, such as vision, touch or proprioception. Understanding how sound enhances, substitutes or modifies the way we perceive and interact with the world is an important element when designing interactive multimodal experiences. In this chapter, we present an overview of sound in a multimodal context, ranging from basic experiments in multimodal perception to more advanced interactive experiences in virtual reality.},
  isbn = {978-3-031-04020-7 978-3-031-04021-4},
  langid = {english},
  file = {Human Computer Interaction/Virtual Reality/Serafin, 2023 - Audio in Multisensory Interactions.pdf},
  url = {https://doi.org/10.1007/978-3-031-04021-4_10}
}

@article{seth2012,
  title = {An {{Interoceptive Predictive Coding Model}} of {{Conscious Presence}}},
  author = {Seth, Anil K. and Suzuki, Keisuke and Critchley, Hugo D.},
  year = {2012},
  journal = {Frontiers in Psychology},
  volume = {2},
  issn = {1664-1078},
  urldate = {2022-08-19},
  abstract = {We describe a theoretical model of the neurocognitive mechanisms underlying conscious presence and its disturbances. The model is based on interoceptive prediction error and is informed by predictive models of agency, general models of hierarchical predictive coding and dopaminergic signaling in cortex, the role of the anterior insular cortex (AIC) in interoception and emotion, and cognitive neuroscience evidence from studies of virtual reality and of psychiatric disorders of presence, specifically depersonalization/derealization disorder. The model associates presence with successful suppression by top-down predictions of informative interoceptive signals evoked by autonomic control signals and, indirectly, by visceral responses to afferent sensory signals. The model connects presence to agency by allowing that predicted interoceptive signals will depend on whether afferent sensory signals are determined, by a parallel predictive-coding mechanism, to be self-generated or externally caused. Anatomically, we identify the AIC as the likely locus of key neural comparator mechanisms. Our model integrates a broad range of previously disparate evidence, makes predictions for conjoint manipulations of agency and presence, offers a new view of emotion as interoceptive inference, and represents a step toward a mechanistic account of a fundamental phenomenological property of consciousness.},
  langid = {english},
  file = {Cognitive Science/Interoception/Seth et al., 2012 - An Interoceptive Predictive Coding Model of Conscious Presence.pdf},
  url = {https://doi.org/10.3389/fpsyg.2011.00395}
}

@article{seth2013,
  title = {Interoceptive Inference, Emotion, and the Embodied Self},
  author = {Seth, Anil K.},
  year = {2013},
  month = nov,
  journal = {Trends in Cognitive Sciences},
  volume = {17},
  number = {11},
  pages = {565--573},
  issn = {13646613},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/seth2013.md;Cognitive Science/Interoception/Seth, 2013 - Interoceptive inference, emotion, and the embodied self.pdf},
  url = {https://doi.org/10.1016/j.tics.2013.09.007}
}

@article{seth2014,
  title = {A Predictive Processing Theory of Sensorimotor Contingencies: {{Explaining}} the Puzzle of Perceptual Presence and Its Absence in Synesthesia},
  shorttitle = {A Predictive Processing Theory of Sensorimotor Contingencies},
  author = {Seth, Anil K.},
  year = {2014},
  month = apr,
  journal = {Cognitive Neuroscience},
  volume = {5},
  number = {2},
  pages = {97--118},
  issn = {1758-8928, 1758-8936},
  urldate = {2022-08-19},
  langid = {english},
  file = {Philosophy/Extended Cognition/Seth, 2014 - A predictive processing theory of sensorimotor contingencies.pdf},
  url = {https://doi.org/10.1080/17588928.2013.877880}
}

@book{shafer1967,
  title = {Ear {{Cleaning}}: {{Notes}} for an {{Experimental Music Course}}},
  author = {Shafer, Raymond},
  year = {1967},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/shafer1967.md;Arts & Humanities/Musicology/Shafer, 1967 - Ear Cleaning.pdf}
}

@article{sharma1998,
  title = {Toward Multimodal Human-Computer Interface},
  author = {Sharma, R. and Pavlovic, V.I. and Huang, T.S.},
  year = {1998},
  month = may,
  journal = {Proceedings of the IEEE},
  volume = {86},
  number = {5},
  pages = {853--869},
  issn = {00189219},
  urldate = {2020-05-25},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/sharma1998.md;Human Computer Interaction/Multisensory Interfacing/Sharma et al., 1998 - Toward multimodal human-computer interface.pdf},
  url = {https://doi.org/10.1109/5.664275}
}

@inproceedings{sharma2015,
  title = {Towards {{Understanding}} and {{Verbalising Spatial Sound Phenomena}} in {{Electronic Music}}},
  booktitle = {Proceedings of {{inSONIC2015}}, {{Aesthetics}} of {{Spatial Audio}} in {{Sound}}, {{Music}} and {{Sound Art}}},
  author = {Sharma, Gerriet K and Frank, Matthias and Zotter, Franz},
  year = {2015},
  address = {{ZKM, Karlsruhe}},
  url = {https://www.researchgate.net/publication/301890625},
  abstract = {How do we describe spatial sound phenomena in electronic music? This paper is concerned with the questions whether the electronic music of today takes into account the perception of its audience at all, whether it is necessary to have a typology of electronic music sounds at all, and how to find or generate terms that could be helpful for composition and analysis of spatialized sound. Before going into detail about how to deal with spatial phenomena, it is valuable to review the main concepts of verbalization of sound from the last 100 years of sound-based music. Following this, approaches and methodologies are introduced to develop a specific terminology for a certain way of spatial sound projection within the framework of the artistic research project `Orchestrating Space by Icosahedral Loudspeaker' (OSIL). By this we intent to encourage the aesthetic discussion about spatial sound composition and therefore enlarge the compositional contingencies of this art.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/sharma2015.md;Arts & Humanities/Computational Art/Sharma et al., 2015 - Towards Understanding and Verbalising Spatial Sound Phenomena in Electronic.pdf}
}

@phdthesis{sharma2018,
  type = {Artistic {{Doctoral Degree}}},
  title = {Composing with {{Sculptural Sound Phenomena}} in {{Computer Music Dissertation}}},
  author = {Sharma, Gerriet K},
  year = {2018},
  address = {{Graz, Austria}},
  langid = {english},
  school = {University of Music and Performing Arts},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/sharma2018.md;Arts & Humanities/Computational Art/Sharma, 2018 - Composing with Sculptural Sound Phenomena in Computer Music Dissertation.pdf}
}

@misc{shaw1975,
  title = {Viewpoint by {{Jeffrey Shaw}} and {{Theo Botschuijver}}},
  author = {Shaw, Jefferey},
  year = {1975},
  url = {https://www.jeffreyshawcompendium.com/portfolio/viewpoint/},
  urldate = {2022-12-21},
  abstract = {Viewpoint 1975 Paris, France~Coauthors: Jeffrey Shaw, Theo Botschuijver Production: Eventstructure Research Group, Amsterdam Default Video Source Alt Video Source (SD) ~ play ~ ~ ~ play stop mute max volume ~ ~ full screen This pioneering augmented reality installation created a montage of fictional events within a museum environment by enabling the projection of staged performances to be perceptually contiguous with the real space and actual events taking place there. The work was constituted by two structural elements: a large projection screen and an optical viewing console with an automated pair of slide projectors. Because of the screen's retro-reflective properties (it was made from 3M Scotchlite), the projected image was only visible through the viewing console. From every other position in the room the screen appeared as a plain grey surface. This optical projection system was so inherently bright that it could match the ambient lighting in the museum exactly, and a perceptual conjunction of the projected images with the surroundings could thus be achieved. Furthermore, these projected images showed the exact portion of the museum environment that was hidden by the screen, creating a seamless continuity between the virtual and actual spaces. A further consequence of this optical alignment {\dots}},
  langid = {american},
  file = {../../../../../Zotero/storage/W6EG4B4S/viewpoint.html}
}

@misc{shaw1981,
  title = {Virtual {{Sculpture}} by {{Jeffrey Shaw}}, {{Theo Botschuijver}}, and {{Larry Abel}} in {{Amsterdam}}, {{Netherlands}}},
  author = {Shaw, Jeffrey},
  year = {1981},
  url = {https://www.jeffreyshawcompendium.com/portfolio/sculpture/},
  urldate = {2022-12-12},
  abstract = {Virtual Sculpture 1981~Amsterdam, Netherlands Coauthors: Jeffrey Shaw, Theo Botschuijver Software: Larry Abel Production: Eventstructure Research Group, Amsterdam Default Video Source Alt Video Source (SD) ~ play ~ ~ ~ play stop mute max volume ~ ~ full screen For this pioneering augmented reality installation, a Fresnel lens and semitransparent mirror was mounted on top of a tripod-mounted monitor. The viewer could rotate and tilt monitor and, looking through the mirror, could discover various simple computer-generated virtual objects floating in different locations in the real space in front of them. The optical method is based on an illusion technique called `Pepper's ghost', which goes back to the 16th century. It is updated in the Virtual Sculpture by using a video image and a Fresnel lens to change the focal length so that this image appear some meters away when viewed through the semitransparent mirror. The system's rotate and tilt functions then allow these virtual images to be physically distributed all around the viewer {\textendash} a virtual reality paradigm inspired by Ivan Sutherland's `Sword of Damocles' (1968).~ The installation used an Apple II computer with its game paddles attached to the monitor to register the tilt and rotation movements.},
  langid = {american},
  file = {../../../../../Zotero/storage/UFT78PK8/sculpture.html}
}

@inproceedings{sheffield2016,
  title = {The {{Haptic Capstans}}: {{Rotational Force Feedback}} for {{Music}} Using a {{FireFader Derivative Device}}},
  booktitle = {Proceedings of the {{International Conference}} on {{New Interfaces}} for {{Musical Expression}}},
  author = {Sheffield, Eric and Berdahl, Edgar and Pfalz, Andrew},
  year = {2016},
  pages = {2},
  address = {{Brisbane, Australia}},
  abstract = {The Haptic Capstans are two rotational force-feedback knobs circumscribed by eye-catching LED rings. In this work, the Haptic Capstans are programmed using physical models in order to experiment with audio-visual-haptic interactions for music applications.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/sheffield2016.md;Human Computer Interaction/Augmented Reality/Shefï¬eld et al., 2016 - The Haptic Capstans.pdf},
  url = {https://doi.org/10.5281/zenodo.1176124}
}

@article{sheridan1992,
  title = {Musings on {{Telepresence}} and {{Virtual Presence}}},
  author = {Sheridan, Thomas B.},
  year = {1992},
  month = jan,
  journal = {Presence: Teleoperators and Virtual Environments},
  volume = {1},
  number = {1},
  pages = {120--126},
  issn = {1054-7460},
  urldate = {2021-02-12},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/sheridan1992.md;Human Computer Interaction/Augmented Reality/Sheridan, 1992 - Musings on Telepresence and Virtual Presence.pdf},
  url = {https://doi.org/10.1162/pres.1992.1.1.120}
}

@article{shimojo2001,
  title = {Sensory Modalities Are Not Separate Modalities: Plasticity and Interactions},
  shorttitle = {Sensory Modalities Are Not Separate Modalities},
  author = {Shimojo, S},
  year = {2001},
  month = aug,
  journal = {Current Opinion in Neurobiology},
  volume = {11},
  number = {4},
  pages = {505--509},
  issn = {09594388},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/shimojo2001.md;Cognitive Science/Multisensory Integration/Shimojo, 2001 - Sensory modalities are not separate modalities.pdf},
  url = {https://doi.org/10.1016/S0959-4388(00)00241-5}
}

@article{shivers1993,
  title = {{{BodyTalk}} and the {{BodyNet}}: {{A Personal Information Infrastructure}}},
  author = {Shivers, Olin},
  year = {1993},
  pages = {19},
  abstract = {The current evolution of personal information appliances, such as cellular telephones, personal digital assistants, and notebook computers, can be made more effective if re-structured into a personal network architecture. This architecture is based upon two central components: a hardware communications system, the BodyNet, and a common interface language, BodyTalk.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/shivers1993.md;Human Computer Interaction/Augmented Reality/Shivers, 1993 - BodyTalk and the BodyNet.pdf}
}

@phdthesis{sjoberg2018,
  title = {Making Use of the Environmental Space in Augmented Reality},
  author = {Sjoberg, Jesper},
  year = {2018},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/sjoberg2018.md;Human Computer Interaction/Augmented Reality/Sjoberg, 2018 - Making use of the environmental space in augmented reality.pdf}
}

@incollection{skwarek2018,
  title = {Augmented {{Reality Activism}}},
  booktitle = {Augmented {{Reality Art}}},
  author = {Skwarek, Mark},
  editor = {Geroimenko, Vladimir},
  year = {2018},
  pages = {3--40},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  url = {https://doi.org/10.1007/978-3-319-69932-5_1},
  urldate = {2021-05-17},
  isbn = {978-3-319-69931-8 978-3-319-69932-5},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/skwarek2018.md}
}

@misc{skymavis2022,
  type = {Whitepaper},
  title = {Axie {{Infinity}}: {{Gameplay}}},
  author = {{Sky Mavis}},
  year = {2022},
  journal = {Axie Infinity: Gameplay},
  url = {https://whitepaper.axieinfinity.com/gameplay},
  urldate = {2022-09-12},
  file = {../../../../../Zotero/storage/UMD2QDCA/gameplay.html}
}

@article{slater1994,
  title = {Depth of {{Presence}} in {{Virtual Environments}}},
  author = {Slater, Mel and Usoh, Martin and Steed, Anthony},
  year = {1994},
  month = jan,
  journal = {Presence: Teleoperators and Virtual Environments},
  volume = {3},
  number = {2},
  pages = {130--144},
  issn = {1054-7460},
  urldate = {2022-09-12},
  abstract = {This paper describes a study to assess the influence of a variety of factors on reported level of presence in immersive virtual environments. It introduces the idea of ``stacking depth,'' that is, where a participant can simulate the process of entering the virtual environment while already in such an environment, which can be repeated to several levels of depth. An experimental study including 24 subjects was carried out. Half of the subjects were transported between environments by using virtual head-mounted displays, and the other half by going through doors. Three other binary factors were whether or not gravity operated, whether or not the subject experienced a virtual precipice, and whether or not the subject was followed around by a virtual actor. Visual, auditory, and kinesthetic representation systems and egocentric/exocentric perceptual positions were assessed by a preexperiment questionnaire. Presence was assessed by the subjects as their sense of ``being there,'' the extent to which they experienced the virtual environments as more the presenting reality than the real world in which the experiment was taking place, and the extent to which the subject experienced the virtual environments as places visited rather than images seen. A logistic regression analysis revealed that subjective reporting of presence was significantly positively associated with visual and kinesthetic representation systems, and negatively with the auditory system. This was not surprising since the virtual reality system used was primarily visual. The analysis also showed a significant and positive association with stacking level depth for those who were transported between environments by using the virtual HMD, and a negative association for those who were transported through doors. Finally, four of the subjects moved their real left arm to match movement of the left arm of the virtual body displayed by the system. These four scored significantly higher on the kinesthetic representation system than the remainder of the subjects.},
  langid = {english},
  file = {Human Computer Interaction/Virtual Reality/Slater et al., 1994 - Depth of Presence in Virtual Environments.pdf},
  url = {https://doi.org/10.1162/pres.1994.3.2.130}
}

@article{slater2010,
  title = {First {{Person Experience}} of {{Body Transfer}} in {{Virtual Reality}}},
  author = {Slater, Mel and Spanlang, Bernhard and {Sanchez-Vives}, Maria V. and Blanke, Olaf},
  editor = {Williams, Mark A.},
  year = {2010},
  month = may,
  journal = {PLoS ONE},
  volume = {5},
  number = {5},
  pages = {e10564},
  issn = {1932-6203},
  urldate = {2022-08-19},
  abstract = {Background: Altering the normal association between touch and its visual correlate can result in the illusory perception of a fake limb as part of our own body. Thus, when touch is seen to be applied to a rubber hand while felt synchronously on the corresponding hidden real hand, an illusion of ownership of the rubber hand usually occurs. The illusion has also been demonstrated using visuomotor correlation between the movements of the hidden real hand and the seen fake hand. This type of paradigm has been used with respect to the whole body generating out-of-the-body and body substitution illusions. However, such studies have only ever manipulated a single factor and although they used a form of virtual reality have not exploited the power of immersive virtual reality (IVR) to produce radical transformations in body ownership.},
  langid = {english},
  file = {Human Computer Interaction/Virtual Reality/Slater et al., 2010 - First Person Experience of Body Transfer in Virtual Reality.pdf},
  url = {https://doi.org/10.1371/journal.pone.0010564}
}

@misc{slater2019,
  title = {Lauren {{Sarah Hayes}} Performs at {{Bates Mill Blending Shed}}, in {{Huddersfield}}, {{U}}.{{K}}.},
  author = {Slater, Brian},
  year = {2019},
  month = nov,
  url = {https://news.asu.edu/20200302-asu-professor-shares-research-conference-and-performs-musical-festival}
}

@article{slawinski2017,
  title = {The {{Role}} of {{Short-Termism}} and {{Uncertainty Avoidance}} in {{Organizational Inaction}} on {{Climate Change}}: {{A Multi-Level Framework}}},
  shorttitle = {The {{Role}} of {{Short-Termism}} and {{Uncertainty Avoidance}} in {{Organizational Inaction}} on {{Climate Change}}},
  author = {Slawinski, Natalie and Pinkse, Jonatan and Busch, Timo and Banerjee, Subhabrata Bobby},
  year = {2017},
  month = feb,
  journal = {Business \& Society},
  volume = {56},
  number = {2},
  pages = {253--282},
  issn = {0007-6503, 1552-4205},
  urldate = {2022-12-11},
  abstract = {Despite increasing pressure to address climate change, firms have been slow to respond with effective action. This paper derives a multi-level framework for a better understanding of why many firms are failing to reduce their absolute greenhouse gas emissions, which contribute to climate change. To explain the phenomenon of organizational inaction on climate change, we draw on the related concepts of short-termism and uncertainty avoidance from research in psychology, sociology and organization theory. We argue that antecedents related to shorttermism and uncertainty avoidance reinforce each other at three levels {\textendash} individual, organizational and institutional {\textendash} and result in organizational inaction on climate change. We discuss the implications of our framework for research on corporate sustainability.},
  langid = {english},
  file = {Politics/Marxism/Slawinski et al., 2017 - The Role of Short-Termism and Uncertainty Avoidance in Organizational Inaction.pdf},
  url = {https://doi.org/10.1177/0007650315576136}
}

@article{smalley1997,
  title = {Spectromorphology: Explaining Sound-Shapes},
  shorttitle = {Spectromorphology},
  author = {Smalley, Denis},
  year = {1997},
  month = aug,
  journal = {Organised Sound},
  volume = {2},
  number = {2},
  pages = {107--126},
  issn = {13557718},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/smalley1997.md;Arts & Humanities/Computational Art/Smalley, 1997 - Spectromorphology.pdf},
  url = {https://doi.org/10.1017/S1355771897009059}
}

@article{smalley2007,
  title = {Space-Form and the Acousmatic Image},
  author = {Smalley, Denis},
  year = {2007},
  month = apr,
  journal = {Organised Sound},
  volume = {12},
  number = {1},
  pages = {35--58},
  issn = {1355-7718, 1469-8153},
  urldate = {2020-01-10},
  abstract = {Abstract             The analytical discussion of acousmatic music can benefit from being based on spatial concepts, and this article aims to provide a framework for investigation. A personal experience of soundscape listening is the starting point, and uncovers basic ideas relating to the disposition and behaviour of sounding content, and listening strategy. This enables the opening out of the discussion to include source-bonded sounds in general, giving particular consideration to how experience of sense modes other than the aural are implicated in our understanding of space, and in acousmatic listening. Attention then shifts to a source-bonded spatial model based on the production of space by the gestural activity of music performance, prior to focusing in more detail on acousmatic music, initially by delving into spectral space, where ideas about gravitation and diagonal forces are germane. This leads to concepts central to the structuring of perspectival space in relation to the vantage point of the listener. The final section considers a methodology for space-form investigation.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/smalley2007.md;Arts & Humanities/Computational Art/Smalley, 2007 - Space-form and the acousmatic image.pdf},
  url = {https://doi.org/10.1017/S1355771807001665}
}

@inproceedings{speicher2019,
  title = {What Is {{Mixed Reality}}?},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}  - {{CHI}} '19},
  author = {Speicher, Maximilian and Hall, Brian D. and Nebeling, Michael},
  year = {2019},
  pages = {1--15},
  publisher = {{ACM Press}},
  address = {{Glasgow, Scotland Uk}},
  urldate = {2020-05-25},
  abstract = {What is Mixed Reality (MR)? To revisit this question given the many recent developments, we conducted interviews with ten AR/VR experts from academia and industry, as well as a literature survey of 68 papers. We find that, while there are prominent examples, there is no universally agreed on, one-size-fits-all definition of MR. Rather, we identified six partially competing notions from the literature and experts' responses. We then started to isolate the different aspects of reality relevant for MR experiences, going beyond the primarily visual notions and extending to audio, motion, haptics, taste, and smell. We distill our findings into a conceptual framework with seven dimensions to characterize MR applications in terms of the number of environments, number of users, level of immersion, level of virtuality, degree of interaction, input, and output. Our goal with this paper is to support classification and discussion of MR applications' design and provide a better means to researchers to contextualize their work within the increasingly fragmented MR landscape.},
  isbn = {978-1-4503-5970-2},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/speicher2019.md;Human Computer Interaction/Mixed Reality/Speicher et al., 2019 - What is Mixed Reality.pdf},
  url = {https://doi.org/10.1145/3290605.3300767}
}

@article{spence2015,
  title = {Olfactory Dining: Designing for the Dominant Sense},
  shorttitle = {Olfactory Dining},
  author = {Spence, Charles and Youssef, Jozef},
  year = {2015},
  month = dec,
  journal = {Flavour},
  volume = {4},
  number = {1},
  pages = {32},
  issn = {2044-7248},
  urldate = {2020-02-07},
  abstract = {The majority of researchers agree that olfactory cues play a dominant role in our perception and enjoyment of the taste (or rather flavour) of food and drink. It is no surprise then that in recent years, a variety of modern (or dare we say it, modernist) solutions have been developed with the explicit aim of delivering an enhanced olfactory input to the diners/dishes served in the restaurant, and occasionally also in the home setting too. Such innovations include everything from aromatic cutlery and plateware through to the use of atomizers and dry ice. A few augmented reality (AR; i.e. an experience of a physical, real-world environment whose elements have been augmented, or supplemented, by computer-generated sensory input) solutions have also made their way out from well-funded technology labs, and scent-enabled plug-ins for mobile devices are slowly being commercialized. The latter could potentially be used to enhance the orthonasal olfactory component of our multisensory food experiences in the years to come. Ultimately, though, there is an important question here as to the authenticity of those food and flavour experiences that have been augmented/enhanced by aroma and fragrance cues that are not integral to the food or drink itself. It is this lack of authenticity that may, at least in your authors' humble opinion, limit the more widespread uptake of such a sense-by-sense approach to the contemporary construction of multisensory gastronomic experiences. The challenge, as always, remains to find the unique selling point (USP) of such approaches to olfactory stimulation, over and above their mere feasibility and inherent theatricality.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/spence2015.md;Human Computer Interaction/Augmented Reality/Spence and Youssef, 2015 - Olfactory dining.pdf},
  url = {https://doi.org/10.1186/s13411-015-0042-0}
}

@misc{spielberg2002,
  type = {Science {{Fiction}}},
  title = {Minority {{Report}}},
  author = {Spielberg, Steven},
  year = {2002},
  publisher = {{20th Century Fox}},
  langid = {english}
}

@inproceedings{steil2019,
  title = {Privacy-Aware Eye Tracking Using Differential Privacy},
  booktitle = {Proceedings of the 11th {{ACM Symposium}} on {{Eye Tracking Research}} \& {{Applications}}},
  author = {Steil, Julian and Hagestedt, Inken and Huang, Michael Xuelin and Bulling, Andreas},
  year = {2019},
  month = jun,
  pages = {1--9},
  publisher = {{ACM}},
  address = {{Denver Colorado}},
  urldate = {2020-05-25},
  abstract = {With eye tracking being increasingly integrated into virtual and augmented reality (VR/AR) head-mounted displays, preserving users' privacy is an ever more important, yet under-explored, topic in the eye tracking community. We report a large-scale online survey (N=124) on privacy aspects of eye tracking that provides the first comprehensive account of with whom, for which services, and to what extent users are willing to share their gaze data. Using these insights, we design a privacy-aware VR interface that uses differential privacy, which we evaluate on a new 20-participant dataset for two privacy sensitive tasks: We show that our method can prevent user re-identification and protect gender information while maintaining high performance for gaze-based document type classification. Our results highlight the privacy challenges particular to gaze data and demonstrate that differential privacy is a potential means to address them. Thus, this paper lays important foundations for future research on privacy-aware gaze interfaces.},
  isbn = {978-1-4503-6709-7},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/steil2019.md;Human Computer Interaction/Security & Privacy/Steil et al., 2019 - Privacy-aware eye tracking using differential privacy.pdf},
  url = {https://doi.org/10.1145/3314111.3319915}
}

@book{stephenson1992,
  title = {Snow {{Crash}}},
  author = {Stephenson, Neal},
  year = {1992},
  series = {A {{Bantam}} Spectra Book},
  publisher = {{Bantam Books}},
  address = {{New York}},
  isbn = {978-0-553-08853-3 978-0-553-35192-7},
  lccn = {PS3569.T3868 S65 1992},
  keywords = {Humorous stories,Science fiction}
}

@book{stern2013,
  title = {Interactive Art and Embodiment: The Implicit Body as Performance},
  shorttitle = {Interactive Art and Embodiment},
  author = {Stern, Nathaniel},
  year = {2013},
  publisher = {{Gylphi Limited}},
  address = {{Canterbury}},
  isbn = {978-1-78024-009-1 978-1-78024-010-7 978-1-78024-011-4},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/stern2013.md}
}

@misc{subpac2020,
  title = {{{SUBPAC X1}}},
  author = {Subpac},
  year = {2020},
  journal = {SUBPAC},
  url = {https://uk.subpac.com/products/subpac-x1},
  urldate = {2020-10-03},
  abstract = {EARLY BIRD PRE ORDER PRICE~ SHIPS FROM THE USA - CUSTOMS DUTIES INCLUDED IN SHIPPING. SUBPAC pre-orders are first come, first serve, with the first ones expected to ship by the end of the year. We wish we could give you an exact date but the global pandemic has meant that we have had to change our manufacturing and shi},
  langid = {english},
  file = {../../../../../Zotero/storage/DHVE9HUS/subpac-x1.html}
}

@article{suhr2018,
  title = {The {{Audience}} and {{Artist Interactivity}} in {{Augmented Reality Art}}: {{The Solo Exhibition}} on the {{{\emph{Flame}}}} {{Series}}},
  shorttitle = {The {{Audience}} and {{Artist Interactivity}} in {{Augmented Reality Art}}},
  author = {Suhr, H. Cecilia},
  year = {2018},
  month = may,
  journal = {Critical Arts},
  volume = {32},
  number = {3},
  pages = {111--125},
  issn = {0256-0046, 1992-6049},
  urldate = {2020-05-27},
  abstract = {Traditional art exhibitions are typically limited to artworks being viewed on the walls of galleries and museums. While walking around galleries, viewers often view artworks spontaneously within a matter of a few seconds or minutes. The act of viewing artworks can take many forms; one might quickly glance at the works, or stare at them, or intensely view the works as a whole group and/or in part. The frequent assumption is that the artist is communicating their vision from one direction. This paper explores how augmented reality art (AR) has affected viewing behaviours and norms, and the ways in which viewers experience traditional paintings, as well as new media arts. Based on Cecilia Suhr's invitational solo exhibition, Flame, at the Nameseoul University IANG Gallery in Seoul, Korea, in May 2017, the goal of this paper is threefold: 1) to unpack the conceptual framework of the Flame series by loosely drawing on Deleuze's notion of ``becoming''; 2) to explore audiences' viewing behaviours of AR art in relation to the inherent characteristics and ontology of the AR medium; and 3) to problematise how the AR medium affects the hegemonic tension between artist and audience in the dichotomisation of active/passive audiences.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/suhr2018.md;Human Computer Interaction/Augmented Reality/Suhr, 2018 - The Audience and Artist Interactivity in Augmented Reality Art.pdf},
  url = {https://doi.org/10.1080/02560046.2018.1493054}
}

@misc{summers2019,
  title = {Virtual {{Reality Artist}} - {{Live}} Clips},
  author = {Summers, Rosie},
  year = {2019},
  month = nov,
  url = {https://www.youtube.com/watch?v=wJqYvlWgBlY},
  urldate = {2022-11-03}
}

@inproceedings{sutherland1965,
  title = {The {{Ultimate Display}}},
  booktitle = {Proceedings of the {{IFIP Congress}}},
  author = {Sutherland, Ivan},
  year = {1965},
  pages = {506--508},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/sutherland1965.md;Human Computer Interaction/Multisensory Interfacing/Sutherland, 1965 - The Ultimate Display.pdf}
}

@inproceedings{sutherland1968,
  title = {A Head-Mounted Three Dimensional Display},
  booktitle = {Proceedings of the {{December}} 9-11, 1968, {{Fall Joint Computer Conference}}},
  author = {Sutherland, Ivan},
  year = {1968},
  pages = {757--764},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/sutherland1968.md;Human Computer Interaction/Augmented Reality/Sutherland, 1968 - A head-mounted three dimensional display.pdf},
  url = {https://doi.org/10.1145/1476589.1476686}
}

@article{suzuki2013,
  title = {Multisensory Integration across Exteroceptive and Interoceptive Domains Modulates Self-Experience in the Rubber-Hand Illusion},
  author = {Suzuki, Keisuke and Garfinkel, Sarah N. and Critchley, Hugo D. and Seth, Anil K.},
  year = {2013},
  month = nov,
  journal = {Neuropsychologia},
  volume = {51},
  number = {13},
  pages = {2909--2917},
  issn = {00283932},
  urldate = {2022-08-19},
  abstract = {Identifying with a body is central to being a conscious self. The now classic ``rubber hand illusion'' demonstrates that the experience of body-ownership can be modulated by manipulating the timing of exteroceptive (visual and tactile) body-related feedback. Moreover, the strength of this modulation is related to individual differences in sensitivity to internal bodily signals (interoception). However the interaction of exteroceptive and interoceptive signals in determining the experience of body-ownership within an individual remains poorly understood. Here, we demonstrate that this depends on the online integration of exteroceptive and interoceptive signals by implementing an innovative ``cardiac rubber hand illusion'' that combined computer-generated augmented-reality with feedback of interoceptive (cardiac) information. We show that both subjective and objective measures of virtual-hand ownership are enhanced by cardio-visual feedback in-time with the actual heartbeat, as compared to asynchronous feedback. We further show that these measures correlate with individual differences in interoceptive sensitivity, and are also modulated by the integration of proprioceptive signals instantiated using realtime visual remapping of finger movements to the virtual hand. Our results demonstrate that interoceptive signals directly influence the experience of body ownership via multisensory integration, and they lend support to models of conscious selfhood based on interoceptive predictive coding.},
  langid = {english},
  file = {Cognitive Science/Multisensory Integration/Suzuki et al., 2013 - Multisensory integration across exteroceptive and interoceptive domains.pdf},
  url = {https://doi.org/10.1016/j.neuropsychologia.2013.08.014}
}

@article{suzuki2017,
  title = {A {{Deep-Dream Virtual Reality Platform}} for {{Studying Altered Perceptual Phenomenology}}},
  author = {Suzuki, Keisuke and Roseboom, Warrick and Schwartzman, David J. and Seth, Anil K.},
  year = {2017},
  month = dec,
  journal = {Scientific Reports},
  volume = {7},
  number = {1},
  pages = {15982},
  issn = {2045-2322},
  urldate = {2022-08-19},
  langid = {english},
  file = {Human Computer Interaction/Virtual Reality/Suzuki et al., 2017 - A Deep-Dream Virtual Reality Platform for Studying Altered Perceptual.pdf},
  url = {https://doi.org/10.1038/s41598-017-16316-2}
}

@misc{suzuki2017a,
  title = {Deep {{Dream 4K Panorama}}},
  author = {Suzuki, Keisuke},
  year = {2017},
  month = nov,
  url = {https://www.youtube.com/watch?v=g_6qb25WPGs},
  urldate = {2022-12-12}
}

@article{suzuki2019,
  title = {Sensorimotor Contingency Modulates Breakthrough of Virtual {{3D}} Objects during a Breaking Continuous Flash Suppression Paradigm},
  author = {Suzuki, Keisuke and Schwartzman, David J. and Augusto, Rafael and Seth, Anil K.},
  year = {2019},
  month = jun,
  journal = {Cognition},
  volume = {187},
  pages = {95--107},
  issn = {00100277},
  urldate = {2022-08-19},
  abstract = {To investigate how embodied sensorimotor interactions shape subjective visual experience, we developed a novel combination of Virtual Reality (VR) and Augmented Reality (AR) within an adapted breaking continuous flash suppression (bCFS) paradigm. In a first experiment, participants manipulated novel virtual 3D objects, viewed through a head-mounted display, using three interlocking cogs. This setup allowed us to manipulate the sensorimotor contingencies governing interactions with virtual objects, while characterising the effects on subjective visual experience by measuring breakthrough times from bCFS. We contrasted the effects of the congruency (veridical versus reversed sensorimotor coupling) and contingency (live versus replayed interactions) using a motion discrimination task. The results showed that the contingency but not congruency of sensorimotor coupling affected breakthrough times, with live interactions displaying faster breakthrough times. In a second experiment, we investigated how the contingency of sensorimotor interactions affected object category discrimination within a more naturalistic setting, using a motion tracker that allowed object interactions with increased degrees of freedom. We again found that breakthrough times were faster for live compared to replayed interactions (contingency effect). Together, these data demonstrate that bCFS breakthrough times for unfamiliar 3D virtual objects are modulated by the contingency of the dynamic causal coupling between actions and their visual consequences, in line with theories of perception that emphasise the influence of sensorimotor contingencies on visual experience. The combination of VR/AR and motion tracking technologies with bCFS provides a novel methodology extending the use of binocular suppression paradigms into more dynamic and realistic sensorimotor environments.},
  langid = {english},
  file = {Philosophy/Extended Cognition/Suzuki et al., 2019 - Sensorimotor contingency modulates breakthrough of virtual 3D objects during a.pdf},
  url = {https://doi.org/10.1016/j.cognition.2019.03.003}
}

@article{talsma2015,
  title = {Predictive Coding and Multisensory Integration: An Attentional Account of the Multisensory Mind},
  shorttitle = {Predictive Coding and Multisensory Integration},
  author = {Talsma, Durk},
  year = {2015},
  month = mar,
  journal = {Frontiers in Integrative Neuroscience},
  volume = {09},
  issn = {1662-5145},
  urldate = {2020-01-10},
  abstract = {Multisensory integration involves a host of different cognitive processes, occurring at different stages of sensory processing. Here I argue that, despite recent insights suggesting that multisensory interactions can occur at very early latencies, the actual integration of individual sensory traces into an internally consistent mental representation is dependent on both top{\textendash}down and bottom{\textendash}up processes. Moreover, I argue that this integration is not limited to just sensory inputs, but that internal cognitive processes also shape the resulting mental representation. Studies showing that memory recall is affected by the initial multisensory context in which the stimuli were presented will be discussed, as well as several studies showing that mental imagery can affect multisensory illusions. This empirical evidence will be discussed from a predictive coding perspective, in which a central top{\textendash}down attentional process is proposed to play a central role in coordinating the integration of all these inputs into a coherent mental representation.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/talsma2015.md;Cognitive Science/Multisensory Integration/Talsma, 2015 - Predictive coding and multisensory integration.pdf},
  url = {https://doi.org/10.3389/fnint.2015.00019}
}

@inproceedings{tcha-tokey2016,
  title = {A Questionnaire to Measure the User Experience in Immersive Virtual Environments},
  booktitle = {Proceedings of the 2016 {{Virtual Reality International Conference}} on - {{VRIC}} '16},
  author = {{Tcha-Tokey}, Katy and {Loup-Escande}, Emilie and Christmann, Olivier and Richir, Simon},
  year = {2016},
  pages = {1--5},
  publisher = {{ACM Press}},
  address = {{Laval, France}},
  urldate = {2020-01-30},
  isbn = {978-1-4503-4180-6},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/tcha-tokey2016.md;Human Computer Interaction/Virtual Reality/Tcha-Tokey et al., 2016 - A questionnaire to measure the user experience in immersive virtual environments.pdf},
  url = {https://doi.org/10.1145/2927929.2927955}
}

@article{tcha-tokey2016a,
  title = {Proposition and {{Validation}} of a {{Questionnaire}} to {{Measure}} the {{User Experience}} in {{Immersive Virtual Environments}}},
  author = {{Tcha-Tokey}, Katy and Christmann, Olivier and {Loup-Escande}, Emilie and Richir, Simon},
  year = {2016},
  month = jan,
  journal = {International Journal of Virtual Reality},
  volume = {16},
  number = {1},
  pages = {33--48},
  issn = {1081-1451},
  urldate = {2021-07-19},
  abstract = {There are increasing new advances in Virtual Reality technologies as well as a rise in Immersive Virtual Environments research and in User eXperience research. Within this framework, we decided to address the overall user experience in Immersive virtual environments. Indeed, in our point of view, this topic is not fully dealt with in the scientific literature, neither in terms of user experience components nor in terms of user experience measurement methods. It is in this context that we conducted a study aiming at proposing and validating a unified questionnaire on User eXperience in Immersive Virtual Environment. Our questionnaire contains 10 scales measuring presence, engagement, immersion, flow, usability, skill, emotion, experience consequence, judgement and technology adoption. Scale construction was based on existing questionnaires. Our questionnaire was tested on 116 participants after they use the edutainment Virtual Environment ``Think and Shoot''. The number of participants allows us to assess the reliability and the sensitivity of our questionnaire. Results show that 9 out of 10 subscales and 68 out of 87 items are reliable as demonstrated by an internal consistency analysis with Cronbach's alpha and an item analysis. Findings also indicate that the scale scores from 6 subscales are considered normal distributed (e.g. presence) whereas the scale scores from 3 subscales are considered negatively skewed (e.g. skill).},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/tcha-tokey2016a.md;Human Computer Interaction/User Experience Design/Tcha-Tokey et al., 2016 - Proposition and Validation of a Questionnaire to Measure the User Experience in.pdf},
  url = {https://doi.org/10.20870/IJVR.2016.16.1.2880}
}

@article{theeconomist2021,
  title = {Cloning {{DARPA}}},
  author = {Economist},
  year = {2021},
  month = jun,
  journal = {The Economist},
  url = {https://archive.today/OTbUd},
  urldate = {2022-12-19}
}

@misc{thiel2011,
  title = {Invisible Istanbul},
  author = {Thiel, Tamiko and Kozar, Cem and {\"U}nal, I{\c s}{\i}l},
  year = {2011},
  month = nov,
  url = {https://archive.today/qlbjT},
  urldate = {2021-05-17},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/thiel2011.md;../../../../../Zotero/storage/C7WGJ42D/www.invisibleistanbul.org.html}
}

@incollection{thiel2018,
  title = {Critical {{Interventions}} into {{Canonical Spaces}}: {{Augmented Reality}} at the 2011 {{Venice}} and {{Istanbul Biennials}}},
  shorttitle = {Critical {{Interventions}} into {{Canonical Spaces}}},
  booktitle = {Augmented {{Reality Art}}},
  author = {Thiel, Tamiko},
  editor = {Geroimenko, Vladimir},
  year = {2018},
  pages = {41--72},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  url = {https://doi.org/10.1007/978-3-319-69932-5_2},
  urldate = {2021-05-17},
  isbn = {978-3-319-69931-8 978-3-319-69932-5},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/thiel2018.md}
}

@article{thorleifsson2022,
  title = {From Cyberfascism to Terrorism: {{On}} 4chan/Pol/ Culture and the Transnational Production of Memetic Violence},
  shorttitle = {From Cyberfascism to Terrorism},
  author = {Thorleifsson, Cathrine},
  year = {2022},
  journal = {Nations and Nationalism},
  volume = {28},
  number = {1},
  pages = {286--301},
  issn = {1469-8129},
  urldate = {2022-12-11},
  abstract = {This article examines the fascists imaginaries that are produced and circulated at 4chan /pol/. Based on analysis of memes and posts collected during a 6-month period in 2019, it explores the diagnoses given by anonymous users to the imagining of the ultra-nation and dehumanized others, and the prescriptions for the remedies needed to bring about its saving. It argues that the cultural practices of /pol/ where fascist fantasies of white supremacy are spread fast and anonymously in a transnational milieu through transgressive play frames are particularly powerful for the amplification of the logic of an endangered ultra-nation that needs urgent violent defence to obtain racial palingenesis. As such cyberfascism co-produced in a leaderless network among users scattered across continents lends itself to calls for violent action against minority communities, including terrorism.},
  langid = {english},
  keywords = {chan culture,cyberfascism,far-right,terrorism,ultranationalism},
  file = {Politics/Marxism/Thorleifsson, 2022 - From cyberfascism to terrorism.pdf;../../../../../Zotero/storage/SE2MQA77/nana.html},
  url = {https://doi.org/10.1111/nana.12780}
}

@inproceedings{tieben2011,
  title = {Curiosity and {{Interaction}}: Making People Curious through Interactive Systems},
  shorttitle = {Curiosity and {{Interaction}}},
  booktitle = {Proceedings of {{HCI}} 2011 {{The}} 25th {{BCS Conference}} on {{Human Computer Interaction}}},
  author = {Tieben, Rob and Bekker, Tilde and Schouten, Ben},
  year = {2011},
  month = jul,
  urldate = {2020-05-25},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/tieben2011.md;Human Computer Interaction/User Experience Design/Tieben et al., 2011 - Curiosity and Interaction.pdf},
  url = {https://doi.org/10.14236/ewic/HCI2011.66}
}

@inproceedings{tikander2008,
  title = {An {{Augmented Reality Audio Headset}}},
  booktitle = {Proceedings of the 11th {{International Conference}} on {{Digital Audio Effects}}},
  author = {Tikander, Miikka and Karjalainen, Matti and Riikonen, Ville},
  year = {2008},
  pages = {4},
  address = {{Espoo, Finland}},
  abstract = {Augmented reality audio (ARA) means mixing the natural sound environment with artificially created sound scenes. This requires that the perception of natural environment has to be preserved as well as possible, unless some modification to it is desired. A basic ARA headset consists of binaural microphones, an amplifier/mixer, and earphones feeding sound to the ear canals. All these components more or less change the perceived sound scene. In this paper we describe an ARA headset, equalization of its response, and particularly the results of a usability study. The usability was tested by subjects wearing the headset for relatively long periods in different environments of their everyday-life conditions. The goal was to find out what works well and what are the problems in lengthened use. It was found that acoustically the headset worked fine in most occasions when equalized individually or generically (averaged over several subjects). The main problems of usage were related to handling inconveniences and special environments.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/tikander2008.md;Human Computer Interaction/Augmented Reality/Tikander et al., 2008 - An Augmented Reality Audio Headset.pdf}
}

@article{timmers2016,
  title = {Representation of Pitch in Horizontal Space and Its Dependence on Musical and Instrumental Experience.},
  author = {Timmers, Renee and Li, Shen},
  year = {2016},
  journal = {Psychomusicology: Music, Mind, and Brain},
  volume = {26},
  number = {2},
  pages = {139--148},
  issn = {2162-1535, 0275-3987},
  urldate = {2020-05-26},
  abstract = {Representation of pitch in horizontal space and its relationship to musical and instrumental experience was examined in three behavioral experiments. Each experiment investigated the influence of a task-irrelevant dimension (pitch or location) on the perception of a taskrelevant dimension (location or pitch, respectively). Sine tones with nine different pitches were presented from nine locations, and participants estimated the pitch or location of the stimuli. Experiment 1 showed an influence of the (task irrelevant) pitch of presented stimuli on the perceived location of the stimuli in musically experienced participants only. This influence increased with the degree of musical training of participants. No influence was found of presented location on the perception of pitch. Experiments 2 and 3 investigated the influence of instrumental expertise comparing the responses of a group of flutists with a group of pianists. An interaction with instrumental expertise was found only in Experiment 3, where participants played shortly on their respective instruments before doing the perceptual judgments. The experiments indicate that musical training in general influence the pitchlocation association, and pianistic experience in particular.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/timmers2016.md;Cognitive Science/Psychophysics/Timmers and Li, 2016 - Representation of pitch in horizontal space and its dependence on musical and.pdf},
  url = {https://doi.org/10.1037/pmu0000146}
}

@misc{tonn2017,
  title = {Sensory {{Cartographies}} of {{Madeira}}},
  author = {Tonn, Sissel Marie and Reus, Jonathan Chaim},
  year = {2017},
  month = aug,
  url = {https://archive.today/X3IN1},
  urldate = {2022-12-13},
  abstract = {In this project we explore the relationships between consciousness, body and environment, as mediated by the filtration mechanisms of the senses. In February of 2016 we traveled to the cloud [{\dots}]},
  langid = {american},
  file = {../../../../../Zotero/storage/K9PTJHTJ/sensory-cartographies-of-madeira.html}
}

@inproceedings{toppano2019,
  title = {Moving across {{Sonic Atmospheres}}},
  booktitle = {Proceedings of the 14th {{International Audio Mostly Conference}}: {{A Journey}} in {{Sound}}},
  author = {Toppano, Elio and Toppano, Sveva and Basiaco, Alessandro},
  year = {2019},
  month = sep,
  pages = {139--146},
  publisher = {{ACM}},
  address = {{Nottingham United Kingdom}},
  urldate = {2020-09-19},
  abstract = {The concept of sonic atmosphere has become the focus of an increasing amount of attention in both academic and public forums, but scholars have developed diverging and overlapping definitions of the concept which threatens to inhibit our progress in understanding atmospheric phenomena. This paper draws on recent developments in the field of New Aesthetics and New Phenomenology. In particular, the research work highlights the role a sonic atmosphere has as a backdrop of the acoustic environment and the soundscape, and explores the relationships existing among these concepts. This provides us with a reference framework for studying movement through and between sonic atmospheres and to understand the possible relationships unfolding between an individual' s mood and the affective tonality and affordances of a sonic space. A case study exemplifies the application of the proposed conceptual framework in the field of urban design.},
  isbn = {978-1-4503-7297-8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/toppano2019.md;Arts & Humanities/Computational Art/Toppano et al., 2019 - Moving across Sonic Atmospheres.pdf},
  url = {https://doi.org/10.1145/3356590.3356612}
}

@misc{tremosa2022,
  title = {Virtuality {{Continuum}}},
  author = {Tremosa, Laia},
  year = {2022},
  url = {https://www.interaction-design.org/literature/topics/virtuality-continuum}
}

@inproceedings{turchet2018,
  title = {Smart {{Mandolin}}: Autobiographical Design, Implementation, Use Cases, and Lessons Learned},
  shorttitle = {Smart {{Mandolin}}},
  booktitle = {Proceedings of the {{Audio Mostly}} 2018 on {{Sound}} in {{Immersion}} and {{Emotion}}  - {{AM}}'18},
  author = {Turchet, Luca},
  year = {2018},
  pages = {1--7},
  publisher = {{ACM Press}},
  address = {{Wrexham, United Kingdom}},
  urldate = {2020-05-26},
  abstract = {This paper presents the Smart Mandolin, an exemplar of the family of the so-called smart instruments. Developed according to the paradigms of autobiographical design, it consists of a conventional acoustic mandolin enhanced with different types of sensors, a microphone, a loudspeaker, wireless connectivity to both local networks and the Internet, and a low-latency audio processing board. Various implemented use cases are presented, which leverage the smart qualities of the instrument. These include the programming of the instrument via applications for smartphones and desktop computer, as well as the wireless control of devices enabling multimodal performances such as screen projecting visuals, smartphones, and tactile devices used by the audience. The paper concludes with an evaluation conducted by the author himself after extensive use, which pinpointed pros and cons of the instrument and provided a comparison with the Hyper-Mandolin, an instance of augmented instruments previously developed by the author.},
  isbn = {978-1-4503-6609-0},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/turchet2018.md;Arts & Humanities/Computational Art/Turchet, 2018 - Smart Mandolin.pdf},
  url = {https://doi.org/10.1145/3243274.3243280}
}

@article{turchet2021,
  title = {Music in {{Extended Realities}}},
  author = {Turchet, Luca and Hamilton, Rob and {\c C}amci, An{\i}l},
  year = {2021},
  journal = {IEEE Access},
  volume = {9},
  issn = {2169-3536},
  abstract = {The intersection between music and Extended Reality (XR) has grown significantly over the past twenty years, amounting to an established area of research today. The use of XR technologies represents a fundamental paradigm shift for various musical contexts as they disrupt traditional notions of musical interaction by enabling performers and audiences to interact musically with virtual objects, agents, and environments. This article both surveys and expands upon the knowledge accumulated in existing research in this area to build a foundation for future works that bring together Music and XR. To this end, we created a freely available dataset of 260 publications in this space and conducted an in-depth analysis covering 199 works in the last decade. We conducted this analysis using a list of conceptual dimensions belonging to technical, artistic, perceptual and methodological domains. This review of the literature is complemented with a set of interviews with domain experts with the goal of establishing a definition for the emergent field of Musical XR, i.e., the field of music in Extended Realities. Based on the results of the conducted review, a research agenda for the field is proposed.},
  keywords = {augmented reality,augmented virtuality,digital musical instruments,extended reality,Extended reality,Internet of Musical Things,mixed reality,Mixed reality,Music,Tracking,Virtual environments,virtual reality,Visualization,X reality},
  file = {Human Computer Interaction/Augmented Reality/Turchet et al., 2021 - Music in Extended Realities.pdf;../../../../../Zotero/storage/BI6XJAGL/stamp.html},
  url = {https://doi.org/10.1109/ACCESS.2021.3052931}
}

@article{turk2014,
  title = {Multimodal Interaction: {{A}} Review},
  shorttitle = {Multimodal Interaction},
  author = {Turk, Matthew},
  year = {2014},
  month = jan,
  journal = {Pattern Recognition Letters},
  volume = {36},
  pages = {189--195},
  issn = {01678655},
  urldate = {2020-05-24},
  abstract = {People naturally interact with the world multimodally, through both parallel and sequential use of multiple perceptual modalities. Multimodal human{\textendash}computer interaction has sought for decades to endow computers with similar capabilities, in order to provide more natural, powerful, and compelling interactive experiences. With the rapid advance in non-desktop computing generated by powerful mobile devices and affordable sensors in recent years, multimodal research that leverages speech, touch, vision, and gesture is on the rise. This paper provides a brief and personal review of some of the key aspects and issues in multimodal interaction, touching on the history, opportunities, and challenges of the area, especially in the area of multimodal integration. We review the question of early vs. late integration and find inspiration in recent evidence in biological sensory integration. Finally, we list challenges that lie ahead for research in multimodal human{\textendash}computer interaction.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/turk2014.md;Human Computer Interaction/Multisensory Interfacing/Turk, 2014 - Multimodal interaction.pdf},
  url = {https://doi.org/10.1016/j.patrec.2013.07.003}
}

@incollection{tuters2015,
  title = {Through {{Glass Darkly}}: {{On Google}}'s {{Gnostic Governance}}},
  shorttitle = {Through {{Glass Darkly}}},
  booktitle = {Postdigital {{Aesthetics}}},
  author = {Tuters, Marc},
  editor = {Berry, David and Dieter, Michael},
  year = {2015},
  pages = {245--258},
  publisher = {{Palgrave Macmillan UK}},
  address = {{London}},
  url = {https://doi.org/10.1057/9781137437204_19},
  urldate = {2020-09-21},
  isbn = {978-1-349-49378-4 978-1-137-43720-4},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/tuters2015.md;Arts & Humanities/Media Studies/Tuters, 2015 - Through Glass Darkly.pdf}
}

@misc{ulfarsson2014,
  title = {Halldorophone},
  author = {{\'U}lfarsson, Hald{\'o}r},
  year = {2014},
  url = {https://commons.wikimedia.org/w/index.php?curid=85696600},
  abstract = {A halldorophone, an electro acoustic string instrument.},
  copyright = {CC-BY-SA 4.0 International}
}

@inproceedings{ulfarsson2018,
  title = {The {{Halldorophone}}: {{The}} Ongoing Innovation of a Cello-like Drone Instrument},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  author = {{\'U}lfarsson, Halld{\'o}r},
  editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
  year = {2018},
  month = jun,
  pages = {269--274},
  publisher = {{Virginia Tech}},
  address = {{Blacksburg, Virginia, USA}},
  issn = {2220-4806},
  abstract = {This paper reports upon the process of innovation of a new instrument. The author has developed the halldorophone a new electroacoustic string instrument which makes use of positive feedback as a key element in generating its sound. An important objective of the project has been to encourage its use by practicing musicians. After ten years of use, the halldorophone has a growing repertoire of works by prominent composers and performers. During the development of the instrument, the question has been asked: ``why do musicians want to use this instrument?'' and answers have been found through on-going (informal) user studies and feedback. As the project progresses, a picture emerges of what qualities have led to a culture of acceptance and use around this new instrument. This paper describes the halldorophone and presents the rationale for its major design features and ergonomic choices, as they relate to the overarching objective of nurturing a culture of use and connects it to wider trends.},
  isbn = {978-1-949373-99-8},
  url = {https://doi.org/10.5281/zenodo.1302579}
}

@article{ullmer2000,
  title = {Emerging Frameworks for Tangible User Interfaces},
  author = {Ullmer, B. and Ishii, H.},
  year = {2000},
  journal = {IBM Systems Journal},
  volume = {39},
  number = {3.4},
  pages = {915--931},
  issn = {0018-8670},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ullmer2000.md;Human Computer Interaction/User Interface Design/Ullmer and Ishii, 2000 - Emerging frameworks for tangible user interfaces.pdf},
  url = {https://doi.org/10.1147/sj.393.0915}
}

@misc{ultraleap2020,
  title = {Leap {{Motion Controller}}},
  author = {UltraLeap},
  year = {2020},
  url = {https://www.ultraleap.com/product/leap-motion-controller/},
  urldate = {2020-05-25},
  abstract = {Small. Fast. Accurate. The LeapMotion Controller is an optical hand tracking module that captures the movements of your hands with unparalleled accuracy.},
  langid = {english},
  file = {../../../../../Zotero/storage/QT3Y43VM/leap-motion-controller.html}
}

@misc{ultraleap2020a,
  title = {Touch {{Screen Kiosks}}: {{Back}} to {{Business}} as {{Usual}}?},
  author = {Gupta, Saurabh},
  year = {2020},
  url = {https://www.ultraleap.com/company/news/blog/touch-screen-kiosks/},
  urldate = {2020-11-19},
  abstract = {COVID-19 has dramatically changed consumers' perception of the hygiene risks of touch screen kiosks. Saurabh Gupta, Director of Out-of-Home Product at Ultraleap, explores the likely business impact {\textendash} and the importance of developing touchless interfaces.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ultraleap2020a.md;../../../../../Zotero/storage/5WMB9HGB/contactless-technology.html}
}

@inproceedings{unander-scharin2014,
  title = {The Vocal Chorder: Empowering Opera Singers with a Large Interactive Instrument},
  shorttitle = {The Vocal Chorder},
  booktitle = {Proceedings of the 32nd Annual {{ACM}} Conference on {{Human}} Factors in Computing Systems - {{CHI}} '14},
  author = {{Unander-Scharin}, Carl and {Unander-Scharin}, Asa and H{\"o}{\"o}k, Kristina},
  year = {2014},
  pages = {1001--1010},
  publisher = {{ACM Press}},
  address = {{Toronto, Ontario, Canada}},
  urldate = {2020-05-26},
  abstract = {With The Vocal Chorder, a large interactive instrument to create accompaniment, opera singers can get more power over the performance. The device allows performers to interactively accompany themselves through pushing, leaning on and bending steel wires. The design was guided by the unique needs of the solo-singer, explored through autobiographical design and material explorations, some on stage, and later tested by other singers. We discuss how designing for opera and for the stage requires extraordinary durability and how opera performances can change with a bodilyoriented instrument such as The Vocal Chorder. Through a designerly exploration, we arrived at a device that offered (1) a tool for singers to take control over the rhythmical pace and overall artistic and aesthetic outcome of their performances, (2) an enriched sense of embodiment between their voice and the overall performance; and (3) a means to empower opera singers on stage.},
  isbn = {978-1-4503-2473-1},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/unander-scharin2014.md;Arts & Humanities/Computational Art/Unander-Scharin et al., 2014 - The vocal chorder.pdf},
  url = {https://doi.org/10.1145/2556288.2557050}
}

@misc{unitytechnologies2020,
  title = {{{Unity3D}}},
  author = {Unity Technologies},
  year = {2020},
  url = {https://www.unity.com/},
  urldate = {2020-05-26},
  abstract = {New address, same Unity3d. Unity real-time development platform. Create 3D, 2D VR \& AR visualizations for Games, Auto, Transportation, Film, Animation, Architecture, Engineering \& more.,},
  langid = {english},
  file = {../../../../../Zotero/storage/W7Q2EUD6/unity.com.html}
}

@inproceedings{vallgarda2007,
  title = {Computational Composites},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}  - {{CHI}} '07},
  author = {Vallg{\aa}rda, Anna and Redstr{\"o}m, Johan},
  year = {2007},
  pages = {513--522},
  publisher = {{ACM Press}},
  address = {{San Jose, California, USA}},
  urldate = {2020-05-25},
  abstract = {Computational composite is introduced as a new type of composite material. Arguing that this is not just a metaphorical maneuver, we provide an analysis of computational technology as material in design, which shows how computers share important characteristics with other materials used in design and architecture. We argue that the notion of computational composites provides a precise understanding of the computer as material, and of how computations need to be combined with other materials to come to expression as material. Besides working as an analysis of computers from a designer's point of view, the notion of computational composites may also provide a link for computer science and human-computer interaction to an increasingly rapid development and use of new materials in design and architecture.},
  isbn = {978-1-59593-593-9},
  langid = {english},
  file = {../../../../../../../../C\:\\Users\\Sam Bilbow\\OneDrive\\Literature\\Philosophy\\Materiality\\VallgÃ¥rda and RedstrÃ¶m, 2007 - Computational composites.pdf;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/vallgarda2007.md},
  url = {https://doi.org/10.1145/1240624.1240706}
}

@phdthesis{vallino1998,
  title = {Interactive {{Augmented Reality}}},
  author = {Vallino, James R},
  year = {1998},
  address = {{New York}},
  langid = {english},
  school = {University of Rochester},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/vallino1998.md;Human Computer Interaction/Augmented Reality/Vallino, 1998 - Interactive Augmented Reality.pdf}
}

@misc{valve2019,
  title = {Valve {{Index}}},
  author = {Valve},
  year = {2019},
  url = {https://store.steampowered.com/valveindex},
  urldate = {2020-07-12},
  abstract = {Upgrade your experience.},
  langid = {english},
  file = {../../../../../Zotero/storage/FJ9PCXVP/valveindex.html}
}

@article{vankrevelen2010,
  title = {A {{Survey}} of {{Augmented Reality Technologies}}, {{Applications}} and {{Limitations}}},
  author = {Van Krevelen, D.W.F. and Poelman, R.},
  year = {2010},
  month = jan,
  journal = {International Journal of Virtual Reality},
  volume = {9},
  number = {2},
  pages = {1--20},
  issn = {1081-1451},
  urldate = {2020-01-10},
  abstract = {A Survey of Augmented Reality Technologies, Applications and Limitations},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/vankrevelen2010.md;Human Computer Interaction/Augmented Reality/Van Krevelen and Poelman, 2010 - A Survey of Augmented Reality Technologies, Applications and Limitations.pdf},
  url = {https://doi.org/10.20870/IJVR.2010.9.2.2767}
}

@book{varela1993,
  title = {The Embodied Mind: Cognitive Science and Human Experience},
  shorttitle = {The Embodied Mind},
  author = {Varela, Francisco J. and Thompson, Evan and Rosch, Eleanor},
  year = {1993},
  publisher = {{MIT press}},
  address = {{Cambridge (Mass.) London}},
  isbn = {978-0-262-72021-2},
  langid = {english},
  lccn = {153.4},
  file = {Philosophy/Extended Cognition/Varela et al., 1993 - The embodied mind.pdf}
}

@article{varese1966,
  title = {The {{Liberation}} of {{Sound}}},
  author = {Varese, Edgard},
  editor = {{Wen-chung}, Chou},
  year = 1966,
  journal = {Perspectives of New Music},
  volume = {5},
  number = {1},
  eprint = {832385},
  eprinttype = {jstor},
  pages = {11},
  issn = {00316016},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/varese23.md;Arts & Humanities/Musicology/Varese, 1966 - The Liberation of Sound.pdf},
  url = {https://doi.org/10.2307/832385}
}

@misc{varjo2019,
  title = {Varjo {{XR-1}}},
  author = {{Varjo}},
  year = {2019},
  journal = {Varjo.com},
  url = {https://varjo.com/products/xr-1/},
  urldate = {2020-10-03},
  abstract = {Varjo XR-1 is the world's most advanced mixed reality headset for professionals, with photorealistic visual fidelity and ultra-low latency.},
  langid = {american},
  file = {../../../../../Zotero/storage/LQV4PK8K/xr-1.html}
}

@incollection{veal2012,
  title = {Starship {{Africa}}},
  booktitle = {The Sound Studies Reader},
  author = {Veal, Michael},
  editor = {Sterne, Jonathan},
  year = {2012},
  publisher = {{Routledge}},
  address = {{New York}},
  abstract = {"The Sound Studies Reader is a groundbreaking anthology blending recent work that self-consciously describes itself as 'sound studies' with earlier and lesser known scholarship on sound. The collection begins with an introduction to welcome novice readers to the field and acquaint them with key themes and concepts in sound studies. Individual section introductions give readers further background on the essays and an extensive up to date bibliography for further reading in 'sound studies' make this an original and accessible guide to the field"--},
  isbn = {978-0-415-77130-6 978-0-415-77131-3},
  lccn = {TK7881.4 .S684 2012},
  keywords = {Hearing,Listening,MUSIC / Recording \& Reproduction,Recording and reproducing History,Recording and reproducing Social aspects,SOCIAL SCIENCE / Media Studies,Sound},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/veal2012.md;Arts & Humanities/Musicology/Veal, 2012 - Starship Africa.pdf}
}

@misc{veenhof2010,
  title = {We {{AR}} in {{MoMA}}},
  author = {Veenhof, Sander and Skwarek, Mark},
  year = {2010},
  url = {https://archive.today/0gD2y},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/veenhof2010.md}
}

@incollection{veerapen2011,
  title = {Encountering Oneself and the Other: {{A}} Case Study of Identity Formation in {{Second Life}}.},
  booktitle = {Reinventing {{Ourselves}}: {{Contemporary Concepts}} of {{Identity}} in {{Virtual Worlds}}},
  author = {Veerapen, Maeva},
  editor = {Peachey, Anna and Childs, Mark},
  year = {2011},
  series = {Springer {{Series}} in {{Immersive Environments}}},
  publisher = {{Springer London}},
  address = {{London}},
  url = {https://doi.org/10.1007/978-0-85729-361-9},
  urldate = {2022-09-12},
  isbn = {978-0-85729-360-2 978-0-85729-361-9},
  langid = {english},
  file = {Human Computer Interaction/Metaverse/Veerapen, 2011 - Encountering oneself and the other.pdf}
}

@article{vermeulen2015,
  title = {Space Is the {{Place}}},
  author = {Vermeulen, Timotheus},
  year = {2015},
  month = apr,
  journal = {Frieze},
  url = {https://archive.today/IYBIK},
  urldate = {2022-09-12},
  abstract = {Rediscovering the late, great philosopher Henri Lefebvre, whose ideas are increasingly relevant to contemporary life},
  langid = {english},
  file = {../../../../../Zotero/storage/2IPADCQV/space-place.html}
}

@inproceedings{vi2017,
  title = {{{TastyFloats}}: {{A Contactless Food Delivery System}}},
  shorttitle = {{{TastyFloats}}},
  booktitle = {Proceedings of the {{Interactive Surfaces}} and {{Spaces}} - {{ISS}} '17},
  author = {Vi, Chi Thanh and Marzo, Asier and Ablart, Damien and Memoli, Gianluca and Subramanian, Sriram and Drinkwater, Bruce and Obrist, Marianna},
  year = {2017},
  pages = {161--170},
  publisher = {{ACM Press}},
  address = {{Brighton, United Kingdom}},
  urldate = {2020-05-25},
  abstract = {We present two realizations of TastyFloats, a novel system that uses acoustic levitation to deliver food morsels to the users' tongue. To explore TastyFloats' associated design framework, we first address the technical challenges to successfully levitate and deliver different types of foods on the tongue. We then conduct a user study, assessing the effect of acoustic levitation on users' taste perception, comparing three basic taste stimuli (i.e., sweet, bitter and umami) and three volume sizes of droplets (5{\textmu}L, 10{\textmu}L and 20{\textmu}L). Our results show that users perceive sweet and umami easily, even in minimal quantities, whereas bitter is the least detectable taste, despite its typical association with an unpleasant taste experience. Our results are a first step towards the creation of new culinary experiences and innovative gustatory interfaces.},
  isbn = {978-1-4503-4691-7},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/vi2017.md;Human Computer Interaction/Multisensory Interfacing/Vi et al., 2017 - TastyFloats.pdf},
  url = {https://doi.org/10.1145/3132272.3134123}
}

@article{vi2017a,
  title = {Not Just Seeing, but Also Feeling Art: {{Mid-air}} Haptic Experiences Integrated in a Multisensory Art Exhibition},
  shorttitle = {Not Just Seeing, but Also Feeling Art},
  author = {Vi, Chi Thanh and Ablart, Damien and Gatti, Elia and Velasco, Carlos and Obrist, Marianna},
  year = {2017},
  month = dec,
  journal = {International Journal of Human-Computer Studies},
  volume = {108},
  pages = {1--14},
  issn = {10715819},
  urldate = {2020-01-10},
  abstract = {The use of the senses of vision and audition as interactive means has dominated the field of Human-Computer Interaction (HCI) for decades, even though nature has provided us with many more senses for perceiving and interacting with the world around us. That said, it has become attractive for HCI researchers and designers to harness touch, taste, and smell in interactive tasks and experience design. In this paper, we present research and design insights gained throughout an interdisciplinary collaboration on a six-week multisensory display {\textendash} Tate Sensorium {\textendash} exhibited at the Tate Britain art gallery in London, UK. This is a unique and first time case study on how to design art experiences whilst considering all the senses (i.e., vision, sound, touch, smell, and taste), in particular touch, which we exploited by capitalizing on a novel haptic technology, namely, mid-air haptics. We first describe the overall set up of Tate Sensorium and then move on to describing in detail the design process of the mid-air haptic feedback and its integration with sound for the Full Stop painting by John Latham (1961). This was the first time that mid-air haptic technology was used in a museum context over a prolonged period of time and integrated with sound to enhance the experience of visual art. As part of an interdisciplinary team of curators, sensory designers, sound artists, we selected a total of three variations of the mid-air haptic experience (i.e., haptic patterns), which were alternated at dedicated times throughout the six-week exhibition. We collected questionnaire-based feedback from 2500 visitors and conducted 50 interviews to gain quantitative and qualitative insights on visitors' experiences and emotional reactions. Whilst the questionnaire results are generally very positive with only a small variation of the visitors' arousal ratings across the three tactile experiences designed for the Full Stop painting, the interview data shed light on the differences in the visitors' subjective experiences. Our findings suggest multisensory designers and art curators can ensure a balance between surprising experiences versus the possibility of free exploration for visitors. In addition, participants expressed that experiencing art with the combination of mid-air haptic and sound was immersive and provided an up-lifting experience of touching without touch. We are convinced that the insights gained from this large-scale and real-world field exploration of multisensory experience design exploiting a new and emerging technology provide a solid starting point for the HCI community, creative industries, and art curators to think beyond conventional art experiences. Specifically, our work demonstrates how novel mid-air technology can make art more emotionally engaging and stimulating, especially abstract art that is often open to interpretation.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/vi2017a.md;Human Computer Interaction/Multisensory Interfacing/Vi et al., 2017 - Not just seeing, but also feeling art.pdf},
  url = {https://doi.org/10.1016/j.ijhcs.2017.06.004}
}

@inproceedings{vi2017b,
  title = {Gustatory Interface: The Challenges of `How' to Stimulate the Sense of Taste},
  shorttitle = {Gustatory Interface},
  booktitle = {Proceedings of the 2nd {{ACM SIGCHI International Workshop}} on {{Multisensory Approaches}} to {{Human-Food Interaction}} - {{MHFI}} 2017},
  author = {Vi, Chi Thanh and Ablart, Damien and Arthur, Daniel and Obrist, Marianna},
  year = {2017},
  pages = {29--33},
  publisher = {{ACM Press}},
  address = {{Glasgow, UK}},
  urldate = {2020-01-10},
  abstract = {Gustatory interfaces have gained popularity in the field of humancomputer interaction, especially in the context of augmenting gaming and virtual reality experiences, but also in the context of food interaction design enabling the creation of new eating experiences. In this paper, we first review prior works on gustatory interfaces and particularly discuss them based on the use of either a chemical, electrical and/or thermal stimulation approach. We then present two concepts for gustatory interfaces that represent a more traditional delivery approach (using a mouthpiece) versus a novel approach that is based on principles of acoustic levitation (contactless delivery). We discuss the design opportunities around those two concepts in particular to overcome challenges of "how" to stimulate the sense of taste.},
  isbn = {978-1-4503-5556-8},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/vi2017b.md;Human Computer Interaction/Multisensory Interfacing/Vi et al., 2017 - Gustatory interface.pdf},
  url = {https://doi.org/10.1145/3141788.3141794}
}

@inproceedings{vidyarthi2012,
  title = {Sonic {{Cradle}}: Designing for an Immersive Experience of Meditation by Connecting Respiration to Music},
  shorttitle = {{\emph{Sonic }}{{{\emph{Cradle}}}}},
  booktitle = {Proceedings of the {{Designing Interactive Systems Conference}} on - {{DIS}} '12},
  author = {Vidyarthi, Jay and Riecke, Bernhard E. and Gromala, Diane},
  year = {2012},
  pages = {408},
  publisher = {{ACM Press}},
  address = {{Newcastle Upon Tyne, United Kingdom}},
  urldate = {2020-05-25},
  abstract = {Sonic Cradle is a chamber of complete darkness where users shape a peaceful soundscape using only their respiration. This interactive system was designed to foster a meditative experience by facilitating users' sense of immersion while following a specific attentional pattern characteristic of mindfulness. The goal of Sonic Cradle is twofold: first, to trigger the proven effects of mindfulness on stress, and second, to help teach and demystify the concept of meditation for users' long-term benefit. This paper presents the design phase of the project, starting by theoretically grounding the initial concept. We then discuss 15 co-design sessions which provided informal conceptual validation and led to several concrete design iterations aimed at balancing users' perceived sense of control. The presented approach to designing an interactive stress management system can be considered research through design, as it also resulted in a novel theoretical framework for the psychology of media immersion which has implications for a wide range of research areas.},
  isbn = {978-1-4503-1210-3},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/vidyarthi2012.md;Human Computer Interaction/Audio Interfacing/Vidyarthi et al., 2012 - Sonic Cradle.pdf},
  url = {https://doi.org/10.1145/2317956.2318017}
}

@article{vines2006,
  title = {Cross-Modal Interactions in the Perception of Musical Performance},
  author = {Vines, B and Krumhansl, C and Wanderley, M and Levitin, D},
  year = {2006},
  month = aug,
  journal = {Cognition},
  volume = {101},
  number = {1},
  pages = {80--113},
  issn = {00100277},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/vines2006.md;Cognitive Science/Multisensory Integration/Vines et al., 2006 - Cross-modal interactions in the perception of musical performance.pdf},
  url = {https://doi.org/10.1016/j.cognition.2005.09.003}
}

@misc{vuforia2020,
  title = {Vuforia},
  author = {Vuforia},
  year = {2020},
  url = {https://library.vuforia.com/getting-started/overview.html},
  urldate = {2020-05-25},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/vuforia2020.md;../../../../../Zotero/storage/J3N5DP6X/overview.html}
}

@inproceedings{walther-hansen2020,
  title = {Don't Extend! {{Reduce}}! {{The}} Sound Approach to Reality},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {{Walther-Hansen}, Mads and {Grimshaw-Aagaard}, Mark},
  year = {2020},
  series = {{{AM}} '20},
  pages = {8--15},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {In this paper we propose a reduced reality concept of less-is-more that VR designers can use to create technological frameworks that reduce sensory overload and allow for better concentration and focus, less stress, and novel scenarios. We question the approach taken by scholars in the field of XR research, where the focus is typically to design and use technology that adds sensory information to the user's perceptual field and we address some of the confusion related to the typical uses of the term reality. To address the latter terminological muddle, we define reality as our conscious experience of the environment as emergent perception and we use this definition as the basis for a discussion of the role of sound in balancing sensory information and in the construction of a less cluttered and less stressful perceptual environments.},
  isbn = {978-1-4503-7563-4},
  keywords = {augmented reality,cognition,crossmodality,diminished reality,environment,extended reality,listening,presence,reduced reality,sound},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/walther-hansen2020.md;Human Computer Interaction/Augmented Reality/Walther-Hansen and Grimshaw-Aagaard, 2020 - Don't extend.pdf},
  url = {https://doi.org/10.1145/3411109.3411111}
}

@article{walzer2017,
  title = {Independent Music Production: How Individuality, Technology and Creative Entrepreneurship Influence Contemporary Music Industry Practices},
  shorttitle = {Independent Music Production},
  author = {Walzer, Daniel A.},
  year = {2017},
  month = jan,
  journal = {Creative Industries Journal},
  volume = {10},
  number = {1},
  pages = {21--39},
  issn = {1751-0694, 1751-0708},
  urldate = {2019-05-15},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/walzer2017.md},
  url = {https://doi.org/10.1080/17510694.2016.1247626}
}

@article{wang2022,
  title = {Cubing {{Sound}}: {{Designing}} a {{NIME}} for {{Head-mounted Augmented Reality}}},
  shorttitle = {Cubing {{Sound}}},
  author = {Wang, Yichen and Martin, Charles},
  year = {2022},
  month = jun,
  journal = {International Conference on New Interfaces for Musical Expression},
  urldate = {2023-01-24},
  abstract = {We present an empirical study of designing a NIME for the head-mounted augmented reality (HMAR) environment. In the NIME community, various sonic applications have incorporated augmented reality (AR) for sonic experience and audio production. With this novel digital form, new opportunities for musical expression and interface are presented. Yet few works consider whether and how the design of the NIME will be affected given the technology's affordance. In this paper, we take an autobiographical design approach to design a NIME in HMAR, exploring what is a genuine application of AR in a NIMEs and how AR mediates between the performer and sound as a creative expression. Three interface prototypes are created for a frequency modulation synthesis system. We report on their design process and our learning and experiences through self-usage and improvisation. Our designs explore free-hand and embodied interaction in our interfaces, and we reflect on how these unique qualities of HMAR contribute to an expressive medium for sonic creation.},
  langid = {english},
  file = {Human Computer Interaction/Augmented Reality/Wang and Martin, 2022 - Cubing Sound.pdf},
  url = {https://doi.org/10.21428/92fbeb44.b540aa59}
}

@inproceedings{wang2022a,
  title = {Designing Sound Synthesis Interfaces for Head-Mounted Augmented Reality},
  booktitle = {2022 {{IEEE}} Conference on Virtual Reality and {{3D}} User Interfaces Abstracts and Workshops ({{VRW}})},
  author = {Wang, Yichen and Martin, Charles},
  year = {2022},
  pages = {351--353},
  file = {Human Computer Interaction/Augmented Reality/Wang and Martin, 2022 - Designing sound synthesis interfaces for head-mounted augmented reality.pdf},
  url = {https://doi.org/10.1109/VRW55335.2022.00078}
}

@article{wanstall1989,
  title = {{{HUD}} on the Head for Combat Pilots},
  author = {Wanstall, Brian},
  year = {1989},
  journal = {Interavia},
  volume = {44},
  pages = {334--338}
}

@article{ward2010,
  title = {Visual Experiences in the Blind Induced by an Auditory Sensory Substitution Device},
  author = {Ward, Jamie and Meijer, Peter},
  year = {2010},
  month = mar,
  journal = {Consciousness and Cognition},
  volume = {19},
  number = {1},
  pages = {492--500},
  issn = {1053-8100},
  urldate = {2020-10-03},
  abstract = {In this report, the phenomenology of two blind users of a sensory substitution device {\textendash} ``The vOICe'' {\textendash} that converts visual images to auditory signals is described. The users both report detailed visual phenomenology that developed within months of immersive use and has continued to evolve over a period of years. This visual phenomenology, although triggered through use of The vOICe, is likely to depend not only on online visualization of the auditory signal but also on the users' previous (albeit distant) experience of veridical vision (e.g. knowledge of shapes and visual perspective). Once established, the sensory substitution mapping between the auditory and visual domains is not confined to when the device is worn and, thus, may constitute an example of acquired synaesthesia.},
  langid = {english},
  keywords = {Blind,Mental imagery,Sensory substitution,Synaesthesia/synesthesia,Visual consciousness,vOICe},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ward2010.md;../../../../../Zotero/storage/6I98CSUU/S1053810009001718.html},
  url = {https://doi.org/10.1016/j.concog.2009.10.006}
}

@article{ward2016,
  title = {Visual {{Cues}} to {{Reorient Attention}} from {{Head Mounted Displays}}},
  author = {Ward, Matthew and Barde, Amit and Russell, Paul N. and Billinghurst, Mark and Helton, William S.},
  year = {2016},
  month = sep,
  journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  volume = {60},
  number = {1},
  pages = {1574--1578},
  issn = {1541-9312},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/ward2016.md;Human Computer Interaction/Augmented Reality/Ward et al., 2016 - Visual Cues to Reorient Attention from Head Mounted Displays.pdf},
  url = {https://doi.org/10.1177/1541931213601363}
}

@inproceedings{waters2007,
  title = {Performance {{Ecosystems}}: {{Ecological}} Approaches to Musical Interaction},
  booktitle = {Electroacoustic {{Music Studies Network EMS-07 Proceedings}}},
  author = {Waters, Simon},
  year = {2007},
  pages = {20},
  address = {{DeMonfort University, Leicester}},
  url = {http://www.ems-network.org/IMG/pdf_WatersEMS07.pdf},
  urldate = {2021-07-13},
  abstract = {Music is understood as a dynamical complex of interacting situated embodied behaviours. These behaviours may be physical or virtual, composed or emergent, or of a time scale such that they figure as constraints or constructs. All interact in the same space by a process of mutual modelling, redescription, and emergent restructuring.},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/waters2007.md;Arts & Humanities/Computational Art/Waters, 2007 - Performance Ecosystems.pdf}
}

@inbook{waterworth2014,
  title = {Altered, {{Expanded}} and {{Distributed Embodiment}}: The {{Three Stages}} of {{Interactive Presence}}},
  shorttitle = {Altered, {{Expanded}} and {{Distributed Embodiment}}},
  booktitle = {Interacting with {{Presence}}: {{HCI}} and the {{Sense}} of {{Presence}} in {{Computer-mediated Environments}}},
  author = {Waterworth, John and Waterworth, Eva},
  year = {2014},
  month = sep,
  pages = {32--45},
  publisher = {{De Gruyter Open}},
  url = {https://doi.org/10.2478/9783110409697.2},
  urldate = {2022-08-19},
  abstract = {This conceptual chapter outlines three stages in the development of interactive presence, and outlines some possibilities and challenges raised by each, and by their combination. The first stage, presence via altered embodiment, refers to the way technology allows us to experience the world with modified or enhanced senses. The second stage, via expanded embodiment, refers to technology pushing the envelope of the mental body in which one feels present, out beyond the physical body. Finally, distributed embodiment refers to how the sense of being present in the world can be separated from that of ownership of a particular body, through the development of new approaches to deploying the technologies of virtual realization. We suggest that presence is the yardstick of embodiment from an experiential perspective. If you cannot feel presence, you are not embodied in the world.},
  collaborator = {Riva, Giuseppe and Waterworth, John and Murray, Dianne},
  isbn = {978-3-11-040967-3},
  langid = {english},
  file = {Philosophy/Extended Cognition/Waterworth and Waterworth, 2014 - Altered, Expanded and Distributed Embodiment.pdf}
}

@article{weis2016,
  title = {{{SNARC}} (Spatial{\textendash}Numerical Association of Response Codes) Meets {{SPARC}} (Spatial{\textendash}Pitch Association of Response Codes): {{Automaticity}} and Interdependency in Compatibility Effects},
  shorttitle = {{{SNARC}} (Spatial{\textendash}Numerical Association of Response Codes) Meets {{SPARC}} (Spatial{\textendash}Pitch Association of Response Codes)},
  author = {Weis, Tina and Estner, Barbara and {van Leeuwen}, Cees and Lachmann, Thomas},
  year = {2016},
  month = jul,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {69},
  number = {7},
  pages = {1366--1383},
  issn = {1747-0218, 1747-0226},
  urldate = {2020-05-26},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/weis2016.md;Cognitive Science/Psychophysics/Weis et al., 2016 - SNARC (spatialâ€“numerical association of response codes) meets SPARC.pdf},
  url = {https://doi.org/10.1080/17470218.2015.1082142}
}

@article{weiser1991,
  title = {The {{Computer}} for the 21st {{Century}}},
  author = {Weiser, Mark},
  year = {1991},
  journal = {SCIENTIFIC AMERICAN},
  pages = {12},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/weiser1991.md;Human Computer Interaction/Miscellaneous/Weiser, 1991 - The Computer for the 21st Century.pdf}
}

@article{wellner1993,
  title = {Interacting with Paper on the {{DigitalDesk}}},
  author = {Wellner, Pierre},
  year = {1993},
  month = jul,
  journal = {Communications of the ACM},
  volume = {36},
  number = {7},
  pages = {87--96},
  issn = {00010782},
  urldate = {2020-01-10},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/wellner1993.md;Human Computer Interaction/Augmented Reality/Wellner, 1993 - Interacting with paper on the DigitalDesk.pdf},
  url = {https://doi.org/10.1145/159544.159630}
}

@article{wendt2017,
  title = {Perception of {{Spatial Sound Phenomena Created}} by the {{Icosahedral Loudspeaker}}},
  author = {Wendt, Florian and Sharma, Gerriet K. and Frank, Matthias and Zotter, Franz and H{\"o}ldrich, Robert},
  year = {2017},
  month = mar,
  journal = {Computer Music Journal},
  volume = {41},
  number = {1},
  pages = {76--88},
  issn = {0148-9267, 1531-5169},
  urldate = {2020-01-10},
  abstract = {The icosahedral loudspeaker (IKO) is able to project strongly focused sound beams into arbitrary directions. Incorporating artistic experience and psychoacoustic research, this article presents three listening experiments that provide evidence for a common, intersubjective perception of spatial sonic phenomena created by the IKO. The experiments are designed on the basis of a hierarchical model of spatiosonic phenomena that exhibit increasing complexity, ranging from a single static sonic object to combinations of multiple, partly moving objects. The results are promising and explore new compositional perspectives in spatial computer music.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/wendt2017.md;Arts & Humanities/Computational Art/Wendt et al., 2017 - Perception of Spatial Sound Phenomena Created by the Icosahedral Loudspeaker.pdf},
  url = {https://doi.org/10.1162/COMJ_a_00396}
}

@misc{wikipedia2018,
  title = {Autoethnography},
  author = {Wikipedia},
  year = {2018},
  month = apr,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Autoethnography&oldid=833892679},
  urldate = {2018-04-10},
  abstract = {Autoethnography is a form of qualitative research in which an author uses self-reflection and writing to explore their personal experience and connect this autobiographical story to wider cultural, political, and social meanings and understandings. Autoethnography is a self-reflective form of writing used across various disciplines such as communication studies, performance studies, education, English literature, anthropology, social work, sociology, history, psychology, marketing, business and educational administration, arts education and physiotherapy. According to Mar{\'e}chal (2010), "autoethnography is a form or method of research that involves self-observation and reflexive investigation in the context of ethnographic field work and writing" (p. 43). A well-known autoethnographer, Carolyn Ellis (2004) defines it as "research, writing, story, and method that connect the autobiographical and personal to the cultural, social, and political" (p. xix). However, it is not easy to reach a consensus on the term's definition. For instance, in the 1970s, autoethnography was more narrowly defined as "insider ethnography," referring to studies of the (culture of) a group of which the researcher is a member (Hayano, 1979). Nowadays, however, as Ellingson and Ellis (2008) point out, "the meanings and applications of autoethnography have evolved in a manner that makes precise definition difficult" (p. 449). According to Adams, Jones, and Ellis in Autoethnography: Understanding Qualitative Research, "Autoethnography is a research method that: Uses a researcher's personal experience to describe and critique cultural beliefs, practices, and experiences. Acknowledges and values a researcher's relationships with others. . . . Shows 'people in the process of figuring out what to do, how to live, and the meaning of their struggles'" (Adams, 2015). "Social life is messy, uncertain, and emotional. If our desire to research social life, then we must embrace a research method that, to the best of its/our ability, acknowledges and accommodates mess and chaos, uncertainty and emotion" (Adams, 2015).},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english}
}

@misc{wikipedia2020,
  title = {Inertial Measurement Unit},
  author = {Wikipedia},
  year = {2020},
  month = may,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Inertial_measurement_unit&oldid=958821399},
  urldate = {2020-05-25},
  abstract = {An inertial measurement unit (IMU) is an electronic device that measures and reports a body's specific force, angular rate, and sometimes the orientation of the body, using a combination of accelerometers, gyroscopes, and sometimes magnetometers. IMUs are typically used to maneuver aircraft (an attitude and heading reference system), including unmanned aerial vehicles (UAVs), among many others, and spacecraft, including satellites and landers. Recent developments allow for the production of IMU-enabled GPS devices. An IMU allows a GPS receiver to work when GPS-signals are unavailable, such as in tunnels, inside buildings, or when electronic interference is present.  A wireless IMU is known as a WIMU.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  file = {../../../../../Zotero/storage/C8BZWMSF/index.html}
}

@misc{wikipedia2020a,
  title = {Ambisonics},
  author = {Wikipedia},
  year = {2020},
  month = apr,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Ambisonics&oldid=953930554},
  urldate = {2020-05-25},
  abstract = {Ambisonics is a full-sphere surround sound format: in addition to the horizontal plane, it covers sound sources above and below the listener.Unlike other multichannel surround formats, its transmission channels do not carry speaker signals. Instead, they contain a speaker-independent representation of a sound field called B-format, which is then decoded to the listener's speaker setup. This extra step allows the producer to think in terms of source directions rather than loudspeaker positions, and offers the listener a considerable degree of flexibility as to the layout and number of speakers used for playback. Ambisonics was developed in the UK in the 1970s under the auspices of the British National Research Development Corporation. Despite its solid technical foundation and many advantages, Ambisonics had not until recently been a commercial success, and survived only in niche applications and among recording enthusiasts. With the easy availability of powerful digital signal processing (as opposed to the expensive and error-prone analog circuitry that had to be used during its early years) and the successful market introduction of home theatre surround sound systems since the 1990s, interest in Ambisonics among recording engineers, sound designers, composers, media companies, broadcasters and researchers has returned and continues to increase.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  file = {../../../../../Zotero/storage/82WQ9UGX/index.html}
}

@book{wikstrom2009,
  title = {The Music Industry: Music in the Cloud},
  shorttitle = {The Music Industry},
  author = {Wikstr{\"o}m, Patrik},
  year = {2009},
  series = {Digital Media and Society Series},
  publisher = {{Polity}},
  address = {{Cambridge ; Malden, MA}},
  isbn = {978-0-7456-4389-2 978-0-7456-4390-8},
  lccn = {ML3790 .W52 2009},
  keywords = {History and criticism,Music,Music trade,Musikwirtschaft,Neue Medien,Popular music,Social aspects},
  file = {../../../../../../../../C\:\\Users\\Sam Bilbow\\OneDrive\\Literature\\Arts & Humanities\\Musicology\\WikstrÃ¶m, 2009 - The music industry.pdf;../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/wikstrom2009.md}
}

@incollection{willans2016,
  title = {Enactive {{Emotion}} and {{Presence}} in {{Virtual Environments}}},
  booktitle = {Emotions, {{Technology}}, and {{Behaviors}}},
  author = {Willans, Tom and Rivers, Sue and {Prasolova-F{\o}rland}, Ekaterina},
  year = {2016},
  pages = {181--210},
  publisher = {{Elsevier}},
  url = {https://doi.org/10.1016/B978-0-12-801873-6.00010-8},
  urldate = {2022-08-18},
  isbn = {978-0-12-801873-6},
  langid = {english},
  file = {Philosophy/Extended Cognition/Willans et al., 2016 - Enactive Emotion and Presence in Virtual Environments.pdf}
}

@misc{winer2016,
  title = {{{ESP32 Arduino Library}}},
  author = {Winer, Kris},
  year = {2016},
  url = {https://github.com/kriswiner/ESP32},
  urldate = {2020-05-20},
  abstract = {Arduino sketches for the ESP32. Contribute to kriswiner/ESP32 development by creating an account on GitHub.},
  keywords = {esp32}
}

@article{xue2019,
  title = {Researcher Introspection for Experience-Driven Design Research},
  author = {Xue, Haian and Desmet, Pieter M.A.},
  year = {2019},
  month = jul,
  journal = {Design Studies},
  volume = {63},
  pages = {37--64},
  issn = {0142694X},
  urldate = {2020-03-17},
  abstract = {We challenge the unquestioning pursuit of the appearance of objectivity and ingrained designer-user dualism in human-centred design research and propose a resurrection of introspection as a valid approach to investigating subjective experiences. Through comparing epistemic perspectives and reviewing the histories of introspection in several disciplines, we liberate the research field of experience-driven design from a long-lasting doubt about and the disguised and unsystematic use of this method. To establish a foundation for the further development of introspective methods, we focus on its most controversial type (i.e. researcher introspection) and discuss its strengths and weaknesses, preconditions of use, diverse ways to practise for different suitable experiencedriven design research purposes, and useful techniques and tools. {\'O} 2019 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-ncnd/4.0/).},
  langid = {english},
  file = {Research Methods/Autobiographical Design/Xue and Desmet, 2019 - Researcher introspection for experience-driven design research.pdf},
  url = {https://doi.org/10.1016/j.destud.2019.03.001}
}

@inproceedings{yang2020,
  title = {Fast Synthesis of Perceptually Adequate Room Impulse Responses from Ultrasonic Measurements},
  booktitle = {Proceedings of the 15th International Conference on Audio Mostly},
  author = {Yang, Jing and Pfreundtner, Felix and Barde, Amit and Heutschi, Kurt and S{\"o}r{\"o}s, G{\'a}bor},
  year = {2020},
  series = {{{AM}} '20},
  pages = {53--60},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  abstract = {Audio augmented reality (AAR) applications need to render virtual sounds with acoustic effects that match the real environment of the user to create an experience with strong sense of presence. This audio rendering process can be formulated as the convolution between the dry sound signal and the room impulse response (IR) that covers the audible frequency spectrum (20Hz - 20kHz). While the IR can be pre-calculated in virtual reality (VR) scenes, AR applications need to continuously estimate it. We propose a method to synthesize room IRs based on the corresponding IR in the ultrasound frequency band (20kHz - 22kHz) and two parameters we propose in this paper: slope factor and RT60 ratio. We assess the synthesized IRs using common acoustic metrics and we conducted a user study to evaluate participants' perceptual similarity between the sounds rendered with the synthesized IR and with the recorded IR in different rooms. The method requires only a small number of pre-measurements in the environment to determine the synthesis parameters and it uses only inaudible signals at runtime for fast IR synthesis, making it well suited for interactive AAR applications.},
  isbn = {978-1-4503-7563-4},
  keywords = {auditory perception,augmented reality,room acoustic effects,room impulse response,ultrasound},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/yang2020.md;Human Computer Interaction/Augmented Reality/Yang et al., 2020 - Fast synthesis of perceptually adequate room impulse responses from ultrasonic.pdf},
  url = {https://doi.org/10.1145/3411109.3412300}
}

@misc{zamborlin2018,
  title = {An Entire Public Square in {{Milan}} Transformed into a Giant Musical Instrument},
  author = {Zamborlin, Bruno},
  year = {2018},
  month = may,
  url = {https://www.youtube.com/watch?v=DJ3h6J0CNZA},
  urldate = {2022-11-03}
}

@inproceedings{zappi2011,
  title = {Design and {{Evaluation}} of a {{Hybrid Reality Performance}}},
  booktitle = {New {{Interfaces}} for {{Musical Expression}}},
  author = {Zappi, Victor and Mazzanti, D. and Brogni, A. and Caldwell, D.},
  year = {2011},
  url = {https://www.semanticscholar.org/paper/Design-and-Evaluation-of-a-Hybrid-Reality-Zappi-Mazzanti/7d66a297f3077658440c4de5168a6e24886e6978},
  urldate = {2022-12-22},
  abstract = {In this paper we introduce a multimodal platform for Hybrid Reality live performances: by means of non-invasive Virtual Reality technology, we developed a system to present artists and interactive virtual objects in audio/visual choreographies on the same real stage. These choreographies could include spectators too, providing them with the possibility to directly modify the scene and its audio/visual features. We also introduce the rst interactive performance staged with this technology, in which an electronic musician played live ve tracks manipulating the 3D projected visuals. As questionnaires have been distributed after the show, in the last part of this work we discuss the analysis of collected data, underlining positive and negative aspects of the proposed experience. This paper belongs together with a performance proposal called Dissonance, in which two performers exploit the platform to create a progressive soundtrack along with the exploration of an interactive virtual environment.},
  file = {Human Computer Interaction/Augmented Reality/Zappi et al., 2011 - Design and Evaluation of a Hybrid Reality Performance.pdf}
}

@incollection{zappi2023,
  title = {From the {{Lab}} to the {{Stage}}: {{Practical Considerations}} on {{Designing Performances}} with {{Immersive Virtual Musical Instruments}}},
  shorttitle = {From the {{Lab}} to the {{Stage}}},
  booktitle = {Sonic {{Interactions}} in {{Virtual Environments}}},
  author = {Zappi, Victor and Mazzanti, Dario and Berthaut, Florent},
  editor = {Geronazzo, Michele and Serafin, Stefania},
  year = {2023},
  pages = {383--424},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  urldate = {2024-01-29},
  abstract = {Abstract                            Immersive virtual musical instruments (IVMIs) lie at the intersection between music technology and virtual reality. Being both digital musical instruments (DMIs) and elements of virtual environments (VEs), IVMIs have the potential to transport the musician into a world of imagination and unprecedented musical expression. But when the final aim is to perform live on stage, the employment of these technologies is anything but straightforward, for sharing the virtual musical experience with the audience gets quite arduous. In this chapter, we assess in detail the several technical and conceptual challenges linked to the composition of IVMI performances on stage, i.e., their               scenography               , providing a new critical perspective on IVMI performance and design. We first propose a set of dimensions meant to analyse IVMI scenographies, as well as to evaluate their compatibility with different instrument metaphors and performance rationales. Such dimensions are built from the specifics and constraints of DMIs and VEs; they include the level of immersion of musicians and spectators and provide an insight into the interaction techniques afforded by 3D user interfaces in the context of musical expression. We then analyse a number of existing IVMIs and stage setups, and finally suggest new ones, with the aim to facilitate the design of future immersive performances.},
  isbn = {978-3-031-04020-7 978-3-031-04021-4},
  langid = {english},
  file = {Human Computer Interaction/Virtual Reality/Zappi et al., 2023 - From the Lab to the Stage.pdf},
  url = {https://doi.org/10.1007/978-3-031-04021-4_13}
}

@article{zavota2016,
  title = {Expanding the {{Extended Mind}}: {{Merleau-Ponty}}'s {{Late Ontology}} as {{Radical Enactive Cognition}}},
  shorttitle = {Expanding the {{Extended Mind}}},
  author = {Zavota, Gina},
  year = {2016},
  journal = {Essays in Philosophy},
  volume = {17},
  number = {2},
  pages = {94--124},
  issn = {15260569},
  urldate = {2021-06-11},
  abstract = {In this essay, I argue that the late ontology of Maurice MerleauPonty, in particular the system he began to develop in The Visible and the Invisible, can be conceived of as a form of Radical Enactive Cognition, as described by Hutto and Myin in Radicalizing Enactivism. I will begin by discussing Clark and Chalmers' extended mind hypothesis, as well as the enactive view of consciousness proposed by Varela, Thompson, and Rosch in The Embodied Mind. However, neither Clark and Chalmers' extended mind hypothesis nor the enactive view of consciousness advanced by Varela et al. are radical enough to fully capture Merleau-Ponty's late ontology. Inasmuch as Hutto and Myin's formulation combines features of the extended mind thesis and enactivism, and expresses both in a sufficiently radical fashion, it overcomes the deficits of both theories and can serve as a translation, so to speak, of MerleauPonty's ``ontology of the flesh'' into contemporary terms. In particular, their formulation makes explicit several central aspects of his theory: the intimate, mutually constitutive relationship between perceiver and perceived world, the equal weight given to the contributions of perceiver and world within this relationship, and the displacement of representational content from its central position in the understanding of consciousness. It is thus the ideal vehicle for demonstrating some perhaps unexpected ways in which Merleau-Ponty's thought is compatible with contemporary conversations concerning the nature of mind.},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/zavota2016.md;Philosophy/Extended Cognition/Zavota, 2016 - Expanding the Extended Mind.pdf},
  url = {https://doi.org/10.7710/1526-0569.1558}
}

@inproceedings{zellerbach2022,
  title = {A Framework for the Design and Analysis of Mixed Reality Musical Instruments},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  author = {Zellerbach, Karitta Christina and Roberts, Charlie},
  year = {2022},
  month = jun,
  address = {{The University of Auckland, New Zealand}},
  issn = {2220-4806},
  abstract = {In the context of immersive sonic interaction, Virtual Reality Musical Instruments have had the relative majority of attention thus far, fueled by the increasing availability of affordable technology. Recent advances in Mixed Reality (MR) experiences have provided the means for a new wave of research that goes beyond Virtual Reality. In this paper, we explore the taxonomy of Extended Reality systems, establishing our own notion of MR. From this, we propose a new classification of Virtual Musical Instrument, known as a Mixed Reality Musical Instrument (MRMI). We define this system as an embodied interface for expressive musical performance, characterized by the relationships between the performer, the virtual, and the physical environment. After a review of existing literature concerning the evaluation of immersive musical instruments and the affordances of MR systems, we offer a new framework based on three dimensions to support the design and analysis of MRMIs. We illustrate its use with application to existing works.},
  articleno = {29},
  url = {https://doi.org/10.21428/92fbeb44.b2a44bc9}
}

@article{zeltzer1992,
  title = {Autonomy, {{Interaction}}, and {{Presence}}},
  author = {Zeltzer, David},
  year = {1992},
  month = jan,
  journal = {Presence: Teleoperators and Virtual Environments},
  volume = {1},
  number = {1},
  pages = {127--132},
  issn = {1054-7460},
  urldate = {2021-02-12},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/zeltzer1992.md;Human Computer Interaction/Augmented Reality/Zeltzer, 1992 - Autonomy, Interaction, and Presence.pdf},
  url = {https://doi.org/10.1162/pres.1992.1.1.127}
}

@inproceedings{zhou2008,
  title = {Trends in Augmented Reality Tracking, Interaction and Display: {{A}} Review of Ten Years of {{ISMAR}}},
  shorttitle = {Trends in Augmented Reality Tracking, Interaction and Display},
  booktitle = {2008 7th {{IEEE}}/{{ACM International Symposium}} on {{Mixed}} and {{Augmented Reality}}},
  author = {Zhou, Feng and Duh, Henry Been-Lirn and Billinghurst, Mark},
  year = {2008},
  month = sep,
  pages = {193--202},
  publisher = {{IEEE}},
  address = {{Cambridge, UK}},
  urldate = {2020-05-25},
  abstract = {Although Augmented Reality technology was first developed over forty years ago, there has been little survey work giving an overview of recent research in the field. This paper reviews the tenyear development of the work presented at the ISMAR conference and its predecessors with a particular focus on tracking, interaction and display research. It provides a roadmap for future augmented reality research which will be of great value to this relatively young field, and also for helping researchers decide which topics should be explored when they are beginning their own studies in the area.},
  isbn = {978-1-4244-2840-3},
  langid = {english},
  file = {../../../../../../../Users/sambilbow/Documents/Vault/40 Research/42 Literature/42.04 Source Notes/zhou2008.md;Human Computer Interaction/Augmented Reality/Zhou et al., 2008 - Trends in augmented reality tracking, interaction and display.pdf},
  url = {https://doi.org/10.1109/ISMAR.2008.4637362}
}

@inproceedings{zotero-1276,
  type = {Inproceedings}
}

@book{zuboff2019,
  title = {The {{Age}} of {{Surveillance Capitalism}}: {{The Fight}} for a {{Human Future}} at the {{New Frontier}} of {{Power}}},
  shorttitle = {The {{Age}} of {{Surveillance Capitalism}}},
  author = {Zuboff, Shoshana},
  year = {2019},
  publisher = {{Profile Books}},
  address = {{London}},
  isbn = {978-1-78125-684-8 978-1-78125-685-5},
  langid = {english},
  lccn = {306.3}
}
