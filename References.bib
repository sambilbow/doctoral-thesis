
@book{merleau-ponty1945,
	title = {Phenomenology of {Perception}},
	publisher = {Routledge},
	author = {Merleau-Ponty, Maurice},
	year = {1945},
}

@inproceedings{neustaedter2012,
	address = {Newcastle Upon Tyne, United Kingdom},
	title = {Autobiographical design in {HCI} research: designing and learning through use-it-yourself},
	doi = {10.1145/2317956.2318034},
	abstract = {Designing a system with yourself as a target user and evaluating the design through your own self-usage is commonly considered a questionable approach in HCI research. Perhaps for this reason, HCI research including extensive self-usage of a design is underdocumented. Yet such self-usage does happen and many researchers have found great value in the lessons learned from it. Our goal in this paper is to bring these hidden practices to light and offer guidelines for how HCI researchers can usefully engage in what we term ‘autobiographical design’—design research drawing on extensive, genuine usage by those creating or building a system. Through interviews with HCI experts who have engaged in variations of autobiographical design, we draw out the possibilities and limitations of autobiographical design methods and lay out best practices for its use as an HCI research method.},
	language = {en},
	booktitle = {{DIS} '12: {Proceedings} of the {Designing} {Interactive} {Systems} {Conference}},
	author = {Neustaedter, Carman and Sengers, Phoebe},
	year = {2012},
	pages = {10},
}

@incollection{gunzel2019,
	address = {Bielefeld, Germany},
	edition = {1},
	series = {Edition {Medienwissenschaft}},
	title = {What {Do} {They} {Represent}? {Computer} {Games} as {Spatial} {Concepts}},
	volume = {63},
	isbn = {978-3-8376-4730-3 978-3-8394-4730-7},
	url = {https://www.transcript-open.de/isbn/4730},
	abstract = {Where do computer games »happen«? The articles collected in this pioneering volume explore the categories of »space«, »place« and »territory« featuring in most general theories of space to lay the groundwork for the study of spatiality in games. Shifting the focus away from earlier debates on, e.g., the narrative nature of games, this collection proposes, instead, that thorough attention be given to the tension between experienced spaces and narrated places as well as to the mapping of both of these.},
	language = {en},
	urldate = {2022-09-30},
	booktitle = {Ludotopia: {Spaces}, {Places} and {Territories} in {Computer} {Games}},
	publisher = {transcript Verlag},
	author = {Günzel, Stephan},
	editor = {Aarseth, Espen and Günzel, Stephan},
	month = sep,
	year = {2019},
	doi = {10.14361/9783839447307},
}

@book{ross1999,
	address = {London},
	series = {Electronic libraries programme studies {P}},
	title = {Digital archaeology: rescuing neglected and damaged data resources: a {JISC}/{NPO} study with the {Electronic} {Libraries} ({eLib}) {Programme} on the preservation of electronic materials},
	isbn = {978-1-900508-51-3},
	shorttitle = {Digital archaeology},
	language = {en},
	number = {2},
	publisher = {Library Information Technology Centre},
	author = {Ross, Seamus and Gow, Ann},
	year = {1999},
}

@book{ernst2016,
	address = {Amsterdam},
	series = {Recursions: theories of media, materiality, and cultural techniques},
	title = {Sonic time machines: explicit sound, sirenic voices, and implicit sonicity},
	isbn = {978-90-8964-949-2},
	shorttitle = {Sonic time machines},
	publisher = {Amsterdam University Press},
	author = {Ernst, Wolfgang},
	year = {2016},
	keywords = {Music, Philosophy and aesthetics, Sound (Philosophy), Sound in mass media},
}

@misc{berweck2012,
	title = {It {Worked} {Yesterday}},
	url = {http://eprints.hud.ac.uk/id/eprint/17540/1/sberweckfinalthesis.pdf},
	urldate = {2018-04-10},
	author = {Berweck, Sebastian},
	year = {2012},
}

@book{huber2013,
	title = {Modern {Recording} {Techniques}},
	isbn = {978-1-136-11782-4},
	abstract = {As the most popular and authoritative guide to recording Modern Recording Techniques provides everything you need to master the tools and day to day practice of music recording and production. From room acoustics and running a session to mic placement and designing a studio Modern Recording Techniques will give you a really good grounding in the theory and industry practice. Expanded to include the latest digital audio technology the 7th edition now includes sections on podcasting, new surround sound formats and HD and audio.If you are just starting out or looking for a step up in industry, Modern Recording Techniques provides an in depth excellent read- the must have book},
	language = {en},
	publisher = {CRC Press},
	author = {Huber, David Miles and Runstein, Robert E.},
	month = aug,
	year = {2013},
	keywords = {Computers / Digital Media / Audio, Music / General, Music / Recording \& Reproduction, TECHNOLOGY \& ENGINEERING / Mechanical, Technology \& Engineering / Acoustics \& Sound},
}

@misc{parikka2010,
	title = {What is {Media} {Archaeology}?},
	shorttitle = {What is {Media} {Archaeology}?},
	url = {http://mediacartographies.blogspot.com/2010/10/what-is-media-archaeology-beta.html},
	urldate = {2018-04-13},
	author = {Parikka, Jussi},
	month = oct,
	year = {2010},
}

@article{roy2016,
	title = {Inside sonicity},
	volume = {2},
	issn = {2055-1940},
	url = {https://doi.org/10.1080/20551940.2016.1245990},
	doi = {10.1080/20551940.2016.1245990},
	number = {2},
	urldate = {2018-04-13},
	journal = {Sound Studies},
	author = {Roy, Elodie A.},
	month = jul,
	year = {2016},
	pages = {192--194},
}

@misc{wikipedia2018,
	title = {Autoethnography},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Autoethnography&oldid=833892679},
	abstract = {Autoethnography is a form of qualitative research in which an author uses self-reflection and writing to explore their personal experience and connect this autobiographical story to wider cultural, political, and social meanings and understandings. Autoethnography is a self-reflective form of writing used across various disciplines such as communication studies, performance studies, education, English literature, anthropology, social work, sociology, history, psychology, marketing, business and educational administration, arts education and physiotherapy.
According to Maréchal (2010), "autoethnography is a form or method of research that involves self-observation and reflexive investigation in the context of ethnographic field work and writing" (p. 43). A well-known autoethnographer, Carolyn Ellis (2004) defines it as "research, writing, story, and method that connect the autobiographical and personal to the cultural, social, and political" (p. xix). However, it is not easy to reach a consensus on the term's definition. For instance, in the 1970s, autoethnography was more narrowly defined as "insider ethnography," referring to studies of the (culture of) a group of which the researcher is a member (Hayano, 1979). Nowadays, however, as Ellingson and Ellis (2008) point out, "the meanings and applications of autoethnography have evolved in a manner that makes precise definition difficult" (p. 449).
According to Adams, Jones, and Ellis in Autoethnography: Understanding Qualitative Research, "Autoethnography is a research method that: Uses a researcher's personal experience to describe and critique cultural beliefs, practices, and experiences. Acknowledges and values a researcher's relationships with others. . . . Shows 'people in the process of figuring out what to do, how to live, and the meaning of their struggles'" (Adams, 2015). "Social life is messy, uncertain, and emotional. If our desire to research social life, then we must embrace a research method that, to the best of its/our ability, acknowledges and accommodates mess and chaos, uncertainty and emotion" (Adams, 2015).},
	language = {en},
	urldate = {2018-04-10},
	journal = {Wikipedia},
	author = {Wikipedia},
	month = apr,
	year = {2018},
}

@misc{cornford2016,
	title = {Review of {Wolgang} {Ernst}'s {Sonic} {Time} {Machines}},
	url = {https://www.theoryculturesociety.org/review-wolgang-ernsts-sonic-time-machines-stephen-cornford/},
	abstract = {Review of Wolgang Ernst, Sonic Time Machines (Amsterdam University Press, 2016), 184 pages, €79.00.   Reviewed by Stephen Cornford   Book details: http://en.aup.nl/books/9789089649492-sonic-time-machines.html         Sonic Time Machines is Wolfgang Ernst’s first book to be published directly in},
	language = {en-US},
	urldate = {2018-04-10},
	journal = {Theory, Culture \& Society},
	author = {Cornford, Stephen},
	month = oct,
	year = {2016},
}

@book{negus2009,
	address = {Cambridge},
	edition = {Reprinted},
	title = {Popular music in theory: an introduction},
	isbn = {978-0-7456-1318-5 978-0-7456-1317-8},
	shorttitle = {Popular music in theory},
	language = {eng},
	publisher = {Polity Press},
	author = {Negus, Keith},
	year = {2009},
}

@misc{musgrave1987,
	title = {Narcissus},
	copyright = {Music Sales Classical},
	url = {http://www.musicsalesclassical.com/composer/work/11633},
	urldate = {2018-04-13},
	journal = {Music Sales Classical},
	author = {Musgrave, Thea},
	year = {1987},
}

@misc{musgrave1993,
	title = {Orfeo {III}},
	copyright = {Music Sales Classical},
	url = {http://www.musicsalesclassical.com/composer/work/1098/8437#},
	urldate = {2018-04-13},
	journal = {Music Sales Classical},
	author = {Musgrave, Thea},
	year = {1993},
}

@misc{musgrave1975,
	title = {Orfeo {II}: {An} {Improvisation} on a {Theme}},
	copyright = {Music Sales Classical},
	url = {http://www.musicsalesclassical.com/composer/work/8436},
	urldate = {2018-04-13},
	journal = {Music Sales Classical},
	author = {Musgrave, Thea},
	year = {1975},
}

@misc{musgrave1975a,
	title = {Orfeo {I}},
	copyright = {Music Sales Classical},
	url = {http://www.musicsalesclassical.com/composer/work/8432},
	urldate = {2018-04-13},
	journal = {Music Sales Classical},
	author = {Musgrave, Thea},
	year = {1975},
}

@article{hennion1983,
	title = {The production of success: an anti-musicology of the pop song},
	volume = {3},
	issn = {0261-1430, 1474-0095},
	shorttitle = {The production of success},
	language = {en},
	journal = {Popular Music},
	author = {Hennion, Antoine},
	month = jan,
	year = {1983},
	pages = {159},
}

@book{moorefield2010,
	address = {Cambridge, Mass},
	edition = {1st MIT Press pbk. ed},
	title = {The producer as composer: shaping the sounds of popular music},
	isbn = {978-0-262-51405-7},
	shorttitle = {The producer as composer},
	publisher = {MIT Press},
	author = {Moorefield, Virgil},
	year = {2010},
	keywords = {Analysis, appreciation, Popular music, Production and direction History, Sound recordings},
}

@book{madinger2000,
	address = {Chesterfield, Missouri},
	title = {Eight arms to hold you: the solo {Beatles} compendium},
	isbn = {978-0-615-11724-9},
	shorttitle = {Eight arms to hold you},
	language = {English},
	publisher = {44.1 Productions},
	author = {Madinger, Chip and Easter, Mark},
	year = {2000},
}

@incollection{blake2009,
	address = {Cambridge},
	title = {Recording practices and the role of the producer},
	isbn = {978-1-139-00268-4},
	url = {https://www.cambridge.org/core/product/identifier/CBO9781139002684A013/type/book_part},
	urldate = {2019-05-15},
	booktitle = {The {Cambridge} {Companion} to {Recorded} {Music}},
	publisher = {Cambridge University Press},
	author = {Blake, Andrew},
	editor = {Cook, Nicholas and Clarke, Eric and Leech-Wilkinson, Daniel and Rink, John},
	year = {2009},
	pages = {36--53},
}

@article{walzer2017,
	title = {Independent music production: how individuality, technology and creative entrepreneurship influence contemporary music industry practices},
	volume = {10},
	issn = {1751-0694, 1751-0708},
	shorttitle = {Independent music production},
	url = {https://www.tandfonline.com/doi/full/10.1080/17510694.2016.1247626},
	doi = {10.1080/17510694.2016.1247626},
	language = {en},
	number = {1},
	urldate = {2019-05-15},
	journal = {Creative Industries Journal},
	author = {Walzer, Daniel A.},
	month = jan,
	year = {2017},
	pages = {21--39},
}

@article{barde2016,
	title = {Attention {Redirection} {Using} {Binaurally} {Spatialised} {Cues} {Delivered} {Over} a {Bone} {Conduction} {Headset}},
	volume = {60},
	issn = {1541-9312},
	url = {http://journals.sagepub.com/doi/10.1177/1541931213601352},
	doi = {10.1177/1541931213601352},
	language = {en},
	number = {1},
	urldate = {2020-01-10},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Barde, Amit and Ward, Matt and Helton, William S. and Billinghurst, Mark and Lee, Gun},
	month = sep,
	year = {2016},
	pages = {1534--1538},
}

@book{deleuze1988,
	address = {London},
	title = {A thousand plateaus: capitalism and schizophrenia},
	isbn = {978-0-485-12058-5 978-0-485-11335-8},
	shorttitle = {A thousand plateaus},
	publisher = {Athlone Press},
	author = {Deleuze, Gilles and Guattari, Félix},
	year = {1988},
	keywords = {Philosophy},
}

@book{salen2003,
	address = {Cambridge, Mass},
	title = {Rules of play: game design fundamentals},
	isbn = {978-0-262-24045-1},
	shorttitle = {Rules of play},
	publisher = {MIT Press},
	author = {Salen, Katie and Zimmerman, Eric},
	year = {2003},
	keywords = {Computer games, Design, Programming},
}

@book{magnusson2019,
	address = {New York, NY},
	title = {Sonic writing: technologies of material, symbolic and signal inscriptions},
	isbn = {978-1-5013-1385-1 978-1-5013-1386-8 978-1-5013-1389-9},
	shorttitle = {Sonic writing},
	publisher = {Bloomsbury Academic},
	author = {Magnusson, Thor},
	year = {2019},
	keywords = {Music, Musical instruments, Musical notation, Philosophy and aesthetics, Recording and reproducing Philosophy, Sound},
}

@book{giddens1984,
	address = {Berkeley},
	title = {The constitution of society: outline of the theory of structuration},
	isbn = {978-0-520-05292-5},
	shorttitle = {The constitution of society},
	publisher = {University of California Press},
	author = {Giddens, Anthony},
	year = {1984},
	keywords = {Political sociology, Social institutions, Social structure, Sociology},
}

@article{krueger1991,
	title = {Artificial reality: {Past} and future},
	shorttitle = {Artificial reality},
	journal = {Virtual Reality: Theory, Practiсe and Promise/Ed. SK Helsel, JP Roth.–Westport, London: Meckler},
	author = {Krueger, Myron W.},
	year = {1991},
	pages = {19--26},
}

@book{latour2007,
	address = {Oxford},
	series = {Clarendon lectures in management studies},
	title = {Reassembling the social: an introduction to {Actor}-{Network}-{Theory}},
	isbn = {978-0-19-925605-1 978-0-19-925604-4},
	shorttitle = {Reassembling the social},
	language = {eng},
	publisher = {Oxford Univ. Press},
	author = {Latour, Bruno},
	year = {2007},
}

@book{kwastek2013,
	title = {Aesthetics of {Interaction} in {Digital} {Art}},
	isbn = {0-262-31722-2},
	publisher = {MIT Press},
	author = {Kwastek, Katja},
	year = {2013},
}

@book{latour2003,
	address = {Cambridge, Mass},
	edition = {11. print},
	title = {Science in action: how to follow scientists and engineers through society},
	isbn = {978-0-674-79291-3},
	shorttitle = {Science in action},
	language = {eng},
	publisher = {Harvard Univ. Press},
	author = {Latour, Bruno},
	year = {2003},
}

@article{feingold1995,
	title = {{OU}: {Interactivity} as {Divination} as {Vending} {Machine}},
	volume = {28},
	issn = {0024094X},
	shorttitle = {{OU}},
	url = {https://www.jstor.org/stable/1576224?origin=crossref},
	doi = {10.2307/1576224},
	language = {en},
	number = {5},
	urldate = {2019-08-17},
	journal = {Leonardo},
	author = {Feingold, Ken},
	year = {1995},
	pages = {399},
}

@article{nystrom2011,
	title = {Textons and the {Propagation} of {Space} in {Acousmatic} {Music}},
	volume = {16},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S1355771810000397/type/journal_article},
	doi = {10.1017/S1355771810000397},
	abstract = {The concepts introduced by Smalley in the context of space-form (2007) have firmly put acousmatic music on a discourse of spatial exploration, holding much potential for the developing of aesthetics in new directions. This article approaches space from the low level of musical structure, with a multi-dimensional attitude to space-form, exploring
              spatial texture
              , a concept introduced by Smalley to describe the temporal formations of space in spectromorphology (1997). Spatial articulation is investigated in the context of granular-oriented textures, proposing a micro-spatial, perceptual morphology – the
              texton
              – as an aesthetic approach to acousmatic music. This follows Albert Bregman's speculation regarding equivalents to visual perception in texture, where the theory of textons was first developed by the neuroscientist Béla Julesz.
            
            The article discusses acousmatic textons, in terms of intrinsic properties, the way they propagate in time, and how they organise in distributions to form spatial textures. The emergent macroscopic qualities of textonal formations are also reflected upon in the introduction of a group of textural states, where source-bonded spaces and abstract musical thinking coalesce.},
	language = {en},
	number = {1},
	urldate = {2020-01-10},
	journal = {Organised Sound},
	author = {Nyström, Erik},
	month = apr,
	year = {2011},
	pages = {14--26},
}

@article{nystrom2015,
	title = {Low-{Level} {Topology} of {Spatial} {Texture}},
	abstract = {Low-level topology of spatial texture is here introduced as the basis of an aesthetic principle of sonic texture and spatial structure in electroacoustic music. The term spatial texture is used to describe aggregate sound structures which have a perceived three-dimensional spatial presence, specifically meaning that they occupy several areas or a stretch of horizontal perspectival space1 whilst also having a dynamic behaviour in spectral space2. The word topology refers to properties, qualities and structural features which remain distinct to a texture despite continuous change or recurrent incarnations in different specific shapes throughout a work.3 Ultimately, topology of spatial texture may be thought of as the core principle behind an attitude to music which considers all elements of structure to be part of an elastic spatiotemporal sound fabric. Rather than conceiving a work as built from time-finite morphological ‘objects’, this view emphasises processes of deformation, where any singular shapes may be seen as instances of textural topologies. The terminology presented here is intended as a contribution to discourse on spatiality in music, with special relevance to multichannel compositions.4 This article focuses on the low-level, internal, structure of a spatial texture.},
	language = {en},
	author = {Nyström, Erik},
	year = {2015},
	pages = {5},
}

@incollection{burnham1968,
	title = {System {Esthetics}},
	booktitle = {Artforum},
	author = {Burnham, Jack},
	year = {1968},
}

@phdthesis{sharma2018,
	title = {Composing with {Sculptural} {Sound} {Phenomena} in {Computer} {Music} {Dissertation}},
	language = {en},
	author = {Sharma, Gerriet K},
	year = {2018},
}

@book{bourriaud2009,
	address = {Dijon},
	edition = {Nachdr.},
	series = {Documents sur l'art},
	title = {Relational aesthetics},
	isbn = {978-2-84066-060-6},
	language = {eng},
	publisher = {Presses du réel},
	author = {Bourriaud, Nicolas},
	year = {2009},
}

@article{critchley2004,
	title = {Neural systems supporting interoceptive awareness},
	volume = {7},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/nn1176},
	doi = {10.1038/nn1176},
	language = {en},
	number = {2},
	urldate = {2020-01-10},
	journal = {Nature Neuroscience},
	author = {Critchley, Hugo D and Wiens, Stefan and Rotshtein, Pia and Öhman, Arne and Dolan, Raymond J},
	month = feb,
	year = {2004},
	pages = {189--195},
}

@article{varese1966,
	title = {The {Liberation} of {Sound}},
	volume = {5},
	issn = {00316016},
	url = {https://www.jstor.org/stable/832385?origin=crossref},
	doi = {10.2307/832385},
	language = {en},
	number = {1},
	urldate = {2020-01-10},
	journal = {Perspectives of New Music},
	author = {Varese, Edgard and Wen-chung, Chou},
	year = {1966},
	pages = {11},
}

@article{kania2006,
	title = {Making {Tracks}: {The} {Ontology} of {Rock} {Music}},
	volume = {64},
	issn = {0021-8529, 1542-6245},
	shorttitle = {Making {Tracks}},
	url = {http://doi.wiley.com/10.1111/j.1540-594X.2006.00219.x},
	doi = {10.1111/j.1540-594X.2006.00219.x},
	language = {en},
	number = {4},
	urldate = {2020-01-10},
	journal = {Journal of Aesthetics and Art Criticism},
	author = {Kania, Andrew},
	month = sep,
	year = {2006},
	pages = {401--414},
}

@phdthesis{nystrom2013,
	title = {Topology of {Spatial} {Texture} in the {Acousmatic} {Medium}},
	language = {en},
	school = {City University London},
	author = {Nyström, Erik},
	year = {2013},
}

@article{sharma2015,
	title = {Towards {Understanding} and {Verbalising} {Spatial} {Sound} {Phenomena} in {Electronic} {Music}},
	abstract = {How do we describe spatial sound phenomena in electronic music? This paper is concerned with the questions whether the electronic music of today takes into account the perception of its audience at all, whether it is necessary to have a typology of electronic music sounds at all, and how to ﬁnd or generate terms that could be helpful for composition and analysis of spatialized sound. Before going into detail about how to deal with spatial phenomena, it is valuable to review the main concepts of verbalization of sound from the last 100 years of sound-based music. Following this, approaches and methodologies are introduced to develop a speciﬁc terminology for a certain way of spatial sound projection within the framework of the artistic research project ‘Orchestrating Space by Icosahedral Loudspeaker’ (OSIL). By this we intent to encourage the aesthetic discussion about spatial sound composition and therefore enlarge the compositional contingencies of this art.},
	language = {en},
	author = {Sharma, Gerriet K and Frank, Matthias and Zotter, Franz},
	year = {2015},
}

@article{smalley2007,
	title = {Space-form and the acousmatic image},
	volume = {12},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S1355771807001665/type/journal_article},
	doi = {10.1017/S1355771807001665},
	abstract = {Abstract
            The analytical discussion of acousmatic music can benefit from being based on spatial concepts, and this article aims to provide a framework for investigation. A personal experience of soundscape listening is the starting point, and uncovers basic ideas relating to the disposition and behaviour of sounding content, and listening strategy. This enables the opening out of the discussion to include source-bonded sounds in general, giving particular consideration to how experience of sense modes other than the aural are implicated in our understanding of space, and in acousmatic listening. Attention then shifts to a source-bonded spatial model based on the production of space by the gestural activity of music performance, prior to focusing in more detail on acousmatic music, initially by delving into spectral space, where ideas about gravitation and diagonal forces are germane. This leads to concepts central to the structuring of perspectival space in relation to the vantage point of the listener. The final section considers a methodology for space-form investigation.},
	language = {en},
	number = {1},
	urldate = {2020-01-10},
	journal = {Organised Sound},
	author = {Smalley, Denis},
	month = apr,
	year = {2007},
	pages = {35--58},
}

@article{kiefer2019,
	title = {Sample-level sound synthesis with recurrent neural networks and conceptors},
	volume = {5},
	issn = {2376-5992},
	url = {https://peerj.com/articles/cs-205},
	doi = {10.7717/peerj-cs.205},
	abstract = {Conceptors are a recent development in the field of reservoir computing; they can be used to influence the dynamics of recurrent neural networks (RNNs), enabling generation of arbitrary patterns based on training data. Conceptors allow interpolation and extrapolation between patterns, and also provide a system of boolean logic for combining patterns together. Generation and manipulation of arbitrary patterns using conceptors has significant potential as a sound synthesis method for applications in computer music but has yet to be explored. Conceptors are untested with the generation of multi-timbre audio patterns, and little testing has been done on scalability to longer patterns required for audio. A novel method of sound synthesis based on conceptors is introduced. Conceptular Synthesis is based on granular synthesis; sets of conceptors are trained to recall varying patterns from a single RNN, then a runtime mechanism switches between them, generating short patterns which are recombined into a longer sound. The quality of sound resynthesis using this technique is experimentally evaluated. Conceptor models are shown to resynthesise audio with a comparable quality to a close equivalent technique using echo state networks with stored patterns and output feedback. Conceptor models are also shown to excel in their malleability and potential for creative sound manipulation, in comparison to echo state network models which tend to fail when the same manipulations are applied. Examples are given demonstrating creative sonic possibilities, by exploiting conceptor pattern morphing, boolean conceptor logic and manipulation of RNN dynamics.},
	language = {en},
	urldate = {2020-01-10},
	journal = {PeerJ Computer Science},
	author = {Kiefer, Chris},
	year = {2019},
	pages = {e205},
}

@article{discipio2003,
	title = {'{Sound} is the interface': from interactive to ecosystemic signal processing},
	volume = {8},
	issn = {1355-7718, 1469-8153},
	shorttitle = {‘{Sound} is the interface’},
	url = {https://www.cambridge.org/core/product/identifier/S1355771803000244/type/journal_article},
	doi = {10.1017/S1355771803000244},
	abstract = {This paper takes a systemic perspective on interactive signal processing and introduces the author's
              Audible Eco-Systemic Interface
              (AESI) project. It starts with a discussion of the paradigm of ‘interaction’ in existing computer music and live electronics approaches, and develops following bio-cybernetic principles such as ‘system/ambience coupling’, ‘noise’, and ‘self-organisation’. Central to the paper is an understanding of ‘interaction’ as a network of interdependencies among system components, and as a means for dynamical behaviour to emerge upon the contact of an autonomous system (e.g. a DSP unit) with the external environment (room or else hosting the performance). The author describes the design philosophy in his current work with the AESI (whose DSP component was implemented as a signal patch in K
              YMA
              5.2), touching on compositional implications (not only live electronics situations, but also sound installations).},
	language = {en},
	number = {3},
	urldate = {2020-01-10},
	journal = {Organised Sound},
	author = {Di Scipio, Agostino},
	month = dec,
	year = {2003},
	pages = {269--277},
}

@article{smalley1997,
	title = {Spectromorphology: explaining sound-shapes},
	volume = {2},
	issn = {13557718},
	shorttitle = {Spectromorphology},
	url = {http://www.journals.cambridge.org/abstract_S1355771897009059},
	doi = {10.1017/S1355771897009059},
	language = {en},
	number = {2},
	urldate = {2020-01-10},
	journal = {Organised Sound},
	author = {Smalley, Denis},
	month = aug,
	year = {1997},
	pages = {107--126},
}

@article{wendt2017,
	title = {Perception of {Spatial} {Sound} {Phenomena} {Created} by the {Icosahedral} {Loudspeaker}},
	volume = {41},
	issn = {0148-9267, 1531-5169},
	url = {http://www.mitpressjournals.org/doi/10.1162/COMJ_a_00396},
	doi = {10.1162/COMJ_a_00396},
	abstract = {The icosahedral loudspeaker (IKO) is able to project strongly focused sound beams into arbitrary directions. Incorporating artistic experience and psychoacoustic research, this article presents three listening experiments that provide evidence for a common, intersubjective perception of spatial sonic phenomena created by the IKO. The experiments are designed on the basis of a hierarchical model of spatiosonic phenomena that exhibit increasing complexity, ranging from a single static sonic object to combinations of multiple, partly moving objects. The results are promising and explore new compositional perspectives in spatial computer music.},
	language = {en},
	number = {1},
	urldate = {2020-01-10},
	journal = {Computer Music Journal},
	author = {Wendt, Florian and Sharma, Gerriet K. and Frank, Matthias and Zotter, Franz and Höldrich, Robert},
	month = mar,
	year = {2017},
	pages = {76--88},
}

@article{hesmondhalgh1998,
	title = {The {British} {Dance} {Music} {Industry}: {A} {Case} {Study} of {Independent} {Cultural} {Production}},
	volume = {49},
	issn = {00071315},
	shorttitle = {The {British} {Dance} {Music} {Industry}},
	url = {https://www.jstor.org/stable/591311?origin=crossref},
	doi = {10.2307/591311},
	abstract = {This article analyses the British dance music industry and assesses claims that it offers a powerful alternative to the 'mainstream' music business. Two unusual features of the sector are identified. Whereas the recording industry as a whole is marked by concentration and centralization, the UK dance music industry is relatively decentralized and is made up of large numbers of 'independent' companies. Reasons for the success of small, local companies are offered, in particular the emphasis amongst dance audiences on genre, rather than on performer identity; and the low promotional costs enabled by negative press coverage of 'acid house' in the late 1980s. But the article argues that a number of features of the British dance music industry work against a view of the sector as a radical challenge to prevailing cultural-industry practices. These are as follows: firstly, the reliance of dance music companies on crossover hits and compilation albums; secondly, close ties between the independents and corporate partners; and thirdly, the pressures placed upon small companies to follow the standard ways of dealing with risk in the recording industry- in particular, the development of a star system.},
	language = {en},
	number = {2},
	urldate = {2020-01-10},
	journal = {The British Journal of Sociology},
	author = {Hesmondhalgh, David},
	month = jun,
	year = {1998},
	pages = {234},
}

@book{frith1996,
	address = {Cambridge, Mass},
	title = {Performing rites: on the value of popular music},
	isbn = {978-0-674-66195-0},
	shorttitle = {Performing rites},
	language = {en},
	publisher = {Harvard University Press},
	author = {Frith, Simon},
	year = {1996},
	keywords = {History and criticism, Music, Philosophy and aesthetics, Popular music, Social aspects},
}

@article{cardew1961,
	title = {Notation: {Interpretation}, etc.},
	url = {http://www.jstor.org/stable/944250},
	language = {en},
	number = {58},
	journal = {Tempo, New Series},
	author = {Cardew, Cornelius},
	year = {1961},
	pages = {21--33},
}

@book{berry2011,
	address = {Houndmills, Basingstoke, Hampshire; New York},
	title = {The philosophy of software: code and mediation in the digital age},
	isbn = {9780230306479 9781283067690 9786613067692},
	shorttitle = {The philosophy of software},
	url = {http://site.ebrary.com/id/10462131},
	abstract = {This book is a critical introduction to code and software that develops an understanding of its social and philosophical implications in the digital age. Written specifically for people interested in the subject from a non-technical background, the book provides a lively and interesting analysis of these new media forms.},
	language = {English.},
	urldate = {2020-01-10},
	publisher = {Palgrave Macmillan},
	author = {Berry, David},
	year = {2011},
}

@incollection{ndalianis2003,
	address = {Cambridge, Mass},
	series = {Media in transition},
	title = {Architectures of the {Senses}: {Neobaroque} {Entertainment} {Spectacles}},
	isbn = {978-0-262-20146-9},
	booktitle = {Rethinking media change: the aesthetics of transition},
	publisher = {MIT Press},
	author = {Ndalianis, Angela},
	year = {2003},
	keywords = {History, Mass media},
}

@book{manovich2001,
	address = {Cambridge, Mass.},
	series = {Leonardo},
	title = {The language of new media},
	isbn = {978-0-262-63255-3 978-0-262-13374-6},
	language = {eng},
	publisher = {MIT Press},
	author = {Manovich, Lev},
	year = {2001},
}

@book{fuchs2014,
	address = {Los Angeles},
	title = {Social media: a critical introduction},
	isbn = {978-1-4462-5730-2 978-1-4462-5731-9},
	shorttitle = {Social media},
	abstract = {"Now more than ever, we need to understand social media - the good as well as the bad. We need critical knowledge that helps us to navigate the controversies and contradictions of this complex digital media landscape. Only then can we make informed judgments about what's happening in our media world, and why. Showing the reader how to ask the right kinds of questions about social media, Christian Fuchs takes us on a journey across social media, delving deep into case studies on Google, Facebook, Twitter, WikiLeaks and Wikipedia. The result lays bare the structures and power relations at the heart of our media landscape." -- Publisher's description},
	language = {en},
	publisher = {SAGE},
	author = {Fuchs, Christian},
	year = {2014},
	keywords = {Social media},
}

@article{kendall2011,
	title = {Why {Things} {Don}'t {Work}: {What} you need to know about spatial audio},
	abstract = {Composers engaged in the sonic arts have frequently found themselves attempting to use spatial audio in ways that didn’t work as intended. Maybe more than any other facet of technological music, mastering spatial audio seems to involve a learning process in which one slowly discovers the things that work and those that don’t. The purpose of this paper is to foster understanding of spatial audio through examples of practical problems. These problems reveal some general misconceptions about spatial hearing that explain why things go wrong. A particular lesson to be gleaned from this discussion is that there is no silver bullet for solving spatial audio problems, and every situation needs to be understood in its proper context.},
	language = {en},
	author = {Kendall, Gary S},
	year = {2011},
	pages = {4},
}

@article{mcalpine1999,
	title = {Making {Music} with {Algorithms}: {A} {Case}-{Study} {System}},
	volume = {23},
	url = {http://www.jstor.org/stable/3680733},
	language = {en},
	number = {2},
	journal = {Computer Music Journal},
	author = {McAlpine, Kenneth and Miranda, Eduardo and Hoggar, Stuart},
	year = {1999},
	pages = {19--30},
}

@phdthesis{kiefer2012,
	title = {Multiparametric {Interfaces} {For} {Fine}-{Grained} {Control} of {Digital} {Music}},
	language = {en},
	school = {University of Sussex},
	author = {Kiefer, Chris},
	year = {2012},
}

@article{talsma2015,
	title = {Predictive coding and multisensory integration: an attentional account of the multisensory mind},
	volume = {09},
	issn = {1662-5145},
	shorttitle = {Predictive coding and multisensory integration},
	url = {http://www.frontiersin.org/Integrative_Neuroscience/10.3389/fnint.2015.00019/abstract},
	doi = {10.3389/fnint.2015.00019},
	abstract = {Multisensory integration involves a host of different cognitive processes, occurring at different stages of sensory processing. Here I argue that, despite recent insights suggesting that multisensory interactions can occur at very early latencies, the actual integration of individual sensory traces into an internally consistent mental representation is dependent on both top–down and bottom–up processes. Moreover, I argue that this integration is not limited to just sensory inputs, but that internal cognitive processes also shape the resulting mental representation. Studies showing that memory recall is affected by the initial multisensory context in which the stimuli were presented will be discussed, as well as several studies showing that mental imagery can affect multisensory illusions. This empirical evidence will be discussed from a predictive coding perspective, in which a central top–down attentional process is proposed to play a central role in coordinating the integration of all these inputs into a coherent mental representation.},
	language = {en},
	urldate = {2020-01-10},
	journal = {Frontiers in Integrative Neuroscience},
	author = {Talsma, Durk},
	month = mar,
	year = {2015},
}

@article{battaglia2003,
	title = {Bayesian integration of visual and auditory signals for spatial localization},
	volume = {20},
	issn = {1084-7529, 1520-8532},
	url = {https://www.osapublishing.org/abstract.cfm?URI=josaa-20-7-1391},
	doi = {10.1364/JOSAA.20.001391},
	language = {en},
	number = {7},
	urldate = {2020-01-10},
	journal = {Journal of the Optical Society of America A},
	author = {Battaglia, Peter W. and Jacobs, Robert A. and Aslin, Richard N.},
	month = jul,
	year = {2003},
	pages = {1391},
}

@article{seth2013,
	title = {Interoceptive inference, emotion, and the embodied self},
	volume = {17},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661313002118},
	doi = {10.1016/j.tics.2013.09.007},
	language = {en},
	number = {11},
	urldate = {2020-01-10},
	journal = {Trends in Cognitive Sciences},
	author = {Seth, Anil K.},
	month = nov,
	year = {2013},
	pages = {565--573},
}

@article{shimojo2001,
	title = {Sensory modalities are not separate modalities: plasticity and interactions},
	volume = {11},
	issn = {09594388},
	shorttitle = {Sensory modalities are not separate modalities},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438800002415},
	doi = {10.1016/S0959-4388(00)00241-5},
	language = {en},
	number = {4},
	urldate = {2020-01-10},
	journal = {Current Opinion in Neurobiology},
	author = {Shimojo, S},
	month = aug,
	year = {2001},
	pages = {505--509},
}

@inproceedings{lindeman2007,
	address = {Newport Beach, California},
	title = {A classification scheme for multi-sensory augmented reality},
	isbn = {978-1-59593-863-3},
	url = {http://portal.acm.org/citation.cfm?doid=1315184.1315216},
	doi = {10.1145/1315184.1315216},
	abstract = {We present a new classification framework for describing augmented reality (AR) applications based on where the mixing of real and computer-generated stimuli takes place. In addition to "classical" visual AR techniques, such as optical-see-through and video-see-through AR, our framework encompasses AR directed at the other senses as well. This "axis of mixing location" is a continuum ranging from the physical environment to the human brain. There are advantages and disadvantages of mixing at different points along the continuum, and while there is no "best" location, we present sample usage scenarios that illustrate the expressiveness of this classification approach.},
	language = {en},
	urldate = {2020-01-10},
	booktitle = {Proceedings of the 2007 {ACM} symposium on {Virtual} reality software and technology  - {VRST} '07},
	publisher = {ACM Press},
	author = {Lindeman, Robert W. and Noma, Haruo},
	year = {2007},
	pages = {175},
}

@book{bimber2005,
	edition = {0},
	title = {Spatial {Augmented} {Reality}: {Merging} {Real} and {Virtual} {Worlds}},
	isbn = {978-0-429-10850-1},
	shorttitle = {Spatial {Augmented} {Reality}},
	url = {https://www.taylorfrancis.com/books/9781439864944},
	language = {en},
	urldate = {2020-01-10},
	publisher = {A K Peters/CRC Press},
	author = {Bimber, Oliver and Raskar, Ramesh},
	month = aug,
	year = {2005},
}

@article{bermejo2017,
	title = {A survey on haptic technologies for mobile augmented reality},
	url = {http://arxiv.org/abs/1709.00698},
	abstract = {Augmented Reality (AR) and Mobile Augmented Reality (MAR) applications have gained much research and industry attention these days. The mobile nature of MAR applications limits users’ interaction capabilities such as inputs, and haptic feedbacks. This survey reviews current research issues in the area of human computer interaction for MAR and haptic devices. The survey ﬁrst presents human sensing capabilities and their applicability in AR applications. We classify haptic devices into two groups according to the triggered sense: cutaneous/tactile: touch, active surfaces, and mid-air; kinesthetic: manipulandum, grasp, and exoskeleton. Due to the mobile capabilities of MAR applications, we mainly focus our study on wearable haptic devices for each category and their AR possibilities. To conclude, we discuss the future paths that haptic feedbacks should follow for MAR applications and their challenges.},
	language = {en},
	urldate = {2020-01-10},
	journal = {arXiv:1709.00698 [cs]},
	author = {Bermejo, Carlos and Hui, Pan},
	month = sep,
	year = {2017},
	keywords = {Computer Science - Human-Computer Interaction},
}

@article{vines2006,
	title = {Cross-modal interactions in the perception of musical performance},
	volume = {101},
	issn = {00100277},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027705001538},
	doi = {10.1016/j.cognition.2005.09.003},
	language = {en},
	number = {1},
	urldate = {2020-01-10},
	journal = {Cognition},
	author = {Vines, B and Krumhansl, C and Wanderley, M and Levitin, D},
	month = aug,
	year = {2006},
	pages = {80--113},
}

@inproceedings{melchior2005,
	address = {Vienna, Austria},
	title = {Authoring and user interaction for the production of wave field synthesis content in an augmented reality system},
	isbn = {978-0-7695-2459-7},
	url = {http://ieeexplore.ieee.org/document/1544662/},
	doi = {10.1109/ISMAR.2005.20},
	abstract = {Wave field synthesis (WFS) enables the accurate reproduction of a sound field for a large listening area with correct characteristics for each listener position. An exact perspective on the synthesized wave field is provided for every listener. Therefore, WFS-technology is ideally suited to be combined with augmented reality systems, where every user perceives his own visual perspective of a given scene. This paper presents a concept for authoring and user interaction for the production of wave field synthesis content in an augmented reality system. Also, the implementation of a prototype WFS-AR System based on ARToolkit is explained.},
	language = {en},
	urldate = {2020-01-10},
	booktitle = {Fourth {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR}'05)},
	publisher = {IEEE},
	author = {Melchior, F. and Laubach, T. and de Vries, D.},
	year = {2005},
	pages = {48--51},
}

@article{hayes2011,
	title = {Vibrotactile {Feedback}-{Assisted} {Performance}},
	abstract = {When performing digital music it is important to be able to acquire a comparable level of sensitivity and control to what can be achieved with acoustic instruments. By examining the links between sound and touch, new compositional and performance strategies start to emerge for performers using digital instruments1. These involve technological implementations utilizing the haptic2 information channels, o↵ering insight into how our tacit knowledge of the physical world can be introduced to the digital domain, enforcing the view that sound is a ‘species of touch’ [14].},
	language = {en},
	author = {Hayes, Lauren},
	year = {2011},
	pages = {4},
}

@article{gupta2018,
	title = {On the use of closed-back headphones for active hear-through equalization in augmented reality applications},
	abstract = {Augmented Reality (AR) audio refers to techniques where virtual sounds are superimposed with real sounds to produce immersive digital content. Headphones are widely used in consumer devices for playback of virtual sounds. However, for AR audio, an important step is to make sure that headphones allow external sounds to pass through naturally. To achieve this, a technique called Hear-Through (HT) processing is commonly employed to reproduce the incoming real sound by playing back processed version of it. In this context, open-back and headphones and closed in-ear headphones have been employed for HT processing. Closed-back headphones provide strong isolation unlike open-back headphones and do not have fittings issue as well as modified ear canal resonance effect found in closed in-ear headphones. In this paper, an investigation of HT design using closed-back circumaural headphones equipped with two pairs of microphones was conducted. An adaptive filtering algorithm was used to derive the ideal equalization filter. To alleviate the direction dependency of the ideal equalization filter and simplify HT filter design, two simplified equalization filters were also introduced. Experiments with objective evaluation using spectral difference and subjective evaluation on both timbre and spatial performance were conducted. These experimental results indicate a close match of the ideal equalized signal with the reference signal in open ear listening, which is slightly degraded in the simplified equalization filters, but outperforms the default ambient hear-through mode in the commercial headphones.},
	language = {en},
	author = {Gupta, Rishabh and Ranjan, Rishabh and He, Jianjun and Gan, Woon-Seng},
	year = {2018},
	pages = {12},
}

@article{das2017,
	title = {Music {Everywhere} – {Augmented} {Reality} {Piano} {Improvisation} {Learning} {System}},
	abstract = {This paper describes the design and implementation of an augmented reality (AR) piano learning tool that uses a Microsoft HoloLens and a MIDI-over-Bluetooth-enabled electric piano. The tool presents a unique visual interface—a “mirror key overlay” approach—fitted for the AR environment, and opens up the possibility of on-instrument learning experiences. The curriculum focuses on teaching improvisation in blues, rock, jazz and classical genres. Users at the piano engage with interactive lessons, watch virtual hand demonstrations, see and hear example improvisations, and play their own solos and accompaniment along with AR-projected virtual musicians. The tool aims to be entertaining yet also effective in teaching core musical concepts.},
	language = {en},
	author = {Das, Shantanu and Glickman, Seth and Hsiao, Fu Yen and Lee, Byunghwan},
	year = {2017},
	pages = {2},
}

@incollection{blum2012,
	address = {Berlin, Heidelberg},
	title = {What’s around {Me}? {Spatialized} {Audio} {Augmented} {Reality} for {Blind} {Users} with a {Smartphone}},
	volume = {104},
	isbn = {978-3-642-30972-4 978-3-642-30973-1},
	shorttitle = {What’s around {Me}?},
	url = {http://link.springer.com/10.1007/978-3-642-30973-1_5},
	abstract = {Numerous projects have investigated assistive navigation technologies for the blind community, tackling challenges ranging from interface design to sensory substitution. However, none of these have successfully integrated what we consider to be the three factors necessary for a widely deployable system that delivers a rich experience of one’s environment: implementation on a commodity device, use of a preexisting worldwide point of interest (POI) database, and a means of rendering the environment that is superior to a naive playback of spoken text. Our “In Situ Audio Services” (ISAS) application responds to these needs, allowing users to explore an urban area without necessarily having a particular destination in mind. We describe the technical aspects of its implementation, user requirements, interface design, safety concerns, POI data source issues, and further requirements to make the system practical on a wider basis. Initial qualitative feedback from blind users is also discussed.},
	language = {en},
	urldate = {2020-01-10},
	booktitle = {Mobile and {Ubiquitous} {Systems}: {Computing}, {Networking}, and {Services}},
	publisher = {Springer Berlin Heidelberg},
	author = {Blum, Jeffrey R. and Bouchard, Mathieu and Cooperstock, Jeremy R.},
	editor = {Puiatti, Alessandro and Gu, Tao},
	year = {2012},
	pages = {49--62},
}

@article{azuma2001,
	title = {Recent advances in augmented reality},
	volume = {21},
	issn = {02721716},
	url = {http://ieeexplore.ieee.org/document/963459/},
	doi = {10.1109/38.963459},
	language = {en},
	number = {6},
	urldate = {2020-01-10},
	journal = {IEEE Computer Graphics and Applications},
	author = {Azuma, Ronald and Baillot, Yohan and Behringer, R and Feiner, Steven and Julier, S and MacIntyre, Blair},
	year = {2001},
	pages = {34--47},
}

@article{panciroli2018,
	title = {Educating about {Art} by {Augmented} {Reality}: {New} {Didactic} {Mediation} {Perspectives} at {School} and in {Museums}},
	volume = {1},
	issn = {2504-3900},
	shorttitle = {Educating about {Art} by {Augmented} {Reality}},
	url = {http://www.mdpi.com/2504-3900/1/9/1107},
	doi = {10.3390/proceedings1091107},
	abstract = {Different national and international researches have stressed relevant aspects concerning the application of augmented reality in formal and non-formal educational contexts, especially at school and in museums. In fact, augmented reality plays a meaningful role in the relationship between technologies and didactic mediation; its applications are the prerequisite for an augmented learning, through the reproduction of specific scenarios which go beyond the pure theoretical dimension. More specifically the present contribution aims to set out an option for a reflection on the relationship between art education and augmented reality technologies from the didactic mediation point of view, with reference to a shared and collaborative construction of knowledge of artistic and cultural heritage.},
	language = {en},
	number = {9},
	urldate = {2020-01-10},
	journal = {Proceedings},
	author = {Panciroli, Chiara and Macauda, Anita and Russo, Veronica},
	month = mar,
	year = {2018},
	pages = {1107},
}

@phdthesis{ranjan2016,
	title = {{3D} {Audio} {Reproduction}: {Natural} {Augmented} {Reality} {Headset} {And} {Next} {Generation} {Entertainment} {System} {Using} {Wave} {Field} {Synthesis}},
	language = {en},
	school = {Nanyang Technological University},
	author = {Ranjan, Rishabh},
	year = {2016},
}

@article{ramo2012,
	title = {Digital {Augmented} {Reality} {Audio} {Headset}},
	volume = {2012},
	issn = {2090-0147, 2090-0155},
	url = {http://www.hindawi.com/journals/jece/2012/457374/},
	doi = {10.1155/2012/457374},
	abstract = {Augmented reality audio (ARA) combines virtual sound sources with the real sonic environment of the user. An ARA system can be realized with a headset containing binaural microphones. Ideally, the ARA headset should be acoustically transparent, that is, it should not cause audible modification to the surrounding sound. A practical implementation of an ARA mixer requires a low-latency headphone reproduction system with additional equalization to compensate for the attenuation and the modified ear canal resonances caused by the headphones. This paper proposes digital IIR filters to realize the required equalization and evaluates a real-time prototype ARA system. Measurements show that the throughput latency of the digital prototype ARA system can be less than 1.4 ms, which is sufficiently small in practice. When the direct and processed sounds are combined in the ear, a comb filtering effect is brought about and appears as notches in the frequency response. The comb filter effect in speech and music signals was studied in a listening test and it was found to be inaudible when the attenuation is 20 dB. Insert ARA headphones have a sufficient attenuation at frequencies above about 1 kHz. The proposed digital ARA system enables several immersive audio applications, such as a virtual audio tourist guide and audio teleconferencing.},
	language = {en},
	urldate = {2020-01-10},
	journal = {Journal of Electrical and Computer Engineering},
	author = {Rämö, Jussi and Välimäki, Vesa},
	year = {2012},
	pages = {1--13},
}

@article{papagiannis2014,
	title = {Working towards defining an aesthetics of augmented reality: {A} medium in transition},
	volume = {20},
	issn = {1354-8565, 1748-7382},
	shorttitle = {Working towards defining an aesthetics of augmented reality},
	url = {http://journals.sagepub.com/doi/10.1177/1354856513514333},
	doi = {10.1177/1354856513514333},
	abstract = {The present is a critical time in augmented reality’s (AR) definition, as a new medium with aesthetics and conventions just beginning to emerge. We are at a moment when we can look both to the future and to the past: still seeing the previous forms that are shaping AR as a medium while paving new paths, contributing to novel styles and tropes. This article will work toward defining an aesthetics of AR as a new medium in transition, discussing my work as both an artist and a researcher in AR.},
	language = {en},
	number = {1},
	urldate = {2020-01-10},
	journal = {Convergence: The International Journal of Research into New Media Technologies},
	author = {Papagiannis, Helen},
	month = feb,
	year = {2014},
	pages = {33--40},
}

@incollection{papagiannis2017,
	title = {The {Critical} {Role} of {Artists} in {Advancing} {Augmented} {Reality}},
	language = {en},
	booktitle = {The {Next} {Step}: {Exponential} {Life}},
	publisher = {Turner Libros},
	author = {Papagiannis, Helen},
	year = {2017},
	pages = {124--139},
}

@article{azuma1997,
	title = {A {Survey} of {Augmented} {Reality}},
	volume = {6},
	abstract = {This paper surveys the field of Augmented Reality, in which 3-D virtual objects are integrated into a 3-D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment and military applications that have been explored. This paper describes the characteristics of Augmented Reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective Augmented Reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using Augmented Reality.},
	language = {en},
	number = {4},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Azuma, Ronald},
	year = {1997},
	pages = {355--385},
}

@article{vankrevelen2010,
	title = {A {Survey} of {Augmented} {Reality} {Technologies}, {Applications} and {Limitations}},
	volume = {9},
	issn = {1081-1451},
	url = {https://ijvr.eu/article/view/2767},
	doi = {10.20870/IJVR.2010.9.2.2767},
	abstract = {A Survey of Augmented Reality Technologies, Applications and Limitations},
	language = {en},
	number = {2},
	urldate = {2020-01-10},
	journal = {International Journal of Virtual Reality},
	author = {Van Krevelen, D.W.F. and Poelman, R.},
	month = jan,
	year = {2010},
	pages = {1--20},
}

@phdthesis{sjoberg2018,
	title = {Making use of the environmental space in augmented reality},
	language = {en},
	author = {Sjoberg, Jesper},
	year = {2018},
}

@inproceedings{sheffield2016,
	address = {Brisbane, Australia},
	title = {The {Haptic} {Capstans}: {Rotational} {Force} {Feedback} for {Music} using a {FireFader} {Derivative} {Device}},
	doi = {10.5281/zenodo.1176124},
	abstract = {The Haptic Capstans are two rotational force-feedback knobs circumscribed by eye-catching LED rings. In this work, the Haptic Capstans are programmed using physical models in order to experiment with audio-visual-haptic interactions for music applications.},
	language = {en},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Shefﬁeld, Eric and Berdahl, Edgar and Pfalz, Andrew},
	year = {2016},
	pages = {2},
}

@phdthesis{schraffenberger2018,
	title = {Arguably augmented reality: relationships between the virtual and the real},
	shorttitle = {Arguably augmented reality},
	language = {en},
	school = {University of Leiden},
	author = {Schraffenberger, Hanna},
	year = {2018},
}

@inproceedings{tikander2008,
	address = {Espoo, Finland},
	title = {An {Augmented} {Reality} {Audio} {Headset}},
	abstract = {Augmented reality audio (ARA) means mixing the natural sound environment with artiﬁcially created sound scenes. This requires that the perception of natural environment has to be preserved as well as possible, unless some modiﬁcation to it is desired. A basic ARA headset consists of binaural microphones, an ampliﬁer/mixer, and earphones feeding sound to the ear canals. All these components more or less change the perceived sound scene. In this paper we describe an ARA headset, equalization of its response, and particularly the results of a usability study. The usability was tested by subjects wearing the headset for relatively long periods in different environments of their everyday-life conditions. The goal was to ﬁnd out what works well and what are the problems in lengthened use. It was found that acoustically the headset worked ﬁne in most occasions when equalized individually or generically (averaged over several subjects). The main problems of usage were related to handling inconveniences and special environments.},
	language = {en},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Digital} {Audio} {Effects}},
	author = {Tikander, Miikka and Karjalainen, Matti and Riikonen, Ville},
	year = {2008},
	pages = {4},
}

@inproceedings{schraffenberger2016,
	address = {Tokyo, Japan},
	title = {Multimodal augmented reality: the norm rather than the exception},
	isbn = {978-1-4503-4559-0},
	shorttitle = {Multimodal augmented reality},
	url = {http://dl.acm.org/citation.cfm?doid=3001959.3001960},
	doi = {10.1145/3001959.3001960},
	abstract = {Augmented reality (AR) is commonly seen as a technology that overlays virtual imagery onto a participant’s view of the world. In line with this, most AR research is focused on what we see. In this paper, we challenge this focus on vision and make a case for an experience-focused and modalitiesencompassing understanding of AR. We argue that multimodality in AR is the norm rather than the exception, as AR environments consist of both virtual content and our real, physical, multimodal world. We explore the role multimodal and non-visual aspects of our physical reality can play when creating AR scenarios and the possibilities and challenges that emerge when approaching AR from a modalitiesencompassing perspective.},
	language = {en},
	urldate = {2020-01-10},
	booktitle = {Proceedings of the 2016 workshop on {Multimodal} {Virtual} and {Augmented} {Reality} - {MVAR} '16},
	publisher = {ACM Press},
	author = {Schraffenberger, Hanna and van der Heide, Edwin},
	year = {2016},
	pages = {1--6},
}

@article{vi2017a,
	title = {Not just seeing, but also feeling art: {Mid}-air haptic experiences integrated in a multisensory art exhibition},
	volume = {108},
	issn = {10715819},
	shorttitle = {Not just seeing, but also feeling art},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581917300988},
	doi = {10.1016/j.ijhcs.2017.06.004},
	abstract = {The use of the senses of vision and audition as interactive means has dominated the ﬁeld of Human-Computer Interaction (HCI) for decades, even though nature has provided us with many more senses for perceiving and interacting with the world around us. That said, it has become attractive for HCI researchers and designers to harness touch, taste, and smell in interactive tasks and experience design. In this paper, we present research and design insights gained throughout an interdisciplinary collaboration on a six-week multisensory display – Tate Sensorium – exhibited at the Tate Britain art gallery in London, UK. This is a unique and ﬁrst time case study on how to design art experiences whilst considering all the senses (i.e., vision, sound, touch, smell, and taste), in particular touch, which we exploited by capitalizing on a novel haptic technology, namely, mid-air haptics. We ﬁrst describe the overall set up of Tate Sensorium and then move on to describing in detail the design process of the mid-air haptic feedback and its integration with sound for the Full Stop painting by John Latham (1961). This was the ﬁrst time that mid-air haptic technology was used in a museum context over a prolonged period of time and integrated with sound to enhance the experience of visual art. As part of an interdisciplinary team of curators, sensory designers, sound artists, we selected a total of three variations of the mid-air haptic experience (i.e., haptic patterns), which were alternated at dedicated times throughout the six-week exhibition. We collected questionnaire-based feedback from 2500 visitors and conducted 50 interviews to gain quantitative and qualitative insights on visitors’ experiences and emotional reactions. Whilst the questionnaire results are generally very positive with only a small variation of the visitors’ arousal ratings across the three tactile experiences designed for the Full Stop painting, the interview data shed light on the diﬀerences in the visitors’ subjective experiences. Our ﬁndings suggest multisensory designers and art curators can ensure a balance between surprising experiences versus the possibility of free exploration for visitors. In addition, participants expressed that experiencing art with the combination of mid-air haptic and sound was immersive and provided an up-lifting experience of touching without touch. We are convinced that the insights gained from this large-scale and real-world ﬁeld exploration of multisensory experience design exploiting a new and emerging technology provide a solid starting point for the HCI community, creative industries, and art curators to think beyond conventional art experiences. Speciﬁcally, our work demonstrates how novel mid-air technology can make art more emotionally engaging and stimulating, especially abstract art that is often open to interpretation.},
	language = {en},
	urldate = {2020-01-10},
	journal = {International Journal of Human-Computer Studies},
	author = {Vi, Chi Thanh and Ablart, Damien and Gatti, Elia and Velasco, Carlos and Obrist, Marianna},
	month = dec,
	year = {2017},
	pages = {1--14},
}

@article{obrist2017a,
	title = {Multisensory {Experiences} in {HCI}},
	volume = {24},
	issn = {1070-986X},
	url = {http://ieeexplore.ieee.org/document/7924204/},
	doi = {10.1109/MMUL.2017.33},
	language = {en},
	number = {2},
	urldate = {2020-01-10},
	journal = {IEEE MultiMedia},
	author = {Obrist, Marianna and Gatti, Elia and Maggioni, Emanuela and Vi, Chi Thanh and Velasco, Carlos},
	month = apr,
	year = {2017},
	pages = {9--13},
}

@inproceedings{obrist2016a,
	address = {San Jose, California, USA},
	title = {Touch, {Taste}, \& {Smell} {User} {Interfaces}: {The} {Future} of {Multisensory} {HCI}},
	isbn = {978-1-4503-4082-3},
	shorttitle = {Touch, {Taste}, \& {Smell} {User} {Interfaces}},
	url = {http://dl.acm.org/citation.cfm?doid=2851581.2856462},
	doi = {10.1145/2851581.2856462},
	abstract = {The senses we call upon when interacting with technology are very restricted. We mostly rely on vision and audition, increasingly harnessing touch, whilst taste and smell remain largely underexploited. In spite of our current knowledge about sensory systems and sensory devices, the biggest stumbling block for progress concerns the need for a deeper understanding of people’s multisensory experiences in HCI. It is essential to determine what tactile, gustatory, and olfactory experiences we can design for, and how we can meaningfully stimulate such experiences when interacting with technology. Importantly, we need to determine the contribution of the different senses along with their interactions in order to design more effective and engaging digital multisensory experiences. Finally, it is vital to understand what the limitations are that come into play when users need to monitor more than one sense at a time. The aim of this workshop is to deepen and expand the discussion on touch, taste, and smell within the CHI community and promote the relevance of multisensory experience design and research in HCI.},
	language = {en},
	urldate = {2020-01-10},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}  - {CHI} {EA} '16},
	publisher = {ACM Press},
	author = {Obrist, Marianna and Velasco, Carlos and Vi, Chi Thanh and Ranasinghe, Nimesha and Israr, Ali and Cheok, Adrian D. and Spence, Charles and Gopalakrishnakone, Ponnampalam},
	year = {2016},
	pages = {3285--3292},
}

@inproceedings{narumi2011,
	address = {Vancouver, BC, Canada},
	title = {Augmented reality flavors: gustatory display based on edible marker and cross-modal interaction},
	isbn = {978-1-4503-0228-9},
	shorttitle = {Augmented reality flavors},
	url = {http://dl.acm.org/citation.cfm?doid=1978942.1978957},
	doi = {10.1145/1978942.1978957},
	abstract = {The main contribution of this paper is to realize computer generated augmented flavors and establish a method to integrate gustatory information into computer human interactions. There are several reasons for the scarcity of research on gustatory information. One reason is that taste sensations are affected by a number of factors, such as vision, olfaction and memories. This produces a complex cognition mechanism for a user's gustatory sensation, and makes it difficult to build up a gustatory display which produces a specific taste on demand.},
	language = {en},
	urldate = {2020-01-10},
	booktitle = {Proceedings of the 2011 annual conference on {Human} factors in computing systems - {CHI} '11},
	publisher = {ACM Press},
	author = {Narumi, Takuji and Nishizaka, Shinya and Kajinami, Takashi and Tanikawa, Tomohiro and Hirose, Michitaka},
	year = {2011},
	pages = {93},
}

@article{ward2016,
	title = {Visual {Cues} to {Reorient} {Attention} from {Head} {Mounted} {Displays}},
	volume = {60},
	issn = {1541-9312},
	url = {http://journals.sagepub.com/doi/10.1177/1541931213601363},
	doi = {10.1177/1541931213601363},
	language = {en},
	number = {1},
	urldate = {2020-01-10},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Ward, Matthew and Barde, Amit and Russell, Paul N. and Billinghurst, Mark and Helton, William S.},
	month = sep,
	year = {2016},
	pages = {1574--1578},
}

@article{ullmer2000,
	title = {Emerging frameworks for tangible user interfaces},
	volume = {39},
	issn = {0018-8670},
	url = {http://ieeexplore.ieee.org/document/5387042/},
	doi = {10.1147/sj.393.0915},
	language = {en},
	number = {3.4},
	urldate = {2020-01-10},
	journal = {IBM Systems Journal},
	author = {Ullmer, B. and Ishii, H.},
	year = {2000},
	pages = {915--931},
}

@inproceedings{vi2017b,
	address = {Glasgow, UK},
	title = {Gustatory interface: the challenges of ‘how’ to stimulate the sense of taste},
	isbn = {978-1-4503-5556-8},
	shorttitle = {Gustatory interface},
	url = {http://dl.acm.org/citation.cfm?doid=3141788.3141794},
	doi = {10.1145/3141788.3141794},
	abstract = {Gustatory interfaces have gained popularity in the field of humancomputer interaction, especially in the context of augmenting gaming and virtual reality experiences, but also in the context of food interaction design enabling the creation of new eating experiences. In this paper, we first review prior works on gustatory interfaces and particularly discuss them based on the use of either a chemical, electrical and/or thermal stimulation approach. We then present two concepts for gustatory interfaces that represent a more traditional delivery approach (using a mouthpiece) versus a novel approach that is based on principles of acoustic levitation (contactless delivery). We discuss the design opportunities around those two concepts in particular to overcome challenges of "how" to stimulate the sense of taste.},
	language = {en},
	urldate = {2020-01-10},
	booktitle = {Proceedings of the 2nd {ACM} {SIGCHI} {International} {Workshop} on {Multisensory} {Approaches} to {Human}-{Food} {Interaction} - {MHFI} 2017},
	publisher = {ACM Press},
	author = {Vi, Chi Thanh and Ablart, Damien and Arthur, Daniel and Obrist, Marianna},
	year = {2017},
	pages = {29--33},
}

@inproceedings{obrist2017,
	address = {Cagliari, Italy},
	title = {Mastering the {Senses} in {HCI}: {Towards} {Multisensory} {Interfaces}},
	isbn = {978-1-4503-5237-6},
	shorttitle = {Mastering the {Senses} in {HCI}},
	url = {http://dl.acm.org/citation.cfm?doid=3125571.3125603},
	doi = {10.1145/3125571.3125603},
	abstract = {With the proliferation of sensory technologies that do not only stimulate the sense of vision and hearing, but also our sense of touch, smell, and taste, we are confronted with the challenge of mastering those “new” senses in the design of interactive systems. To meaningfully design multisensory interfaces and enrich human-technology interactions we need to systematically investigate the technical, perceptual, and experiential parameters of sensory and multisensory stimulation. Here, I particularly focus on the study of tactile, gustatory, and olfactory experiences facilitated by the use of novel technologies (e.g., mid-air haptic devices, olfactory devices) and the combination of objective and subjective measures within sensory science, psychology, HCI, and user experience research.},
	language = {en},
	urldate = {2020-01-10},
	booktitle = {Proceedings of the 12th {Biannual} {Conference} on {Italian} {SIGCHI} {Chapter} - {CHItaly} '17},
	publisher = {ACM Press},
	author = {Obrist, Marianna},
	year = {2017},
	pages = {1--2},
}

@article{ablart2017,
	title = {The how and why behind a multisensory art display},
	volume = {24},
	issn = {10725520},
	url = {http://dl.acm.org/citation.cfm?doid=3155029.3137091},
	doi = {10.1145/3137091},
	language = {en},
	number = {6},
	urldate = {2020-01-10},
	journal = {interactions},
	author = {Ablart, Damien and Velasco, Carlos and Vi, Chi Thanh and Gatti, Elia and Obrist, Marianna},
	month = oct,
	year = {2017},
	pages = {38--43},
}

@article{wellner1993,
	title = {Interacting with paper on the {DigitalDesk}},
	volume = {36},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=159544.159630},
	doi = {10.1145/159544.159630},
	language = {en},
	number = {7},
	urldate = {2020-01-10},
	journal = {Communications of the ACM},
	author = {Wellner, Pierre},
	month = jul,
	year = {1993},
	pages = {87--96},
}

@book{durlach1995,
	address = {Washington, D.C.},
	title = {Virtual {Reality}: {Scientific} and {Technological} {Challenges}},
	isbn = {978-0-309-05135-4},
	shorttitle = {Virtual {Reality}},
	url = {http://www.nap.edu/catalog/4761},
	language = {en},
	urldate = {2020-01-10},
	publisher = {National Academies Press},
	author = {Durlach, Nathaniel and Mavor, Anne},
	month = dec,
	year = {1995},
}

@inproceedings{altosaar2019,
	address = {Tempe, Arizona, USA},
	title = {Physically {Colliding} with {Music}: {Full}-body {Interactions} with an {Audio}-only {Virtual} {Reality} {Interface}},
	isbn = {978-1-4503-6196-5},
	shorttitle = {Physically {Colliding} with {Music}},
	url = {http://dl.acm.org/citation.cfm?doid=3294109.3301256},
	doi = {10.1145/3294109.3301256},
	abstract = {A Very Real Looper (AVRL) is an audio-only virtual reality (VR) interface inside of which a performer triggers and controls music through full-body movement. Contrary to how musical interfaces in VR are normally used, a performer using AVRL is not disconnected from their surrounding environment through immersion, nor is their body restrained by a head-mounted display. Rather, AVRL utilizes two VR sensors and the Unity game engine to map virtual musical sounds onto physical objects in the real world. These objects help the performer locate the sounds. Using two handheld VR controllers, these sounds can be triggered, looped, acoustically affected, or repositioned in space. AVRL thus combines the affordances of the physical world and a VR system with the reconfigurability of a game engine. This integration results in an expansive and augmented performance environment that facilitates full-body musical interactions.},
	language = {en},
	urldate = {2020-01-10},
	booktitle = {Proceedings of the {Thirteenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction}  - {TEI} '19},
	publisher = {ACM Press},
	author = {Altosaar, Raul and Tindale, Adam and Doyle, Judith},
	year = {2019},
	pages = {553--557},
}

@incollection{hollerer2004,
	edition = {1},
	title = {Mobile {Augmented} {Reality}},
	isbn = {978-0-203-50107-8},
	url = {https://www.taylorfrancis.com/books/9780203501078},
	language = {en},
	urldate = {2020-01-10},
	booktitle = {Telegeoinformatics: {Location}-{Based} {Computing} and {Services}},
	publisher = {CRC Press},
	author = {Höllerer, T. and Feiner, S.},
	month = mar,
	year = {2004},
}

@misc{ray2018,
	title = {Brian {Eno} and {Peter} {Chilvers} create ‘quite magical’ flower garden of sound in {Amsterdam} with ‘{Bloom}: {Open} {Space}’ - {Stories}},
	url = {https://news.microsoft.com/features/brian-eno-peter-chilvers-create-quite-magical-flower-garden-sound-amsterdam-bloom-open-space/},
	urldate = {2020-01-10},
	author = {Ray, Susanna},
	month = feb,
	year = {2018},
}

@article{johnson2017,
	title = {{VRMin}: {Using} {Mixed} {Reality} to {Augment} the {Theremin} for {Musical} {Tutoring}},
	abstract = {The recent resurgence of Virtual Reality (VR) technologies provide new platforms for augmenting traditional music instruments. Instrument augmentation is a common approach for designing new interfaces for musical expression, as shown through hyperinstrument research. New visual aﬀordances present in VR give designers new methods for augmenting instruments to extend not only their expressivity, but also their capabilities for computer assisted tutoring. In this work, we present VRMin, a mobile Mixed Reality (MR) application for augmenting a physical theremin, with an immersive virtual environment (VE), for real time computer assisted tutoring. We augment a physical theremin with 3D visual cues to indicate correct hand positioning for performing given notes and volumes. The physical theremin acts as a domain speciﬁc controller for the resulting MR environment. The initial eﬀectiveness of this approach is measured by analyzing a performer’s hand position while training with and without the VRMin. We also evaluate the usability of the interface using heuristic evaluation based on a newly proposed set of guidelines designed for VR musical environments.},
	language = {en},
	author = {Johnson, David and Tzanetakis, George},
	year = {2017},
	pages = {6},
}

@article{clark1998,
	title = {The {Extended} {Mind}},
	volume = {58},
	issn = {0003-2638, 1467-8284},
	url = {https://academic.oup.com/analysis/article-lookup/doi/10.1093/analys/58.1.7},
	doi = {10.1093/analys/58.1.7},
	language = {en},
	number = {1},
	urldate = {2020-01-10},
	journal = {Analysis},
	author = {Clark, A. and Chalmers, D.},
	month = jan,
	year = {1998},
	pages = {7--19},
}

@book{clark2001,
	address = {Cambridge, Mass.},
	edition = {1. paperback ed},
	series = {A {Bradford} book},
	title = {Being there: putting brain, body, and world together again},
	isbn = {978-0-262-53156-6 978-0-262-03240-7},
	shorttitle = {Being there},
	language = {eng},
	publisher = {MIT Press},
	author = {Clark, Andy},
	year = {2001},
}

@article{serafin2016,
	title = {Virtual {Reality} {Musical} {Instruments}: {State} of the {Art}, {Design} {Principles}, and {Future} {Directions}},
	volume = {40},
	issn = {0148-9267, 1531-5169},
	shorttitle = {Virtual {Reality} {Musical} {Instruments}},
	url = {http://www.mitpressjournals.org/doi/10.1162/COMJ_a_00372},
	doi = {10.1162/COMJ_a_00372},
	abstract = {The rapid development and availability of low-cost technologies have created a wide interest in virtual reality. In the field of computer music, the term “virtual musical instruments” has been used for a long time to describe software simulations, extensions of existing musical instruments, and ways to control them with new interfaces for musical expression. Virtual reality musical instruments (VRMIs) that include a simulated visual component delivered via a head-mounted display or other forms of immersive visualization have not yet received much attention. In this article, we present a field overview of VRMIs from the viewpoint of the performer. We propose nine design guidelines, describe evaluation methods, analyze case studies, and consider future challenges.},
	language = {en},
	number = {3},
	urldate = {2020-01-10},
	journal = {Computer Music Journal},
	author = {Serafin, Stefania and Erkut, Cumhur and Kojs, Juraj and Nilsson, Niels C. and Nordahl, Rolf},
	month = sep,
	year = {2016},
	pages = {22--40},
}

@inproceedings{tcha-tokey2016,
	address = {Laval, France},
	title = {A questionnaire to measure the user experience in immersive virtual environments},
	isbn = {978-1-4503-4180-6},
	url = {http://dl.acm.org/citation.cfm?doid=2927929.2927955},
	doi = {10.1145/2927929.2927955},
	language = {en},
	urldate = {2020-01-30},
	booktitle = {Proceedings of the 2016 {Virtual} {Reality} {International} {Conference} on - {VRIC} '16},
	publisher = {ACM Press},
	author = {Tcha-Tokey, Katy and Loup-Escande, Emilie and Christmann, Olivier and Richir, Simon},
	year = {2016},
	pages = {1--5},
}

@article{grasset2008,
	title = {Art and {Mixed} {Reality}: {New} {Technology} for {Seamless} {Merging} {Between} {Virtual} and {Real}},
	abstract = {Mixed Reality (MR) describes new technology that intrinsically supports the mixing between the real world with the virtual world. In this paper, we present different interactive Mixed Reality experiences we have been developing that explore the artistic applications of the technology. We discuss our approach, the knowledge we have gained and review issues raised by these diverse experiences. Finally, we introduce some initial design guidelines to help others to develop their own interactive Mixed Reality artistic creations.},
	language = {en},
	journal = {IMedia-Space},
	author = {Grasset, Raphaël and Woods, Eric and Billinghurst, Mark},
	year = {2008},
	pages = {10},
}

@article{kim2018,
	title = {Revisiting {Trends} in {Augmented} {Reality} {Research}: {A} {Review} of the 2nd {Decade} of {ISMAR} (2008–2017)},
	volume = {24},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Revisiting {Trends} in {Augmented} {Reality} {Research}},
	url = {https://ieeexplore.ieee.org/document/8456568/},
	doi = {10.1109/TVCG.2018.2868591},
	abstract = {In 2008, Zhou et al. presented a survey paper summarizing the previous ten years of ISMAR publications, which provided invaluable insights into the research challenges and trends associated with that time period. Ten years later, we review the research that has been presented at ISMAR conferences since the survey of Zhou et al., at a time when both academia and the AR industry are enjoying dramatic technological changes. Here we consider the research results and trends of the last decade of ISMAR by carefully reviewing the ISMAR publications from the period of 2008–2017, in the context of the ﬁrst ten years. The numbers of papers for different research topics and their impacts by citations were analyzed while reviewing them—which reveals that there is a sharp increase in AR evaluation and rendering research. Based on this review we offer some observations related to potential future research areas or trends, which could be helpful to AR researchers and industry members looking ahead.},
	language = {en},
	number = {11},
	urldate = {2020-02-07},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kim, Kangsoo and Billinghurst, Mark and Bruder, Gerd and Duh, Henry Been-Lirn and Welch, Gregory F.},
	month = nov,
	year = {2018},
	pages = {2947--2962},
}

@article{ross2005,
	title = {New {Media} {Arts} {Hybridity}: {The} {Vases} ({Dis})communicants {Between} {Art}, {Affective} {Science} and {AR} {Technology}},
	volume = {11},
	issn = {1354-8565, 1748-7382},
	shorttitle = {New {Media} {Arts} {Hybridity}},
	url = {http://journals.sagepub.com/doi/10.1177//1354856505061051},
	doi = {10.1177//1354856505061051},
	abstract = {Following Annie Coombes’s and Avtar Brah’s (authors of Hybridity and its Discontents: Politics, Science, Culture, 2000) request that we not merely apply but in fact historicise hybridity, and arguing that the art and science explorations of new media art have produced some of the strongest new media hybridities to date, the author focuses on one of the important ﬁelds of investigation currently linking media art, science and technology: augmented reality or what should be called augmented perception of time and space. This aesthetic ﬁeld of investigation has led to a reassessment of representation, one that is not without (1) sharing some of the fundamental concerns of current neuroscientiﬁc investigation of mental processes and (2) questioning the image/real continuum principle at the core of recent augmented reality technology research. The article examines media artist Bill Viola’s The Passions series (2000–2001) to contend that new media’s original contribution to the practice of hybridity lies in the interaction that it both articulates and encourages with affective sciences, an interaction that redeﬁnes representation as an approximation, a facilitator – a projection screen for complex mental processes.},
	language = {en},
	number = {4},
	urldate = {2020-02-07},
	journal = {Convergence: The International Journal of Research into New Media Technologies},
	author = {Ross, Christine},
	month = nov,
	year = {2005},
	pages = {32--42},
}

@article{spence2015,
	title = {Olfactory dining: designing for the dominant sense},
	volume = {4},
	issn = {2044-7248},
	shorttitle = {Olfactory dining},
	url = {http://www.flavourjournal.com/content/4/1/32},
	doi = {10.1186/s13411-015-0042-0},
	abstract = {The majority of researchers agree that olfactory cues play a dominant role in our perception and enjoyment of the taste (or rather flavour) of food and drink. It is no surprise then that in recent years, a variety of modern (or dare we say it, modernist) solutions have been developed with the explicit aim of delivering an enhanced olfactory input to the diners/dishes served in the restaurant, and occasionally also in the home setting too. Such innovations include everything from aromatic cutlery and plateware through to the use of atomizers and dry ice. A few augmented reality (AR; i.e. an experience of a physical, real-world environment whose elements have been augmented, or supplemented, by computer-generated sensory input) solutions have also made their way out from well-funded technology labs, and scent-enabled plug-ins for mobile devices are slowly being commercialized. The latter could potentially be used to enhance the orthonasal olfactory component of our multisensory food experiences in the years to come. Ultimately, though, there is an important question here as to the authenticity of those food and flavour experiences that have been augmented/enhanced by aroma and fragrance cues that are not integral to the food or drink itself. It is this lack of authenticity that may, at least in your authors’ humble opinion, limit the more widespread uptake of such a sense-by-sense approach to the contemporary construction of multisensory gastronomic experiences. The challenge, as always, remains to find the unique selling point (USP) of such approaches to olfactory stimulation, over and above their mere feasibility and inherent theatricality.},
	language = {en},
	number = {1},
	urldate = {2020-02-07},
	journal = {Flavour},
	author = {Spence, Charles and Youssef, Jozef},
	month = dec,
	year = {2015},
	pages = {32},
}

@inproceedings{rosenberg1993,
	address = {Seattle, WA, USA},
	title = {Virtual fixtures: {Perceptual} tools for telerobotic manipulation},
	isbn = {978-0-7803-1363-7},
	shorttitle = {Virtual fixtures},
	url = {https://ieeexplore.ieee.org/document/380795/},
	doi = {10.1109/VRAIS.1993.380795},
	urldate = {2020-01-16},
	booktitle = {Proceedings of {IEEE} {Virtual} {Reality} {Annual} {International} {Symposium}},
	publisher = {IEEE},
	author = {Rosenberg, Louis},
	year = {1993},
	pages = {76--82},
}

@book{lefebvre1991,
	address = {Oxford, OX, UK ; Cambridge, Mass., USA},
	title = {The production of space},
	isbn = {978-0-631-14048-1},
	language = {eng},
	publisher = {Blackwell},
	author = {Lefebvre, Henri},
	year = {1991},
	keywords = {Space and time},
}

@book{stern2013,
	address = {Canterbury},
	title = {Interactive art and embodiment: the implicit body as performance},
	isbn = {978-1-78024-009-1 978-1-78024-010-7 978-1-78024-011-4},
	shorttitle = {Interactive art and embodiment},
	language = {eng},
	publisher = {Gylphi Limited},
	author = {Stern, Nathaniel},
	year = {2013},
}

@article{delanda2015,
	title = {The {New} {Materiality}: {The} {New} {Materiality}},
	volume = {85},
	issn = {00038504},
	shorttitle = {The {New} {Materiality}},
	url = {http://doi.wiley.com/10.1002/ad.1948},
	doi = {10.1002/ad.1948},
	language = {en},
	number = {5},
	urldate = {2020-02-11},
	journal = {Architectural Design},
	author = {DeLanda, Manuel},
	month = sep,
	year = {2015},
	pages = {16--21},
}

@inproceedings{normand2012,
	address = {Meg\&\#232;ve, France},
	title = {A new typology of augmented reality applications},
	isbn = {978-1-4503-1077-2},
	url = {http://dl.acm.org/citation.cfm?doid=2160125.2160143},
	doi = {10.1145/2160125.2160143},
	abstract = {In recent years Augmented Reality (AR) has become more and more popular, especially since the availability of mobile devices, such as smartphones or tablets, brought AR into our everyday life. Although the AR community has not yet agreed on a formal deﬁnition of AR, some work focused on proposing classiﬁcations of existing AR methods or applications. Such applications cover a wide variety of technologies, devices and goals, consequently existing taxonomies rely on multiple classiﬁcation criteria that try to take into account AR applications diversity. In this paper we review existing taxonomies of augmented reality applications and we propose our own, which is based on (1) the number of degrees of freedom required by the application, as well as on (2) the visualization mode used, (3) the temporal base of the displayed content and (4) the rendering modalities used in the application. Our taxonomy covers location-based services as well as more traditional visionbased AR applications. Although AR is mainly based on the visual sense, other rendering modalities are also covered by the same degree-of-freedom criterion in our classiﬁcation.},
	language = {en},
	urldate = {2020-02-07},
	booktitle = {Proceedings of the 3rd {Augmented} {Human} {International} {Conference} on - {AH} '12},
	publisher = {ACM Press},
	author = {Normand, Jean-Marie and Servières, Myriam and Moreau, Guillaume},
	year = {2012},
	pages = {1--8},
}

@article{graham2013,
	title = {Augmented reality in urban places: contested content and the duplicity of code: \textit{{Augmented} reality in urban places}},
	volume = {38},
	issn = {00202754},
	shorttitle = {Augmented reality in urban places},
	url = {http://doi.wiley.com/10.1111/j.1475-5661.2012.00539.x},
	doi = {10.1111/j.1475-5661.2012.00539.x},
	language = {en},
	number = {3},
	urldate = {2020-02-07},
	journal = {Transactions of the Institute of British Geographers},
	author = {Graham, Mark and Zook, Matthew and Boulton, Andrew},
	month = jul,
	year = {2013},
	pages = {464--479},
}

@article{klopfer2008,
	title = {Environmental {Detectives}—the development of an augmented reality platform for environmental simulations},
	volume = {56},
	issn = {1042-1629, 1556-6501},
	url = {http://link.springer.com/10.1007/s11423-007-9037-6},
	doi = {10.1007/s11423-007-9037-6},
	language = {en},
	number = {2},
	urldate = {2020-02-07},
	journal = {Educational Technology Research and Development},
	author = {Klopfer, Eric and Squire, Kurt},
	month = apr,
	year = {2008},
	pages = {203--228},
}

@article{mackay1996,
	title = {Augmenting {Reality}: {A} new paradigm for interacting with computers},
	abstract = {A revolution in computer interface design is changing the way we think about computers. Rather than typing on a keyboard and watching a television monitor, Augmented Reality lets people use familiar, everyday objects in ordinary ways. The difference is that these objects also provide a link into a computer network. Doctors can examine patients while viewing superimposed medical images; children can program their own LEGO constructions; and construction engineers can use ordinary paper engineering drawings to make live video connections to colleagues far away. Rather than immersing people in an artifically-created virtual world, the goal is to augment everyday objects in the physical world by enhancing them with a wealth of digital information and communication capabilities.},
	language = {en},
	author = {Mackay, Wendy E},
	year = {1996},
	pages = {9},
}

@phdthesis{vallino1998,
	address = {New York},
	title = {Interactive {Augmented} {Reality}},
	language = {en},
	school = {University of Rochester},
	author = {Vallino, James R},
	year = {1998},
}

@article{turk2014,
	title = {Multimodal interaction: {A} review},
	volume = {36},
	issn = {01678655},
	shorttitle = {Multimodal interaction},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167865513002584},
	doi = {10.1016/j.patrec.2013.07.003},
	abstract = {People naturally interact with the world multimodally, through both parallel and sequential use of multiple perceptual modalities. Multimodal human–computer interaction has sought for decades to endow computers with similar capabilities, in order to provide more natural, powerful, and compelling interactive experiences. With the rapid advance in non-desktop computing generated by powerful mobile devices and affordable sensors in recent years, multimodal research that leverages speech, touch, vision, and gesture is on the rise. This paper provides a brief and personal review of some of the key aspects and issues in multimodal interaction, touching on the history, opportunities, and challenges of the area, especially in the area of multimodal integration. We review the question of early vs. late integration and ﬁnd inspiration in recent evidence in biological sensory integration. Finally, we list challenges that lie ahead for research in multimodal human–computer interaction.},
	language = {en},
	urldate = {2020-05-24},
	journal = {Pattern Recognition Letters},
	author = {Turk, Matthew},
	month = jan,
	year = {2014},
	pages = {189--195},
}

@article{manovich2006,
	title = {The poetics of augmented space},
	volume = {5},
	issn = {1470-3572, 1741-3214},
	url = {http://journals.sagepub.com/doi/10.1177/1470357206065527},
	doi = {10.1177/1470357206065527},
	abstract = {This article discusses how people experience spatial forms when they are filled in with dynamic and rich multimedia information; spaces such as shopping or entertainment areas or other spaces where various information can be accessed wirelessly. The author calls such spaces ‘augmented space’: the physical space overlaid with dynamically changing information, multimedia in form and localized for each user. The article asks whether this form becomes irrelevant and ‘invisible’ or if people end up with a new experience in which the spatial and information layers are equally important. The author also discusses the general dynamic between spatial form and information and how this might function differently in today’s computer culture. Throughout the article, augmentation is reconceptualized as an idea and cultural and aesthetic practice rather than as technology. Various practices in professional and vernacular architecture and built environments, cinema, 20th-century art and media art are discussed in terms of augmentation.},
	language = {en},
	number = {2},
	urldate = {2020-05-24},
	journal = {Visual Communication},
	author = {Manovich, Lev},
	month = jun,
	year = {2006},
	pages = {219--240},
}

@misc{winer2016,
	title = {{ESP32} {Arduino} {Library}},
	url = {https://github.com/kriswiner/ESP32},
	abstract = {Arduino sketches for the ESP32. Contribute to kriswiner/ESP32 development by creating an account on GitHub.},
	urldate = {2020-05-20},
	author = {Winer, Kris},
	year = {2016},
	keywords = {esp32},
}

@article{emmerson1998,
	title = {Aural landscape: musical space},
	volume = {3},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Aural landscape},
	url = {https://www.cambridge.org/core/product/identifier/S1355771898002064/type/journal_article},
	doi = {10.1017/S1355771898002064},
	abstract = {This paper seeks to examine how sound in general (and electroacoustic music in particular) can evoke a sense of being and place which may be strongly related to our visual experience. The auditory system has evolved to seek the reasons for the soundfield it encounters and this property cannot meaningfully be ignored by composers in this medium. The acousmatic condition stimulates and enhances this response. The science of acoustics cannot any longer alone explain sound phenomena and requires psychological and ecological dimensions. The idea of the ‘frame’ is developed from large-scale to small-scale soundfields: ‘landscape’, ‘arena’ and ‘stage’ are seen to be flexible components of this approach to composition. The paper concludes that a mature relationship of audio and visual art forms requires a greater acknowledgement of these attributes of sound.},
	language = {en},
	number = {2},
	urldate = {2020-02-11},
	journal = {Organised Sound},
	author = {Emmerson, Simon},
	month = aug,
	year = {1998},
	pages = {135--140},
}

@incollection{emmerson2015,
	address = {Bielefeld},
	edition = {1. Aufl.},
	title = {Local/{Field} and {Beyond} {The} {Scale} of {Spaces}},
	isbn = {978-3-8394-3076-7},
	url = {https://www.degruyter.com/view/books/9783839430767/9783839430767-001/9783839430767-001.xml},
	urldate = {2020-02-11},
	booktitle = {Kompositionen für hörbaren {RaumDie} frühe elektroakustische {Musik} und ihre {Kontexte}},
	publisher = {transcript Verlag},
	author = {Emmerson, Simon},
	year = {2015},
}

@article{martina2001,
	title = {Raumsoziologie},
	journal = {Frankfurt am Main: Suhrkamp},
	author = {Martina, Löw},
	year = {2001},
}

@article{dupreez2008,
	title = {({Im}){Materiality} - {On} the {Immateriality} of {Art}},
	volume = {2008},
	number = {14},
	journal = {Image \& Text: a Journal for Design},
	author = {Du Preez, Amanda},
	year = {2008},
	pages = {30--41},
}

@inproceedings{lucero2019,
	address = {San Diego, CA, USA},
	title = {A {Sample} of {One}: {First}-{Person} {Research} {Methods} in {HCI}},
	isbn = {978-1-4503-6270-2},
	shorttitle = {A {Sample} of {One}},
	url = {http://dl.acm.org/citation.cfm?doid=3301019.3319996},
	doi = {10.1145/3301019.3319996},
	abstract = {First-person research (i.e., research that involves data collection and experiences from the researcher themselves) continues to become a viable addition and, possibly even, alternative to more traditional HCI methods. While we have seen the benefits of using methods such as autoethnography, autobiographical design, and autoethnographical research through design, we also see the need to further explore, define, and investigate the practices, techniques, tactics, and implications of first-person research in HCI. To address this, this one-day workshop aims to bring together a community of researchers, designers, and practitioners who are interested in exploring and reimagining research in HCI and interaction design, with an emphasis on first-person methods.},
	language = {en},
	urldate = {2020-03-17},
	booktitle = {Companion {Publication} of the 2019 on {Designing} {Interactive} {Systems} {Conference} 2019 {Companion} - {DIS} '19 {Companion}},
	publisher = {ACM Press},
	author = {Lucero, Andrés and Desjardins, Audrey and Neustaedter, Carman and Höök, Kristina and Hassenzahl, Marc and Cecchinato, Marta E.},
	year = {2019},
	pages = {385--388},
}

@inproceedings{desjardins2018,
	address = {Hong Kong, China},
	title = {Revealing {Tensions} in {Autobiographical} {Design} in {HCI}},
	isbn = {978-1-4503-5198-0},
	url = {http://dl.acm.org/citation.cfm?doid=3196709.3196781},
	doi = {10.1145/3196709.3196781},
	abstract = {While self-usage has long been regarded as a questionable approach in human-computer interaction (HCI) research, recent projects have shown the successful use of autobiographical design as a method to investigate long-term and intimate relations between people and technologies in everyday life. In an effort to continue the development of methodological best practices, we need to acknowledge with more nuance the tensions that arise in use. In this paper, we articulate such tensions by examining two first-hand accounts of using autobiographical design and four autobiographical design projects of other HCI researchers. Our findings address: genuine needs, design participation, intimacy, reflexivity, and authorial voice. Our contribution is constituted of critical insights into the complexities of using autobiographical design and recommendations for researchers interested in using this method.},
	language = {en},
	urldate = {2020-03-17},
	booktitle = {Proceedings of the 2018 on {Designing} {Interactive} {Systems} {Conference} 2018 - {DIS} '18},
	publisher = {ACM Press},
	author = {Desjardins, Audrey and Ball, Aubree},
	year = {2018},
	pages = {753--764},
}

@article{aceti2013,
	title = {Not {Here} {Not} {There}},
	volume = {19},
	number = {2},
	journal = {Leonardo},
	editor = {Aceti, Lanfranco},
	year = {2013},
}

@article{litovsky1998,
	title = {The {Precedence} {Effect}},
	doi = {10.1121/1.427914},
	language = {en},
	author = {Litovsky, Ruth Y and Colburn, H Steven and Yost, William A and Guzman, Sandra J},
	year = {1998},
	pages = {23},
}

@article{rumsey2002,
	title = {Spatial {Quality} {Evaluation} for {Reproduced} {Sound}: {Terminology}, {Meaning}, and a {Scene}-{Based} {Paradigm}},
	volume = {50},
	language = {en},
	number = {9},
	journal = {J. Audio Eng. Soc.},
	author = {Rumsey, Francis},
	year = {2002},
	pages = {16},
}

@inproceedings{chatzidimitris2016,
	address = {Lemesos, Cyprus},
	title = {{SoundPacman}: {Audio} augmented reality in location-based games},
	isbn = {978-1-5090-0058-6},
	shorttitle = {{SoundPacman}},
	url = {http://ieeexplore.ieee.org/document/7495414/},
	doi = {10.1109/MELCON.2016.7495414},
	abstract = {Sound design has received little attention in location-based games research. Typically, existing prototypes heavily rely on visual information with sound only having a marginal role in the game design and development process. This paper investigates the role of sound as primary interface for conveying game information and creating engaging gaming experiences. As a case study, we present SoundPacman, a prototype location-based game, wherein players experience the game space with the use of 3D sounds, which augment the physical environment. Preliminary tests utilizing EEG analysis provide evidence that sound augmentation may significantly contribute towards enhancing the immersion levels of players.},
	language = {en},
	urldate = {2020-02-13},
	booktitle = {2016 18th {Mediterranean} {Electrotechnical} {Conference} ({MELECON})},
	publisher = {IEEE},
	author = {Chatzidimitris, Thomas and Gavalas, Damianos and Michael, Despina},
	month = apr,
	year = {2016},
	pages = {1--6},
}

@inproceedings{caudell1992,
	address = {Kauai, HI, USA},
	title = {Augmented reality: an application of heads-up display technology to manual manufacturing processes},
	isbn = {978-0-8186-2420-9},
	shorttitle = {Augmented reality},
	url = {http://ieeexplore.ieee.org/document/183317/},
	doi = {10.1109/HICSS.1992.183317},
	abstract = {We describe the design and prototyping steps we have taken toward the implementation of a heads-up, see-through, head-mounted display (HUDSET). Combined with head position sensing and a real world registration system, this technology allows a computer-produced diagram to be superimposed and stabilized on a specific position on a real-world object. Successful development of the HUDset technology will enable cost reductions and efficiency improvements in many of the human-involved operations in aircraft manufacturing, by eliminating templates, formboard diagrams, and other masking devices.},
	language = {en},
	urldate = {2020-02-13},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {Hawaii} {International} {Conference} on {System} {Sciences}},
	publisher = {IEEE},
	author = {Caudell, Thomas and Mizell, David},
	year = {1992},
	pages = {659--669 vol.2},
}

@article{kendall2010,
	title = {Spatial {Perception} and {Cognition} in {Multichannel} {Audio} for {Electroacoustic} {Music}},
	volume = {15},
	issn = {1355-7718, 1469-8153},
	url = {http://www.journals.cambridge.org/abstract_S1355771810000336},
	doi = {10.1017/S1355771810000336},
	language = {en},
	number = {03},
	urldate = {2020-02-12},
	journal = {Organised Sound},
	author = {Kendall, Gary S.},
	month = dec,
	year = {2010},
	pages = {228--238},
}

@article{kendall2010a,
	title = {Meaning in {Electroacoustic} {Music} and the {Everyday} {Mind}},
	volume = {15},
	issn = {1355-7718, 1469-8153},
	url = {http://www.journals.cambridge.org/abstract_S1355771809990276},
	doi = {10.1017/S1355771809990276},
	language = {en},
	number = {01},
	urldate = {2020-02-12},
	journal = {Organised Sound},
	author = {Kendall, Gary S.},
	month = apr,
	year = {2010},
	pages = {63},
}

@article{bayle2007,
	title = {Space, and more},
	volume = {12},
	issn = {1469-8153, 1355-7718},
	url = {https://www.cambridge.org/core/journals/organised-sound/article/space-and-more/7077374DBC2E7FAA49E1608184C0A1F5},
	doi = {10.1017/S1355771807001872},
	abstract = {Among the questions regularly put to me, those that recur most often touch upon three aspects, three things to consider that are, truth to tell, unending within the domain of organised sounds. Those questions that take the lead are usually concerned with space – the representation of space as well as the production of space. Then come those that deal with listening, active or passive. Last are those relating to tools for making and for listening. Together, these approaches run through the stages that are very natural in position problematics: where, when, how, for whom, why? I would like, in formulating these repeated questions once more, to make myself re-orientate them in such a way to show that by bringing to bear forty years of experience, I have tried to reply to them as much through practice as through theory, putting forward the idea of a family of operational concepts linked together through the perceptual radical ‘acous’: acousmatic, acousmonium, acousmographe, acousmathèque.},
	language = {en},
	number = {3},
	urldate = {2020-02-11},
	journal = {Organised Sound},
	author = {Bayle, François},
	month = dec,
	year = {2007},
	pages = {241--249},
}

@inproceedings{brooks2020,
	title = {Trigeminal-based {Temperature} {Illusions}},
	doi = {10.1145/3313831.3376806},
	abstract = {We explore a temperature illusion that uses low-powered electronics and enables the miniaturization of simple warm and cool sensations. Our illusion relies on the properties of certain scents, such as the coolness of mint or hotness of peppers. These odors trigger not only the olfactory bulb, but also the nose’s trigeminal nerve, which has receptors that respond to both temperature and chemicals. To exploit this, we engineered a wearable device based on micropumps and an atomizer that emits up to three custom-made “thermal” scents directly to the user’s nose. Breathing in these scents causes the user to feel warmer or cooler. We demonstrate how our device renders warmth and cooling sensations in virtual experiences. Participants rated VR experiences with our trigeminal stimulants as significantly warmer or cooler than the baseline conditions. Lastly, we believe this offers an alternative to thermal feedback devices, which unfortunately rely on power-hungry heat-lamps or Peltier-elements.},
	booktitle = {{CHI} '20: {Proceedings} of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Brooks, Jas and Nagels, Steven and Lopes, Pedro},
	year = {2020},
}

@article{xue2019,
	title = {Researcher introspection for experience-driven design research},
	volume = {63},
	issn = {0142694X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0142694X19300158},
	doi = {10.1016/j.destud.2019.03.001},
	abstract = {We challenge the unquestioning pursuit of the appearance of objectivity and ingrained designer-user dualism in human-centred design research and propose a resurrection of introspection as a valid approach to investigating subjective experiences. Through comparing epistemic perspectives and reviewing the histories of introspection in several disciplines, we liberate the research ﬁeld of experience-driven design from a long-lasting doubt about and the disguised and unsystematic use of this method. To establish a foundation for the further development of introspective methods, we focus on its most controversial type (i.e. researcher introspection) and discuss its strengths and weaknesses, preconditions of use, diverse ways to practise for diﬀerent suitable experiencedriven design research purposes, and useful techniques and tools. Ó 2019 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-ncnd/4.0/).},
	language = {en},
	urldate = {2020-03-17},
	journal = {Design Studies},
	author = {Xue, Haian and Desmet, Pieter M.A.},
	month = jul,
	year = {2019},
	pages = {37--64},
}

@inproceedings{speicher2019,
	address = {Glasgow, Scotland Uk},
	title = {What is {Mixed} {Reality}?},
	isbn = {978-1-4503-5970-2},
	url = {http://dl.acm.org/citation.cfm?doid=3290605.3300767},
	doi = {10.1145/3290605.3300767},
	abstract = {What is Mixed Reality (MR)? To revisit this question given the many recent developments, we conducted interviews with ten AR/VR experts from academia and industry, as well as a literature survey of 68 papers. We find that, while there are prominent examples, there is no universally agreed on, one-size-fits-all definition of MR. Rather, we identified six partially competing notions from the literature and experts’ responses. We then started to isolate the different aspects of reality relevant for MR experiences, going beyond the primarily visual notions and extending to audio, motion, haptics, taste, and smell. We distill our findings into a conceptual framework with seven dimensions to characterize MR applications in terms of the number of environments, number of users, level of immersion, level of virtuality, degree of interaction, input, and output. Our goal with this paper is to support classification and discussion of MR applications’ design and provide a better means to researchers to contextualize their work within the increasingly fragmented MR landscape.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '19},
	publisher = {ACM Press},
	author = {Speicher, Maximilian and Hall, Brian D. and Nebeling, Michael},
	year = {2019},
	pages = {1--15},
}

@inproceedings{steil2019,
	address = {Denver Colorado},
	title = {Privacy-aware eye tracking using differential privacy},
	isbn = {978-1-4503-6709-7},
	url = {https://dl.acm.org/doi/10.1145/3314111.3319915},
	doi = {10.1145/3314111.3319915},
	abstract = {With eye tracking being increasingly integrated into virtual and augmented reality (VR/AR) head-mounted displays, preserving users’ privacy is an ever more important, yet under-explored, topic in the eye tracking community. We report a large-scale online survey (N=124) on privacy aspects of eye tracking that provides the first comprehensive account of with whom, for which services, and to what extent users are willing to share their gaze data. Using these insights, we design a privacy-aware VR interface that uses differential privacy, which we evaluate on a new 20-participant dataset for two privacy sensitive tasks: We show that our method can prevent user re-identification and protect gender information while maintaining high performance for gaze-based document type classification. Our results highlight the privacy challenges particular to gaze data and demonstrate that differential privacy is a potential means to address them. Thus, this paper lays important foundations for future research on privacy-aware gaze interfaces.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the 11th {ACM} {Symposium} on {Eye} {Tracking} {Research} \& {Applications}},
	publisher = {ACM},
	author = {Steil, Julian and Hagestedt, Inken and Huang, Michael Xuelin and Bulling, Andreas},
	month = jun,
	year = {2019},
	pages = {1--9},
}

@inproceedings{cecchinato2017,
	address = {Denver Colorado USA},
	title = {Always {On}(line)?: {User} {Experience} of {Smartwatches} and their {Role} within {Multi}-{Device} {Ecologies}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {Always {On}(line)?},
	url = {https://dl.acm.org/doi/10.1145/3025453.3025538},
	doi = {10.1145/3025453.3025538},
	abstract = {Users have access to a growing ecosystem of devices (desktop, mobile and wearable) that can deliver notifications and help people to stay in contact. Smartwatches are gaining popularity, yet little is known about the user experience and their impact on our increasingly always online culture. We report on a qualitative study with existing users on their everyday use of smartwatches to understand both the added value and the challenges of being constantly connected at the wrist. Our findings show that users see a large benefit in receiving notifications on their wrist, especially in terms of helping manage expectations of availability. Moreover, we find that response rates after viewing a notification on a smartwatch change based on the other devices available: laptops prompt quicker replies than smartphones. Finally, there are still many costs associated with using smartwatches, thus we make a series of design recommendations to improve the user experience of smartwatches.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Cecchinato, Marta E. and Cox, Anna L. and Bird, Jon},
	month = may,
	year = {2017},
	pages = {3557--3568},
}

@book{murchison2010,
	address = {San Francisco},
	edition = {1st ed},
	series = {Research methods for the social sciences},
	title = {Ethnography essentials: designing, conducting, and presenting your research},
	isbn = {978-0-470-34389-0},
	shorttitle = {Ethnography essentials},
	language = {en},
	publisher = {Jossey-Bass},
	author = {Murchison, Julian M.},
	year = {2010},
	keywords = {Ethnology, Methodology},
}

@book{fetterman2010,
	address = {Los Angeles},
	edition = {3rd ed},
	series = {Applied social research methods series},
	title = {Ethnography: step-by-step},
	isbn = {978-1-4129-5045-9},
	shorttitle = {Ethnography},
	language = {en},
	number = {17},
	publisher = {SAGE},
	author = {Fetterman, David M.},
	year = {2010},
	keywords = {Ethnology, Methodology},
}

@incollection{rhodes2018,
	address = {Cham},
	title = {Augmented {Reality} in {Art}: {Aesthetics} and {Material} for {Expression}},
	isbn = {978-3-319-69931-8 978-3-319-69932-5},
	shorttitle = {Augmented {Reality} in {Art}},
	url = {http://link.springer.com/10.1007/978-3-319-69932-5_7},
	urldate = {2020-05-25},
	booktitle = {Augmented {Reality} {Art}},
	publisher = {Springer International Publishing},
	author = {Rhodes, Geoffrey Alan},
	editor = {Geroimenko, Vladimir},
	year = {2018},
	pages = {163--172},
}

@article{milgram1994,
	title = {A {Taxonomy} of {Mixed} {Reality} {Visual} {Displays}},
	volume = {E77-D},
	abstract = {Mixed Reality (MR) visual displays, a particular subset of Virtual Reality (VR) related technologies, involve the merging of real and virtual worlds somewhere along the 'virtuality continuum' which connects completely real environments to completely virtual ones. Augmented Reality (AR), probably the best known of these, refers to all cases in which the display of an otherwise real environment is augmented by means of virtual (computer graphic) objects. The converse case on the virtuality continuum is therefore Augmented Virtuality (AV). Six classes of hybrid MR display environments are identified. However quite different groupings are possible and this demonstrates the need for an efficient taxonomy, or classification framework, according to which essential differences can be identified. An approximately three-dimensional taxonomy is proposed comprising the following dimensions: extent of world knowledge, reproduction fidelity, and extent of presence metaphor.},
	number = {12},
	journal = {IEICE Transactions on Information and Systems},
	author = {Milgram, Paul and Kishino, Fumio},
	month = dec,
	year = {1994},
	pages = {8},
}

@phdthesis{barde2018,
	title = {Design {Considerations} for a {Wearable}, {Bi}-{Modal} {Interface}},
	school = {University of Canterbury},
	author = {Barde, Amit},
	year = {2018},
}

@article{brooks1996,
	title = {The {Computer} {Scientist} as {Toolsmith} {II}},
	volume = {39},
	number = {3},
	journal = {Communications of the ACM},
	author = {Brooks, Fred},
	year = {1996},
}

@article{ruth2019,
	title = {Secure {Multi}-{User} {Content} {Sharing} for {Augmented} {Reality} {Applications}},
	abstract = {Augmented reality (AR), which overlays virtual content on top of the user’s perception of the real world, has now begun to enter the consumer market. Besides smartphone platforms, early-stage head-mounted displays such as the Microsoft HoloLens are under active development. Many compelling uses of these technologies are multi-user: e.g., inperson collaborative tools, multiplayer gaming, and telepresence. While prior work on AR security and privacy has studied potential risks from AR applications, new risks will also arise among multiple human users. In this work, we explore the challenges that arise in designing secure and private content sharing for multi-user AR. We analyze representative application case studies and systematize design goals for security and functionality that a multi-user AR platform should support. We design an AR content sharing control module that achieves these goals and build a prototype implementation (ShareAR) for the HoloLens. This work builds foundations for secure and private multi-user AR interactions.},
	language = {en},
	author = {Ruth, Kimberly and Kohno, Tadayoshi and Roesner, Franziska},
	year = {2019},
	pages = {19},
}

@inproceedings{maggioni2017,
	address = {Erfurt, Germany},
	title = {Measuring the added value of haptic feedback},
	isbn = {978-1-5386-4024-1},
	url = {http://ieeexplore.ieee.org/document/7965670/},
	doi = {10.1109/QoMEX.2017.7965670},
	abstract = {While there is an increased appreciation for integrating haptic feedback with audio-visual content, there is still a lack of understanding of how to quantify the added value of touch for a user’s experience (UX) of multimedia content. Here we focus on three main concepts to measure this added value: UX, emotions, and expectations. We present a case study measuring the added value of haptic feedback for a standardized set of audio-visual content (i.e., short video clips), comparing two haptic stimulation modalities (i.e., mid-air vs. vibro-tactile stimuli). Our findings demonstrate that UX of hapticallyenhanced audio-visual content is perceived as a more pleasant, unpredictable, and creative experience. The users’ overall liking increases together with a positive change of the users’ expectations, independently from the haptic stimulation modality. We discuss how our approach provides the foundation for future work on developing a measurement model to predict the added value of haptic feedback for users’ experiences within and beyond the multimedia context.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {2017 {Ninth} {International} {Conference} on {Quality} of {Multimedia} {Experience} ({QoMEX})},
	publisher = {IEEE},
	author = {Maggioni, Emanuela and Agostinelli, Erika and Obrist, Marianna},
	month = may,
	year = {2017},
	pages = {1--6},
}

@inproceedings{zhou2008,
	address = {Cambridge, UK},
	title = {Trends in augmented reality tracking, interaction and display: {A} review of ten years of {ISMAR}},
	isbn = {978-1-4244-2840-3},
	shorttitle = {Trends in augmented reality tracking, interaction and display},
	url = {http://ieeexplore.ieee.org/document/4637362/},
	doi = {10.1109/ISMAR.2008.4637362},
	abstract = {Although Augmented Reality technology was first developed over forty years ago, there has been little survey work giving an overview of recent research in the field. This paper reviews the tenyear development of the work presented at the ISMAR conference and its predecessors with a particular focus on tracking, interaction and display research. It provides a roadmap for future augmented reality research which will be of great value to this relatively young field, and also for helping researchers decide which topics should be explored when they are beginning their own studies in the area.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {2008 7th {IEEE}/{ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	publisher = {IEEE},
	author = {Zhou, Feng and Duh, Henry Been-Lirn and Billinghurst, Mark},
	month = sep,
	year = {2008},
	pages = {193--202},
}

@incollection{veal2012,
	address = {New York},
	title = {Starship {Africa}},
	isbn = {978-0-415-77130-6 978-0-415-77131-3},
	abstract = {"The Sound Studies Reader is a groundbreaking anthology blending recent work that self-consciously describes itself as 'sound studies' with earlier and lesser known scholarship on sound. The collection begins with an introduction to welcome novice readers to the field and acquaint them with key themes and concepts in sound studies. Individual section introductions give readers further background on the essays and an extensive up to date bibliography for further reading in 'sound studies' make this an original and accessible guide to the field"--},
	booktitle = {The sound studies reader},
	publisher = {Routledge},
	author = {Veal, Michael},
	editor = {Sterne, Jonathan},
	year = {2012},
	keywords = {Hearing, Listening, MUSIC / Recording \& Reproduction, Recording and reproducing History, Recording and reproducing Social aspects, SOCIAL SCIENCE / Media Studies, Sound},
}

@book{schmidthorning2015,
	series = {Studies in industry and society},
	title = {Chasing sound: technology, culture, and the art of studio recording from {Edison} to the {LP}},
	isbn = {978-1-4214-1848-3},
	shorttitle = {Chasing sound},
	language = {eng},
	author = {Schmidt Horning, Susan},
	month = jan,
	year = {2015},
}

@incollection{concannon1990,
	address = {Walter Phillips Gallery},
	title = {Cut and {Paste}: {Collage} and the {Art} of {Sound}},
	booktitle = {Sound by {Artists}},
	publisher = {Art Metropole},
	author = {Concannon, Kevin},
	year = {1990},
}

@book{wikstrom2009,
	address = {Cambridge ; Malden, MA},
	series = {Digital media and society series},
	title = {The music industry: music in the cloud},
	isbn = {978-0-7456-4389-2 978-0-7456-4390-8},
	shorttitle = {The music industry},
	publisher = {Polity},
	author = {Wikström, Patrik},
	year = {2009},
	keywords = {History and criticism, Music, Music trade, Musikwirtschaft, Neue Medien, Popular music, Social aspects},
}

@book{shafer1967,
	title = {Ear {Cleaning}: {Notes} for an {Experimental} {Music} {Course}},
	author = {Shafer, Raymond},
	year = {1967},
}

@incollection{cutler2000,
	address = {Aldershot ; Burlington, USA},
	title = {Plunderphonics},
	isbn = {978-0-7546-0109-8},
	booktitle = {Music, electronic media, and culture},
	publisher = {Ashgate},
	author = {Cutler, Chris},
	editor = {Simon, Emmerson},
	year = {2000},
	keywords = {20th century, Electronic music, History and criticism, Music, Music and technology},
}

@article{raskin2005,
	title = {Comments are {More} {Important} than {Code}},
	volume = {3},
	issn = {1542-7730, 1542-7749},
	url = {https://dl.acm.org/doi/10.1145/1053331.1053354},
	doi = {10.1145/1053331.1053354},
	language = {en},
	number = {2},
	urldate = {2020-05-24},
	journal = {Queue},
	author = {Raskin, Jef},
	month = mar,
	year = {2005},
	pages = {64--65},
}

@inproceedings{kiefer2020,
	address = {Birmingham, UK},
	title = {Shaping the behaviour of feedback instruments with complexity-controlled gain dynamics},
	abstract = {Feedback instruments oﬀer radical new ways of engaging with instrument design and musicianship. They are deﬁned by recurrent circulation of signals through the instrument, which give the instrument ‘a life of its own’ and a ’stimulating uncontrollability’. Arguably, the most interesting musical behaviour in these instruments happens when their dynamic complexity is maximised, without falling into saturating feedback. It is often challenging to keep the instrument in this zone; this research looks at algorithmic ways to manage the behaviour of feedback loops in order to make feedback instruments more playable and musical; to expand the ‘sweet spot’. We propose a solution that manages gain dynamics based on measurement of complexity, using a realtime implementation of the Eﬀort to Compress algorithm. The system was evaluated with four musicians, all who have diﬀerent variations of string-based feedback instruments, following an autobiographical design approach. Qualitative feedback was gathered, showing that the system was successful in modifying the behaviour of these instruments to allow easier access to edge transition zones, sometimes at the expense of losing some of the more compelling dynamics of the instruments. Basic eﬃcacy of the system is evidenced by descriptive audio analysis. This paper is accompanied by a dataset of sounds collected during the study, and open source software that was written to support the research.},
	language = {en},
	booktitle = {{NIME} 2020},
	publisher = {New Interfaces for Musical Expression},
	author = {Kiefer, Chris and Overholt, Dan and Eldridge, Alice},
	year = {2020},
	pages = {6},
}

@article{parikka2015,
	title = {Mutating {Media} {Ecologies}},
	language = {en},
	author = {Parikka, Jussi},
	year = {2015},
	pages = {8},
}

@misc{microsoft2019,
	title = {Microsoft {HoloLens}},
	url = {https://www.microsoft.com/en-us/hololens},
	abstract = {Introducing HoloLens 2, an untethered mixed reality headset that's designed to help you solve real business problems today using intelligent apps and solutions.},
	language = {en-us},
	urldate = {2020-05-25},
	journal = {Microsoft HoloLens 2},
	author = {Microsoft},
	year = {2019},
}

@article{cadoz2014,
	title = {Tangibility, {Presence}, {Materiality}, {Reality} in {Artistic} {Creation} with {Digital} {Technology}},
	abstract = {The democratization of Computer Arts and Computer Music has, due to dematerialization (virtualization) consequence of digital technologies, considerably widened the boundaries of creativity. As we are now entering a second phase that has been labeled “post-digital”, we are called to reconcile this openness with notions such as embodiment, presence, enaction and tangibility. These notions are in our view inherently linked to creativity. Here we outline some approaches to this problem under development within the “European Art-ScienceTechnology Network” (EASTN1). Several areas of artistic creation are represented (Music, Animation, Multisensory Arts, Architecture, Fine Arts, Graphic communication, etc.). A main objective of this network is to establish common grounds through collaborative reflection and work on the above notions, using the concept of tangibility as a focal point. In this paper we describe several different approaches to the tangibility, in relation to concepts such as reality, materiality, objectivity, presence, concreteness, etc. and their antonyms. Our objective is to open a debate on tangibility, in the belief that it has a strong unifying potential but is also at the same time presents challenging and difficult to define. Here we present some initial thoughts on this topic in a first effort to bring together the approaches that arise from the different practices and projects developed within the partner institutions involved in the EASTN network.},
	language = {en},
	author = {Cadoz, Claude and Luciani, Annie and Villeneuve, Jerome and Kontogeorgakopoulos, Alexandros and Zannos, Iannis},
	year = {2014},
	pages = {9},
}

@inproceedings{vallgarda2007,
	address = {San Jose, California, USA},
	title = {Computational composites},
	isbn = {978-1-59593-593-9},
	url = {http://dl.acm.org/citation.cfm?doid=1240624.1240706},
	doi = {10.1145/1240624.1240706},
	abstract = {Computational composite is introduced as a new type of composite material. Arguing that this is not just a metaphorical maneuver, we provide an analysis of computational technology as material in design, which shows how computers share important characteristics with other materials used in design and architecture. We argue that the notion of computational composites provides a precise understanding of the computer as material, and of how computations need to be combined with other materials to come to expression as material. Besides working as an analysis of computers from a designer’s point of view, the notion of computational composites may also provide a link for computer science and human-computer interaction to an increasingly rapid development and use of new materials in design and architecture.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '07},
	publisher = {ACM Press},
	author = {Vallgårda, Anna and Redström, Johan},
	year = {2007},
	pages = {513--522},
}

@article{jung2011,
	title = {Form and {Materiality} in {Interaction} {Design}: {A} {New} {Approach} to {HCI}},
	abstract = {This paper is motivated by the increasing significance of form in design and use of interactive artifacts. The objective of this paper is to conceptualize what we mean by form in the context of interaction design and HCI research and how we can approach it in regard to emerging type of digital materiality. To do this, we first examine conceptual dimensions of form in interactive artifacts through the lens of three existing perspectives with their respective focus on: material, meaning, and making. We then apply these perspectives in our analysis of specific forms of interactive artifacts. Based on this analysis, we suggest a model of four different types of forms: the cognitive, embodied, expressive, and exploratory forms. Reflecting on this model, we propose form-driven interaction design research with its epistemological and methodological implications.},
	language = {en},
	author = {Jung, Heekyoung and Stolterman, Erik},
	year = {2011},
	pages = {10},
}

@inproceedings{jung2011a,
	address = {Funchal, Portugal},
	title = {Material probe: exploring materiality of digital artifacts},
	isbn = {978-1-4503-0478-8},
	shorttitle = {Material probe},
	url = {http://portal.acm.org/citation.cfm?doid=1935701.1935731},
	doi = {10.1145/1935701.1935731},
	abstract = {We present an approach for exploring materiality of digital artifacts by suggesting a study method—material probe. The purpose with the method is to understand how people perceive material qualities of artifacts and to discuss how designers could intentionally and methodologically include such non-functional user desires related to material qualities in the design of digital artifacts. The study procedure and results from preliminary studies are described with their implications for future work.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the fifth international conference on {Tangible}, embedded, and embodied interaction - {TEI} '11},
	publisher = {ACM Press},
	author = {Jung, Heekyoung and Stolterman, Erik},
	year = {2011},
	pages = {153},
}

@inproceedings{lopes2018,
	address = {Montreal QC, Canada},
	title = {Adding {Force} {Feedback} to {Mixed} {Reality} {Experiences} and {Games} using {Electrical} {Muscle} {Stimulation}},
	isbn = {978-1-4503-5620-6},
	url = {http://dl.acm.org/citation.cfm?doid=3173574.3174020},
	doi = {10.1145/3173574.3174020},
	abstract = {We present a mobile system that enhances mixed reality experiences and games with force feedback by means of electrical muscle stimulation (EMS). The benefit of our approach is that it adds physical forces while keeping the users’ hands free to interact unencumbered—not only with virtual objects, but also with physical objects, such as props and appliances. We demonstrate how this supports three classes of applications along the mixed-reality continuum: (1) entirely virtual objects, such as furniture with EMS friction when pushed or an EMS-based catapult game. (2) Virtual objects augmented via passive props with EMSconstraints, such as a light control panel made tangible by means of a physical cup or a balance-the-marble game with an actuated tray. (3) Augmented appliances with virtual behaviors, such as a physical thermostat dial with EMSdetents or an escape-room that repurposes lamps as levers with detents. We present a user-study in which participants rated the EMS-feedback as significantly more realistic than a no-EMS baseline.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {Lopes, Pedro and You, Sijing and Ion, Alexandra and Baudisch, Patrick},
	year = {2018},
	pages = {1--13},
}

@article{correia2020,
	title = {Affordances and {Constraints} in {Interactive} {Audio} / {Visual} {Systems}},
	volume = {7},
	issn = {2409-9708},
	url = {http://eudl.eu/doi/10.4108/eai.23-4-2020.164000},
	doi = {10.4108/eai.23-4-2020.164000},
	language = {en},
	number = {23},
	urldate = {2020-05-25},
	journal = {EAI Endorsed Transactions on Creative Technologies},
	author = {Correia, Nuno and Masu, Raul},
	month = apr,
	year = {2020},
	pages = {164000},
}

@article{raskar1998,
	title = {Spatially {Augmented} {Reality}},
	abstract = {To create an effective illusion of virtual objects coexisting with the real world, see-through HMD-based Augmented Reality techniques supplement the user's view with images of virtual objects. We introduce here a new paradigm, Spatially Augmented Reality (SAR), where virtual objects are rendered directly within or on the user's physical space.},
	language = {en},
	author = {Raskar, Ramesh and Welch, Greg and Fuchs, Henry},
	month = sep,
	year = {1998},
	pages = {8},
}

@inproceedings{jung2012,
	address = {Copenhagen, Denmark},
	title = {Digital form and materiality: propositions for a new approach to interaction design research},
	isbn = {978-1-4503-1482-4},
	shorttitle = {Digital form and materiality},
	url = {http://dl.acm.org/citation.cfm?doid=2399016.2399115},
	doi = {10.1145/2399016.2399115},
	abstract = {Advanced information and interaction technology pervades everyday life, introducing new forms and meanings of computer applications beyond desktop computers—from varying types of digital devices to interactive fashion and architecture. Motivated by the notion of digital technology as a material for interaction design, this research aims to develop a theoretical foundation to create and critique digital artifacts in the context of interaction design and HCI research. Specifically we conceptualize digital form and materiality as two reciprocal aspects of digital artifact based on the perspectives from relevant disciplines including design, arts, craft, material culture and philosophy of technology. The conceptualization emphasizes the process of making, personal meanings, and socio-cultural values of digital artifacts, constructing a new theoretical framework for exploratory and critical research approaches. In the end we discuss a proposal for form-driven interaction design research as a new approach to HCI with its focus on form and materiality aspects of digital artifacts based on the reflection on our theoretical propositions.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the 7th {Nordic} {Conference} on {Human}-{Computer} {Interaction} {Making} {Sense} {Through} {Design} - {NordiCHI} '12},
	publisher = {ACM Press},
	author = {Jung, Heekyoung and Stolterman, Erik},
	year = {2012},
	pages = {645},
}

@inproceedings{lopes2017,
	address = {Denver Colorado USA},
	title = {Providing {Haptics} to {Walls} \& {Heavy} {Objects} in {Virtual} {Reality} by {Means} of {Electrical} {Muscle} {Stimulation}},
	isbn = {978-1-4503-4655-9},
	url = {https://dl.acm.org/doi/10.1145/3025453.3025600},
	doi = {10.1145/3025453.3025600},
	abstract = {We explore how to add haptics to walls and other heavy objects in virtual reality. When a user tries to push such an object, our system actuates the user’s shoulder, arm, and wrist muscles by means of electrical muscle stimulation, creating a counter force that pulls the user's arm backwards. Our device accomplishes this in a wearable form factor.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lopes, Pedro and You, Sijing and Cheng, Lung-Pan and Marwecki, Sebastian and Baudisch, Patrick},
	month = may,
	year = {2017},
	pages = {1471--1482},
}

@inproceedings{obrist2014,
	address = {Toronto, Ontario, Canada},
	title = {Temporal, affective, and embodied characteristics of taste experiences: a framework for design},
	isbn = {978-1-4503-2473-1},
	shorttitle = {Temporal, affective, and embodied characteristics of taste experiences},
	url = {http://dl.acm.org/citation.cfm?doid=2556288.2557007},
	doi = {10.1145/2556288.2557007},
	abstract = {We present rich descriptions of taste experience through an analysis of the diachronic and synchronic experiences of each of the five basic taste qualities: sweet, sour, salt, bitter, and umami. Our findings, based on a combination of user experience evaluation techniques highlight three main themes: temporality, affective reactions, and embodiment. We present the taste characteristics as a framework for design and discuss each taste in order to elucidate the design qualities of individual taste experiences. These findings add a semantic understanding of taste experiences, their temporality enhanced through descriptions of the affective reactions and embodiment that the five basic tastes elicit. These findings are discussed on the basis of established psychological and behavioral phenomena, highlighting the potential for taste-enhanced design.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the 32nd annual {ACM} conference on {Human} factors in computing systems - {CHI} '14},
	publisher = {ACM Press},
	author = {Obrist, Marianna and Comber, Rob and Subramanian, Sriram and Piqueras-Fiszman, Betina and Velasco, Carlos and Spence, Charles},
	year = {2014},
	pages = {2853--2862},
}

@article{obrist2016,
	title = {Sensing the future of {HCI}: touch, taste, and smell user interfaces},
	volume = {23},
	issn = {10725520},
	shorttitle = {Sensing the future of {HCI}},
	url = {http://dl.acm.org/citation.cfm?doid=2991131.2973568},
	doi = {10.1145/2973568},
	language = {en},
	number = {5},
	urldate = {2020-05-25},
	journal = {interactions},
	author = {Obrist, Marianna and Velasco, Carlos and Vi, Chi and Ranasinghe, Nimesha and Israr, Ali and Cheok, Adrian and Spence, Charles and Gopalakrishnakone, Ponnampalam},
	month = aug,
	year = {2016},
	pages = {40--49},
}

@article{sharma1998,
	title = {Toward multimodal human-computer interface},
	volume = {86},
	issn = {00189219},
	url = {http://ieeexplore.ieee.org/document/664275/},
	doi = {10.1109/5.664275},
	language = {en},
	number = {5},
	urldate = {2020-05-25},
	journal = {Proceedings of the IEEE},
	author = {Sharma, R. and Pavlovic, V.I. and Huang, T.S.},
	month = may,
	year = {1998},
	pages = {853--869},
}

@inproceedings{vidyarthi2012,
	address = {Newcastle Upon Tyne, United Kingdom},
	title = {Sonic {Cradle}: designing for an immersive experience of meditation by connecting respiration to music},
	isbn = {978-1-4503-1210-3},
	shorttitle = {\textit{{Sonic} {Cradle}}},
	url = {http://dl.acm.org/citation.cfm?doid=2317956.2318017},
	doi = {10.1145/2317956.2318017},
	abstract = {Sonic Cradle is a chamber of complete darkness where users shape a peaceful soundscape using only their respiration. This interactive system was designed to foster a meditative experience by facilitating users’ sense of immersion while following a specific attentional pattern characteristic of mindfulness. The goal of Sonic Cradle is twofold: first, to trigger the proven effects of mindfulness on stress, and second, to help teach and demystify the concept of meditation for users’ long-term benefit. This paper presents the design phase of the project, starting by theoretically grounding the initial concept. We then discuss 15 co-design sessions which provided informal conceptual validation and led to several concrete design iterations aimed at balancing users’ perceived sense of control. The presented approach to designing an interactive stress management system can be considered research through design, as it also resulted in a novel theoretical framework for the psychology of media immersion which has implications for a wide range of research areas.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the {Designing} {Interactive} {Systems} {Conference} on - {DIS} '12},
	publisher = {ACM Press},
	author = {Vidyarthi, Jay and Riecke, Bernhard E. and Gromala, Diane},
	year = {2012},
	pages = {408},
}

@article{deguzman2020,
	title = {Security and {Privacy} {Approaches} in {Mixed} {Reality}: {A} {Literature} {Survey}},
	volume = {52},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Security and {Privacy} {Approaches} in {Mixed} {Reality}},
	url = {http://arxiv.org/abs/1802.05797},
	doi = {10.1145/3359626},
	abstract = {Mixed reality (MR) technology development is now gaining momentum due to advances in computer vision, sensor fusion, and realistic display technologies. With most of the research and development focused on delivering the promise of MR, there is only barely a few working on the privacy and security implications of this technology. This survey paper aims to put in to light these risks, and to look into the latest security and privacy work on MR. Specifically, we list and review the different protection approaches that have been proposed to ensure user and data security and privacy in MR. We extend the scope to include work on related technologies such as augmented reality (AR), virtual reality (VR), and human-computer interaction (HCI) as crucial components, if not the origins, of MR, as well as numerous related work from the larger area of mobile devices, wearables, and Internet-of-Things (IoT). We highlight the lack of investigation, implementation, and evaluation of data protection approaches in MR. Further challenges and directions on MR security and privacy are also discussed.},
	language = {en},
	number = {6},
	urldate = {2020-05-25},
	journal = {ACM Computing Surveys},
	author = {de Guzman, Jaybie A. and Thilakarathna, Kanchana and Seneviratne, Aruna},
	month = jan,
	year = {2020},
	keywords = {Computer Science - Computers and Society, Computer Science - Cryptography and Security, Computer Science - Human-Computer Interaction},
	pages = {1--37},
}

@inproceedings{metatla2016,
	address = {San Jose California USA},
	title = {Tap the {ShapeTones}: {Exploring} the {Effects} of {Crossmodal} {Congruence} in an {Audio}-{Visual} {Interface}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {Tap the {ShapeTones}},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858456},
	doi = {10.1145/2858036.2858456},
	abstract = {There is growing interest in the application of crossmodal perception to interface design. However, most research has focused on task performance measures and often ignored user experience and engagement. We present an examination of crossmodal congruence in terms of performance and engagement in the context of a memory task of audio, visual, and audio-visual stimuli. Participants in a ﬁrst study showed improved performance when using a visual congruent mapping that was cancelled by the addition of audio to the baseline conditions, and a subjective preference for the audio-visual stimulus that was not reﬂected in the objective data. Based on these ﬁndings, we designed an audio-visual memory game to examine the effects of crossmodal congruence on user experience and engagement. Results showed higher engagement levels with congruent displays with some reported preference for potential challenge and enjoyment that an incongruent display may support, particularly for increased task complexity.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Metatla, Oussama and Correia, Nuno N. and Martin, Fiore and Bryan-Kinns, Nick and Stockman, Tony},
	month = may,
	year = {2016},
	pages = {1055--1066},
}

@inproceedings{tieben2011,
	title = {Curiosity and {Interaction}: making people curious through interactive systems},
	shorttitle = {Curiosity and {Interaction}},
	url = {https://scienceopen.com/document?vid=3d7cfbf0-7c46-4a52-8bbb-3e5bc60842b2},
	doi = {10.14236/ewic/HCI2011.66},
	language = {en},
	urldate = {2020-05-25},
	author = {Tieben, Rob and Bekker, Tilde and Schouten, Ben},
	month = jul,
	year = {2011},
}

@article{baldassi2018,
	title = {Challenges and {New} {Directions} in {Augmented} {Reality}, {Computer} {Security}, and {Neuroscience} -- {Part} 1: {Risks} to {Sensation} and {Perception}},
	shorttitle = {Challenges and {New} {Directions} in {Augmented} {Reality}, {Computer} {Security}, and {Neuroscience} -- {Part} 1},
	url = {http://arxiv.org/abs/1806.10557},
	abstract = {Rapidly advancing AR technologies are in a unique position to directly mediate between the human brain and the physical world. Though this tight coupling presents tremendous opportunities for human augmentation, it also presents new risks due to potential adversaries, including AR applications or devices themselves, as well as bugs or accidents. In this paper, we begin exploring potential risks to the human brain from augmented reality. Our initial focus is on sensory and perceptual risks (e.g., accidentally or maliciously induced visual adaptations, motion-induced blindness, and photosensitive epilepsy), but similar risks may span both lower- and higher-level human brain functions, including cognition, memory, and decision-making. Though they have not yet manifested in practice in early-generation AR technologies, we believe that such risks are uniquely dangerous in AR due to the richness and depth with which it interacts with a user's experience of the physical world. We propose a framework, based in computer security threat modeling, to conceptually and experimentally evaluate such risks. The ultimate goal of our work is to aid AR technology developers, researchers, and neuroscientists to consider these issues before AR technologies are widely deployed and become targets for real adversaries. By considering and addressing these issues now, we can help ensure that future AR technologies can meet their full, positive potential.},
	urldate = {2020-05-25},
	journal = {arXiv:1806.10557 [cs]},
	author = {Baldassi, Stefano and Kohno, Tadayoshi and Roesner, Franziska and Tian, Moqian},
	month = jun,
	year = {2018},
	keywords = {Computer Science - Cryptography and Security},
}

@inproceedings{denning2014,
	address = {Toronto, Ontario, Canada},
	title = {In situ with bystanders of augmented reality glasses: perspectives on recording and privacy-mediating technologies},
	isbn = {978-1-4503-2473-1},
	shorttitle = {In situ with bystanders of augmented reality glasses},
	url = {http://dl.acm.org/citation.cfm?doid=2556288.2557352},
	doi = {10.1145/2556288.2557352},
	abstract = {Augmented reality (AR) devices are poised to enter the market. It is unclear how the properties of these devices will affect individuals’ privacy. In this study, we investigate the privacy perspectives of individuals when they are bystanders around AR devices. We conducted 12 field sessions in cafés and interviewed 31 bystanders regarding their reactions to a co-located AR device. Participants were predominantly split between having indifferent and negative reactions to the device. Participants who expressed that AR devices change the bystander experience attributed this difference to subtleness, ease of recording, and the technology’s lack of prevalence. Additionally, participants surfaced a variety of factors that make recording more or less acceptable, including what they are doing when the recording is being taken. Participants expressed interest in being asked permission before being recorded and in recording-blocking devices. We use the interview results to guide an exploration of design directions for privacymediating technologies.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the 32nd annual {ACM} conference on {Human} factors in computing systems - {CHI} '14},
	publisher = {ACM Press},
	author = {Denning, Tamara and Dehlawi, Zakariya and Kohno, Tadayoshi},
	year = {2014},
	pages = {2377--2386},
}

@techreport{franziskaroesner2020,
	title = {Mixed {Reality}: {Security} {Privacy} and {Safety}},
	url = {https://ar-sec.cs.washington.edu/files/MixedReality_SecurityPrivacySafety_Summit2019.pdf},
	urldate = {2020-05-25},
	institution = {University of Washington},
	editor = {{Franziska Roesner} and Kohno, Tadayoshi},
	year = {2020},
}

@misc{ircam2014,
	title = {Leap {Motion} skeletal tracking in {Max}},
	url = {http://ismm.ircam.fr/leapmotion/},
	abstract = {We developed a new object for using the Leap Motion in Max, based on the Leap Motion SDK V2 Skeletal Tracking Beta.},
	language = {en},
	urldate = {2020-05-25},
	journal = {Sound Music Movement Interaction - ISMM},
	author = {IRCAM},
	month = nov,
	year = {2014},
}

@misc{rode2020,
	title = {{SoundField} by {RØDE} {Plugin}},
	url = {https://www.rode.com/soundfieldplugin},
	urldate = {2020-05-25},
	author = {RØDE},
	year = {2020},
}

@misc{wikipedia2020,
	title = {Inertial measurement unit},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Inertial_measurement_unit&oldid=958821399},
	abstract = {An inertial measurement unit (IMU) is an electronic device that measures and reports a body's specific force, angular rate, and sometimes the orientation of the body, using a combination of accelerometers, gyroscopes, and sometimes magnetometers. IMUs are typically used to maneuver aircraft (an attitude and heading reference system), including unmanned aerial vehicles (UAVs), among many others, and spacecraft, including satellites and landers. Recent developments allow for the production of IMU-enabled GPS devices. An IMU allows a GPS receiver to work when GPS-signals are unavailable, such as in tunnels, inside buildings, or when electronic interference is present.  A wireless IMU is known as a WIMU.},
	language = {en},
	urldate = {2020-05-25},
	journal = {Wikipedia},
	author = {Wikipedia},
	month = may,
	year = {2020},
}

@misc{aftershokz2020,
	title = {Aftershockz {Aeropex}},
	url = {https://aftershokz.co.uk/products/aeropex},
	abstract = {Listen to music through bone vibration with these contemporary Aftershokz Aeropex headphones. The open ear design and bone conduction technology lets you hear external sounds, such as traffic, during use, and the Enhanced Audio feature ensures deeper bass and less vibration. These Aftershokz Aeropex headphones are lightweight for comfortable all-day wearing and can be used during workouts and runs in the rain with an IP67 waterproof rating.},
	language = {en},
	urldate = {2020-05-25},
	journal = {AfterShokz},
	author = {Aftershokz},
	year = {2020},
}

@misc{ultraleap2020,
	title = {Leap {Motion} {Controller}},
	url = {https://www.ultraleap.com/product/leap-motion-controller/},
	abstract = {Small. Fast. Accurate. The LeapMotion Controller is an optical hand tracking module that captures the movements of your hands with unparalleled accuracy.},
	language = {en},
	urldate = {2020-05-25},
	author = {UltraLeap},
	year = {2020},
}

@misc{cycling742020,
	title = {Max {MSP}},
	shorttitle = {What is {Max}?},
	url = {https://cycling74.com/products/max},
	abstract = {Max is an infinitely flexible place to create interactive media software. With in-depth tools for audio, graphics, interaction, and communication, Max is an environment to explore and develop your own ideas.},
	language = {en},
	urldate = {2020-05-25},
	author = {Cycling'74},
	year = {2020},
}

@misc{espressif2020,
	title = {{ESP32}},
	url = {https://www.espressif.com/en/products/socs/esp32/overview},
	urldate = {2020-05-25},
	author = {Espressif},
	year = {2020},
}

@misc{wikipedia2020a,
	title = {Ambisonics},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Ambisonics&oldid=953930554},
	abstract = {Ambisonics is a full-sphere surround sound format: in addition to the horizontal plane, it covers sound sources above and below the listener.Unlike other multichannel surround formats, its transmission channels do not carry speaker signals. Instead, they contain a speaker-independent representation of a sound field called B-format, which is then decoded to the listener's speaker setup. This extra step allows the producer to think in terms of source directions rather than loudspeaker positions, and offers the listener a considerable degree of flexibility as to the layout and number of speakers used for playback.
Ambisonics was developed in the UK in the 1970s under the auspices of the British National Research Development Corporation.
Despite its solid technical foundation and many advantages, Ambisonics had not until recently been a commercial success, and survived only in niche applications and among recording enthusiasts.
With the easy availability of powerful digital signal processing (as opposed to the expensive and error-prone analog circuitry that had to be used during its early years) and the successful market introduction of home theatre surround sound systems since the 1990s, interest in Ambisonics among recording engineers, sound designers, composers, media companies, broadcasters and researchers has returned and continues to increase.},
	language = {en},
	urldate = {2020-05-25},
	journal = {Wikipedia},
	author = {Wikipedia},
	month = apr,
	year = {2020},
}

@misc{oxfordreference2020,
	title = {ocularcentrism},
	url = {https://www.oxfordreference.com/view/10.1093/oi/authority.20110803100245338},
	abstract = {"ocularcentrism" published on  by null.},
	language = {en},
	urldate = {2020-05-25},
	journal = {Oxford Reference},
	author = {Oxford Reference},
	year = {2020},
}

@inproceedings{vi2017,
	address = {Brighton, United Kingdom},
	title = {{TastyFloats}: {A} {Contactless} {Food} {Delivery} {System}},
	isbn = {978-1-4503-4691-7},
	shorttitle = {{TastyFloats}},
	url = {http://dl.acm.org/citation.cfm?doid=3132272.3134123},
	doi = {10.1145/3132272.3134123},
	abstract = {We present two realizations of TastyFloats, a novel system that uses acoustic levitation to deliver food morsels to the users’ tongue. To explore TastyFloats’ associated design framework, we first address the technical challenges to successfully levitate and deliver different types of foods on the tongue. We then conduct a user study, assessing the effect of acoustic levitation on users’ taste perception, comparing three basic taste stimuli (i.e., sweet, bitter and umami) and three volume sizes of droplets (5µL, 10µL and 20µL). Our results show that users perceive sweet and umami easily, even in minimal quantities, whereas bitter is the least detectable taste, despite its typical association with an unpleasant taste experience. Our results are a first step towards the creation of new culinary experiences and innovative gustatory interfaces.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the {Interactive} {Surfaces} and {Spaces} - {ISS} '17},
	publisher = {ACM Press},
	author = {Vi, Chi Thanh and Marzo, Asier and Ablart, Damien and Memoli, Gianluca and Subramanian, Sriram and Drinkwater, Bruce and Obrist, Marianna},
	year = {2017},
	pages = {161--170},
}

@incollection{seah2015,
	address = {Cham},
	title = {Need for {Touch} in {Human} {Space} {Exploration}: {Towards} the {Design} of a {Morphing} {Haptic} {Glove} – {ExoSkin}},
	volume = {9299},
	isbn = {978-3-319-22722-1 978-3-319-22723-8},
	shorttitle = {Need for {Touch} in {Human} {Space} {Exploration}},
	url = {http://link.springer.com/10.1007/978-3-319-22723-8_3},
	abstract = {The spacesuit, particularly the spacesuit glove, creates a barrier between astronauts and their environment. Motivated by the vision of facilitating full-body immersion for effortless space exploration, it is necessary to understand the sensory needs of astronauts during extra-vehicular activities (EVAs). In this paper, we present the outcomes from a two-week field study performed at the Mars Desert Research Station, a facility where crews carry out Marssimulated missions. We used a combination of methods (a haptic logbook, technology probes, and interviews) to investigate user needs for haptic feedback in EVAs in order to inform the design of a haptic glove. Our results contradict the common belief that a haptic technology should always convey as much information as possible, but should rather offer a controllable transfer. Based on these findings, we identified two main design requirements to enhance haptic feedback through the glove: (i) transfer of the shape and pressure features of haptic information and (ii) control of the amount of haptic information. We present the implementation of these design requirements in the form of the concept and first prototype of ExoSkin. ExoSkin is a morphing haptic feedback layer that augments spacesuit gloves by controlling the transfer of haptic information from the outside world onto the astronauts’ skin.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2015},
	publisher = {Springer International Publishing},
	author = {Seah, Sue Ann and Obrist, Marianna and Roudaut, Anne and Subramanian, Sriram},
	editor = {Abascal, Julio and Barbosa, Simone and Fetter, Mirko and Gross, Tom and Palanque, Philippe and Winckler, Marco},
	year = {2015},
	pages = {18--36},
}

@inproceedings{lindeman2008,
	address = {Reno, NV, USA},
	title = {An {Empirical} {Study} of {Hear}-{Through} {Augmented} {Reality}: {Using} {Bone} {Conduction} to {Deliver} {Spatialized} {Audio}},
	isbn = {978-1-4244-1971-5},
	shorttitle = {An {Empirical} {Study} of {Hear}-{Through} {Augmented} {Reality}},
	url = {http://ieeexplore.ieee.org/document/4480747/},
	doi = {10.1109/VR.2008.4480747},
	abstract = {Augmented reality (AR) is the mixing of computer-generated stimuli with real-world stimuli. In this paper, we present results from a controlled, empirical study comparing three ways of delivering spatialized audio for AR applications: a speaker array, headphones, and a bone-conduction headset. Analogous to optical-see-through AR in the visual domain, Hear-Through AR allows users to receive computer-generated audio using the bone-conduction headset, and real-world audio using their unoccluded ears. Our results show that subjects achieved the best accuracy using a speaker array physically located around the listener when stationary sounds were played, but that there was no difference in accuracy between the speaker array and the bone-conduction device for sounds that were moving, and that both devices outperformed standard headphones for moving sounds. Subjective comments by subjects following the experiment support this performance data.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {2008 {IEEE} {Virtual} {Reality} {Conference}},
	publisher = {IEEE},
	author = {Lindeman, Robert W. and Noma, Haruo and de Barros, Paulo Goncalves},
	year = {2008},
	pages = {35--42},
}

@inproceedings{mcduff2017,
	address = {Gothenburg Sweden},
	title = {Pulse and vital sign measurement in mixed reality using a {HoloLens}},
	isbn = {978-1-4503-5548-3},
	url = {https://dl.acm.org/doi/10.1145/3139131.3139134},
	doi = {10.1145/3139131.3139134},
	abstract = {Cardiography, quantitative measurement of the functioning of the heart, traditionally requires customized obtrusive contact sensors. Using new methods photoplethysmography and ballistocardiography signals can be captured using ubiquitous sensors, such as webcams and accelerometers. However, these signals are not visible to the unaided eye. We present Cardiolens - a mixed reality system that enables real-time, hands-free measurement and visualization of blood ow and vital signs from multiple people. e system combines a front-facing webcam, imaging ballistocardiography, and remote imaging photoplethysmography methods for recovering pulse signals. A heads up display allows users to view their own heart rate whenever they are wearing the device and the heart rate and heart rate variability of another person simply by looking at them. Cardiolens provides the wearer with a new way to understand physiological signals and has applications in human-computer interaction and in the study of social psychology.},
	language = {en},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the 23rd {ACM} {Symposium} on {Virtual} {Reality} {Software} and {Technology}},
	publisher = {ACM},
	author = {McDuff, Daniel and Hurter, Christophe and Gonzalez-Franco, Mar},
	month = nov,
	year = {2017},
	pages = {1--9},
}

@article{bohil2011,
	title = {Virtual reality in neuroscience research and therapy},
	volume = {12},
	issn = {1471-003X, 1471-0048},
	url = {http://www.nature.com/articles/nrn3122},
	doi = {10.1038/nrn3122},
	abstract = {Virtual reality (VR) environments are increasingly being used by neuroscientists to simulate natural events and social interactions. VR creates interactive, multimodal sensory stimuli that offer unique advantages over other approaches to neuroscientific research and applications. VR’s compatibility with imaging technologies such as functional MRI allows researchers to present multimodal stimuli with a high degree of ecological validity and control while recording changes in brain activity. Therapists, too, stand to gain from progress in VR technology, which provides a high degree of control over the therapeutic experience. Here we review the latest advances in VR technology and its applications in neuroscience research.},
	language = {en},
	number = {12},
	urldate = {2020-05-25},
	journal = {Nature Reviews Neuroscience},
	author = {Bohil, Corey J. and Alicea, Bradly and Biocca, Frank A.},
	month = dec,
	year = {2011},
	pages = {752--762},
}

@misc{eliasson2020,
	title = {Wunderkammer},
	url = {https://olafureliasson.net/},
	abstract = {Official website of Olafur Eliasson and his studio: Studio Olafur Eliasson},
	urldate = {2020-05-25},
	author = {Eliasson, Olafur},
	year = {2020},
}

@misc{google2020,
	title = {{ARCore}},
	url = {https://developers.google.com/ar},
	abstract = {With ARCore, build new augmented reality experiences that seamlessly blend the digital and physical worlds. Transform the way people play, shop, learn, create, and experience the world together—at Google scale.},
	language = {en},
	urldate = {2020-05-25},
	journal = {ARCore},
	author = {Google},
	year = {2020},
}

@misc{apple2020,
	title = {{ARKit}},
	url = {https://developer.apple.com/augmented-reality/arkit/},
	abstract = {Take advantage of the latest advances in ARKit to create incredible augmented reality experiences for Apple platforms.},
	language = {en},
	urldate = {2020-05-25},
	journal = {ARKit},
	author = {Apple},
	year = {2020},
}

@misc{vuforia2020,
	title = {Vuforia},
	url = {https://library.vuforia.com/getting-started/overview.html},
	urldate = {2020-05-25},
	author = {Vuforia},
	year = {2020},
}

@misc{leapmotion2018,
	title = {Project {North} {Star}},
	url = {https://developer.leapmotion.com/northstar},
	language = {en-US},
	urldate = {2020-05-25},
	journal = {Leap Motion Developer},
	author = {Leap Motion},
	year = {2018},
}

@misc{magicleap2018,
	title = {Magic {Leap} 1},
	url = {https://www.magicleap.com/magic-leap-1},
	abstract = {Step aside VR and smartphone AR. Magic Leap 1 is a wearable spatial computer that brings the physical and digital worlds together as one.},
	language = {en-us},
	urldate = {2020-05-25},
	author = {Magic Leap},
	year = {2018},
}

@incollection{misker2010,
	address = {London},
	title = {Authoring {Immersive} {Mixed} {Reality} {Experiences}},
	isbn = {978-1-84882-732-5 978-1-84882-733-2},
	url = {http://link.springer.com/10.1007/978-1-84882-733-2_14},
	abstract = {Creating a mixed reality experience is a complicated endeavour. From our practice as a media lab in the artistic domain we found that engineering is ‘only’ a first step in creating a mixed reality experience. Designing the appearance and directing the user experience are equally important for creating an engaging, immersive experience. We found that mixed reality artworks provide a very good test bed for studying these topics. This chapter details three steps required for authoring mixed reality experiences: engineering, designing and directing. We will describe a platform (VGE) for creating mixed reality environments that incorporates these steps. A case study (EI4) is presented in which this platform was used to not only engineer the system, but in which an artist was given the freedom to explore the artistic merits of mixed reality as an artistic medium, which involved areas such as the look and feel, multimodal experience and interaction, immersion as a subjective emotion and game play scenarios.},
	language = {en},
	urldate = {2020-05-27},
	booktitle = {The {Engineering} of {Mixed} {Reality} {Systems}},
	publisher = {Springer London},
	author = {Misker, Jan M.V. and van der Ster, Jelle},
	editor = {Dubois, Emmanuel and Gray, Philip and Nigay, Laurence},
	year = {2010},
	pages = {275--291},
}

@article{chng2017,
	title = {Shift-{Life} {Interactive} {Art}: {Mixed}-{Reality} {Artificial} {Ecosystem} {Simulation}},
	volume = {26},
	issn = {1054-7460, 1531-3263},
	shorttitle = {Shift-{Life} {Interactive} {Art}},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/PRES_a_00291},
	doi = {10.1162/PRES_a_00291},
	abstract = {This article presents a detailed design, development and implementation of a Mixed Reality Art-Science collaboration project which was exhibited during Darwin’s bicentenary exhibition at Shrewsbury, England. As an artist-led project the concerns of the artist were paramount, and this article presents Shift-Life as part of an on-going exploration into the parallels between the non-linear human thinking process and computation using semantic association to link items into ideas, and ideas into holistic concepts. Our art explores perceptions and states of mind as we move our attention between the simulated world of the computer and the real-world we inhabit, which means that any viewer engagement is participatory rather than passive. From a Mixed Reality point of view, the lead author intends to explore the convergence of the physical and virtual, therefore the formalization of the Mixed Reality system, focusing on the integration of artificial life, ecology, physical sensors and participant interaction through an interface of physical props. It is common for digital media artists to allow viewers to activate a work either through a computer screen via direct keyboard or mouse manipulation, or through immersive means to activate their work, for “Shift-Life” the artist was concerned with a direct “relational” approach where viewers would intuitively engage with the installation’s everyday objects, and with each other, to fully experience the piece. The Mixed Reality system is mediated via physical environmental sensors, which affect the virtual environment and autonomous agents, which in turn reacts and is expressed as virtual pixels projected onto a physical surface. The tangible hands-on interface proved to be instinctive, attractive and informative on many levels, delivering a good example of collaboration between the Arts and Science.},
	language = {en},
	number = {2},
	urldate = {2020-05-27},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Ch’ng, Eugene and Harrison, Dew and Moore, Samantha},
	month = may,
	year = {2017},
	pages = {157--181},
}

@misc{gottschalk2017,
	title = {Move {Over}, {Virtual} {Reality}—a {New} {Artistic} {Medium} {Is} about to {Emerge}},
	url = {https://www.artsy.net/article/artsy-editorial-move-virtual-reality-new-artistic-medium-emerge},
	abstract = {This week at The Armory Show, a new technology-driven medium, mixed reality, makes its debut courtesy of Studio Drift and Microsoft’s HoloLens.},
	language = {en},
	urldate = {2020-05-27},
	journal = {Artsy},
	author = {Gottschalk, Molly},
	month = mar,
	year = {2017},
}

@inproceedings{berthaut2016,
	address = {Niagara Falls, Ontario, Canada},
	title = {{ControllAR}: {Appropriation} of {Visual} {Feedback} on {Control} {Surfaces}},
	isbn = {978-1-4503-4248-3},
	shorttitle = {{ControllAR}},
	url = {http://dl.acm.org/citation.cfm?doid=2992154.2992170},
	doi = {10.1145/2992154.2992170},
	abstract = {Despite the development of touchscreens, many expert systems for working with digital multimedia content, such as in music composition and performance, video editing or visual performance, still rely on control surfaces. This can be due to the accuracy and appropriateness of their sensors, the haptic feedback that they offer, and most importantly the way they can be adapted to the speciﬁc subset of gestures and tasks that users need to perform. On the other hand, visual feedback on controllers remains limited and/or ﬁxed, preventing similar personalizing. In this paper, we propose ControllAR, a novel system that facilitates the appropriation of rich visual feedback on control surfaces through remixing of graphical user interfaces and augmented reality display. We then use our system to study current and potential appropriation of visual feedback in the case of digital musical instruments and derive guidelines for designers and developers.},
	language = {en},
	urldate = {2020-05-27},
	booktitle = {Proceedings of the 2016 {ACM} on {Interactive} {Surfaces} and {Spaces} - {ISS} '16},
	publisher = {ACM Press},
	author = {Berthaut, Florent and Jones, Alex},
	year = {2016},
	pages = {271--277},
}

@misc{combinereality2020,
	title = {Portable {Project} {Northstar} {Rig}},
	shorttitle = {{CombineReality} on {Twitter}},
	url = {https://twitter.com/CombineReality/status/1252638433870143488},
	language = {en},
	urldate = {2020-05-26},
	journal = {Twitter},
	author = {Combine Reality},
	month = apr,
	year = {2020},
}

@misc{unitytechnologies2020,
	title = {{Unity3D}},
	url = {https://www.unity.com/},
	abstract = {New address, same Unity3d. Unity real-time development platform. Create 3D, 2D VR \& AR visualizations for Games, Auto, Transportation, Film, Animation, Architecture, Engineering \& more.,},
	language = {en},
	urldate = {2020-05-26},
	author = {Unity Technologies},
	year = {2020},
}

@article{martin2017,
	title = {Percussionist-{Centred} {Design} for {Touchscreen} {Digital} {Musical} {Instruments}},
	volume = {36},
	issn = {0749-4467, 1477-2256},
	url = {https://www.tandfonline.com/doi/full/10.1080/07494467.2017.1370794},
	doi = {10.1080/07494467.2017.1370794},
	language = {en},
	number = {1-2},
	urldate = {2020-05-26},
	journal = {Contemporary Music Review},
	author = {Martin, Charles P.},
	month = mar,
	year = {2017},
	pages = {64--85},
}

@inproceedings{turchet2018,
	address = {Wrexham, United Kingdom},
	title = {Smart {Mandolin}: autobiographical design, implementation, use cases, and lessons learned},
	isbn = {978-1-4503-6609-0},
	shorttitle = {Smart {Mandolin}},
	url = {http://dl.acm.org/citation.cfm?doid=3243274.3243280},
	doi = {10.1145/3243274.3243280},
	abstract = {This paper presents the Smart Mandolin, an exemplar of the family of the so-called smart instruments. Developed according to the paradigms of autobiographical design, it consists of a conventional acoustic mandolin enhanced with different types of sensors, a microphone, a loudspeaker, wireless connectivity to both local networks and the Internet, and a low-latency audio processing board. Various implemented use cases are presented, which leverage the smart qualities of the instrument. These include the programming of the instrument via applications for smartphones and desktop computer, as well as the wireless control of devices enabling multimodal performances such as screen projecting visuals, smartphones, and tactile devices used by the audience. The paper concludes with an evaluation conducted by the author himself after extensive use, which pinpointed pros and cons of the instrument and provided a comparison with the Hyper-Mandolin, an instance of augmented instruments previously developed by the author.},
	language = {en},
	urldate = {2020-05-26},
	booktitle = {Proceedings of the {Audio} {Mostly} 2018 on {Sound} in {Immersion} and {Emotion}  - {AM}'18},
	publisher = {ACM Press},
	author = {Turchet, Luca},
	year = {2018},
	pages = {1--7},
}

@inproceedings{unander-scharin2014,
	address = {Toronto, Ontario, Canada},
	title = {The vocal chorder: empowering opera singers with a large interactive instrument},
	isbn = {978-1-4503-2473-1},
	shorttitle = {The vocal chorder},
	url = {http://dl.acm.org/citation.cfm?doid=2556288.2557050},
	doi = {10.1145/2556288.2557050},
	abstract = {With The Vocal Chorder, a large interactive instrument to create accompaniment, opera singers can get more power over the performance. The device allows performers to interactively accompany themselves through pushing, leaning on and bending steel wires. The design was guided by the unique needs of the solo-singer, explored through autobiographical design and material explorations, some on stage, and later tested by other singers. We discuss how designing for opera and for the stage requires extraordinary durability and how opera performances can change with a bodilyoriented instrument such as The Vocal Chorder. Through a designerly exploration, we arrived at a device that offered (1) a tool for singers to take control over the rhythmical pace and overall artistic and aesthetic outcome of their performances, (2) an enriched sense of embodiment between their voice and the overall performance; and (3) a means to empower opera singers on stage.},
	language = {en},
	urldate = {2020-05-26},
	booktitle = {Proceedings of the 32nd annual {ACM} conference on {Human} factors in computing systems - {CHI} '14},
	publisher = {ACM Press},
	author = {Unander-Scharin, Carl and Unander-Scharin, Asa and Höök, Kristina},
	year = {2014},
	pages = {1001--1010},
}

@article{magnusson2009,
	title = {Of {Epistemic} {Tools}: musical instruments as cognitive extensions},
	volume = {14},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Of {Epistemic} {Tools}},
	url = {https://www.cambridge.org/core/product/identifier/S1355771809000272/type/journal_article},
	doi = {10.1017/S1355771809000272},
	abstract = {This paper explores the differences in the design and performance of acoustic and new digital musical instruments, arguing that with the latter there is an increased encapsulation of musical theory. The point of departure is the phenomenology of musical instruments, which leads to the exploration of designed artefacts as extensions of human cognition – as scaffolding onto which we delegate parts of our cognitive processes. The paper succinctly emphasises the pronounced epistemic dimension of digital instruments when compared to acoustic instruments. Through the analysis of material epistemologies it is possible to describe the digital instrument as an
              epistemic tool
              : a designed tool with such a high degree of symbolic pertinence that it becomes a system of knowledge and thinking in its own terms. In conclusion, the paper rounds up the phenomenological and epistemological arguments, and points at issues in the design of digital musical instruments that are germane due to their strong aesthetic implications for musical culture.},
	language = {en},
	number = {2},
	urldate = {2020-05-26},
	journal = {Organised Sound},
	author = {Magnusson, Thor},
	month = aug,
	year = {2009},
	pages = {168--176},
}

@article{hutmacher2019,
	title = {Why {Is} {There} {So} {Much} {More} {Research} on {Vision} {Than} on {Any} {Other} {Sensory} {Modality}?},
	volume = {10},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2019.02246/full},
	doi = {10.3389/fpsyg.2019.02246},
	abstract = {Why is there so much more research on vision than on any other sensory modality? There is a seemingly easy answer to this question: It is because vision is our most important and most complex sense. Although there are arguments in favor of this explanation, it can be challenged in two ways: by showing that the arguments regarding the importance and complexity of vision are debatable and by demonstrating that there are other aspects that need to be taken into account. Here, I argue that the explanation is debatable, as there are various ways of deﬁning “importance” and “complexity” and, as there is no clear consensus that vision is indeed the most important and most complex of our senses. Hence, I propose two additional explanations: According to the methodological-structural explanation, there is more research on vision because the available, present-day technology is better suited for studying vision than for studying other modalities – an advantage which most likely is the result of an initial bias toward vision, which reinforces itself. Possible reasons for such an initial bias are discussed. The cultural explanation emphasizes that the dominance of the visual is not an unchangeable constant, but rather the result of the way our societies are designed and thus heavily inﬂuenced by human decision-making. As it turns out, there is no universal hierarchy of the senses, but great historical and cross-cultural variation. Realizing that the dominance of the visual is socially and culturally reinforced and not simply a law of nature, gives us the opportunity to take a step back and to think about the kind of sensory environments we want to create and about the kinds of theories that need to be developed in research.},
	language = {en},
	urldate = {2020-05-26},
	journal = {Frontiers in Psychology},
	author = {Hutmacher, Fabian},
	month = oct,
	year = {2019},
	pages = {2246},
}

@misc{constanzo2015,
	title = {Tool: karma{\textasciitilde} (sampler/looper external) {\textbar} {Cycling} '74},
	shorttitle = {Tool},
	url = {https://cycling74.com/tools/karma-samplerlooper-external},
	abstract = {karma{\textasciitilde} is a looper/sampler external for Max.},
	language = {en},
	urldate = {2020-05-26},
	author = {Constanzo, Rodrigo},
	month = may,
	year = {2015},
}

@article{rusconi2006,
	title = {Spatial representation of pitch height: the {SMARC} effect},
	volume = {99},
	issn = {00100277},
	shorttitle = {Spatial representation of pitch height},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027705000260},
	doi = {10.1016/j.cognition.2005.01.004},
	abstract = {Through the preferential pairing of response positions to pitch, here we show that the internal representation of pitch height is spatial in nature and affects performance, especially in musically trained participants, when response alternatives are either vertically or horizontally aligned. The ﬁnding that our cognitive system maps pitch height onto an internal representation of space, which in turn affects motor performance even when this perceptual attribute is irrelevant to the task, extends previous studies on auditory perception and suggests an interesting analogy between music perception and mathematical cognition. Both the basic elements of mathematical cognition (i.e. numbers) and the basic elements of musical cognition (i.e. pitches), appear to be mapped onto a mental spatial representation in a way that affects motor performance.},
	language = {en},
	number = {2},
	urldate = {2020-05-26},
	journal = {Cognition},
	author = {Rusconi, Elena and Kwan, Bonnie and Giordano, Bruno and Umilta, Carlo and Butterworth, Brian},
	month = mar,
	year = {2006},
	pages = {113--129},
}

@article{weis2016,
	title = {{SNARC} (spatial–numerical association of response codes) meets {SPARC} (spatial–pitch association of response codes): {Automaticity} and interdependency in compatibility effects},
	volume = {69},
	issn = {1747-0218, 1747-0226},
	shorttitle = {{SNARC} (spatial–numerical association of response codes) meets {SPARC} (spatial–pitch association of response codes)},
	url = {http://journals.sagepub.com/doi/10.1080/17470218.2015.1082142},
	doi = {10.1080/17470218.2015.1082142},
	language = {en},
	number = {7},
	urldate = {2020-05-26},
	journal = {Quarterly Journal of Experimental Psychology},
	author = {Weis, Tina and Estner, Barbara and van Leeuwen, Cees and Lachmann, Thomas},
	month = jul,
	year = {2016},
	pages = {1366--1383},
}

@article{timmers2016,
	title = {Representation of pitch in horizontal space and its dependence on musical and instrumental experience.},
	volume = {26},
	issn = {2162-1535, 0275-3987},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/pmu0000146},
	doi = {10.1037/pmu0000146},
	abstract = {Representation of pitch in horizontal space and its relationship to musical and instrumental experience was examined in three behavioral experiments. Each experiment investigated the influence of a task-irrelevant dimension (pitch or location) on the perception of a taskrelevant dimension (location or pitch, respectively). Sine tones with nine different pitches were presented from nine locations, and participants estimated the pitch or location of the stimuli. Experiment 1 showed an influence of the (task irrelevant) pitch of presented stimuli on the perceived location of the stimuli in musically experienced participants only. This influence increased with the degree of musical training of participants. No influence was found of presented location on the perception of pitch. Experiments 2 and 3 investigated the influence of instrumental expertise comparing the responses of a group of flutists with a group of pianists. An interaction with instrumental expertise was found only in Experiment 3, where participants played shortly on their respective instruments before doing the perceptual judgments. The experiments indicate that musical training in general influence the pitchlocation association, and pianistic experience in particular.},
	language = {en},
	number = {2},
	urldate = {2020-05-26},
	journal = {Psychomusicology: Music, Mind, and Brain},
	author = {Timmers, Renee and Li, Shen},
	year = {2016},
	pages = {139--148},
}

@incollection{godoy2006,
	address = {Berlin, Heidelberg},
	title = {Playing “{Air} {Instruments}”: {Mimicry} of {Sound}-{Producing} {Gestures} by {Novices} and {Experts}},
	volume = {3881},
	isbn = {978-3-540-32624-3 978-3-540-32625-0},
	shorttitle = {Playing “{Air} {Instruments}”},
	url = {http://link.springer.com/10.1007/11678816_29},
	abstract = {Both musicians and non-musicians can often be seen making sound-producing gestures in the air without touching any real instruments. Such ”air playing” can be regarded as an expression of how people perceive and imagine music, and studying the relationships between these gestures and sound might contribute to our knowledge of how gestures help structure our experience of music.},
	language = {en},
	urldate = {2020-05-26},
	booktitle = {Gesture in {Human}-{Computer} {Interaction} and {Simulation}},
	publisher = {Springer Berlin Heidelberg},
	author = {Godøy, Rolf Inge and Haga, Egil and Jensenius, Alexander Refsum},
	editor = {Gibet, Sylvie and Courty, Nicolas and Kamp, Jean-François},
	year = {2006},
	pages = {256--267},
}

@article{lidji2007,
	title = {Spatial associations for musical stimuli: {A} piano in the head?},
	volume = {33},
	issn = {1939-1277, 0096-1523},
	shorttitle = {Spatial associations for musical stimuli},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-1523.33.5.1189},
	doi = {10.1037/0096-1523.33.5.1189},
	abstract = {This study was aimed at examining whether pitch height and pitch change are mentally represented along spatial axes. A series of experiments explored, for isolated tones and 2-note intervals, the occurrence of effects analogous to the spatial numerical association of response codes (SNARC) effect. Response device orientation (horizontal vs. vertical), task, and musical expertise of the participants were manipulated. The pitch of isolated tones triggered the automatic activation of a vertical axis independently of musical expertise, but the contour of melodic intervals did not. By contrast, automatic associations with the horizontal axis seemed linked to music training for pitch and, to a lower extent, for intervals. These results, discussed in the light of studies on number representation, provide a new example of the effects of musical expertise on music cognition.},
	language = {en},
	number = {5},
	urldate = {2020-05-26},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Lidji, Pascale and Kolinsky, Régine and Lochy, Aliette and Morais, José},
	year = {2007},
	pages = {1189--1207},
}

@incollection{caramiaux2010,
	address = {Berlin, Heidelberg},
	title = {Towards a {Gesture}-{Sound} {Cross}-{Modal} {Analysis}},
	volume = {5934},
	isbn = {978-3-642-12552-2 978-3-642-12553-9},
	url = {http://link.springer.com/10.1007/978-3-642-12553-9_14},
	abstract = {This article reports on the exploration of a method based on canonical correlation analysis (CCA) for the analysis of the relationship between gesture and sound in the context of music performance and listening. This method is a ﬁrst step in the design of an analysis tool for gesture-sound relationships. In this exploration we used motion capture data recorded from subjects performing free hand movements while listening to short sound examples. We assume that even though the relationship between gesture and sound might be more complex, at least part of it can be revealed and quantiﬁed by linear multivariate regression applied to the motion capture data and audio descriptors extracted from the sound examples. After outlining the theoretical background, the article shows how the method allows for pertinent reasoning about the relationship between gesture and sound by analysing the data sets recorded from multiple and individual subjects.},
	language = {en},
	urldate = {2020-05-26},
	booktitle = {Gesture in {Embodied} {Communication} and {Human}-{Computer} {Interaction}},
	publisher = {Springer Berlin Heidelberg},
	author = {Caramiaux, Baptiste and Bevilacqua, Frédéric and Schnell, Norbert},
	year = {2010},
	pages = {158--170},
}

@misc{notion2020,
	title = {Notion – {The} all-in-one workspace for your notes, tasks, wikis, and databases.},
	url = {https://www.notion.so},
	abstract = {A new tool that blends your everyday work apps into one. It's the all-in-one workspace for you and your team},
	language = {en},
	urldate = {2020-05-25},
	journal = {Notion},
	author = {Notion},
	year = {2020},
}

@inproceedings{schacher2006,
	address = {New Orleans, Louisiana, USA},
	title = {Ambisonics {Spatialization} {Tools} for {Max}/{MSP}},
	volume = {2006},
	url = {http://decoy.iki.fi/dsound/ambisonic/motherlode/source/ICST_Ambisonics_ICMC2006.pdf},
	urldate = {2020-05-25},
	booktitle = {Proceedings of the 2006 {International} {Computer} {Music} {Conference}},
	publisher = {Michigan Publishing},
	author = {Schacher, Jan and Kocher, Philippe},
	year = {2006},
	pages = {274--277},
}

@inproceedings{hayes2018,
	address = {Genoa Italy},
	title = {Live {Electronic} {Music} {Performance}: {Embodied} and {Enactive} {Approaches}},
	isbn = {978-1-4503-6504-8},
	shorttitle = {Live {Electronic} {Music} {Performance}},
	url = {https://dl.acm.org/doi/10.1145/3212721.3212891},
	doi = {10.1145/3212721.3212891},
	abstract = {Mini Savior Opt. (2017) is a twenty-five minute live electronic performance which demonstrates an enactive and embodied approach to interactive and improvisational music systems. The piece was formed out of a playful exploration of my most recent hybrid analogue/digital performance system. An excessive number of components mutually affect each other through an ecological network of sound analysis and digital signal processing (DSP). Engaging with different parts of the instrument through tangible and haptic controllers, I bring a sense of immediacy into my hands: the slightest movement may trigger a drastic change in sound, which in turn may activate other processes within the network. Through the physical struggle, the performer, vulnerable to the fragile instabilities that have been potentialised, attempts to navigate the performance space.},
	language = {en},
	urldate = {2020-06-15},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Movement} and {Computing}},
	publisher = {ACM},
	author = {Hayes, Lauren},
	month = jun,
	year = {2018},
	pages = {1--3},
}

@phdthesis{pirro2017,
	address = {Austria},
	title = {Composing {Interactions}},
	language = {en},
	school = {Institute of Electronic Music and Acoustics, University of Music and Performing Arts Graz},
	author = {Pirrò, David},
	year = {2017},
}

@incollection{fazi2016,
	title = {Computational {Aesthetics}},
	url = {https://monoskop.org/images/f/f1/Fazi_M_Beatrice_Fuller_Matthew_2016_Computational_Aesthetics.pdf},
	urldate = {2020-06-11},
	booktitle = {A {Companion} to {Digital} {Art}},
	publisher = {John Wiley \& Sons},
	author = {Fazi, M Beatrice and Fuller, Matthew},
	editor = {Paul, Christiane},
	year = {2016},
}

@article{edmonds2017,
	title = {Systems theory, systems art and the computer: {Ernest} {Edmonds} interviewed by {Francesca} {Franco}},
	volume = {42},
	issn = {0308-0188, 1743-2790},
	shorttitle = {Systems theory, systems art and the computer},
	url = {https://www.tandfonline.com/doi/full/10.1080/03080188.2017.1297158},
	doi = {10.1080/03080188.2017.1297158},
	abstract = {This interview with Edmonds, conducted by Franco in 2016, explores how Systems art, Systems Theory, and his personal relationships with artists such as Malcolm Hughes, Kenneth Martin and Edward Ihnatowicz influenced his art practice.},
	language = {en},
	number = {1-2},
	urldate = {2020-06-11},
	journal = {Interdisciplinary Science Reviews},
	author = {Edmonds, Ernest and Franco, Francesca},
	month = apr,
	year = {2017},
	pages = {169--179},
}

@article{candy2018,
	title = {Practice-{Based} {Research} in the {Creative} {Arts}: {Foundations} and {Futures} from the {Front} {Line}},
	volume = {51},
	issn = {0024-094X, 1530-9282},
	shorttitle = {Practice-{Based} {Research} in the {Creative} {Arts}},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/LEON_a_01471},
	doi = {10.1162/LEON_a_01471},
	language = {en},
	number = {1},
	urldate = {2020-06-11},
	journal = {Leonardo},
	author = {Candy, Linda and Edmonds, Ernest},
	month = feb,
	year = {2018},
	pages = {63--69},
}

@inproceedings{paul2015a,
	address = {Vancouver, BC, Canada},
	title = {From {Immateriality} to {Neomateriality}: {Art} and the {Conditions} of {Digital} {Materiality}},
	abstract = {This paper explores the evolution of materialities in the context of art and digital technologies and proposes “neomateriality” as a current condition of material and objecthood. It traces the evolution from dematerialization and the immaterial to hypermateriality and neomateriality as a term capturing various disruptions that introduce new aesthetic paradigms. The concept of neomateriality strives to describe an objecthood that incorporates networked digital technologies, and embeds, processes, and reflects back the data of humans and the environment, or reveals its own coded materiality and the way in which digital processes see our world.},
	language = {en},
	booktitle = {Proceedings of the 21st {International} {Symposium} on {Electronic} {Art}},
	author = {Paul, Christiane},
	year = {2015},
	pages = {4},
}

@article{rutz2016,
	title = {Agency and {Algorithms}},
	volume = {8},
	issn = {1646-9798},
	url = {http://artes.ucp.pt/citarj/article/view/223},
	doi = {10.7559/citarj.v8i1.223},
	abstract = {Although the concept of algorithms has been established a long time ago, their current topicality indicates a shift in the discourse. Classical definitions based on logic seem to be inadequate to describe their aesthetic capabilities. New approaches stress their involvement in material practices as well as their incompleteness. Algorithmic aesthetics can no longer be tied to the static analysis of programs, but must take into account the dynamic and experimental nature of coding practices. It is suggested that the aesthetic objects thus produced articulate something that could be called algorithmicity or the space of algorithmic agency. This is the space or the medium –following Luhmann’s form/medium distinction – where human and machine undergo mutual incursions. In the resulting coupled “extimate” writing process, human initiative and algorithmic speculation cannot be clearly divided out any longer. An observation is attempted of defining aspects of such a medium by drawing a trajectory across a number of sound pieces. The operation of exchange between form and medium I call reconfiguration and it is indicated by this trajectory.},
	language = {en},
	number = {1},
	urldate = {2020-06-11},
	journal = {Journal of Science and Technology of the Arts},
	author = {Rutz, Hanns Holger},
	month = nov,
	year = {2016},
	pages = {73},
}

@phdthesis{rutz2014,
	title = {Tracing the {Compositional} {Process}. {Sound} art that rewrites its own past: formation, praxis and a computer framework},
	url = {https://pearl.plymouth.ac.uk/bitstream/handle/10026.1/3116/2014rutz10254321phd.pdf?sequence=6&isAllowed=y},
	urldate = {2020-06-11},
	school = {Plymouth University},
	author = {Rutz, Hans Holger},
	year = {2014},
}

@article{edmonds2018,
	title = {Algorithmic {Art} {Machines}},
	volume = {7},
	issn = {2076-0752},
	url = {http://www.mdpi.com/2076-0752/7/1/3},
	doi = {10.3390/arts7010003},
	abstract = {The article reviews the author’s personal development in relation to art made by algorithmic machines and discusses both the nature of such systems and the future implications for art.},
	language = {en},
	number = {1},
	urldate = {2020-06-11},
	journal = {Arts},
	author = {Edmonds, Ernest},
	month = jan,
	year = {2018},
	pages = {3},
}

@article{edmonds2010,
	title = {The {Art} of {Interaction}},
	volume = {21},
	issn = {1462-6268, 1744-3806},
	url = {http://www.tandfonline.com/doi/abs/10.1080/14626268.2010.556347},
	doi = {10.1080/14626268.2010.556347},
	abstract = {Interactive art has become much more common as a result of the many ways in which the computer and the Internet have facilitated it. Issues relating to human– computer interaction (HCI) are as important to interactive art making as issues relating to the colours of paint are to painting. It is not that HCI and art necessarily share goals. It is just that much of the knowledge of HCI and its methods can contribute to interactive art making. This paper reviews recent work that looks at these issues in the art context. In interactive digital art, the artist is concerned with how the artwork behaves, how the audience interacts with it and, ultimately, in participant experience and their degree of engagement. The paper looks at these issues and brings together a collection of research results and art practice experiences that together help to illuminate this signiﬁcant new and expanding area. In particular, it is suggested that this work points towards a much needed critical language that can be used to describe, compare and discuss interactive digital art.},
	language = {en},
	number = {4},
	urldate = {2020-06-11},
	journal = {Digital Creativity},
	author = {Edmonds, Ernest},
	month = dec,
	year = {2010},
	pages = {257--264},
}

@inproceedings{guzman-serrano2019,
	address = {Braga Portugal},
	title = {Where {There} {Are} {Flies}, {Media} {Art} {You}'ll {Find}: {Digital} ({Im})materiality, {Artistic} {Medium}, and {Media} {Art} {Decay}},
	isbn = {978-1-4503-7250-3},
	shorttitle = {Where {There} {Are} {Flies}, {Media} {Art} {You}'ll {Find}},
	url = {https://dl.acm.org/doi/10.1145/3359852.3359903},
	doi = {10.1145/3359852.3359903},
	abstract = {The digital revolution has already left its footprint in the cultural industry by not only introducing new aesthetics and art forms, but also by crucially transforming the practices of museums, libraries, archives, and cultural institutions in general. However, although most museums rely on the use of digital technologies in one way or another, few actively collect and preserve media and digital art. This apparent contradiction has not only endangered the future availability of speciﬁc artworks but it has also impeded the proper contextualization and historicization of media art.},
	language = {en},
	urldate = {2020-06-11},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Digital} and {Interactive} {Arts}},
	publisher = {ACM},
	author = {Guzman-Serrano, Rodrigo},
	month = oct,
	year = {2019},
	pages = {1--7},
}

@inproceedings{kiefer2018,
	address = {Virginia, USA},
	title = {Towards new modes of collective musical expression through audio augmented reality},
	doi = {http://doi.org/10.5281/zenodo.1302661},
	abstract = {We investigate how audio augmented reality can engender new collective modes of musical expression in the context of a sound art installation, Listening Mirrors, exploring the creation of interactive sound environments for musicians and non-musicians alike. Listening Mirrors is designed to incorporate physical objects and computational systems for altering the acoustic environment, to enhance collective listening and challenge traditional musician-instrument performance. At a formative stage in exploring audio AR technology, we conducted an audience experience study investigating questions around the potential of audio AR in creating sound installation environments for collective musical expression. We collected interview evidence about the participants' experience and analysed the data with using a grounded theory approach. The results demonstrated that the technology has the potential to create immersive spaces where an audience can feel safe to experiment musically, and showed how AR can intervene in sound perception to instrumentalise an environment. The results also revealed caveats about the use of audio AR, mainly centred on social inhibition and seamlessness of experience, and finding a balance between mediated worlds to create space for interplay between the two.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Kiefer, Chris and Chevalier, Cécile},
	month = jun,
	year = {2018},
	keywords = {augmented reality, collective musical expression, mobile music making, sound art installation},
	pages = {25--28},
}

@book{billinghurst2015,
	address = {Boston Delft},
	series = {Foundations and trends in human-computer interaction},
	title = {A survey of augmented reality},
	isbn = {978-1-60198-920-8},
	language = {eng},
	number = {8:2-3},
	publisher = {Now},
	author = {Billinghurst, Mark and Clark, Adrian and Lee, Gun},
	year = {2015},
}

@article{burdea1996,
	title = {Multimodal {Virtual} {Reality}: {Input}-{Output} {Devices}, {System} {Integration}, and {Human} {Factors}},
	url = {http://ti.rutgers.edu/publications/papers/1996_ijhci.pdf},
	urldate = {2020-05-28},
	author = {Burdea, Grigore and Coiffet, Paul},
	year = {1996},
}

@article{suhr2018,
	title = {The {Audience} and {Artist} {Interactivity} in {Augmented} {Reality} {Art}: {The} {Solo} {Exhibition} on the \textit{{Flame}} {Series}},
	volume = {32},
	issn = {0256-0046, 1992-6049},
	shorttitle = {The {Audience} and {Artist} {Interactivity} in {Augmented} {Reality} {Art}},
	url = {https://www.tandfonline.com/doi/full/10.1080/02560046.2018.1493054},
	doi = {10.1080/02560046.2018.1493054},
	abstract = {Traditional art exhibitions are typically limited to artworks being viewed on the walls of galleries and museums. While walking around galleries, viewers often view artworks spontaneously within a matter of a few seconds or minutes. The act of viewing artworks can take many forms; one might quickly glance at the works, or stare at them, or intensely view the works as a whole group and/or in part. The frequent assumption is that the artist is communicating their vision from one direction. This paper explores how augmented reality art (AR) has affected viewing behaviours and norms, and the ways in which viewers experience traditional paintings, as well as new media arts. Based on Cecilia Suhr’s invitational solo exhibition, Flame, at the Nameseoul University IANG Gallery in Seoul, Korea, in May 2017, the goal of this paper is threefold: 1) to unpack the conceptual framework of the Flame series by loosely drawing on Deleuze’s notion of “becoming”; 2) to explore audiences’ viewing behaviours of AR art in relation to the inherent characteristics and ontology of the AR medium; and 3) to problematise how the AR medium affects the hegemonic tension between artist and audience in the dichotomisation of active/passive audiences.},
	language = {en},
	number = {3},
	urldate = {2020-05-27},
	journal = {Critical Arts},
	author = {Suhr, H. Cecilia},
	month = may,
	year = {2018},
	pages = {111--125},
}

@article{samanci2014,
	title = {Embodied site-specific animation},
	volume = {20},
	issn = {1354-8565, 1748-7382},
	url = {http://journals.sagepub.com/doi/10.1177/1354856513514335},
	doi = {10.1177/1354856513514335},
	abstract = {Embodied site-specific animation is one of the ways of expanding the conventions of animation and rethinking the animation medium in the digital context. On the air is an interactive installation based on embodied site-specific animation. Existing installations that are based on embodied site-specific animations rely on abstract visualizations and do not attempt to tell a story or portray characters. I am exploring the design strategies and new meaning-making opportunities that arise with the use of embodied site-specific animation for mixed reality art projects.},
	language = {en},
	number = {1},
	urldate = {2020-05-27},
	journal = {Convergence: The International Journal of Research into New Media Technologies},
	author = {Samanci, Ozge},
	month = feb,
	year = {2014},
	pages = {14--24},
}

@article{gould2014,
	title = {Invisible visualities: {Augmented} reality art and the contemporary media ecology},
	volume = {20},
	issn = {1354-8565, 1748-7382},
	shorttitle = {Invisible visualities},
	url = {http://journals.sagepub.com/doi/10.1177/1354856513514332},
	doi = {10.1177/1354856513514332},
	abstract = {Augmented reality (AR) art is a form of artistic expression that complicates traditional notions of the visual arts. A visual AR artist trades in what we might call invisible visualities. In this essay, I consider the questions why does AR art matter as a cultural form of expression? and what does AR art contribute to contemporary technoliterary theoretical discourse? by putting several recent AR artworks into dialogue with some of today’s most important literary-media theorists.},
	language = {en},
	number = {1},
	urldate = {2020-05-27},
	journal = {Convergence: The International Journal of Research into New Media Technologies},
	author = {Gould, Amanda Starling},
	month = feb,
	year = {2014},
	pages = {25--32},
}

@article{holloway-attaway2014,
	title = {Performing materialities: {Exploring} mixed media reality and \textit{{Moby}-{Dick}}},
	volume = {20},
	issn = {1354-8565, 1748-7382},
	shorttitle = {Performing materialities},
	url = {http://journals.sagepub.com/doi/10.1177/1354856513514337},
	doi = {10.1177/1354856513514337},
	abstract = {In my research, I explore mixed reality applications developed to engage and sustain collaborative and participatory digital narratives. In particular, I provide a theoretical context for a collaborative research project, The (re-)Mapping Moby Project, to illustrate how augmented reality tools and social media applications are used to sustain a critical/creative reading of Herman Melville’s 1851 work Moby-Dick through participatory, performative, and locative digital practices. I address how both ‘texts’ and ‘bodies’ assume ontological properties through interfaces and responses that foreground affect, and I demonstrate methods to map locative and narrative shifts as they move from print to digital forms.},
	language = {en},
	number = {1},
	urldate = {2020-05-27},
	journal = {Convergence: The International Journal of Research into New Media Technologies},
	author = {Holloway-Attaway, Lissa},
	month = feb,
	year = {2014},
	pages = {55--68},
}

@inproceedings{brown2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Was that me? {Exploring} the effects of error in gestural digital musical instruments},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411137},
	doi = {10.1145/3411109.3411137},
	abstract = {Traditional Western musical instruments have evolved to be robust and predictable, responding consistently to the same player actions with the same musical response. Consequently, errors occurring in a performance scenario are typically attributed to the performer and thus a hallmark of musical accomplishment is a flawless musical rendition. Digital musical instruments often increase the potential for a second type of error as a result of technological failure within one or more components of the instrument. Gestural instruments using machine learning can be particularly susceptible to these types of error as recognition accuracy often falls short of 100\%, making errors a familiar feature of gestural music performances. In this paper we refer to these technology-related errors as system errors, which can be difficult for players and audiences to disambiguate from performer errors. We conduct a pilot study in which participants repeat a note selection task in the presence of simulated system errors. The results suggest that, for the gestural music system under study, controlled increases in system error correspond to an increase in the occurrence and severity of performer error. Furthermore, we find the system errors reduce a performer's sense of control and result in the instrument being perceived as less accurate and less responsive.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Brown, Dom and Nash, Chris and Mitchell, Thomas J.},
	year = {2020},
	keywords = {augmented reality, game audio, musicology, sonic interaction design, sonification, sound art, spatial audio, virtual reality},
	pages = {168--174},
}

@inproceedings{bisig2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Sounding feet},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411112},
	doi = {10.1145/3411109.3411112},
	abstract = {The project emphSounding Feet explores the creative possibilities of interactively controlling sound synthesis through pressure sensitive shoe inlays that can monitor minute body movements. The project is motivated by the authors' own experience of working with interactive technologies in the context of dance. This experience has led to the desire to more closely relate the sensing capabilities of an interactive system to a dancer's own body awareness which prominently involve aspects of inner perception. The outcome of this project demonstrates that such an approach can help to establish interactive musical scenarios for dance that are not only more intuitive to work with for dancers but that also offer new possibilities for composers to tap into aspects of the dancers' expressivity that are normally hidden for an audience.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Bisig, Daniel and Palacio, Pablo},
	year = {2020},
	keywords = {body awareness, dance and technology, movement sonification, wearable interface},
	pages = {222--228},
}

@inproceedings{jarvis2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Composing in spacetime with rainbows: {Spatial} metacomposition in the real world},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411136},
	doi = {10.1145/3411109.3411136},
	abstract = {There exists a long tradition of incorporating acoustic space as a creative parameter in musical composition and performance. This creative potential has been extended by way of modern sensing and computing technology which allows the position of the listener to act as an input to interactive musical works in immersive, digital environments. Furthermore, the sophistication of sensing technology has reached a point where barriers to implementing these digital interactive musical systems in the physical world are dissolving.In this research we have set out to understand what new modes of artistic performance might be enabled by these interactive spatial musical systems, and what the analysis of these systems can tell us about the compositional principles of arranging musical elements in space as well as time.We have applied a practice-based approach, leveraging processes of software development, composition, and performance to create a complete system for composing and performing what we refer to as spatial metacompositions. The system is tested at scale in the realisation of a musical work based upon the path of a sailplane in flight.Analysis of the work and the supporting system leads us to suggest opportunities exist for extending existing intermodal composition theory through the analysis of audiovisual renderings of performed spatial works. We also point to unique challenges posed by spatial arrangement, such as effective strategies for structuring musical notes in three dimensions as to produce strong harmonic movement.Beyond enabling new modes of artistic expression, the understanding garnered from these musical structures may help inform a more generalisable approach to non-linear composition, leveraging virtual representations of musical space that respond to arbitrary input data.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Jarvis, Robert and Verhagen, Darrin},
	year = {2020},
	keywords = {composition, flight, metacomposition, music, music technology, musical performance, performing arts, sonification},
	pages = {175--182},
}

@inproceedings{barrett2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Deepening presence: {Probing} the hidden artefacts of everyday soundscapes},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411120},
	doi = {10.1145/3411109.3411120},
	abstract = {Sound penetrates our outdoor spaces. Much of it we ignore amidst our fast passage from place to place, its qualities may be too quiet or fleeting to pay heed to above the bustle of our own thoughts, or we may experience the sounds as an annoyance. Manoeuvring our listening to be excited by its features is not so easy.This paper presents new artistic research that probes the hidden artefacts of everyday soundscapes - the sounds and details which we ignore or fail to engage - and draws them into a new audible reality. The work focuses on the affordances of spatial information in a novel combination of art and technology: site-specific composition and the ways of listening established by Schaeffer and his successors are combined with the technology of beam-forming from high resolution (Eigenmike) Ambisonics recordings, Ambisonics sound-field synthesis and the deployment of a new prototype loudspeaker. Underlying the artistic and scientific research is the hypothesis that spatially distributed information offers new opportunities to explore, isolate and musically develop features of interest, and that composition should address the same degree of spatiality as the real landscape. The work is part of the 'Reconfiguring the Landscape' project investigating how 3-D electroacoustic composition and sound-art can incite a new awareness of outdoor sound environments.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Barrett, Natasha},
	year = {2020},
	keywords = {acoustic ecology, acoustics, composition, feature extraction, higher-order ambisonics, loudspeaker technology, sonification, soundscapes},
	pages = {77--84},
}

@inproceedings{toppano2019,
	address = {Nottingham United Kingdom},
	title = {Moving across {Sonic} {Atmospheres}},
	isbn = {978-1-4503-7297-8},
	url = {https://dl.acm.org/doi/10.1145/3356590.3356612},
	doi = {10.1145/3356590.3356612},
	abstract = {The concept of sonic atmosphere has become the focus of an increasing amount of attention in both academic and public forums, but scholars have developed diverging and overlapping definitions of the concept which threatens to inhibit our progress in understanding atmospheric phenomena. This paper draws on recent developments in the field of New Aesthetics and New Phenomenology. In particular, the research work highlights the role a sonic atmosphere has as a backdrop of the acoustic environment and the soundscape, and explores the relationships existing among these concepts. This provides us with a reference framework for studying movement through and between sonic atmospheres and to understand the possible relationships unfolding between an individual' s mood and the affective tonality and affordances of a sonic space. A case study exemplifies the application of the proposed conceptual framework in the field of urban design.},
	language = {en},
	urldate = {2020-09-19},
	booktitle = {Proceedings of the 14th {International} {Audio} {Mostly} {Conference}: {A} {Journey} in {Sound}},
	publisher = {ACM},
	author = {Toppano, Elio and Toppano, Sveva and Basiaco, Alessandro},
	month = sep,
	year = {2019},
	pages = {139--146},
}

@inproceedings{elblaus2020a,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Acoustic modelling as a strategy for composing site-specific music},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411141},
	doi = {10.1145/3411109.3411141},
	abstract = {This paper describes two site-specific musical compositions, focusing on how modelling was used in their respective composition processes. Primarily, the acoustics of the sites were modelled to aid in the preparation and composition of the pieces. From this we propose the general use of modelling as a way to work with the concept of site. But the idea of formulating a model is also applicable more widely in the work described and this is discussed with the two pieces as starting points.Both pieces use acoustic room scale feedback as their only source of sound, so the impact of the room, speakers and microphones used is immense. The first piece, Rundgång, is a commission for the GRM Acousmonium. The second piece, Clockwork, is a public installation that will also be the site of a performance, combining the installation with live interventions. Clockwork will also employ modelling as a component of the piece itself, and include a remote performer and a remote audience. We suggest that there are possibilities to employ compositional strategies to embrace these kinds of hybrid presence situations by composing for many vantage points.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Elblaus, Ludvig and Eckel, Gerhard},
	year = {2020},
	keywords = {acoustics, composition, electroacoustic music, feedback, modelling, presence, room impulse response, site specificity},
	pages = {69--76},
}

@inproceedings{elblaus2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Utruchirp: {An} impulse response measurement and auralisation tool developed for artistic practice},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411140},
	doi = {10.1145/3411109.3411140},
	abstract = {This paper presents the utruchirp software, a tool for measuring impulse responses and modelling room acoustics in real time through auralisation based on convolution using those responses. utruchirp is the result of concerns and needs emerging from the authors' ongoing artistic practice, exploring room scale acoustic feedback as material for live performance, installations, and fixed media pieces as utrumque.The paper provides the technical and, more importantly, the artistic details of the development of utruchirp and its features, highlighting those that are the direct result of insights from artistic work: Monitoring of all stages of measuring and signal processing, auralisations of the measurements from within the measurement process, and integrated round trip delay estimation. Finally, it points out future directions and features that are to be explored next, with an invitation for collaborative efforts, aiming to bring the sensibilities of musical instruments to our measurement tools.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Elblaus, Ludvig and Eckel, Gerhard},
	year = {2020},
	keywords = {acoustics, composition, convolution, electroacoustic music, feedback, impulse response measurement, room modelling},
	pages = {61--68},
}

@inproceedings{walther-hansen2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Don't extend! {Reduce}! {The} sound approach to reality},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411111},
	doi = {10.1145/3411109.3411111},
	abstract = {In this paper we propose a reduced reality concept of less-is-more that VR designers can use to create technological frameworks that reduce sensory overload and allow for better concentration and focus, less stress, and novel scenarios. We question the approach taken by scholars in the field of XR research, where the focus is typically to design and use technology that adds sensory information to the user's perceptual field and we address some of the confusion related to the typical uses of the term reality. To address the latter terminological muddle, we define reality as our conscious experience of the environment as emergent perception and we use this definition as the basis for a discussion of the role of sound in balancing sensory information and in the construction of a less cluttered and less stressful perceptual environments.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Walther-Hansen, Mads and Grimshaw-Aagaard, Mark},
	year = {2020},
	keywords = {augmented reality, cognition, crossmodality, diminished reality, environment, extended reality, listening, presence, reduced reality, sound},
	pages = {8--15},
}

@inproceedings{lin2020,
	address = {Honolulu HI USA},
	title = {{ARchitect}: {Building} {Interactive} {Virtual} {Experiences} from {Physical} {Affordances} by {Bringing} {Human}-in-the-{Loop}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {{ARchitect}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376614},
	doi = {10.1145/3313831.3376614},
	abstract = {Automatic generation of Virtual Reality (VR) worlds which adapt to physical environments have been proposed to enable safe walking in VR. However, such techniques mainly focus on the avoidance of physical objects as obstacles and overlook their interaction affordances as passive haptics. Current VR experiences involving interaction with physical objects in surroundings still require verbal instruction from an assisting partner. We present ARchitect, a proof-of-concept prototype that allows ﬂexible customization of a VR experience with human-in-the-loop. ARchitect brings in an assistant to map physical objects to virtual proxies of matching affordances using Augmented Reality (AR). In a within-subjects study (9 user pairs) comparing ARchitect to a baseline condition, assistants and players experienced decreased workload and players showed increased VR presence and trust in the assistant. Finally, we deﬁned design guidelines of ARchitect for future designers and implemented three demonstrative experiences.},
	language = {en},
	urldate = {2020-09-19},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lin, Chuan-en and Cheng, Ta Ying and Ma, Xiaojuan},
	month = apr,
	year = {2020},
	pages = {1--13},
}

@inproceedings{graham2019,
	address = {Nottingham United Kingdom},
	title = {Composing spatial soundscapes using acoustic metasurfaces},
	isbn = {978-1-4503-7297-8},
	url = {https://dl.acm.org/doi/10.1145/3356590.3356607},
	doi = {10.1145/3356590.3356607},
	abstract = {In this work, we explore the use of acoustic metamaterials in delivering spatially significant acoustic experiences. In particular, we discuss a user study run in a space where a dedicated composition is played through a metamaterial "prism". Results show users perceive sound to be louder in the direction determined by the metamaterial, depending on its frequency. This demonstrates how an acoustic metamaterial prism, in combination with an electronic composer, may be used to deliver different sound messages to different parts of an audience, even with a single speaker. We underpin our conclusions with user observations and heuristic considerations on possible application scenarios.},
	language = {en},
	urldate = {2020-09-19},
	booktitle = {Proceedings of the 14th {International} {Audio} {Mostly} {Conference}: {A} {Journey} in {Sound}},
	publisher = {ACM},
	author = {Graham, Thomas J. and Magnusson, Thor and Rajguru, Chinmay and Yazdan, Arash Pour and Jacobs, Alex and Memoli, Gianluca},
	month = sep,
	year = {2019},
	pages = {103--110},
}

@inproceedings{odea2019,
	address = {Nottingham United Kingdom},
	title = {Auditory {Distraction} in {HCI}: {Towards} a {Framework} for the {Design} of {Hierarchically}-{Graded} {Auditory} {Notifications}},
	isbn = {978-1-4503-7297-8},
	shorttitle = {Auditory {Distraction} in {HCI}},
	url = {https://dl.acm.org/doi/10.1145/3356590.3356601},
	doi = {10.1145/3356590.3356601},
	abstract = {This paper discusses hierarchical structure of auditory distractors based on two human perceptual systems responsible for distinct pre-attentive process:1. the auditory perceptual system and 2. the working memory (WM) system. Specifically, the authors propose accounting for WM function and capacity when designing auditory notifications for multimodal applications, due to interaction between certain auditory attention mechanisms and WM. A review of literature concerning WM disruption caused by auditory streams, as well as reference to relevant ISO (International Organization for Standardization) standards, is also presented.},
	language = {en},
	urldate = {2020-09-19},
	booktitle = {Proceedings of the 14th {International} {Audio} {Mostly} {Conference}: {A} {Journey} in {Sound}},
	publisher = {ACM},
	author = {O'Dea, Ronan and Jedir, Rokaia and Neff, Flaithri},
	month = sep,
	year = {2019},
	pages = {61--66},
}

@inproceedings{iber2019,
	address = {Nottingham United Kingdom},
	title = {Auditory {Augmented} {Reality} for {Cyber} {Physical} {Production} {Systems}},
	isbn = {978-1-4503-7297-8},
	url = {https://dl.acm.org/doi/10.1145/3356590.3356600},
	doi = {10.1145/3356590.3356600},
	abstract = {We describe a proof-of-concept approach on the sonification of estimated operation states of 3D printing processes. The results of this study form the basis for the development of an “intelligent” noise protection headphone as part of Cyber Physical Production Systems, which provides auditorily augmented information to machine operators and enables radio communication between them. Further application areas are implementations in control rooms (equipped with multichannel loudspeaker systems) and utilization for training purposes. The focus of our research lies on situation-specific acoustic processing of conditioned machine sounds and operation related data with high information content, considering the often highly auditorily influenced working knowledge of skilled workers. As a proof-of-concept the data stream of error probability estimations regarding partly manipulated 3D printing processes was mapped to three sonification models, giving evidence about momentary operation states. The neural network applied indicates a high accuracy ({\textgreater}93\%) concerning error estimation distinguishing between normal and manipulated operation states. None of the manipulated states could be identified by listening. An auditory augmentation, respectively sonification of these error estimations provides a considerable benefit to process monitoring.},
	language = {en},
	urldate = {2020-09-19},
	booktitle = {Proceedings of the 14th {International} {Audio} {Mostly} {Conference}: {A} {Journey} in {Sound}},
	publisher = {ACM},
	author = {Iber, Michael and Lechner, Patrik and Jandl, Christian and Mader, Manuel and Reichmann, Michael},
	month = sep,
	year = {2019},
	pages = {53--60},
}

@article{gerzon1973,
	title = {Periphony: {With}-{Height} {Sound} {Reproduction}},
	volume = {21},
	url = {http://decoy.iki.fi/dsound/ambisonic/motherlode/source/Periphony_With-height_sound_reproduction_Michael%20Gerzon_JAES_Jan_Feb_1973.pdf},
	number = {1},
	urldate = {2020-07-22},
	journal = {Journal of The Audio Engeneering Society},
	author = {Gerzon, Michael},
	year = {1973},
	pages = {2--10},
}

@misc{leapmotion2015,
	title = {Touch {Everything} – {Leap} {Motion} {Gallery}},
	url = {https://gallery.leapmotion.com/touch-everything/},
	urldate = {2020-07-22},
	author = {Leap Motion},
	year = {2015},
}

@misc{leapmotion2016,
	title = {{HTC} {Vive} {Setup}},
	url = {https://developer.leapmotion.com/vr-setup/vive},
	abstract = {The VR Developer Kit is available only from the  Leap Motion web store . This setup guide will get you started in minutes.   \_},
	language = {en-US},
	urldate = {2020-07-22},
	journal = {Leap Motion Developer},
	author = {Leap Motion},
	year = {2016},
}

@misc{leapmotion2017,
	title = {Geco {MIDI} – {Leap} {Motion} {Gallery}},
	url = {https://gallery.leapmotion.com/geco-midi/},
	urldate = {2020-07-22},
	author = {Leap Motion},
	year = {2017},
}

@misc{bilbow2020,
	address = {Brighton, United Kingdom},
	title = {area{\textasciitilde} 360° video / ambisonics documentation},
	url = {https://www.youtube.com/watch?v=SPd-f2EXuIQ},
	abstract = {Please use headphones in order to hear the spatial audio effect of both my real and virtual (constructed) environment.
    This is a VR ready 360 video / ambisonics documentation of my system "area{\textasciitilde}" - a gestural sound sampler that uses hand and head tracking to place and manipulate virtual audio nodes in the user’s environment, heard through bone conduction headphones. 
    Through the development of the area{\textasciitilde} system, I call to attention the ability of non-visual augmented reality (AR) displays to provide new aesthetic experiences of real and virtual environments, namely through playful interaction methods such as head and hand gesture, and the use of bone conduction headphones as an audio AR display technology},
	urldate = {2020-07-16},
	author = {Bilbow, Sam},
	month = jul,
	year = {2020},
}

@misc{oculus2019,
	title = {Oculus {Quest}},
	url = {https://www.oculus.com/},
	abstract = {Defy reality and distance with Oculus. Our VR headsets connect people and redefine digital gaming and entertainment. Learn more about Rift, Rift S, Quest and Go.},
	language = {en},
	urldate = {2020-07-12},
	author = {Oculus},
	year = {2019},
}

@misc{valve2019,
	title = {Valve {Index}},
	url = {https://store.steampowered.com/valveindex},
	abstract = {Upgrade your experience.},
	language = {en},
	urldate = {2020-07-12},
	author = {Valve},
	year = {2019},
}

@misc{htc2020,
	title = {{VIVE}},
	url = {https://www.vive.com/uk/product/},
	abstract = {Whether it’s for gaming or business, discover the ideal VIVE device for you, and learn more about what features should be included in a high-end VR solution.},
	urldate = {2020-07-12},
	author = {HTC},
	year = {2020},
}

@misc{oculus2020,
	title = {Oculus {Quest} 2},
	shorttitle = {Oculus {Quest} 2},
	url = {https://www.oculus.com/quest-2/},
	abstract = {Oculus Quest 2 is our most advanced all-in-one VR system yet. Explore an expansive library of awe-inspiring games and immersive experiences with unparalleled freedom.},
	language = {en},
	urldate = {2020-10-01},
	author = {Oculus},
	year = {2020},
}

@book{geroimenko2018,
	address = {Cham},
	series = {Springer {Series} on {Cultural} {Computing}},
	title = {Augmented {Reality} {Art}},
	isbn = {978-3-319-69931-8 978-3-319-69932-5},
	url = {http://link.springer.com/10.1007/978-3-319-69932-5},
	language = {en},
	urldate = {2020-09-22},
	publisher = {Springer International Publishing},
	editor = {Geroimenko, Vladimir},
	year = {2018},
}

@book{geroimenko2014,
	address = {Cham},
	series = {Springer {Series} on {Cultural} {Computing}},
	title = {Augmented {Reality} {Art}: {From} an {Emerging} {Technology} to a {Novel} {Creative} {Medium}},
	isbn = {978-3-319-06202-0 978-3-319-06203-7},
	shorttitle = {Augmented {Reality} {Art}},
	url = {http://link.springer.com/10.1007/978-3-319-06203-7},
	language = {en},
	urldate = {2020-09-22},
	publisher = {Springer International Publishing},
	editor = {Geroimenko, Vladimir},
	year = {2014},
}

@book{holland2019,
	address = {Cham},
	series = {Springer {Series} on {Cultural} {Computing}},
	title = {New {Directions} in {Music} and {Human}-{Computer} {Interaction}},
	isbn = {978-3-319-92068-9 978-3-319-92069-6},
	url = {http://link.springer.com/10.1007/978-3-319-92069-6},
	language = {en},
	urldate = {2020-09-22},
	publisher = {Springer International Publishing},
	editor = {Holland, Simon and Mudd, Tom and Wilkie-McKenna, Katie and McPherson, Andrew and Wanderley, Marcelo M.},
	year = {2019},
}

@book{earnshaw2020,
	address = {Cham},
	series = {Springer {Series} on {Cultural} {Computing}},
	title = {Technology, {Design} and the {Arts} - {Opportunities} and {Challenges}},
	isbn = {978-3-030-42096-3 978-3-030-42097-0},
	url = {http://link.springer.com/10.1007/978-3-030-42097-0},
	language = {en},
	urldate = {2020-09-22},
	publisher = {Springer International Publishing},
	editor = {Earnshaw, Rae and Liggett, Susan and Excell, Peter and Thalmann, Daniel},
	year = {2020},
}

@incollection{bassett2015,
	address = {London},
	title = {Not {Now}? {Feminism}, {Technology}, {Postdigital}},
	isbn = {978-1-349-49378-4 978-1-137-43720-4},
	language = {en},
	booktitle = {Postdigital {Aesthetics}},
	publisher = {Palgrave Macmillan UK},
	author = {Bassett, Caroline},
	editor = {Berry, David and Dieter, Michael},
	year = {2015},
	pages = {136--150},
}

@incollection{cramer2015,
	address = {London},
	title = {What {Is} '{Post}-digital'?},
	isbn = {978-1-349-49378-4 978-1-137-43720-4},
	url = {http://link.springer.com/10.1057/9781137437204_1},
	language = {en},
	booktitle = {Postdigital {Aesthetics}},
	publisher = {Palgrave Macmillan UK},
	author = {Cramer, Florian},
	year = {2015},
	pages = {12--26},
}

@incollection{berry2015,
	address = {London},
	title = {Thinking {Postdigital} {Aesthetics}: {Art}, {Computation} and {Design}},
	isbn = {978-1-349-49378-4 978-1-137-43720-4},
	shorttitle = {Thinking {Postdigital} {Aesthetics}},
	url = {http://link.springer.com/10.1057/9781137437204_1},
	language = {en},
	urldate = {2020-09-21},
	booktitle = {Postdigital {Aesthetics}},
	publisher = {Palgrave Macmillan UK},
	author = {Berry, David M. and Dieter, Michael},
	editor = {Berry, David and Dieter, Michael},
	year = {2015},
	pages = {1--11},
}

@incollection{paul2015,
	address = {London},
	title = {Genealogies of the {New} {Aesthetic}},
	isbn = {978-1-349-49378-4 978-1-137-43720-4},
	language = {en},
	booktitle = {Postdigital {Aesthetics}},
	publisher = {Palgrave Macmillan UK},
	author = {Paul, Christiane and Levy, Malcolm},
	editor = {Berry, David and Dieter, Michael},
	year = {2015},
	pages = {27--43},
}

@incollection{tuters2015,
	address = {London},
	title = {Through {Glass} {Darkly}: {On} {Google}’s {Gnostic} {Governance}},
	isbn = {978-1-349-49378-4 978-1-137-43720-4},
	shorttitle = {Through {Glass} {Darkly}},
	url = {http://link.springer.com/10.1057/9781137437204_19},
	language = {en},
	urldate = {2020-09-21},
	booktitle = {Postdigital {Aesthetics}},
	publisher = {Palgrave Macmillan UK},
	author = {Tuters, Marc},
	editor = {Berry, David and Dieter, Michael},
	year = {2015},
	pages = {245--258},
}

@incollection{dieter2015,
	address = {London},
	title = {Dark {Patterns}: {Interface} {Design}, {Augmentation} and {Crisis}},
	isbn = {978-1-349-49378-4 978-1-137-43720-4},
	shorttitle = {Dark {Patterns}},
	url = {http://link.springer.com/10.1057/9781137437204_13},
	language = {en},
	urldate = {2020-09-21},
	booktitle = {Postdigital {Aesthetics}},
	publisher = {Palgrave Macmillan UK},
	author = {Dieter, Michael},
	editor = {Berry, David and Dieter, Michael},
	year = {2015},
	pages = {163--178},
}

@phdthesis{chevalier2016,
	title = {Remembering to {Remember}: {A} {Practice}-based {Study} in {Digital} {Re}-appropriation and {Bodily} {Perception}},
	abstract = {Through the evolution of digital media technology, social networks and more recently Web 3.0 (e.g. Cloud-based) technologies, culture and memory is being transformed, both in relation to how memories are represented, and how they may be engaged with or re-accessed.},
	language = {en},
	author = {Chevalier, Cécile},
	year = {2016},
}

@inproceedings{onate2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Seeking for spectral manipulation of the sound of musical instruments using metamaterials},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411127},
	doi = {10.1145/3411109.3411127},
	abstract = {The sound of practically all traditional musical instruments is unique and depends on the collective behavior of various vibrators, each one with their own acoustic and mechanical properties. If we pluck a string of an acoustic guitar, a part of the wave is reflected by the sound box, and the other fraction of the elastic energy sets in motion the sound box surfaces. Thereby, the vibration of the surfaces (soundboard, ribs, back and sound hole), are the basis of the guitar sound production.In this work, we explore the effect of locally coupling tunable mechanical metamaterials to the soundboard of an acoustic guitar, in order to absorb specific ranges of frequencies and change its vibrational properties. We show the preliminary results of our research, which involves a mechano-acoustic characterization of tunable mechanical metamaterials and the analysis of the effect of applying them to an acoustic guitar when a string tuned to a convenient frequency is plucked. We observe that this simple mechanism is an alternative to manipulate the spectral properties of the sound signal produced by the instrument. Although the results are inaudible, they seem promising for future explorations of sound manipulation of musical instruments.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Oñate, Carolina Espinoza and Arancibia, Alonso and Cartes, Gabriel and Beas, Claudio Falcón},
	year = {2020},
	keywords = {acoustic, musical instruments, new materials, sonic interaction design},
	pages = {277--280},
}

@inproceedings{kern2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {The influence of mood induction by music or a soundscape on presence and emotions in a virtual reality park scenario},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411129},
	doi = {10.1145/3411109.3411129},
	abstract = {Music and background sound are often used in virtual realities for creating an emotional atmosphere. The present study investigates how music or an ambient soundscape influence presence, the feeling of "being there", as well as positive and negative affect. Fifty-one subjects participated, taking a stroll through a virtual park presented via a head-mounted display while they were walking on a treadmill. Sound was varied within subjects in four audio conditions: In a randomized sequence, participants experienced silence, a nature soundscape and music of positive or negative valence. In addition, time of day (daytime vs. nighttime walk) in the virtual environment was varied between subjects. Afterwards they were asked to rate their experience of presence and the positive and negative affect experienced. Results indicated that replaying any kind of sound lead to higher presence ratings compared to no sound at all, but there was no difference between playing a soundscape or music. Background music, however, tended to induce the expected emotions, though somewhat dependent on the musical pieces chosen. Further studies might evaluate whether it is possible to induce emotions through positive or negative (non-musical) soundscapes as well.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Kern, Angelika C. and Ellermeier, Wolfgang and Jost, Lina},
	year = {2020},
	keywords = {emotion, music, presence, soundscape, virtual reality},
	pages = {233--236},
}

@inproceedings{quinton2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Sonification of an exoplanetary atmosphere},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411117},
	doi = {10.1145/3411109.3411117},
	abstract = {This study investigates the effectiveness of user design methods to create a sonification for an astronomer who analyses exoplanet meteorological data situated in habitable zones. Requirements about the astronomer's work, the dataset and how to sonify it utilising Grounded Theory were identified. Parameter mapping sonification was used to represent effective transiting radii measurements through subtractive synthesis and spatialization. The design was considered to be effective, allowing the instantaneous identification of a water feature overlooked on a visual graph, even when noise within the dataset overlapped the source signal. The results suggest that multiple parameter mappings provide richer auditory stimuli and semantic qualities in order to allow an improved understanding of the dataset.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Quinton, Michael and McGregor, Iain and Benyon, David},
	year = {2020},
	keywords = {astronomy, exoplanet atmospheres, grounded theory, parameter mapping sonification, sonification, user centred design},
	pages = {191--198},
}

@inproceedings{lawton2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Nature soundscapes: {An} audio augmented reality experience},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411142},
	doi = {10.1145/3411109.3411142},
	abstract = {Augmented Reality (AR) has developed to be a popular and exciting technology domain, gaining notable public interest from 2009 to the present day. AR applications have traditionally focused upon paradigms that are visually led. In this paper, we document an Audio Augmented Reality (AAR) project, which considers soundscapes and how they might be transformed via the application of music and sound technologies. This work is concerned with the augmentation of nature soundscapes and explores how this may be used to enhance public understanding of the natural world. At present, we are concerned with the augmentation of spaces with biophony. Two examples of acoustic augmented reality are described: an initial pilot study to investigate the feasibility of the approach and an installation at the Timber International Forest Festival 2019. A technical description of each is provided alongside our own reflection and participant feedback, garnered from a soundwalk inspired approach to evaluation by audiences at the festival.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Lawton, Mark and Cunningham, Stuart and Convery, Ian},
	year = {2020},
	keywords = {augmented reality, nature, soundscapes},
	pages = {85--92},
}

@inproceedings{yang2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Fast synthesis of perceptually adequate room impulse responses from ultrasonic measurements},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3412300},
	doi = {10.1145/3411109.3412300},
	abstract = {Audio augmented reality (AAR) applications need to render virtual sounds with acoustic effects that match the real environment of the user to create an experience with strong sense of presence. This audio rendering process can be formulated as the convolution between the dry sound signal and the room impulse response (IR) that covers the audible frequency spectrum (20Hz - 20kHz). While the IR can be pre-calculated in virtual reality (VR) scenes, AR applications need to continuously estimate it. We propose a method to synthesize room IRs based on the corresponding IR in the ultrasound frequency band (20kHz - 22kHz) and two parameters we propose in this paper: slope factor and RT60 ratio. We assess the synthesized IRs using common acoustic metrics and we conducted a user study to evaluate participants' perceptual similarity between the sounds rendered with the synthesized IR and with the recorded IR in different rooms. The method requires only a small number of pre-measurements in the environment to determine the synthesis parameters and it uses only inaudible signals at runtime for fast IR synthesis, making it well suited for interactive AAR applications.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Yang, Jing and Pfreundtner, Felix and Barde, Amit and Heutschi, Kurt and Sörös, Gábor},
	year = {2020},
	keywords = {auditory perception, augmented reality, room acoustic effects, room impulse response, ultrasound},
	pages = {53--60},
}

@inproceedings{sardana2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Perception of spatial data properties in an immersive multi-layered auditory environment},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411134},
	doi = {10.1145/3411109.3411134},
	abstract = {We present a study of spatial sonification of multidimensional data using a spatial mask and an immersive high-density loudspeaker array. The study participants are asked to identify edges and perceived center of 2D shapes projected across the perimeter of an exocentric environment. The results show that the phase modulation technique results in less accurate user responses than the amplitude modulation or combined modulation techniques. No significant differences are found between stationary and mobile-user scenarios when comparing the angular miss distances of the perceived center of sonified shapes, but significant differences are identified in locating their left and top edges. Further research is warranted to determine why properties of some shapes are easier to pinpoint than others, and how sonification may be improved to minimize such discrepancies.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Sardana, Disha and Joo, Woohun and Bukvic, Ivica Ico and Earle, Gregory},
	year = {2020},
	keywords = {data sonification, immersive environments, perception, spatial audio},
	pages = {30--37},
}

@inproceedings{mendonca2020,
	address = {Graz, Austria},
	series = {{AM} '20},
	title = {Surround sound spreads visual attention and increases cognitive effort in immersive media reproductions},
	isbn = {978-1-4503-7563-4},
	url = {https://doi.org/10.1145/3411109.3411118},
	doi = {10.1145/3411109.3411118},
	abstract = {The goal of this study was to explore the effects of different spatial sound configurations on visual attention and cognitive effort in an immersive environment. For that purpose, different groups of people were exposed to the same immersive video, but with different soundtrack conditions: mono, stereo, 5.1 and 7.4.1. The different sound conditions consisted of different artistic adaptations of the same soundtrack. During the visualization of the video, participants wore an eye-tracking device and were asked to perform a counting task. Gaze direction and pupil dilation metrics were obtained, as measures of attention and cognitive effort. Results demonstrate that the conditions 5.1 and 7.4.1 were associated with larger distributions of the visual attention, with subjects spending more time gazing at task-irrelevant areas on the screen. The sound condition which led to more concentrated attention on the task-relevant area was mono. The wider the spatial sound configuration, the greater the gaze distribution. Conditions 7.4.1 and 5.1 were also associated with larger pupil dilations than the mono and stereo conditions, showing that these conditions might lead to increased cognitive demand and therefore increased task difficulty. We conclude that sound design should be carefully planned to prevent visual distraction. More surrounding spatialized sounds may lead to more distraction and more difficulty in following audiovisual contents than less distributed sounds. We propose that sound spatialization and soundtrack design should be adapted to the audiovisual content and the task at hand, varying in immersiveness accordingly.},
	booktitle = {Proceedings of the 15th international conference on audio mostly},
	publisher = {Association for Computing Machinery},
	author = {Mendonça, Catarina and Korshunova, Victoria},
	year = {2020},
	keywords = {attention, audiovisual, difficulty, perception, pupil dilation, sound design, spatial audio, virtual reality},
	pages = {16--21},
}

@inproceedings{macintyre2001,
	address = {New York, NY, USA},
	title = {Augmented reality as a new media experience},
	isbn = {978-0-7695-1375-1},
	url = {http://ieeexplore.ieee.org/document/970538/},
	doi = {10.1109/ISAR.2001.970538},
	abstract = {In this paper we discuss our work on applying media theory to the creation of narrative augmented reality (AR) experiences. We summarize the concepts of remediation and media forms as they relate to our work, argue for their importance to the development of a new medium such as AR, and present two example AR experiences we have designed using these conceptual tools. In particular, we focus on leveraging the interaction between the physical and virtual world, remediating existing media (ﬁlm, stage and interactive CD-ROM), and building on the cultural expectations of our users.},
	language = {en},
	urldate = {2020-10-27},
	booktitle = {Proceedings {IEEE} and {ACM} {International} {Symposium} on {Augmented} {Reality}},
	publisher = {IEEE Comput. Soc},
	author = {MacIntyre, Blair and Bolter, J.D. and Moreno, E. and Hannigan, B.},
	year = {2001},
	pages = {197--206},
}

@article{engberg2014a,
	title = {Polyaesthetic sights and sounds:},
	volume = {4},
	language = {en},
	number = {1},
	author = {Engberg, Maria},
	year = {2014},
	pages = {20},
}

@article{bolter2013,
	title = {Media studies, mobile augmented reality, and interaction design},
	language = {en},
	author = {Bolter, Jay David and Engberg, Maria and MacIntyre, Blair},
	year = {2013},
	pages = {10},
}

@article{engberg2014,
	title = {Cultural expression in augmented and mixed reality},
	volume = {20},
	issn = {1354-8565, 1748-7382},
	url = {http://journals.sagepub.com/doi/10.1177/1354856513516250},
	doi = {10.1177/1354856513516250},
	language = {en},
	number = {1},
	urldate = {2020-10-27},
	journal = {Convergence: The International Journal of Research into New Media Technologies},
	author = {Engberg, Maria and Bolter, Jay David},
	month = feb,
	year = {2014},
	pages = {3--9},
}

@inproceedings{rompapas2020,
	address = {Lisbon, Portugal},
	title = {Project {Esky}: {Enabling} {High} {Fidelity} {Augmented} {Reality} on an {Open} {Source} {Platform}},
	url = {https://doi.org/10.1145/3380867.3426220},
	urldate = {2020-10-14},
	booktitle = {{ISS} '20: {Proceedings} of the 2020 {ACM} {International} {Conference} on {Interactive} {Surfaces} and {Spaces}},
	author = {Rompapas, Damien Constantine and Quiros, Daniel Flores and Rodda, Charlton and Brown, Bryan Christopher and Zerkin, Noah Benjamin and Cassinelli, Alvaro},
	month = nov,
	year = {2020},
}

@misc{subpac2020,
	title = {{SUBPAC} {X1}},
	url = {https://uk.subpac.com/products/subpac-x1},
	abstract = {EARLY BIRD PRE ORDER PRICE  SHIPS FROM THE USA - CUSTOMS DUTIES INCLUDED IN SHIPPING. SUBPAC pre-orders are first come, first serve, with the first ones expected to ship by the end of the year. We wish we could give you an exact date but the global pandemic has meant that we have had to change our manufacturing and shi},
	language = {en},
	urldate = {2020-10-03},
	journal = {SUBPAC},
	author = {Subpac},
	year = {2020},
}

@article{maggioni2019,
	title = {{OWidgets}: {A} toolkit to enable smell-based experience design},
	volume = {130},
	issn = {10715819},
	shorttitle = {{OWidgets}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581919300825},
	doi = {10.1016/j.ijhcs.2019.06.014},
	abstract = {Interactive technologies are transforming the ways in which people experience, interact and share information. Advances in technology have made it possible to generate real and virtual environments with breath-taking graphics and high-ﬁdelity audio. However, without stimulating the other senses such as touch and smell, and even taste in some cases, such experiences feel hollow and ﬁctitious; they lack realism. One of the main stumbling blocks for progress towards creating truly compelling multisensory experiences is the lack of appropriate tools and guidance for designing beyond audio-visual applications. Here we focus particularly on the sense of smell and how smell-based design can be enabled to create novel user experiences. We present a design toolkit for smell (i.e., OWidgets). The toolkit consists of a graphical user interface and the underlying software framework. The framework uses two main components: a Mapper and Scheduler facilitating the device-independent replication of olfactory experiences. We discuss how our toolkit reduces the complexity of designing with smell and enables a creative exploration based on speciﬁc design features. We conclude by reﬂecting on future directions to extend the toolkit and integrate it into the wider audio-visual ecosystem.},
	language = {en},
	urldate = {2020-10-03},
	journal = {International Journal of Human-Computer Studies},
	author = {Maggioni, Emanuela and Cobden, Robert and Obrist, Marianna},
	month = oct,
	year = {2019},
	pages = {248--260},
}

@inproceedings{hafidh2013,
	address = {Istanbul, Turkey},
	title = {F-{Glove}: {A} glove with force-audio sensory substitution system for diabetic patients},
	isbn = {978-1-4799-0849-3 978-1-4799-0848-6},
	shorttitle = {F-{Glove}},
	url = {http://ieeexplore.ieee.org/document/6679607/},
	doi = {10.1109/HAVE.2013.6679607},
	abstract = {Some diabetic patients experience difficulties in modulating the grip force magnitude when they manipulate objects using their hands. This difficulty is caused by the sensory loss at the fingertips that impairs the feedback loop between the brain and the aforementioned sensors. In this paper, we present a sensory substitution system called “F-Glove”, which is aimed at helping diabetic patients to manipulate objects more efficiently by using appropriate forces. This is achieved by substituting the force felt at the fingertips when grip an object with an audio feedback displayed through the earphones of a mobile phone. The patient wears a glove integrated with pressure sensors mounted on the fingertips, and the sensors’ pressure signals are conditioned and wirelessly transmitted to a mobile phone interface to display an audio with a volume linearly proportional to the pressure applied by the fingers of patients.},
	language = {en},
	urldate = {2020-10-03},
	booktitle = {2013 {IEEE} {International} {Symposium} on {Haptic} {Audio} {Visual} {Environments} and {Games} ({HAVE})},
	publisher = {IEEE},
	author = {Hafidh, Basim and Osman, Hussein Al and Alowaidi, Majed and El-Saddik, Abdulmotaleb and Liu, Xiaoping P.},
	month = oct,
	year = {2013},
	pages = {34--38},
}

@inproceedings{schraffenberger2015,
	address = {Glasgow, Scotland},
	title = {Sonically {Tangible} {Objects}},
	booktitle = {{xCoAx} 2015: {Proceedings} of the {Third} {Conference} on {Computation}, {Communication}, {Aesthetics} and {X}.},
	author = {Schraffenberger, Hanna and van der Heide, Edwin},
	year = {2015},
	pages = {233--248},
}

@inproceedings{ablart2019,
	address = {Subang Jaya, Malaysia},
	title = {Using {Ultrasonic} {Mid}-air {Haptic} {Patterns} in {Multi}-{Modal} {User} {Experiences}},
	isbn = {978-1-72812-355-4},
	url = {https://ieeexplore.ieee.org/document/8920969/},
	doi = {10.1109/HAVE.2019.8920969},
	abstract = {Ultrasonic mid-air tactile displays offer a unique combination of high spatial and temporal resolution and can stimulate a wide range of tactile frequencies. Leveraging those features, a new modulation technique producing spatially distributed tactile sensations has recently been introduced. This new approach, referred to as Spatiotemporal Modulation (STM), draws lines, curves and shapes on users’ palm by moving a midair tactile point rapidly and repeatedly along the path. STM parameters and their impact on tactile perception are yet to be studied systematically. In this work, we ﬁrst study how varying the draw frequency and the size of a simple shape affects the participants perception of texture and their emotional responses. In the second part of our study, we used the most salient tactile patterns of the ﬁrst study to extend the results within a multimodal context. We found that tactile patterns’ perception was consistent within both studies. We also found instances when the tactile patterns could alter the perception of the audio and visual stimuli. Finally, we discuss the beneﬁts of our ﬁndings and conclude with implications for future work.},
	language = {en},
	urldate = {2020-10-03},
	booktitle = {2019 {IEEE} {International} {Symposium} on {Haptic}, {Audio} and {Visual} {Environments} and {Games} ({HAVE})},
	publisher = {IEEE},
	author = {Ablart, Damien and Frier, William and Limerick, Hannah and Georgiou, Orestis and Obrist, Marianna},
	month = oct,
	year = {2019},
	pages = {1--6},
}

@misc{sennheiser2018,
	title = {Sennheiser {AMBEO} {AR} {One} {Headphones}},
	url = {https://en-uk.sennheiser.com/ambeo-application-armr},
	urldate = {2020-10-03},
	author = {Sennheiser},
	year = {2018},
}

@article{ward2010,
	title = {Visual experiences in the blind induced by an auditory sensory substitution device},
	volume = {19},
	issn = {1053-8100},
	url = {http://www.sciencedirect.com/science/article/pii/S1053810009001718},
	doi = {10.1016/j.concog.2009.10.006},
	abstract = {In this report, the phenomenology of two blind users of a sensory substitution device – “The vOICe” – that converts visual images to auditory signals is described. The users both report detailed visual phenomenology that developed within months of immersive use and has continued to evolve over a period of years. This visual phenomenology, although triggered through use of The vOICe, is likely to depend not only on online visualization of the auditory signal but also on the users’ previous (albeit distant) experience of veridical vision (e.g. knowledge of shapes and visual perspective). Once established, the sensory substitution mapping between the auditory and visual domains is not confined to when the device is worn and, thus, may constitute an example of acquired synaesthesia.},
	language = {en},
	number = {1},
	urldate = {2020-10-03},
	journal = {Consciousness and Cognition},
	author = {Ward, Jamie and Meijer, Peter},
	month = mar,
	year = {2010},
	keywords = {Blind, Mental imagery, Sensory substitution, Synaesthesia/synesthesia, Visual consciousness, vOICe},
	pages = {492--500},
}

@article{nagel2005,
	title = {Beyond sensory substitution—learning the sixth sense},
	volume = {2},
	issn = {1741-2560, 1741-2552},
	url = {https://iopscience.iop.org/article/10.1088/1741-2560/2/4/R02},
	doi = {10.1088/1741-2560/2/4/R02},
	abstract = {Rapid advances in neuroscience have sparked numerous efforts to study the neural correlate of consciousness. Prominent subjects include higher sensory area, distributed assemblies bound by synchronization of neuronal activity and neurons in speciﬁc cortical laminae. In contrast, it has been suggested that the quality of sensory awareness is determined by systematic change of afferent signals resulting from behaviour and knowledge thereof. Support for such skill-based theories of perception is provided by experiments on sensory substitution. Here, we pursue this line of thought and create new sensorimotor contingencies and, hence, a new quality of perception. Adult subjects received orientation information, obtained by a magnetic compass, via vibrotactile stimulation around the waist. After six weeks of training we evaluated integration of the new input by a battery of tests. The results indicate that the sensory information provided by the belt (1) is processed and boosts performance, (2) if inconsistent with other sensory signals leads to variable performance, (3) does interact with the vestibular nystagmus and (4) in half of the experimental subjects leads to qualitative changes of sensory experience. These data support the hypothesis that new sensorimotor contingencies can be learned and integrated into behaviour and affect perceptual experience.},
	language = {en},
	number = {4},
	urldate = {2020-10-03},
	journal = {Journal of Neural Engineering},
	author = {Nagel, Saskia K and Carl, Christine and Kringe, Tobias and Märtin, Robert and König, Peter},
	month = dec,
	year = {2005},
	pages = {R13--R26},
}

@misc{lightform2020,
	title = {Lightform: {Design} {Tools} for {Projection}},
	shorttitle = {Lightform},
	url = {https://lightform.com/},
	abstract = {Introducing the next generation of Lightform. LF2 is the first AR projector, and provides everything you need to make magic with light. LFC Kit can be used to go big with your own projector. It's like LF1, but more flexible and faster.},
	language = {en-US},
	urldate = {2020-10-03},
	journal = {Lightform},
	author = {{Lightform}},
	year = {2020},
}

@misc{varjo2019,
	title = {Varjo {XR}-1},
	url = {https://varjo.com/products/xr-1/},
	abstract = {Varjo XR-1 is the world's most advanced mixed reality headset for professionals, with photorealistic visual fidelity and ultra-low latency.},
	language = {en-US},
	urldate = {2020-10-03},
	journal = {Varjo.com},
	author = {{Varjo}},
	year = {2019},
}

@misc{tonn2020,
	title = {Sensory {Cartographies}},
	url = {https://www.researchcatalogue.net/view/403183/403184},
	urldate = {2020-10-03},
	author = {Tonn, Sissel Marie and Reus, Jonathan},
	year = {2020},
}

@inproceedings{barde2020,
	title = {The use of spatialised auditory and visual cues for target acqusition in a search task},
	url = {http://www.aes.org/e-lib/browse.cfm?elib=20875},
	booktitle = {Audio engineering society conference: 2020 {AES} international conference on audio for virtual and augmented reality},
	author = {Barde, Amit and Ward, Matt and Lindeman, Robert and Billinghurst, Mark},
	month = aug,
	year = {2020},
}

@article{dey2018,
	title = {A {Systematic} {Review} of 10 {Years} of {Augmented} {Reality} {Usability} {Studies}: 2005 to 2014},
	volume = {5},
	issn = {2296-9144},
	shorttitle = {A {Systematic} {Review} of 10 {Years} of {Augmented} {Reality} {Usability} {Studies}},
	url = {http://journal.frontiersin.org/article/10.3389/frobt.2018.00037/full},
	doi = {10.3389/frobt.2018.00037},
	abstract = {Augmented Reality (AR) interfaces have been studied extensively over the last few decades, with a growing number of user-based experiments. In this paper, we systematically review 10 years of the most inﬂuential AR user studies, from 2005 to 2014. A total of 291 papers with 369 individual user studies have been reviewed and classiﬁed based on their application areas. The primary contribution of the review is to present the broad landscape of user-based AR research, and to provide a high-level view of how that landscape has changed. We summarize the high-level contributions from each category of papers, and present examples of the most inﬂuential user studies. We also identify areas where there have been few user studies, and opportunities for future research. Among other things, we ﬁnd that there is a growing trend toward handheld AR user studies, and that most studies are conducted in laboratory settings and do not involve pilot testing. This research will be useful for AR researchers who want to follow best practices in designing their own AR user studies.},
	language = {en},
	urldate = {2020-10-02},
	journal = {Frontiers in Robotics and AI},
	author = {Dey, Arindam and Billinghurst, Mark and Lindeman, Robert W. and Swan, J. Edward},
	month = apr,
	year = {2018},
	pages = {37},
}

@misc{apple2020a,
	title = {App {Clips}},
	url = {https://developer.apple.com/app-clips/},
	abstract = {App Clips are a great way for users to quickly access and experience what your app has to offer.},
	language = {en},
	urldate = {2020-10-02},
	journal = {Apple Developer},
	author = {{Apple}},
	year = {2020},
}

@misc{nreal2020,
	title = {Nreal {Light}},
	url = {https://nreal.ai/product/},
	urldate = {2020-10-01},
	author = {{Nreal}},
	year = {2020},
}

@article{mori2017,
	title = {A survey of diminished reality: {Techniques} for visually concealing, eliminating, and seeing through real objects},
	volume = {9},
	issn = {1882-6695},
	shorttitle = {A survey of diminished reality},
	url = {http://ipsjcva.springeropen.com/articles/10.1186/s41074-017-0028-1},
	doi = {10.1186/s41074-017-0028-1},
	abstract = {In this paper, we review diminished reality (DR) studies that visually remove, hide, and see through real objects from the real world. We systematically analyze and classify publications and present a technology map as a reference for future research. We also discuss future directions, including multimodal diminished reality. We believe that this paper will be useful mainly for students who are interested in DR, beginning DR researchers, and teachers who introduce DR in their classes.},
	language = {en},
	number = {1},
	urldate = {2021-02-12},
	journal = {IPSJ Transactions on Computer Vision and Applications},
	author = {Mori, Shohei and Ikeda, Sei and Saito, Hideo},
	month = dec,
	year = {2017},
	pages = {17},
}

@article{zeltzer1992,
	title = {Autonomy, {Interaction}, and {Presence}},
	volume = {1},
	issn = {1054-7460},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/pres.1992.1.1.127},
	doi = {10.1162/pres.1992.1.1.127},
	language = {en},
	number = {1},
	urldate = {2021-02-12},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Zeltzer, David},
	month = jan,
	year = {1992},
	pages = {127--132},
}

@article{sheridan1992,
	title = {Musings on {Telepresence} and {Virtual} {Presence}},
	volume = {1},
	issn = {1054-7460},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/pres.1992.1.1.120},
	doi = {10.1162/pres.1992.1.1.120},
	language = {en},
	number = {1},
	urldate = {2021-02-12},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Sheridan, Thomas B.},
	month = jan,
	year = {1992},
	pages = {120--126},
}

@phdthesis{gamper2014,
	title = {Enabling technologies for audio augmented reality systems},
	abstract = {Audio augmented reality (AAR) refers to technology that embeds computer-generated auditory content into a user's real acoustic environment. An AAR system has speciﬁc requirements that set it apart from regular human--computer interfaces: an audio playback system to allow the simultaneous perception of real and virtual sounds; motion tracking to enable interactivity and location-awareness; the design and implementation of auditory display to deliver AAR content; and spatial rendering to display spatialised AAR content. This thesis presents a series of studies on enabling technologies to meet these requirements.},
	language = {en},
	school = {Aalto University},
	author = {Gamper, Hannes},
	year = {2014},
}

@inproceedings{naimark1991,
	address = {San Jose, CA},
	title = {Elements of real-space imaging: a proposed taxonomy},
	shorttitle = {Elements of real-space imaging},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=961617},
	doi = {10.1117/12.46305},
	abstract = {Along with the marriage of motion pictures and computers has come an increasing interest in making images appear to have a greater degree of realness or presence, which I call "realspace imaging." Such topics as high definition television, 3D, fisheye lenses, surrogate travel, arid "cyberspace" reflect such interest. These topics are usually piled together and are unparsable, with the implicit assumptions that "the more resolution, the more presence" and "the more presence, the better." This paper proposes a taxonomy of the elements of realspace imaging. The taxonomy is organized around six sections: 1) monoscopic imaging, 2) stereoscopic imaging, 3) multiscopic imaging, 4) panoramics, 5) surrogate travel, and 6) realtime imaging.},
	language = {en},
	urldate = {2021-02-12},
	author = {Naimark, Michael},
	editor = {Merritt, John O. and Fisher, Scott S.},
	month = aug,
	year = {1991},
	pages = {169--179},
}

@article{robinett1992,
	title = {Synthetic experience: {A} proposed taxonomy},
	volume = {1},
	issn = {1054-7460},
	abstract = {A taxonomy is proposed to classify all varieties of technologically mediated experience. This includes virtual reality and teleoperation, and also earlier devices such as the microscope and telephone. The model of mediated interaction assumes a sensor-display link from the world to the human, and an action-actuator link going back from the human to the world, with the mediating technology transforming the transmitted experience in some way. The taxonomy is used to classify a number of example systems.Two taxonomies proposed earlier are compared with the ideas presented in this paper. Then the long-term prospects of this field are speculated on, ignoring constraints of cost, effort, or time to develop. Finally, the ultimate limits of synthetic experience are discussed, which derive from properties of the physical universe and the human neural apparatus.},
	number = {2},
	journal = {Presence: Teleoper. Virtual Environ.},
	author = {Robinett, Warren},
	month = jan,
	year = {1992},
	pages = {229--247},
}

@inproceedings{cohen1993,
	title = {Augmented audio reality: telepresence/{VR} hybrid acoustic environments},
	shorttitle = {Augmented audio reality},
	doi = {10.1109/ROMAN.1993.367692},
	abstract = {Augmented audio reality consists of hybrid presentations in which computer-generated sounds are overlayed on top of more directly acquired audio signals. We are exploring the alignability of binaural signals with artificially spatialized sources, synthesized by convolving monaural signals with left/right pairs of directional transfer functions. We use MAW (multidimensional audio windows), a NeXT-based system, as a binaural directional mixing console. Since the rearrangement of a dynamic map is used to dynamically select transfer functions, a user may specify the virtual location of a sound source, throwing the source into perceptual space, using exocentric graphical control to drive egocentric auditory display. As a concept demonstration, we muted a telephone, and then used MAW to spatialize a ringing signal at its location, putting the sonic image of the phone into the office environment. By juxtaposing and mixing 'real' and 'synthetic' audio transmissions, we are exploring the relationship between acoustic telepresence and VR presentations: telepresence manifests as the actual configuration of sources in a sound field, as perceivable by a dummyhead; VR is the perception yielded by filtering of virtual sources with respect to virtual sinks. We have conducted an experiment testing the usefulness of such a hybrid.{\textless}{\textgreater}},
	booktitle = {Proceedings of 1993 2nd {IEEE} {International} {Workshop} on {Robot} and {Human} {Communication}},
	author = {Cohen, M. and Aoki, S. and Koizumi, N.},
	month = nov,
	year = {1993},
	keywords = {Acoustic testing, Humans, Laboratories, Layout, MAW, NeXT-based system, Robots, Signal synthesis, Switches, Telephony, Transfer functions, VR hybrid acoustic environments, Virtual reality, acoustic telepresence, audio-visual systems, augmented audio reality, binaural directional mixing console, binaural signal alignability, computer-generated sounds, convolving monaural signals, directional transfer functions, egocentric auditory display, exocentric graphical control, left/right pairs, multidimensional audio windows, telecontrol, transfer function dynamic selection, virtual location, virtual reality},
	pages = {361--364},
}

@techreport{mann1994,
	title = {Mediated reality},
	url = {https://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=F4FD2D3356DBAD357773B5939176DB12?doi=10.1.1.48.5056&rep=rep1&type=pdf},
	number = {MIT-ML Percom TR-260},
	urldate = {2021-02-10},
	institution = {University of Toronto},
	author = {Mann, Steve},
	year = {1994},
	pages = {21},
}

@article{feiner1993,
	title = {Knowledge-based augmented reality},
	volume = {36},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/159544.159587},
	doi = {10.1145/159544.159587},
	language = {en},
	number = {7},
	urldate = {2021-02-10},
	journal = {Communications of the ACM},
	author = {Feiner, Steven and Macintyre, Blair and Seligmann, Dorée},
	month = jul,
	year = {1993},
	pages = {53--62},
}

@inproceedings{mann2018,
	address = {Santa Clara, CA, USA},
	title = {All {Reality}: {Values}, taxonomy, and continuum, for {Virtual}, {Augmented}, {eXtended}/{MiXed} ({X}), {Mediated} ({X},{Y}), and {Multimediated} {Reality}/{Intelligence}},
	abstract = {Humans are creating a world of eXtended/Artificial Reality/Intelligence (AR, AI, XR, XI or EI), that in many ways is hypocritical, e.g. where cars and buildings are always “allowed” to “wear” cameras, but humans sometimes aren’t, and where machines sense our every movement, yet we can’t even understand how they work. We’re constructing a system of values that gives more rights and less responsibilities to AI (Artificial Intelligence) than to HI (Humanistic Intelligence). Whereas it is becoming common to separate the notions of IRL (In Real Life) and “Augmented” or “Virtual” Reality (AR, VR) into completely disparate realms with clearly delineated boundaries, we propose here the notion of “All Reality” to more holistically represent the links between these soon-to-be-outdated culturally accepted norms of various levels of consciousness. Inclusive in the notion of “All Reality” is also the idea of “ethically aligned reality”, recognizing values-based biases, cultural norms, and applied ethics of the creators of technology.},
	language = {en},
	booktitle = {roceedings of the {AWE} 2018 {Conference}},
	author = {Mann, Steve and Havens, John C and Iorio, Jay and Yuan, Yu and Furness, Tom},
	year = {2018},
	pages = {10},
}

@inproceedings{sutherland1965,
	title = {The {Ultimate} {Display}},
	language = {en},
	booktitle = {Proceedings of the {IFIP} {Congress}},
	author = {Sutherland, Ivan},
	year = {1965},
	pages = {506--508},
}

@book{sathian2019,
	address = {San Deigo},
	edition = {1},
	title = {Multisensory perception: from laboratory to clinic},
	isbn = {978-0-12-812492-5},
	shorttitle = {Multisensory perception},
	language = {en},
	publisher = {Elsevier},
	editor = {Sathian, K. and Ramachandran, V S},
	year = {2019},
}

@article{gibson2014,
	title = {The {Ecological} {Approach} to {Visual} {Perception}},
	language = {en},
	author = {Gibson, James J},
	year = {2014},
	pages = {347},
}

@inproceedings{bilbow2021b,
	address = {Salzburg Austria},
	title = {Developing {Multisensory} {Augmented} {Reality} {As} {A} {Medium} {For} {Computational} {Artists}},
	isbn = {978-1-4503-8213-7},
	url = {https://dl.acm.org/doi/10.1145/3430524.3443690},
	doi = {10.1145/3430524.3443690},
	abstract = {This paper resituates multisensory augmented reality (MSAR) as an artistic medium for the creation of interactive and expressive works by computational artists. If an AR system can be thought of as one that combines real and virtual processes, is interactive in real-time, and is registered in three dimensions; why do we witness the majority of AR applications utilising primarily visual displays of information? In this paper, I propose a practice-led compositional approach for developing ‘MSAR Experiences’, arguing that, as an medium that combines real and virtual multisensory processes, it must be explored with a multisensory approach. The paper further outlines the study methods that I will use to evaluate the developed experiences. The outcome of this project is the practice-led method as well as MSAR hardware, software and experiences that are developed and evaluated.},
	language = {en},
	urldate = {2021-03-05},
	booktitle = {Proceedings of the {Fifteenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction}},
	publisher = {ACM},
	author = {Bilbow, Sam},
	month = feb,
	year = {2021},
	pages = {1--7},
}

@article{bilbow2021a,
	title = {The area{\textasciitilde} system: {Exploring} real and virtual environments through gestural ambisonics and audio augmented reality},
	volume = {2},
	url = {https://www.sonicscope.org/pub/7t8ucdi0},
	doi = {10.21428/66f840a4.b74711a8},
	journal = {Sonic Scope: New Approaches to Audiovisual Culture},
	author = {Bilbow, Sam},
	year = {2021},
}

@article{weiser1991,
	title = {The {Computer} for the 21st {Century}},
	language = {en},
	journal = {SCIENTIFIC AMERICAN},
	author = {Weiser, Mark},
	year = {1991},
	pages = {12},
}

@phdthesis{magnusson2009a,
	title = {Epistemic {Tools}: {The} {Phenomenology} of {Digital} {Musical} {Instruments}},
	url = {https://sro.sussex.ac.uk/id/eprint/83540/1/Magnusson%2C%20Thor%282%29.pdf},
	urldate = {2020-12-15},
	school = {University of Sussex},
	author = {Magnusson, Thor},
	year = {2009},
}

@misc{ultraleap2020a,
	title = {Touchscreens: {Business} as {Usual} {Isn}’t an {Option} {\textbar} {Ultraleap}},
	shorttitle = {Touchscreens},
	url = {https://www.ultraleap.com/company/news/blog/contactless-technology/},
	abstract = {Covid-19 has made consumers hyper-aware of the hygiene risks of public touchscreens. How will contactless interfaces help retail meet this challenge?},
	language = {en},
	urldate = {2020-11-19},
	author = {UltraLeap},
	year = {2020},
}

@article{demetriou2018,
	title = {‘{Imagineering}’ mixed reality ({MR}) immersive experiences in the postdigital revolution: innovation, c},
	volume = {14},
	abstract = {At the frontiers of our technoculture and experience economy, artist-researchers as catalytic agents become Imagineers and entrepreneurs of themselves. Arts are quantiﬁed in expectations of extending forms of communication with people and our environments, by creating humanistic ways of interfacing with machines. Within the experience economy the term ‘immersion’ is overused trending towards VR, which has troubled many researchers and practitioners across disciplines. Drawing on perspectives from performance studies, digital humanities, and human-computer interaction (HCI), this paper reviews the role of XR-enabling technologies, beyond VR, in designing immersive experiences, and their integration into performance practices. It discusses the shift of the artist’s role in imagineering new resources and new ways of working to immerse audiences, and it evaluates this in a postdigital context. It discusses how immersion operates, and critiques components necessary to create aﬀective environments in terms of audience engagement, agency, participation, involvement, presence, embodiment and interaction. The article discusses how performance as a lab can act as a method of inquiry by bringing the anthropological, performative and theatrical perspectives; and the ethics of to testing immersive-enabling technologies and/or experiences within the context of live performances.},
	language = {en},
	number = {2},
	journal = {nternational Journal of Performance Arts and DigitalMedia,},
	author = {Demetriou, Panayiota A},
	year = {2018},
	pages = {19},
}

@misc{veenhof2010,
	title = {We {AR} in {MoMA}},
	url = {http://sndrv.nl/moma/},
	author = {Veenhof, Sander and Skwarek, Mark},
	year = {2010},
}

@misc{eno2018,
	title = {Bloom: {Open} {Space}},
	author = {Eno, Brian and Chilvers, Peter},
	year = {2018},
}

@misc{gordijn2017,
	title = {Concrete {Storm}, {Studio} {Drift}},
	author = {Gordijn, Lonneke and Nauta, Ralph},
	year = {2017},
}

@book{gallagher2017,
	address = {Oxford New York},
	edition = {First edition},
	title = {Enactivist interventions: rethinking the mind},
	isbn = {978-0-19-879432-5},
	shorttitle = {Enactivist interventions},
	abstract = {Enactivist Interventions' is an interdisciplinary work that explores how theories of embodied cognition illuminate many aspects of the mind, including intentionality, representation, the affect, perception, action and free will, higher-order cognition, and intersubjectivity. Gallagher argues for a rethinking of the concept of mind, drawing on pragmatism, phenomenology and cognitive science. Enactivism is presented as a philosophy of nature that has significant methodological and theoretical implications for the scientific investigation of the mind. Gallagher argues that, like the basic phenomena of perception and action, sophisticated cognitive phenomena like reflection, imagining, and mathematical reasoning are best explained in terms of an affordance-based skilled coping. He offers an account of the continuity that runs between basic action, affectivity, and a rationality that in every case remains embodied. Gallagher's analysis also addresses recent predictive models of brain function and outlines an alternative, enactivist interpretation that emphasizes the close coupling of brain, body and environment rather than a strong boundary that isolates the brain in its internal processes. The extensive relational dynamics that integrates the brain with the extra-neural body opens into an environment that is physical, social and cultural and that recycles back into the enactive process. Cognitive processes are in-the-world rather than in-the-head; they are situated in affordance spaces defined across evolutionary, developmental and individual histories, and are constrained by affective processes and normative dimensions of social and cultural practices--},
	language = {en},
	publisher = {Oxford University Press},
	author = {Gallagher, Shaun},
	year = {2017},
}

@article{essl2006,
	title = {An enactive approach to the design of new tangible musical instruments},
	volume = {11},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S135577180600152X/type/journal_article},
	doi = {10.1017/S135577180600152X},
	abstract = {In this paper, we propose a theoretical framework for the design of tangible interfaces for musical expression. The main insight for the proposed approach is the importance and utility of familiar sensorimotor experiences for the creation of engaging and playable new musical instruments. In particular, we suggest exploiting the commonalities between different natural interactions by varying the auditory response or tactile details of the instrument within certain limits. Using this principle, devices for classes of sounds such as coarse grain collision interactions or friction interactions can be designed. The designs we propose retain the familiar tactile aspect of the interaction so that the performer can take advantage of tacit knowledge gained through experiences with such phenomena in the real world.},
	language = {en},
	number = {3},
	urldate = {2021-04-28},
	journal = {Organised Sound},
	author = {Essl, Georg and O'Modhrain, Sile},
	month = dec,
	year = {2006},
	pages = {285--296},
}

@article{chevalier2020,
	title = {What {Does} {Augmented} {Reality} {Mean} as a {Medium} of {Expression} for {Computational} {Artists}?},
	volume = {53},
	issn = {0024-094X, 1530-9282},
	url = {https://direct.mit.edu/leon/article/53/3/263-267/96873},
	doi = {10.1162/leon_a_01740},
	abstract = {As augmented reality (AR) quickly evolves with new technological practice, there is a growing need to question and reevaluate its potential as a medium for creative expression. The authors discuss AR within computational art, framed within AR as a medium, AR aesthetics and applications. The Forum for Augmented Reality Immersive Instruments (ARImI), a two-day event on AR, highlights both possibilities and fundamental concerns for continuing artworks in this field, including visual bias, sensory modalities, interactivity and performativity. The authors offer a new AR definition as real-time computationally mediated perception.},
	language = {en},
	number = {3},
	urldate = {2021-04-28},
	journal = {Leonardo},
	author = {Chevalier, Cécile and Kiefer, Chris},
	month = may,
	year = {2020},
	pages = {263--267},
}

@phdthesis{armstrong2006,
	title = {An {Enactive} {Approach} to {Digital} {Musical} {Instrument} {Design}},
	language = {en},
	school = {Princeton University},
	author = {Armstrong, Newton},
	year = {2006},
}

@inproceedings{bederson1995,
	address = {Denver, Colorado, United States},
	title = {Audio augmented reality: a prototype automated tour guide},
	isbn = {978-0-89791-755-1},
	shorttitle = {Audio augmented reality},
	url = {http://portal.acm.org/citation.cfm?doid=223355.223526},
	doi = {10.1145/223355.223526},
	abstract = {Augmented reality (or computer augmented environments as it is sometimes called) uses computers to enhance the richness of the real world. It differs from virtual reality in that it doesn’t attempt to replace the real world. Our prototype automated tour guide superimposes audio on the world based on where a user is located. We propose this technique for use as an automated tour guide in museums and expect it will enhance the social aspects of museum visits, compared to taped tour guides.},
	language = {en},
	urldate = {2021-04-08},
	booktitle = {Conference companion on {Human} factors in computing systems  - {CHI} '95},
	publisher = {ACM Press},
	author = {Bederson, Benjamin B.},
	year = {1995},
	pages = {210--211},
}

@article{robinett1991,
	title = {A {Computational} {Model} for the {Stereoscopic} {Optics} of a {Head}-{Mounted} {Display}},
	abstract = {For stereoscopic photography or telepresence, orthostereoscopy occurs when the perceived size, shape, and relative position of objects in the three-dimensional scene being viewed match those of the physical objects in front of the camera. In Virtual Reality, the simulated scene has no physical counterpart, so orthostereoscopy must be defined in this case as constancy, as the head moves around, of the perceived size, shape and relative positions of the simulated objects.},
	language = {en},
	author = {Robinett, Warren and Rolland, Jannick P},
	year = {1991},
	pages = {21},
}

@phdthesis{callahan1983,
	address = {Massachusetts Institute of Technology},
	type = {Master of {Science}},
	title = {A 3-{D} display head-set for personalized computing},
	url = {http://hdl.handle.net/1721.1/71348},
	school = {Massachusetts Institute of Technology},
	author = {Callahan, Mark},
	year = {1983},
}

@inproceedings{sutherland1968,
	title = {A head-mounted three dimensional display},
	language = {en},
	booktitle = {Proceedings of the {December} 9-11, 1968, {Fall} {Joint} {Computer} {Conference}},
	author = {Sutherland, Ivan},
	year = {1968},
	pages = {757--764},
}

@inproceedings{kato1999,
	address = {San Francisco, CA, USA},
	title = {Marker tracking and {HMD} calibration for a video-based augmented reality conferencing system},
	isbn = {978-0-7695-0359-2},
	url = {http://ieeexplore.ieee.org/document/803809/},
	doi = {10.1109/IWAR.1999.803809},
	abstract = {We describe an augmented reality conferencing system which uses the overlay of virtual images on the real world. Remote collaborators are represented on Virtual Monitors which can be freely positioned about a user in space. Users can collaboratively view and interact with virtual objects using a shared virtual whiteboard. This is possible through precise virtual image registration using fast and accurate computer vision techniques and HMD calibration. We propose a method for tracking fiducial markers and a calibration method for optical see-through HMD based on the marker tracking.},
	language = {en},
	urldate = {2021-04-17},
	booktitle = {Proceedings 2nd {IEEE} and {ACM} {International} {Workshop} on {Augmented} {Reality} ({IWAR}'99)},
	publisher = {IEEE Comput. Soc},
	author = {Kato, H. and Billinghurst, M.},
	year = {1999},
	pages = {85--94},
}

@article{billinghurst2006,
	title = {Research {Directions} in {Handheld} {AR}},
	volume = {5},
	issn = {1081-1451},
	url = {https://ijvr.eu/article/view/2690},
	doi = {10.20870/IJVR.2006.5.2.2690},
	abstract = {Handheld mobile devices are an exciting new platform for Augmented Reality (AR). Mobile phones and PDAs have the potential to provide AR experiences to hundreds of millions of consumers. However, before widespread use can occur there are some obstacles that must be overcome. In particular, developers must consider the hardware and software capabilities of mobile devices and how these can be used to provide an effective AR experience. They must also develop AR interaction metaphors suitable for handheld AR. In this paper we review current and previous research in the field, provide design guidelines and outline future research directions.},
	language = {en},
	number = {2},
	urldate = {2021-04-17},
	journal = {International Journal of Virtual Reality},
	author = {Billinghurst, Mark and Henrysson, Anders},
	month = jan,
	year = {2006},
	pages = {51--58},
}

@inproceedings{piekarski2001,
	address = {Zurich, Switzerland},
	title = {Tinmith-{Metro}: new outdoor techniques for creating city models with an augmented reality wearable computer},
	isbn = {978-0-7695-1318-8},
	shorttitle = {Tinmith-{Metro}},
	url = {http://ieeexplore.ieee.org/document/962093/},
	doi = {10.1109/ISWC.2001.962093},
	abstract = {This paper presents new techniques for capturing and viewing on site 3D graphical models for large outdoor objects. Using an augmented reality wearable computer, we have developed a software system, known as TinmithMetro. Tinmith-Metro allows users to control a 3D constructive solid geometry modeller for building graphical objects of large physical artefacts, for example buildings, in the physical world. The 3D modeller is driven by a new user interface known as Tinmith-Hand, which allows the user to control the modeller using a set of pinch gloves and hand tracking. These techniques allow user to supply their AR renderers with models that would previously have to be captured with manual, time-consuming, and/or expensive methods.},
	language = {en},
	urldate = {2021-04-14},
	booktitle = {Proceedings {Fifth} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {IEEE Comput. Soc},
	author = {Piekarski, W. and Thomas, B.H.},
	year = {2001},
	pages = {31--38},
}

@inproceedings{satoh2001,
	address = {New York, NY, USA},
	title = {A hybrid registration method for outdoor augmented reality},
	isbn = {978-0-7695-1375-1},
	url = {http://ieeexplore.ieee.org/document/970516/},
	doi = {10.1109/ISAR.2001.970516},
	abstract = {In this paper, a registration method for outdoor wearable AR systems is described. Our approach is based on using a high precision gyroscope, which can measure 3DOF angle of head direction accurately, but with some drift error. We solved the drift problem with a vision-based drift compensation algorithm, which tracks natural features in the outdoor environment as landmarks from images captured by a camera on an HMD. This paper first describes the detail of the vision-based drift compensation method. Then, a calibration method for the orientation sensor is proposed. Finally, using results from an actual wearable AR system, a comparison of registration error with and without vision-based drift compensation demonstrates the feasibility of the proposed method.},
	language = {en},
	urldate = {2021-04-09},
	booktitle = {Proceedings {IEEE} and {ACM} {International} {Symposium} on {Augmented} {Reality}},
	publisher = {IEEE Comput. Soc},
	author = {Satoh, K. and Anabuki, M. and Yamamoto, H. and Tamura, H.},
	year = {2001},
	pages = {67--76},
}

@article{fruend2001,
	title = {The {Augmented} {Reality} {Personal} {Digital} {Assistant}},
	abstract = {This short paper describes a German research project on mobile augmented reality. The idea is to develop a framework that provides AR-services for the consumer market using a personal digital assistant.},
	language = {en},
	author = {Fruend, Juergen and Geiger, Christian and Grafe, Michael and Kleinjohann, Bernd and Institut, Heinz-Nixdorf},
	year = {2001},
	pages = {3},
}

@article{feiner1997,
	title = {A {Touring} {Machine}: {Prototyping} {3D} {Mobile} {Augmented} {Reality} {Systems} for {Exploring} the {Urban} {Environment}},
	volume = {1},
	doi = {https://doi.org/10.1007/BF01682023},
	abstract = {We describe a prototype system that combines together the overlaid 3D graphics of augmented reality with the untethered freedom of mobile computing. The goal is to explore how these two technologies might together make possible wearable computer systems that can support users in their everyday interactions with the world. We introduce an application that presents information about our university’s campus, using a head-tracked, see-through, headworn, 3D display, and an untracked, opaque, handheld, 2D display with stylus and trackpad. We provide an illustrated explanation of how our prototype is used, and describe our rationale behind designing its software infrastructure and selecting the hardware on which it runs.},
	language = {en},
	journal = {Personal Technologies},
	author = {Feiner, Steven and MacIntyre, Blair and Höllerer, Tobias and Webster, Anthony},
	year = {1997},
	pages = {8},
}

@article{julier2000,
	title = {{BARS}: {Battlefield} {Augmented} {Reality} {System}},
	abstract = {Many future military operations are expected to occur in urban environments. These complex, 3D battlefields are extremely demanding and introduce many challenges to the dismounted warfighter. These include limited visibility, lack of familiarity with the environment, sniper threats, concealment of enemy forces, ineffective communications, and a general problem of locating and identifying enemy and friendly forces. Better situational awareness is required for effective operation in the urban environment.},
	language = {en},
	author = {Julier, Simon and Baillot, Yohan and Lanzagorta, Marco and Brown, Dennis and Rosenblum, Lawrence},
	year = {2000},
	pages = {8},
}

@inproceedings{kalkusch2002,
	address = {Darmstadt, Germany},
	title = {Structured visual markers for indoor pathfinding},
	isbn = {978-0-7803-7680-9},
	url = {http://ieeexplore.ieee.org/document/1107018/},
	doi = {10.1109/ART.2002.1107018},
	abstract = {We present a mobile augmented reality (AR) system to guide a user through an unfamiliar building to a destination room. The system presents a world-registered wire frame model of the building labeled with directional information in a see-through heads-up display, and a three-dimensional world-in-miniature (WIM) map on a wrist-worn pad that also acts as an input device. Tracking is done using a combination of wall-mounted ARToolkit markers observed by a head-mounted camera, and an inertial tracker. To allow coverage of arbitrarily large areas with a limited set of markers, a structured marker re-use scheme based on graph coloring has been developed.},
	language = {en},
	urldate = {2021-04-09},
	booktitle = {The {First} {IEEE} {International} {Workshop} {Agumented} {Reality} {Toolkit},},
	publisher = {IEEE},
	author = {Kalkusch, M. and Lidy, T. and Knapp, N. and Reitmayr, G. and Kaufmann, H. and Schmalstieg, D.},
	year = {2002},
	pages = {8},
}

@article{zavota2016,
	title = {Expanding the {Extended} {Mind}: {Merleau}-{Ponty}’s {Late} {Ontology} as {Radical} {Enactive} {Cognition}},
	volume = {17},
	issn = {15260569},
	shorttitle = {Expanding the {Extended} {Mind}},
	url = {http://www.pdcnet.org/oom/service?url_ver=Z39.88-2004&rft_val_fmt=&rft.imuse_id=eip_2016_0017_0002_0094_0124&svc_id=info:www.pdcnet.org/collection},
	doi = {10.7710/1526-0569.1558},
	abstract = {In this essay, I argue that the late ontology of Maurice MerleauPonty, in particular the system he began to develop in The Visible and the Invisible, can be conceived of as a form of Radical Enactive Cognition, as described by Hutto and Myin in Radicalizing Enactivism. I will begin by discussing Clark and Chalmers’ extended mind hypothesis, as well as the enactive view of consciousness proposed by Varela, Thompson, and Rosch in The Embodied Mind. However, neither Clark and Chalmers’ extended mind hypothesis nor the enactive view of consciousness advanced by Varela et al. are radical enough to fully capture Merleau-Ponty’s late ontology. Inasmuch as Hutto and Myin’s formulation combines features of the extended mind thesis and enactivism, and expresses both in a sufficiently radical fashion, it overcomes the deficits of both theories and can serve as a translation, so to speak, of MerleauPonty’s “ontology of the flesh” into contemporary terms. In particular, their formulation makes explicit several central aspects of his theory: the intimate, mutually constitutive relationship between perceiver and perceived world, the equal weight given to the contributions of perceiver and world within this relationship, and the displacement of representational content from its central position in the understanding of consciousness. It is thus the ideal vehicle for demonstrating some perhaps unexpected ways in which Merleau-Ponty’s thought is compatible with contemporary conversations concerning the nature of mind.},
	language = {en},
	number = {2},
	urldate = {2021-06-11},
	journal = {Essays in Philosophy},
	author = {Zavota, Gina},
	year = {2016},
	pages = {94--124},
}

@inproceedings{collins2011,
	address = {Coimbra, Portugal},
	title = {Making gamers cry: mirror neurons and embodied interaction with game sound},
	isbn = {978-1-4503-1081-9},
	shorttitle = {Making gamers cry},
	url = {http://dl.acm.org/citation.cfm?doid=2095667.2095673},
	doi = {10.1145/2095667.2095673},
	abstract = {In this paper, I draw on an embodied cognition approach to describe how sound mediates our identification with and empathy for video game characters. This identification is discussed in terms of mirror neurons and body schema, drawing on theoretical and empirical research to explore ways in which identity is created from our embodied interaction with sound. I conclude by suggesting ways in which sound designers and composers can use this information to create more empathy and identification between players and their game characters.},
	language = {en},
	urldate = {2021-06-11},
	booktitle = {Proceedings of the 6th {Audio} {Mostly} {Conference} on {A} {Conference} on {Interaction} with {Sound} - {AM} '11},
	publisher = {ACM Press},
	author = {Collins, Karen},
	year = {2011},
	pages = {39--46},
}

@book{collins2013,
	address = {Cambridge, Massachusetts},
	title = {Playing with sound: a theory of interacting with sound and music in video games},
	isbn = {978-0-262-01867-8},
	shorttitle = {Playing with sound},
	language = {en},
	publisher = {The MIT Press},
	author = {Collins, Karen},
	year = {2013},
	keywords = {Interactive multimedia, Video games},
}

@incollection{davies2004,
	title = {Virtual space},
	isbn = {978-0-521-82376-0},
	booktitle = {Space: {In} {Science}, {Art}, and {Society}},
	publisher = {Cambridge University Press},
	author = {Davies, Char},
	editor = {Penz, François and Radick, Gregory and Howell, Robert},
	year = {2004},
	pages = {69--104},
}

@inproceedings{rodger2020,
	address = {Birmingham, UK},
	title = {What {Makes} a {Good} {Musical} {Instrument}? {A} {Matter} of {Processes}, {Ecologies} and {Specificities}},
	abstract = {Understanding the question of what makes a good musical instrument raises several conceptual challenges. Researchers have regularly adopted tools from traditional HCI as a framework to address this issue, in which instrumental musical activities are taken to comprise a device and a user, and should be evaluated as such. We argue that this approach is not equipped to fully address the conceptual issues raised by this question. It is worth reflecting on what exactly an instrument is, and how instruments contribute toward meaningful musical experiences. Based on a theoretical framework that incorporates ideas from ecological psychology, enactivism, and phenomenology, we propose an alternative approach to studying musical instruments. According to this approach, instruments are better understood in terms of processes rather than as devices, while musicians are not users, but rather agents in musical ecologies. A consequence of this reframing is that any evaluations of instruments, if warranted, should align with the specificities of the relevant processes and ecologies concerned. We present an outline of this argument and conclude with a description of a current research project to illustrate how our approach can shape the design and performance of a musical instrument in-progress.},
	language = {en},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Rodger, Matthew and Stapleton, Paul and van Walstijn, Maarten and Ortiz, Miguel and Pardue, Laurel},
	year = {2020},
	pages = {6},
}

@article{magnusson2021,
	title = {The migration of musical instruments: {On} the socio-technological conditions of musical evolution},
	volume = {50},
	issn = {0929-8215, 1744-5027},
	shorttitle = {The migration of musical instruments},
	url = {https://www.tandfonline.com/doi/full/10.1080/09298215.2021.1907420},
	doi = {10.1080/09298215.2021.1907420},
	abstract = {Music technologies reflect the most advanced human technologies in most historical periods. Examples range from 40 thousand years old bone flutes found in caves in the Swabian Jura, through ancient Greek water organs or medieval Arabic musical automata, to today’s electronic and digital instruments with deep learning. Music technologies incorporate the musical ideas of a time and place and they disseminate those ideas when adopted by other musical cultures. This article explores how contemporary music technologies are culturally conditioned and applies the concept of ethno-organology to describe the nature of migration of instruments between musical cultures.},
	language = {en},
	number = {2},
	urldate = {2021-06-10},
	journal = {Journal of New Music Research},
	author = {Magnusson, Thor},
	month = mar,
	year = {2021},
	pages = {175--183},
}

@incollection{thiel2018,
	address = {Cham},
	title = {Critical {Interventions} into {Canonical} {Spaces}: {Augmented} {Reality} at the 2011 {Venice} and {Istanbul} {Biennials}},
	isbn = {978-3-319-69931-8 978-3-319-69932-5},
	shorttitle = {Critical {Interventions} into {Canonical} {Spaces}},
	url = {http://link.springer.com/10.1007/978-3-319-69932-5_2},
	urldate = {2021-05-17},
	booktitle = {Augmented {Reality} {Art}},
	publisher = {Springer International Publishing},
	author = {Thiel, Tamiko},
	editor = {Geroimenko, Vladimir},
	year = {2018},
	pages = {41--72},
}

@incollection{skwarek2018,
	address = {Cham},
	title = {Augmented {Reality} {Activism}},
	isbn = {978-3-319-69931-8 978-3-319-69932-5},
	url = {http://link.springer.com/10.1007/978-3-319-69932-5_1},
	urldate = {2021-05-17},
	booktitle = {Augmented {Reality} {Art}},
	publisher = {Springer International Publishing},
	author = {Skwarek, Mark},
	editor = {Geroimenko, Vladimir},
	year = {2018},
	pages = {3--40},
}

@misc{thiel2011,
	title = {invisible istanbul},
	url = {https://web.archive.org/web/20111125101557/http://www.invisibleistanbul.org/},
	urldate = {2021-05-17},
	author = {Thiel, Tamiko and Kozar, Cem and Ünal, Işıl},
	month = nov,
	year = {2011},
}

@inproceedings{nishida2020,
	address = {Virtual Event USA},
	title = {{HandMorph}: a {Passive} {Exoskeleton} that {Miniaturizes} {Grasp}},
	isbn = {978-1-4503-7514-6},
	shorttitle = {{HandMorph}},
	url = {https://dl.acm.org/doi/10.1145/3379337.3415875},
	doi = {10.1145/3379337.3415875},
	abstract = {We engineered an exoskeleton, which we call HandMorph, that approximates the experience of having a smaller grasp­ ing range. It uses mechanical links to transmit motion from the wearer’s ﬁngers to a smaller hand with ﬁve anatomically correct ﬁngers. The result is that HandMorph miniaturizes a wearer’s grasping range while transmitting haptic feedback.},
	language = {en},
	urldate = {2021-05-15},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Nishida, Jun and Matsuda, Soichiro and Matsui, Hiroshi and Teng, Shan-Yuan and Liu, Ziwei and Suzuki, Kenji and Lopes, Pedro},
	month = oct,
	year = {2020},
	pages = {565--578},
}

@inproceedings{hashizume2018,
	address = {Berlin Germany},
	title = {Trans-scale {Playground}: {An} {Immersive} {Visual} {Telexistence} {System} for {Human} {Adaptation}},
	isbn = {978-1-4503-5949-8},
	shorttitle = {Trans-scale {Playground}},
	url = {https://dl.acm.org/doi/10.1145/3266037.3266103},
	doi = {10.1145/3266037.3266103},
	abstract = {In this paper, we present a novel telexistence system and design methods for telexistence studies to explore spatialscale deconstruction. There have been studies on the experience of dwarf-sized or giant-sized telepresence have been conducted over a period of many years. In this study, we discuss the scale of movements, image transformation, technical components of telepresence robots, and user experiences of telexistence-based spatial transformations. We implemented two types of telepresence robots with an omnidirectional stereo camera setup for a spatial trans-scale experience, wheeled robots, and quadcopters. These telepresence robots provide users with a trans-scale experience for a distance ranging from 15 cm to 30 m. We conducted user studies for different camera positions on robots and for different image transformation method.},
	language = {en},
	urldate = {2021-05-15},
	booktitle = {The 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology} {Adjunct} {Proceedings}},
	publisher = {ACM},
	author = {Hashizume, Satoshi and Ishii, Akira and Suzuki, Kenta and Takazawa, Kazuki and Ochiai, Yoichi},
	year = {2018},
	pages = {66--68},
}

@inproceedings{nishida2019,
	address = {Glasgow Scotland Uk},
	title = {Egocentric {Smaller}-person {Experience} through a {Change} in {Visual} {Perspective}},
	isbn = {978-1-4503-5970-2},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300926},
	doi = {10.1145/3290605.3300926},
	language = {en},
	urldate = {2021-05-15},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Nishida, Jun and Matsuda, Soichiro and Oki, Mika and Takatori, Hikaru and Sato, Kosuke and Suzuki, Kenji},
	month = may,
	year = {2019},
	pages = {1--12},
}

@article{kerruish2019,
	title = {Arranging sensations: smell and taste in augmented and virtual reality},
	volume = {14},
	issn = {1745-8927, 1745-8935},
	shorttitle = {Arranging sensations},
	url = {https://www.tandfonline.com/doi/full/10.1080/17458927.2018.1556952},
	doi = {10.1080/17458927.2018.1556952},
	abstract = {The development of digital taste and smell underscores the importance of cultural dimensions of bodily perception in augmented reality (AR) and virtual reality (VR) devices. This can be seen in Vocktail and Season Traveller, two digital devices incorporating taste and smell. Vocktail is an AR technology that augments the experience of drinking water, or even air, through the electrical stimulation of tastebuds and the manipulation of color and smell. Season Traveller is a VR game in which the user moves through four seasonal landscapes. It uses wind, odor, and temperature in addition to the more standard audio-visual displays. The cultural dimensions of these devices can be examined using phenomenological terms. They instigate perceptual circuits, and call on and create sedimented habits. Although VR and AR are often thought of in terms of their similitude to reality, understanding Vocktail and Season Traveller this way illustrates the world-creating dimension of multisensory devices. These technologies structure and shift thresholds of taste and smell, reworking past perceptual styles and habits to develop new perceptual experiences. In so doing, Season Traveller and Vocktail throw to the fore questions about the conditions according to which people exercise their senses in digitally dominated environments.},
	language = {en},
	number = {1},
	urldate = {2021-05-14},
	journal = {The Senses and Society},
	author = {Kerruish, Erika},
	month = jan,
	year = {2019},
	pages = {31--45},
}

@article{rolland2000,
	title = {Optical {Versus} {Video} {See}-{Through} {Head}-{Mounted} {Displays} in {Medical} {Visualization}},
	volume = {9},
	issn = {1054-7460},
	url = {https://direct.mit.edu/pvar/article/9/3/287-309/18346},
	doi = {10.1162/105474600566808},
	abstract = {We compare two technological approaches to augmented reality for 3-D medical visualization: optical and video see-through devices. We provide a context to discuss the technology by reviewing several medical applications of augmented-reality research efforts driven by real needs in the medical ﬁeld, both in the United States and in Europe. We then discuss the issues for each approach, optical versus video, from both a technology and human-factor point of view. Finally, we point to potentially promising future developments of such devices including eye tracking and multifocus planes capabilities, as well as hybrid optical/video technology.},
	language = {en},
	number = {3},
	urldate = {2021-05-14},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Rolland, Jannick P. and Fuchs, Henry},
	month = jun,
	year = {2000},
	pages = {287--309},
}

@inproceedings{mann2018a,
	address = {Galway},
	title = {Phenomenological {Augmented} {Reality} with the {Sequential} {Wave} {Imprinting} {Machine} ({SWIM})},
	isbn = {978-1-5386-6304-2},
	url = {https://ieeexplore.ieee.org/document/8516502/},
	doi = {10.1109/GEM.2018.8516502},
	abstract = {SWIM (Sequential Wave Imprinting Machine) is an invention that makes for visual art as well as scientiﬁc discovery of otherwise invisible physical phenomenology around us, such as sound waves, radio waves, etc.. It uses multimediated reality (sensing, computation, and display) to turn phenomena such as interference patterns between multiple sound sources, into pictures “painted” by nature itself (rather than from computer graphics). This gives us a glimpse into the nature of the real world arouond us, i.e. phenomena arising from physics (natural philosophy).},
	language = {en},
	urldate = {2021-05-20},
	booktitle = {2018 {IEEE} {Games}, {Entertainment}, {Media} {Conference} ({GEM})},
	publisher = {IEEE},
	author = {Mann, Steve},
	year = {2018},
	pages = {1--9},
}

@inproceedings{chevalier2018,
	address = {Porto, Portugal},
	title = {Listening {Mirrors}: {Prototyping} for a {Hybrid} {Audio} {Augmented} {Reality} {Installation}},
	isbn = {978-989-746-170-5},
	url = {https://sro.sussex.ac.uk/id/eprint/74980/},
	abstract = {We introduce ongoing developments of Listening Mirrors, a sound art instal-lation and live interface for musician and non-musician alike. The piece, in its construction and interaction design, investigates ways in which collective sonic expression can be made possi-ble using Audio Augmented Reality technology (AAR) and acoustic mirrors, whilst asking how such environments promote collective sonic expression.},
	urldate = {2021-04-30},
	booktitle = {{ICLI} 2018, 4th {International} {Conference} on {Live} {Interfaces}. {Inspiration}, {Performance}, {Emancipation}.},
	author = {Chevalier, Cécile and Kiefer, Chris},
	editor = {{José Alberto Gomes} and {Miguel Carvalhais} and {Rui Penha}},
	year = {2018},
	pages = {241},
}

@article{shivers1993,
	title = {{BodyTalk} and the {BodyNet}: {A} {Personal} {Information} {Infrastructure}},
	abstract = {The current evolution of personal information appliances, such as cellular telephones, personal digital assistants, and notebook computers, can be made more effective if re-structured into a personal network architecture. This architecture is based upon two central components: a hardware communications system, the BodyNet, and a common interface language, BodyTalk.},
	language = {en},
	author = {Shivers, Olin},
	year = {1993},
	pages = {19},
}

@book{price2011,
	address = {Ann Arbor},
	series = {Corporealities},
	title = {Mad at school: rhetorics of mental disability and academic life},
	isbn = {978-0-472-07138-8 978-0-472-05138-0},
	shorttitle = {Mad at school},
	publisher = {University of Michigan Press},
	author = {Price, Margaret},
	year = {2011},
	keywords = {College students, College teachers, Communication, Education (Higher), Employment, Faculty, Mental health, Mentally Disabled Persons, Mentally ill, Personal Narratives, Stereotyping, psychology},
}

@article{ossaparra2015,
	title = {Engaging in critically reflective teaching: from theory to practice in pursuit of transformative learning},
	volume = {16},
	issn = {1462-3943, 1470-1103},
	shorttitle = {Engaging in critically reflective teaching},
	url = {http://www.tandfonline.com/doi/abs/10.1080/14623943.2014.944141},
	doi = {10.1080/14623943.2014.944141},
	language = {en},
	number = {1},
	urldate = {2021-09-14},
	journal = {Reflective Practice},
	author = {Ossa Parra, Marcela and Gutiérrez, Roberto and Aldana, María Fernanda},
	month = jan,
	year = {2015},
	pages = {16--30},
}

@article{francis2019,
	title = {Undergraduate student perceptions of assessment and feedback practice: fostering agency and dialogue},
	volume = {43},
	issn = {0309-8265, 1466-1845},
	shorttitle = {Undergraduate student perceptions of assessment and feedback practice},
	url = {https://www.tandfonline.com/doi/full/10.1080/03098265.2019.1660867},
	doi = {10.1080/03098265.2019.1660867},
	abstract = {Assessment and feedback practices sit at the heart of education and the student experience. This paper reports on undergraduate perceptions of assessment and feedback in the Department of Geography at King’s College London, UK. Twenty-eight ﬁrst and second-year students across six focus groups provided comments on their understanding of feedback, their feedback experiences, and what they felt could be improved. It was clear that students desired feedback that would help them improve summative performance, but were unsure of how best to use it and consequently had high expectations that led to dissatisfaction. Particular concern was expressed about marking and feedback consistency, and the inherent variation in practice they experienced. Many comments indicated a lack of student agency, which may reﬂect the power relations that students ﬁnd themselves in within their community of practice. Finding ways of fostering agency and improving dialogue over perceptions and expectations are suggested to be important steps in improving assessment and feedback practice, and student satisfaction.},
	language = {en},
	number = {4},
	urldate = {2021-09-13},
	journal = {Journal of Geography in Higher Education},
	author = {Francis, Robert A. and Millington, James D.A. and Cederlöf, Gustav},
	month = oct,
	year = {2019},
	pages = {468--485},
}

@article{bailey2017,
	title = {Online {Feminist} {Pedagogy}: {A} {New} {Doorway} into {Our} {Brick}-and-{Mortar} {Classrooms}?},
	volume = {27},
	issn = {08824843},
	shorttitle = {Online {Feminist} {Pedagogy}},
	url = {https://www.jstor.org/stable/10.5406/femteacher.27.2-3.0253},
	doi = {10.5406/femteacher.27.2-3.0253},
	language = {en},
	number = {2-3},
	urldate = {2021-09-08},
	journal = {Feminist Teacher},
	author = {Bailey, Cathryn},
	year = {2017},
	pages = {253},
}

@article{knight2016,
	title = {A {Companion} to {Public} {Art}},
	language = {en},
	author = {Knight, Cher Krause},
	year = {2016},
	pages = {514},
}

@inproceedings{bilbow2021,
	address = {Italy},
	title = {The {Value} of {Sound} within a {Multisensory} {Approach} to {AR} in the {Arts}},
	abstract = {We explore the potential of sound within broader multisensory augmented reality, and its value in creating coherent, immersive and embodied experiences in computational art. We demonstrate this practically through accounts of the authors experiences in creating two pieces. Looking at the wider place of AR in the arts, we argue that DIY approaches to augmented reality are essential for creative work, and we speculate on how art can contribute to future theory, technologies and practice in the ﬁeld.},
	language = {en},
	booktitle = {Workshop: {Multisensory} {Augmented} {Reality}},
	author = {Bilbow, Sam and Kiefer, Chris and Chevalier, Cécile},
	year = {2021},
	pages = {8},
}

@incollection{paul2016,
	edition = {1},
	title = {Augmented {Realities}: {Digital} {Art} in the {Public} {Sphere}},
	isbn = {978-1-118-47532-4 978-1-118-47533-1},
	shorttitle = {Augmented {Realities}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118475331.ch10},
	language = {en},
	urldate = {2021-06-11},
	booktitle = {A {Companion} to {Public} {Art}},
	publisher = {Wiley},
	author = {Paul, Christiane},
	editor = {Knight, Cher Krause and Senie, Harriet F.},
	month = aug,
	year = {2016},
	pages = {205--225},
}

@article{tcha-tokey2016a,
	title = {Proposition and {Validation} of a {Questionnaire} to {Measure} the {User} {Experience} in {Immersive} {Virtual} {Environments}},
	volume = {16},
	issn = {1081-1451},
	url = {https://ijvr.eu/article/view/2880},
	doi = {10.20870/IJVR.2016.16.1.2880},
	abstract = {There are increasing new advances in Virtual Reality technologies as well as a rise in Immersive Virtual Environments research and in User eXperience research. Within this framework, we decided to address the overall user experience in Immersive virtual environments. Indeed, in our point of view, this topic is not fully dealt with in the scientific literature, neither in terms of user experience components nor in terms of user experience measurement methods. It is in this context that we conducted a study aiming at proposing and validating a unified questionnaire on User eXperience in Immersive Virtual Environment. Our questionnaire contains 10 scales measuring presence, engagement, immersion, flow, usability, skill, emotion, experience consequence, judgement and technology adoption. Scale construction was based on existing questionnaires. Our questionnaire was tested on 116 participants after they use the edutainment Virtual Environment “Think and Shoot”. The number of participants allows us to assess the reliability and the sensitivity of our questionnaire. Results show that 9 out of 10 subscales and 68 out of 87 items are reliable as demonstrated by an internal consistency analysis with Cronbach’s alpha and an item analysis. Findings also indicate that the scale scores from 6 subscales are considered normal distributed (e.g. presence) whereas the scale scores from 3 subscales are considered negatively skewed (e.g. skill).},
	language = {en},
	number = {1},
	urldate = {2021-07-19},
	journal = {International Journal of Virtual Reality},
	author = {Tcha-Tokey, Katy and Christmann, Olivier and Loup-Escande, Emilie and Richir, Simon},
	month = jan,
	year = {2016},
	pages = {33--48},
}

@inproceedings{waters2007,
	address = {DeMonfort University, Leicester},
	title = {Performance {Ecosystems}: {Ecological} approaches to musical interaction},
	url = {http://www.ems-network.org/IMG/pdf_WatersEMS07.pdf},
	abstract = {Music is understood as a dynamical complex of interacting situated embodied behaviours. These behaviours may be physical or virtual, composed or emergent, or of a time scale such that they figure as constraints or constructs. All interact in the same space by a process of mutual modelling, redescription, and emergent restructuring.},
	urldate = {2021-07-13},
	booktitle = {Electroacoustic {Music} {Studies} {Network} {EMS}-07 {Proceedings}},
	author = {Waters, Simon},
	year = {2007},
	pages = {20},
}

@book{dourish2004,
	address = {Cambridge, Mass.},
	edition = {1. MIT Press paperback ed},
	series = {A {Bradford} book},
	title = {Where the action is: the foundations of embodied interaction},
	isbn = {978-0-262-54178-7},
	shorttitle = {Where the action is},
	language = {eng},
	publisher = {MIT Press},
	author = {Dourish, Paul},
	year = {2004},
}

@article{kirchhoff2015,
	title = {Extended {Cognition} \& the {Causal}-{Constitutive} {Fallacy}: {In} {Search} for a {Diachronic} and {Dynamical} {Conception} of {Constitution}},
	volume = {90},
	issn = {00318205},
	shorttitle = {Extended {Cognition} \& the {Causal}-{Constitutive} {Fallacy}},
	url = {http://doi.wiley.com/10.1111/phpr.12039},
	doi = {10.1111/phpr.12039},
	language = {en},
	number = {2},
	urldate = {2021-06-14},
	journal = {Philosophy and Phenomenological Research},
	author = {Kirchhoff, Michael D.},
	month = mar,
	year = {2015},
	pages = {320--360},
}

@book{hutto2017a,
	address = {Cambridge, Massachusetts; London},
	title = {Radicalizing enactivism: basic minds without content},
	isbn = {978-0-262-01854-8 978-0-262-53464-2},
	shorttitle = {Radicalizing enactivism},
	language = {English},
	publisher = {MIT Press},
	author = {Hutto, Daniel D and Myin, Erik and {MIT Press}},
	year = {2017},
}

@book{hutto2017,
	address = {Cambridge, Massachusetts},
	title = {Evolving enactivism: basic minds meet content},
	isbn = {978-0-262-03611-5},
	shorttitle = {Evolving enactivism},
	publisher = {MIT Press},
	author = {Hutto, Daniel D. and Myin, Erik},
	year = {2017},
	keywords = {Act (Philosophy), Cognitive science, Content (Psychology), Intentionalism, Intentionality (Philosophy), Mental representation, Phenomenology, Philosophy of mind},
}

@article{kirchhoff2020,
	title = {Attuning to the {World}: {The} {Diachronic} {Constitution} of the {Extended} {Conscious} {Mind}},
	volume = {11},
	issn = {1664-1078},
	shorttitle = {Attuning to the {World}},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2020.01966/full},
	doi = {10.3389/fpsyg.2020.01966},
	abstract = {It is a near consensus among materialist philosophers of mind that consciousness must somehow be constituted by internal neural processes, even if we remain unsure quite how this works. Even friends of the extended mind theory have argued that when it comes to the material substrate of conscious experience, the boundary of skin and skull is likely to prove somehow to be privileged. Such arguments have, however, typically conceived of the constitution of consciousness in synchronic terms, making a ﬁrm separation between proximate mechanisms and their ultimate causes. We argue that the processes involved in the constitution of some conscious experiences are diachronic, not synchronic. We focus on what we call phenomenal attunement in this paper—the feeling of being at home in a familiar, culturally constructed environment. Such a feeling is missing in cases of culture shock. Phenomenal attunement is a structure of our conscious experience of the world that is ubiquitous and taken for granted. We will argue that it is constituted by cycles of embodied and world-involving engagement whose dynamics are constrained by cultural practices. Thus, it follows that an essential structure of the conscious mind, the absence of which profoundly transforms conscious experience, is extended.},
	language = {en},
	urldate = {2021-06-14},
	journal = {Frontiers in Psychology},
	author = {Kirchhoff, Michael D. and Kiverstein, Julian},
	month = aug,
	year = {2020},
	pages = {1966},
}

@book{landy2007,
	address = {Cambridge, Mass},
	title = {Understanding the art of sound organization},
	isbn = {978-0-262-12292-4},
	language = {en},
	publisher = {MIT Press},
	author = {Landy, Leigh},
	year = {2007},
	keywords = {Computer music, Electro-acoustics, Electronic music, History and criticism},
}

@book{rodgers,
	title = {Pink {Noises}: {Women} on {Electronic} {Music} and {Sound}},
	language = {en},
	author = {Rodgers, Tara},
}

@book{hugill2018,
	address = {New York ; London},
	edition = {Third edition},
	title = {The {Digital} {Musician}},
	isbn = {978-0-203-70421-9},
	language = {en},
	publisher = {Routledge},
	author = {Hugill, Andrew},
	year = {2018},
	keywords = {Computer music, History and criticism, Instruction and study, Music, Philosophy and aesthetics},
}

@book{hooks1994,
	title = {Teaching to {Transgress}},
	publisher = {Taylor \& Francis Group},
	author = {Hooks, Bell},
	year = {1994},
}

@article{slater2010,
	title = {First {Person} {Experience} of {Body} {Transfer} in {Virtual} {Reality}},
	volume = {5},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0010564},
	doi = {10.1371/journal.pone.0010564},
	abstract = {Background: Altering the normal association between touch and its visual correlate can result in the illusory perception of a fake limb as part of our own body. Thus, when touch is seen to be applied to a rubber hand while felt synchronously on the corresponding hidden real hand, an illusion of ownership of the rubber hand usually occurs. The illusion has also been demonstrated using visuomotor correlation between the movements of the hidden real hand and the seen fake hand. This type of paradigm has been used with respect to the whole body generating out-of-the-body and body substitution illusions. However, such studies have only ever manipulated a single factor and although they used a form of virtual reality have not exploited the power of immersive virtual reality (IVR) to produce radical transformations in body ownership.},
	language = {en},
	number = {5},
	urldate = {2022-08-19},
	journal = {PLoS ONE},
	author = {Slater, Mel and Spanlang, Bernhard and Sanchez-Vives, Maria V. and Blanke, Olaf},
	editor = {Williams, Mark A.},
	month = may,
	year = {2010},
	pages = {e10564},
}

@article{seth2014,
	title = {A predictive processing theory of sensorimotor contingencies: {Explaining} the puzzle of perceptual presence and its absence in synesthesia},
	volume = {5},
	issn = {1758-8928, 1758-8936},
	shorttitle = {A predictive processing theory of sensorimotor contingencies},
	url = {http://www.tandfonline.com/doi/abs/10.1080/17588928.2013.877880},
	doi = {10.1080/17588928.2013.877880},
	language = {en},
	number = {2},
	urldate = {2022-08-19},
	journal = {Cognitive Neuroscience},
	author = {Seth, Anil K.},
	month = apr,
	year = {2014},
	pages = {97--118},
}

@book{noe2004,
	address = {Cambridge, Mass},
	series = {Representation and mind},
	title = {Action in perception},
	isbn = {978-0-262-14088-1},
	publisher = {MIT Press},
	author = {Noë, Alva},
	year = {2004},
	keywords = {Act (Philosophy), Perception (Philosophy)},
}

@article{suzuki2013,
	title = {Multisensory integration across exteroceptive and interoceptive domains modulates self-experience in the rubber-hand illusion},
	volume = {51},
	issn = {00283932},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0028393213002789},
	doi = {10.1016/j.neuropsychologia.2013.08.014},
	abstract = {Identifying with a body is central to being a conscious self. The now classic “rubber hand illusion” demonstrates that the experience of body-ownership can be modulated by manipulating the timing of exteroceptive (visual and tactile) body-related feedback. Moreover, the strength of this modulation is related to individual differences in sensitivity to internal bodily signals (interoception). However the interaction of exteroceptive and interoceptive signals in determining the experience of body-ownership within an individual remains poorly understood. Here, we demonstrate that this depends on the online integration of exteroceptive and interoceptive signals by implementing an innovative “cardiac rubber hand illusion” that combined computer-generated augmented-reality with feedback of interoceptive (cardiac) information. We show that both subjective and objective measures of virtual-hand ownership are enhanced by cardio-visual feedback in-time with the actual heartbeat, as compared to asynchronous feedback. We further show that these measures correlate with individual differences in interoceptive sensitivity, and are also modulated by the integration of proprioceptive signals instantiated using realtime visual remapping of ﬁnger movements to the virtual hand. Our results demonstrate that interoceptive signals directly inﬂuence the experience of body ownership via multisensory integration, and they lend support to models of conscious selfhood based on interoceptive predictive coding.},
	language = {en},
	number = {13},
	urldate = {2022-08-19},
	journal = {Neuropsychologia},
	author = {Suzuki, Keisuke and Garfinkel, Sarah N. and Critchley, Hugo D. and Seth, Anil K.},
	month = nov,
	year = {2013},
	pages = {2909--2917},
}

@article{suzuki2019,
	title = {Sensorimotor contingency modulates breakthrough of virtual {3D} objects during a breaking continuous flash suppression paradigm},
	volume = {187},
	issn = {00100277},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027719300587},
	doi = {10.1016/j.cognition.2019.03.003},
	abstract = {To investigate how embodied sensorimotor interactions shape subjective visual experience, we developed a novel combination of Virtual Reality (VR) and Augmented Reality (AR) within an adapted breaking continuous ﬂash suppression (bCFS) paradigm. In a ﬁrst experiment, participants manipulated novel virtual 3D objects, viewed through a head-mounted display, using three interlocking cogs. This setup allowed us to manipulate the sensorimotor contingencies governing interactions with virtual objects, while characterising the eﬀects on subjective visual experience by measuring breakthrough times from bCFS. We contrasted the eﬀects of the congruency (veridical versus reversed sensorimotor coupling) and contingency (live versus replayed interactions) using a motion discrimination task. The results showed that the contingency but not congruency of sensorimotor coupling aﬀected breakthrough times, with live interactions displaying faster breakthrough times. In a second experiment, we investigated how the contingency of sensorimotor interactions aﬀected object category discrimination within a more naturalistic setting, using a motion tracker that allowed object interactions with increased degrees of freedom. We again found that breakthrough times were faster for live compared to replayed interactions (contingency eﬀect). Together, these data demonstrate that bCFS breakthrough times for unfamiliar 3D virtual objects are modulated by the contingency of the dynamic causal coupling between actions and their visual consequences, in line with theories of perception that emphasise the inﬂuence of sensorimotor contingencies on visual experience. The combination of VR/AR and motion tracking technologies with bCFS provides a novel methodology extending the use of binocular suppression paradigms into more dynamic and realistic sensorimotor environments.},
	language = {en},
	urldate = {2022-08-19},
	journal = {Cognition},
	author = {Suzuki, Keisuke and Schwartzman, David J. and Augusto, Rafael and Seth, Anil K.},
	month = jun,
	year = {2019},
	pages = {95--107},
}

@article{suzuki2017,
	title = {A {Deep}-{Dream} {Virtual} {Reality} {Platform} for {Studying} {Altered} {Perceptual} {Phenomenology}},
	volume = {7},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-017-16316-2},
	doi = {10.1038/s41598-017-16316-2},
	language = {en},
	number = {1},
	urldate = {2022-08-19},
	journal = {Scientific Reports},
	author = {Suzuki, Keisuke and Roseboom, Warrick and Schwartzman, David J. and Seth, Anil K.},
	month = dec,
	year = {2017},
	pages = {15982},
}

@incollection{waterworth2014,
	title = {Altered, {Expanded} and {Distributed} {Embodiment}: the {Three} {Stages} of {Interactive} {Presence}},
	isbn = {978-3-11-040967-3},
	shorttitle = {Altered, {Expanded} and {Distributed} {Embodiment}},
	url = {https://www.degruyter.com/document/doi/10.2478/9783110409697.2/html},
	abstract = {This conceptual chapter outlines three stages in the development of interactive presence, and outlines some possibilities and challenges raised by each, and by their combination. The first stage, presence via altered embodiment, refers to the way technology allows us to experience the world with modified or enhanced senses. The second stage, via expanded embodiment, refers to technology pushing the envelope of the mental body in which one feels present, out beyond the physical body. Finally, distributed embodiment refers to how the sense of being present in the world can be separated from that of ownership of a particular body, through the development of new approaches to deploying the technologies of virtual realization. We suggest that presence is the yardstick of embodiment from an experiential perspective. If you cannot feel presence, you are not embodied in the world.},
	language = {en},
	urldate = {2022-08-19},
	booktitle = {Interacting with {Presence}: {HCI} and the {Sense} of {Presence} in {Computer}-mediated {Environments}},
	publisher = {DE GRUYTER OPEN},
	author = {Waterworth, John and Waterworth, Eva},
	collaborator = {Riva, Giuseppe and Waterworth, John and Murray, Dianne},
	month = sep,
	year = {2014},
	pages = {32--45},
}

@article{seth2012,
	title = {An {Interoceptive} {Predictive} {Coding} {Model} of {Conscious} {Presence}},
	volume = {2},
	issn = {1664-1078},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2011.00395/abstract},
	doi = {10.3389/fpsyg.2011.00395},
	abstract = {We describe a theoretical model of the neurocognitive mechanisms underlying conscious presence and its disturbances. The model is based on interoceptive prediction error and is informed by predictive models of agency, general models of hierarchical predictive coding and dopaminergic signaling in cortex, the role of the anterior insular cortex (AIC) in interoception and emotion, and cognitive neuroscience evidence from studies of virtual reality and of psychiatric disorders of presence, speciﬁcally depersonalization/derealization disorder. The model associates presence with successful suppression by top-down predictions of informative interoceptive signals evoked by autonomic control signals and, indirectly, by visceral responses to afferent sensory signals. The model connects presence to agency by allowing that predicted interoceptive signals will depend on whether afferent sensory signals are determined, by a parallel predictive-coding mechanism, to be self-generated or externally caused. Anatomically, we identify the AIC as the likely locus of key neural comparator mechanisms. Our model integrates a broad range of previously disparate evidence, makes predictions for conjoint manipulations of agency and presence, offers a new view of emotion as interoceptive inference, and represents a step toward a mechanistic account of a fundamental phenomenological property of consciousness.},
	language = {en},
	urldate = {2022-08-19},
	journal = {Frontiers in Psychology},
	author = {Seth, Anil K. and Suzuki, Keisuke and Critchley, Hugo D.},
	year = {2012},
}

@article{ryan1991,
	title = {Some remarks on musical instrument design at {STEIM}},
	volume = {6},
	issn = {0749-4467, 1477-2256},
	url = {http://www.tandfonline.com/doi/abs/10.1080/07494469100640021},
	doi = {10.1080/07494469100640021},
	language = {en},
	number = {1},
	urldate = {2022-08-18},
	journal = {Contemporary Music Review},
	author = {Ryan, Joel},
	month = jan,
	year = {1991},
	pages = {3--17},
}

@book{chalmers2022,
	address = {London},
	title = {Reality+: virtual worlds and the problem of philosophy},
	isbn = {978-0-241-32071-6},
	shorttitle = {Reality+},
	abstract = {"A leading philosopher takes a mind-bending journey through virtual worlds, illuminating the nature of reality and our place within it. Virtual reality is genuine reality. That's the central thesis of Reality+. In a highly original work of "technophilosophy," David J. Chalmers argues that virtual worlds generated by computers are not second-class worlds. We can live a meaningful life in virtual reality. We may even be living in a computer simulation already-and if we are, that's not so bad. What is reality, anyway? How do we know there's an external world? What's the relation between mind and body? How can we lead a good life? Is there a god? In Reality+, Chalmers conducts a grand tour of philosophy, using virtual worlds to illuminate all of these questions and to provide new answers to many of them. Studded with illustrations that bring philosophical issues to life, Reality+ is a major statement that will shape discussion of philosophy and technology for years to come"--},
	language = {eng},
	publisher = {Allen Lane, an imprint of Penguin Books},
	author = {Chalmers, David John},
	year = {2022},
}

@article{riva2016,
	title = {Transforming {Experience}: {The} {Potential} of {Augmented} {Reality} and {Virtual} {Reality} for {Enhancing} {Personal} and {Clinical} {Change}},
	volume = {7},
	issn = {1664-0640},
	shorttitle = {Transforming {Experience}},
	url = {http://journal.frontiersin.org/Article/10.3389/fpsyt.2016.00164/abstract},
	doi = {10.3389/fpsyt.2016.00164},
	abstract = {During life, many personal changes occur. These include changing house, school, work, and even friends and partners. However, the daily experience shows clearly that, in some situations, subjects are unable to change even if they want to. The recent advances in psychology and neuroscience are now providing a better view of personal change, the change affecting our assumptive world: (a) the focus of personal change is reducing the distance between self and reality (conflict); (b) this reduction is achieved through (1) an intense focus on the particular experience creating the conflict or (2) an internal or external reorganization of this experience; (c) personal change requires a progression through a series of different stages that however happen in discontinuous and non-linear ways; and (d) clinical psychology is often used to facilitate personal change when subjects are unable to move forward. Starting from these premises, the aim of this paper is to review the potential of virtuality for enhancing the processes of personal and clinical change. First, the paper focuses on the two leading virtual technologies – augmented reality (AR) and virtual reality (VR) – exploring their current uses in behavioral health and the outcomes of the 28 available systematic reviews and meta-analyses. Then the paper discusses the added value provided by VR and AR in transforming our external experience by focusing on the high level of personal efficacy and self-reflectiveness generated by their sense of presence and emotional engagement. Finally, it outlines the potential future use of virtuality for transforming our inner experience by structuring, altering, and/ or replacing our bodily self-consciousness. The final outcome may be a new generation of transformative experiences that provide knowledge that is epistemically inaccessible to the individual until he or she has that experience, while at the same time transforming the individual’s worldview.},
	language = {en},
	urldate = {2022-08-18},
	journal = {Frontiers in Psychiatry},
	author = {Riva, Giuseppe and Baños, Rosa M. and Botella, Cristina and Mantovani, Fabrizia and Gaggioli, Andrea},
	month = sep,
	year = {2016},
}

@incollection{willans2016,
	title = {Enactive {Emotion} and {Presence} in {Virtual} {Environments}},
	isbn = {978-0-12-801873-6},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128018736000108},
	language = {en},
	urldate = {2022-08-18},
	booktitle = {Emotions, {Technology}, and {Behaviors}},
	publisher = {Elsevier},
	author = {Willans, Tom and Rivers, Sue and Prasolova-Førland, Ekaterina},
	year = {2016},
	pages = {181--210},
}

@incollection{hovhannisyan2019,
	address = {Cham},
	title = {Enacting {Virtual} {Reality}: {The} {Philosophy} and {Cognitive} {Science} of {Optimal} {Virtual} {Experience}},
	volume = {11580},
	isbn = {978-3-030-22418-9 978-3-030-22419-6},
	shorttitle = {Enacting {Virtual} {Reality}},
	url = {http://link.springer.com/10.1007/978-3-030-22419-6_17},
	abstract = {The standard approach to immersive virtual reality (VR) is arguably “object-centric” in that it aims to design physically realistic virtual experiences. This article deems the object-centric approach both philosophically and theoretically problematic and builds up to an alternative, “action-predicated” approach, whose aim is to simulate virtual experiences with a primary emphasis on pragmatic functionality instead. Section 1 lays out the rationale of the article and provides an outline for its general structure. Section 2 illustrates the nature of the problem being tackled and articulates a philosophically motivated critique, demonstrating the necessary limitations of the standard approach, as well as the need for an alternative. Section 3 draws on the enactive approach to cognitive science and begins the formulation of such an alternative. Section 4 completes the turn toward an action-predicated approach and argues, in particular, for a flow-based conception of immersive VR experience. Section 5 systematically discusses the methodological implications of the theoretical merits of this article by examining a design probe, Wake, conducted on participants (N = 25) in a mixed reality (MR) setting. Finally, Section 6 constitutes the conclusion of this article, wherein its philosophical, theoretical, and methodological efforts, as well as possible avenues for future research, are briefly noted.},
	language = {en},
	urldate = {2022-08-18},
	booktitle = {Augmented {Cognition}},
	publisher = {Springer International Publishing},
	author = {Hovhannisyan, Garri and Henson, Anna and Sood, Suraj},
	editor = {Schmorrow, Dylan D. and Fidopiastis, Cali M.},
	year = {2019},
	pages = {225--255},
}

@misc{dedomenico2019,
	title = {Complexity {Explained}},
	copyright = {CC-By Attribution 4.0 International},
	url = {10.17605/OSF.IO/TQGNW},
	abstract = {Booklet of the Complexity Explained project},
	urldate = {2022-08-03},
	author = {De Domenico, Manlio and Sayama, Hiroki},
	year = {2019},
}

@book{rowlands2010,
	address = {Cambridge, Mass},
	title = {The new science of the mind: from extended mind to embodied phenomenology},
	isbn = {978-0-262-01455-7},
	shorttitle = {The new science of the mind},
	language = {en},
	publisher = {MIT Press},
	author = {Rowlands, Mark},
	year = {2010},
	keywords = {Cognitive science, Mental Processes, Philosophy, Medical},
}

@book{varela1993,
	address = {Cambridge (Mass.) London},
	title = {The embodied mind: cognitive science and human experience},
	isbn = {978-0-262-72021-2},
	shorttitle = {The embodied mind},
	language = {eng},
	publisher = {MIT press},
	author = {Varela, Francisco J. and Thompson, Evan and Rosch, Eleanor},
	year = {1993},
}

@book{glaser1967,
	address = {New Brunswick},
	title = {The discovery of grounded theory: strategies for qualitative research},
	shorttitle = {The discovery of grounded theory},
	language = {eng},
	publisher = {Aldine Transaction},
	author = {Glaser, Barney G. and Strauss, Anselm L.},
	year = {1967},
}

@misc{ongwesojr.2022,
	title = {The {Metaverse} {Has} {Bosses} {Too}. {Meet} the ‘{Managers}’ of {Axie} {Infinity}},
	url = {https://www.vice.com/en/article/88g3ag/the-metaverse-has-bosses-too-meet-the-managers-of-axie-infinity},
	abstract = {Managers in play-to-earn game Axie Infinity employ large teams of “scholars” who can’t afford their own NFTs even as the game’s economy spirals.},
	language = {en},
	urldate = {2022-09-12},
	journal = {Vice},
	author = {Ongweso Jr., Edward},
	month = apr,
	year = {2022},
	keywords = {Crypto, Metaverse, Nfts, On the Clock, Play to Earn, Worldnews},
}

@misc{gach2022,
	title = {Crypto {Gaming} '{Landlords}' {Upset} {They} {Can}'t {Keep} {Exploiting} {All} {The} {Players} {Quitting}},
	url = {https://www.kotaku.com.au/2022/04/crypto-gaming-landlords-upset-they-cant-keep-exploiting-all-the-players-quitting/},
	abstract = {Axie Infinity is the crypto-backed Pokémon clone in which cute little creatures that double as NFTs battle for fun and...},
	language = {en-AU},
	urldate = {2022-09-12},
	journal = {Kotaku Australia},
	author = {Gach, Ethan},
	year = {2022},
}

@misc{kane2022,
	title = {Metaverse {Meltdown}: {Top} {Metaverse} {Lands} {Lose} 91\% {Value}},
	shorttitle = {Metaverse {Meltdown}},
	url = {https://dappradar.com/blog/metaverse-meltdown-top-metaverse-lands-lose-91-value},
	abstract = {The land may be virtual, but the pain is real},
	language = {en},
	urldate = {2022-09-12},
	journal = {DappRadar},
	author = {Kane, Ian},
	month = aug,
	year = {2022},
}

@misc{frank2022,
	title = {Metaverse real estate sales top \$500 million, and are projected to double this year},
	url = {https://www.cnbc.com/2022/02/01/metaverse-real-estate-sales-top-500-million-metametric-solutions-says.html},
	abstract = {A rush of investors is pouring into the new virtual land craze, hoping to get in on the ground floor of the next digital Manhattan or Monaco.},
	language = {en},
	urldate = {2022-09-12},
	journal = {CNBC},
	author = {Frank, Robert},
	year = {2022},
}

@article{rogers2021,
	title = {Sci-{Fi} {Icon} {Neal} {Stephenson} {Finally} {Takes} on {Global} {Warming}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/sci-fi-icon-neal-stephenson-global-warming/},
	abstract = {The renowned author says his genre should inspire solutions. In his new novel, 'Termination Shock,' he tackles our most existential crisis.},
	language = {en-US},
	urldate = {2022-09-12},
	journal = {Wired},
	author = {Rogers, Adam},
	year = {2021},
	keywords = {climate change, longreads, magazine-29.11, science fiction},
}

@book{stephenson1992,
	address = {New York},
	series = {A {Bantam} spectra book},
	title = {Snow {Crash}},
	isbn = {978-0-553-08853-3 978-0-553-35192-7},
	publisher = {Bantam Books},
	author = {Stephenson, Neal},
	year = {1992},
	keywords = {Humorous stories, Science fiction},
}

@article{vermeulen2015,
	title = {Space is the {Place}},
	issn = {0962-0672},
	url = {https://www.frieze.com/article/space-place},
	abstract = {Rediscovering the late, great philosopher Henri Lefebvre, whose ideas are increasingly relevant to contemporary life},
	language = {en},
	number = {171},
	urldate = {2022-09-12},
	journal = {Frieze},
	author = {Vermeulen, Timotheus},
	month = apr,
	year = {2015},
}

@article{slater1994,
	title = {Depth of {Presence} in {Virtual} {Environments}},
	volume = {3},
	issn = {1054-7460},
	url = {https://direct.mit.edu/pvar/article/3/2/130-144/58820},
	doi = {10.1162/pres.1994.3.2.130},
	abstract = {This paper describes a study to assess the influence of a variety of factors on reported level of presence in immersive virtual environments. It introduces the idea of “stacking depth,” that is, where a participant can simulate the process of entering the virtual environment while already in such an environment, which can be repeated to several levels of depth. An experimental study including 24 subjects was carried out. Half of the subjects were transported between environments by using virtual head-mounted displays, and the other half by going through doors. Three other binary factors were whether or not gravity operated, whether or not the subject experienced a virtual precipice, and whether or not the subject was followed around by a virtual actor. Visual, auditory, and kinesthetic representation systems and egocentric/exocentric perceptual positions were assessed by a preexperiment questionnaire. Presence was assessed by the subjects as their sense of “being there,” the extent to which they experienced the virtual environments as more the presenting reality than the real world in which the experiment was taking place, and the extent to which the subject experienced the virtual environments as places visited rather than images seen. A logistic regression analysis revealed that subjective reporting of presence was significantly positively associated with visual and kinesthetic representation systems, and negatively with the auditory system. This was not surprising since the virtual reality system used was primarily visual. The analysis also showed a significant and positive association with stacking level depth for those who were transported between environments by using the virtual HMD, and a negative association for those who were transported through doors. Finally, four of the subjects moved their real left arm to match movement of the left arm of the virtual body displayed by the system. These four scored significantly higher on the kinesthetic representation system than the remainder of the subjects.},
	language = {en},
	number = {2},
	urldate = {2022-09-12},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Slater, Mel and Usoh, Martin and Steed, Anthony},
	month = jan,
	year = {1994},
	pages = {130--144},
}

@incollection{veerapen2011,
	address = {London},
	series = {Springer {Series} in {Immersive} {Environments}},
	title = {Encountering oneself and the other: {A} case study of identity formation in {Second} {Life}.},
	isbn = {978-0-85729-360-2 978-0-85729-361-9},
	url = {http://link.springer.com/10.1007/978-0-85729-361-9},
	language = {en},
	urldate = {2022-09-12},
	booktitle = {Reinventing {Ourselves}: {Contemporary} {Concepts} of {Identity} in {Virtual} {Worlds}},
	publisher = {Springer London},
	author = {Veerapen, Maeva},
	editor = {Peachey, Anna and Childs, Mark},
	year = {2011},
}

@book{merleau-ponty1968,
	title = {The visible and the invisible: {Followed} by working notes},
	publisher = {Northwestern University Press},
	author = {Merleau-Ponty, Maurice},
	year = {1968},
}

@article{clark1999,
	title = {An embodied cognitive science?},
	volume = {3},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661399013613},
	doi = {10.1016/S1364-6613(99)01361-3},
	language = {en},
	number = {9},
	urldate = {2022-09-12},
	journal = {Trends in Cognitive Sciences},
	author = {Clark, Andy},
	month = sep,
	year = {1999},
	pages = {345--351},
}

@book{zuboff2019,
	address = {London},
	title = {The age of surveillance capitalism: the fight for a human future at the new frontier of power},
	isbn = {978-1-78125-684-8 978-1-78125-685-5},
	shorttitle = {The age of surveillance capitalism},
	language = {eng},
	publisher = {Profile books},
	author = {Zuboff, Shoshana},
	year = {2019},
}

@misc{leddy2021,
	title = {Dewey’s {Aesthetics}},
	url = {https://plato.stanford.edu/archives/fall2021/entries/dewey-aesthetics/},
	abstract = {John Dewey is, with Charles Sanders Peirce and William James, one ofthe leading early figures of the school of American Pragmatists. Hehas also had a great deal of influence in aesthetics and thephilosophy of art. His work Art as Experience (1934) isregarded by many as one of the most important contributions to thisarea in the twentieth century. The work is especially well-known forits full-blown treatment of aesthetic experience., Critical of attempts to limit aesthetic experience solely to thedomain of fine art, Art as Experience has had a highinfluence on trends in aesthetic research, which have sought tobroaden the scope of the field from the traditional arts to popularculture (Shusterman 1992, 2nd edition 2000), the naturalenvironment (Berleant 1997), and the everyday (Kupfer 1983, Saito2007, Stroud 2011, Leddy 2012). The work is also often seen as a keypart of Dewey’s general late philosophical project, mostsystematically developed in Experience and Nature (1925), ofrethinking experience along naturalist lines as an interaction betweenthe organism and its environment as opposed to a discrete sensory unitsuch as stimulus, impression, idea, or sense-datum. Instead ofinvestigating how our senses are in touch with reality and whetherthey represent it correctly—which Dewey takes to be the frame ofmodern epistemology—Dewey’s starting point, building onhis reading of Darwin’s theory of evolution, is to look at theways in which experience is formed as a part of natural processes towhich the human being is fundamentally tied. For Dewey, aestheticexperience is the highest form of this interaction. It is the phasewhen, in Dewey’s often used words, the interaction between theorganism and the environment reaches a stage of fulfillment. AlreadyExperience and Nature includes a chapter on aesthetics thethemes of which Dewey went on to develop in much greater depth anddetail in Art as Experience some ten years later. Due to thehigh value that Dewey places on aesthetic experience, Art asExperience has even been regarded as the culminating work ofDewey’s late philosophical thinking (Alexander 2013).},
	urldate = {2022-09-12},
	journal = {The Stanford Encyclopedia of Philosophy},
	author = {Leddy, Tom and Puolakka, Kalle},
	collaborator = {Zalta, Edward N.},
	year = {2021},
}

@book{dewey1934,
	address = {New York},
	title = {Art as {Experience}},
	publisher = {Capricorn Books},
	author = {Dewey, John},
	year = {1934},
}

@article{hayes2019,
	title = {Beyond {Skill} {Acquisition}: {Improvisation}, {Interdisciplinarity}, and {Enactive} {Music} {Cognition}},
	volume = {38},
	issn = {0749-4467, 1477-2256},
	shorttitle = {Beyond {Skill} {Acquisition}},
	url = {https://www.tandfonline.com/doi/full/10.1080/07494467.2019.1684059},
	doi = {10.1080/07494467.2019.1684059},
	language = {en},
	number = {5},
	urldate = {2022-08-24},
	journal = {Contemporary Music Review},
	author = {Hayes, Lauren},
	month = sep,
	year = {2019},
	pages = {446--462},
}

@article{green2011,
	title = {Agility and {Playfulness}: {Technology} and skill in the performance ecosystem},
	volume = {16},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Agility and {Playfulness}},
	url = {https://www.cambridge.org/core/product/identifier/S1355771811000082/type/journal_article},
	doi = {10.1017/S1355771811000082},
	abstract = {Whilst it is common in much discourse around contemporary musical practices to emphasise the differences between digital and acoustic ways of making music, Simon Waters’ discussion of the Performance Ecosystem as an analytic perspective argues instead for a heightened sense of continuity (Waters 2007). This article lends support to this argument by developing an ecosystemically situated account of our relationships with technology and processes of skill formation. It is argued that this sense of continuity is justified, but that where differences of experiences do arise these are not, as sometimes supposed, an essential characteristic of digital technologies. On the basis that much of our skill formation consists of tacit knowledge, it is suggested that further discussion on how particular circumstances and skills arise would be revealing. Two possible headings for such discussion are suggested in the form of ‘Agility’ and ‘Playfulness’.},
	language = {en},
	number = {2},
	urldate = {2022-08-22},
	journal = {Organised Sound},
	author = {Green, Owen},
	month = aug,
	year = {2011},
	pages = {134--144},
}

@article{serafin2016a,
	title = {Virtual {Reality} {Musical} {Instruments}: {State} of the {Art}, {Design} {Principles}, and {Future} {Directions}},
	volume = {40},
	issn = {0148-9267, 1531-5169},
	shorttitle = {Virtual {Reality} {Musical} {Instruments}},
	url = {https://direct.mit.edu/comj/article/40/3/22-40/94804},
	doi = {10.1162/COMJ_a_00372},
	abstract = {The rapid development and availability of low-cost technologies have created a wide interest in virtual reality. In the field of computer music, the term “virtual musical instruments” has been used for a long time to describe software simulations, extensions of existing musical instruments, and ways to control them with new interfaces for musical expression. Virtual reality musical instruments (VRMIs) that include a simulated visual component delivered via a head-mounted display or other forms of immersive visualization have not yet received much attention. In this article, we present a field overview of VRMIs from the viewpoint of the performer. We propose nine design guidelines, describe evaluation methods, analyze case studies, and consider future challenges.},
	language = {en},
	number = {3},
	urldate = {2022-08-22},
	journal = {Computer Music Journal},
	author = {Serafin, Stefania and Erkut, Cumhur and Kojs, Juraj and Nilsson, Niels C. and Nordahl, Rolf},
	month = sep,
	year = {2016},
	pages = {22--40},
}

@article{schiavio2018,
	title = {{4E} {Music} {Pedagogy} and the {Principles} of {Self}-{Organization}},
	volume = {8},
	issn = {2076-328X},
	url = {http://www.mdpi.com/2076-328X/8/8/72},
	doi = {10.3390/bs8080072},
	abstract = {Recent approaches in the cognitive and psychological sciences conceive of mind as an Embodied, Embedded, Extended, and Enactive (or 4E) phenomenon. While this has stimulated important discussions and debates across a vast array of disciplines, its principles, applications, and explanatory power have not yet been properly addressed in the domain of musical development. Accordingly, it remains unclear how the cognitive processes involved in the acquisition of musical skills might be understood through the lenses of this approach, and what this might offer for practical areas like music education. To begin ﬁlling this gap, the present contribution aims to explore central aspects of music pedagogy through the lenses of 4E cognitive science. By discussing cross-disciplinary research in music, pedagogy, psychology, and philosophy of mind, we will provide novel insights that may help inspire a richer understanding of what musical learning entails. In doing so, we will develop conceptual bridges between the notion of ‘autopoiesis’ (the property of continuous self-regeneration that characterizes living systems) and the emergent dynamics contributing to the ﬂourishing of one’s musical life. This will reveal important continuities between a number of new teaching approaches and principles of self-organization. In conclusion, we will brieﬂy consider how these conceptual tools align with recent work in interactive cognition and collective music pedagogy, promoting the close collaboration of musicians, pedagogues, and cognitive scientists.},
	language = {en},
	number = {8},
	urldate = {2022-09-12},
	journal = {Behavioral Sciences},
	author = {Schiavio, Andrea and van der Schyff, Dylan},
	month = aug,
	year = {2018},
	pages = {72},
}

@article{puyat2021,
	title = {Axie {Infinity} and the concept of play-to-earn},
	url = {https://www.cnnphilippines.com/life/culture/tech/2021/11/9/axie-infinity-play-to-earn-philippines.html},
	language = {en},
	urldate = {2022-09-12},
	journal = {CNN Philippines},
	author = {Puyat, Maia},
	year = {2021},
}

@misc{marr2022,
	title = {How {To} {Buy} {Land} \& {Real} {Estate} {In} {The} {Metaverse}},
	url = {https://www.forbes.com/sites/bernardmarr/2022/03/23/how-to-buy-land--real-estate-in-the-metaverse/},
	abstract = {We are quickly heading towards the age of the metaverse – connected, persistent virtual realities where we will live digital lives alongside our real lives. Increasingly we will use these spaces to work, play, socialize and learn.},
	language = {en},
	urldate = {2022-09-12},
	journal = {Forbes},
	author = {Marr, Bernard},
	year = {2022},
}

@article{merrifield1993,
	title = {Place and {Space}: {A} {Lefebvrian} {Reconciliation}},
	volume = {18},
	issn = {00202754},
	shorttitle = {Place and {Space}},
	url = {https://www.jstor.org/stable/622564?origin=crossref},
	doi = {10.2307/622564},
	language = {en},
	number = {4},
	urldate = {2022-09-12},
	journal = {Transactions of the Institute of British Geographers},
	author = {Merrifield, Andrew},
	year = {1993},
	pages = {516},
}

@book{decerteau1984,
	address = {Berkeley, Calif.},
	title = {The practice of everyday life},
	isbn = {978-0-520-23699-8},
	language = {eng},
	publisher = {University of California Press},
	author = {de Certeau, Michel},
	year = {1984},
}

@article{mieville1998,
	title = {The conspiracy of architecture: {Notes} on a modern anxiety},
	volume = {2},
	url = {https://brill.com/view/journals/hima/2/1/article-p1_1.xml},
	doi = {https://doi.org/10.1163/156920698100414176},
	number = {1},
	journal = {Historical Materialism},
	author = {Miéville, China},
	year = {1998},
	pages = {1 -- 32},
}

@misc{fatemi2022,
	title = {The {Metaverse} {Will} {Radically} {Change} {Content} {Creation} {Forever}},
	url = {https://www.forbes.com/sites/falonfatemi/2022/03/07/the-metaverse-will-radically-change-content-creation-forever/},
	abstract = {Although the metaverse promises to touch nearly every person in our society, there’s one demographic that will almost certainly see disproportionately strong disruption: creators.},
	language = {en},
	urldate = {2022-09-12},
	journal = {Forbes},
	author = {Fatemi, Falon},
	year = {2022},
}

@misc{ledesma2021,
	title = {Axie {Infinity} {Finds} {Ready} {Players} in {Hyperinflation}-{Racked} {Venezuela}},
	url = {https://www.coindesk.com/markets/2021/11/23/axie-infinity-finds-ready-players-in-hyperinflation-racked-venezuela/},
	abstract = {As they have in the Philippines, some players are making enough money to feed their families.},
	language = {en},
	urldate = {2022-09-12},
	author = {Ledesma, Lyllah},
	month = nov,
	year = {2021},
}

@article{dejesus2022,
	title = {Play-to-{Earn}: {A} {Qualitative} {Analysis} of the {Experiences} and {Challenges} {Faced} {By} {Axie} {Infinity} {Online} {Gamers} {Amidst} the {COVID}-19 {Pandemic}},
	volume = {12},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {Play-to-{Earn}},
	url = {https://figshare.com/articles/journal_contribution/Play-to-Earn_A_Qualitative_Analysis_of_the_Experiences_and_Challenges_Faced_By_Axie_Infinity_Online_Gamers_Amidst____the_COVID-19_Pandemic/18856454/1},
	doi = {10.6084/M9.FIGSHARE.18856454.V1},
	abstract = {One of the most in-demand and divisive of these new games that allow players to collect tradeable crypto currencies is the Axie Infinity. Non-employed, along with the students, are finding it difficult to find stable employment since this pandemic brought many setbacks to employed and more particularly to unemployed students. This study explores the lived experiences, challenges, and coping mechanisms of Axie Infinity Players amidst the pandemic. The study employed the Interpretative Phenomenological Analysis with 20 participants. The following conclusions were drawn based on the study's findings: (1 )For the most part, playing Axie Infinity is not as easy as it looks. (2) Most of the Axie Infinity players are students and it takes a lot of their time playing Axie Infinity that most of their time is spent playing instead of resting and studying just to reach their quota for that day. (3)Axie Infinity is both a blessing and stress. The Axie Infinity play-to-earn game is described as a blessing because it became the number one source of income of the participants despite being amid this pandemic. It also became their source of stress because it adds pressure, tension, and strain to their lives as both a player and a student. (4) Axie Infinity players need a strong support system in their psychological, spiritual, emotional, and physical aspects to withstand the situation of lacking sleep and rest, the pressure of the need to reach the quota, slow internet connection, judgments of the people that surround them, and not being able to focus in both playing and studying. (5) Finally, Axie Infinity players value themselves by coping with negative experiences and challenges they have been through.},
	language = {en},
	number = {1},
	urldate = {2022-09-12},
	journal = {International Journal of Psychology and Counseling},
	author = {De Jesus, Shealtielle Blaise and Austria, Daphne and Marcelo, Daniela Raine and Ocampo, Ceejay and Tibudan, April Joyce and Jhoselle, Tus},
	year = {2022},
	keywords = {160801 Applied Sociology, Program Evaluation and Social Impact Assessment, 160804 Rural Sociology, 160808 Sociology and Social Studies of Science and Technology, 160809 Sociology of Education, 160810 Urban Sociology and Community Studies, 160899 Sociology not elsewhere classified, 170102 Developmental Psychology and Ageing, 170103 Educational Psychology, 170105 Gender Psychology, 170106 Health, Clinical and Counselling Psychology, 170113 Social and Community Psychology, 170114 Sport and Exercise Psychology, 170199 Psychology not elsewhere classified, 179999 Psychology and Cognitive Sciences not elsewhere classified, Applied Psychology, Clinical Psychology, Developmental and Educational Psychology, FOS: Psychology, FOS: Sociology, Personality, Social and Criminal Psychology, Sociology},
}

@article{delic2022,
	title = {Profiling the {Potential} {Risks} and {Benefits} of {Emerging} “{Play} to {Earn}” {Games}: a {Qualitative} {Analysis} of {Players}’ {Experiences} with {Axie} {Infinity}},
	issn = {1557-1874, 1557-1882},
	shorttitle = {Profiling the {Potential} {Risks} and {Benefits} of {Emerging} “{Play} to {Earn}” {Games}},
	url = {https://link.springer.com/10.1007/s11469-022-00894-y},
	doi = {10.1007/s11469-022-00894-y},
	abstract = {The invention of blockchain technology, coupled with the growing interest in cryptocurrencies, has given rise to a new form of monetised gaming known as “Play to Earn” (PTE). “Axie Infinity” (AI) is currently the most popular PTE game, occupying a large portion of the online gaming market. In this paper, we profile the risks and benefits of PTE gaming, with a specific focus on AI. Qualitative data in the form of online chat threads was evaluated via a Thematic Analysis (TA) approach. The analysis revealed a number of themes including the dominance of extrinsically motivated gameplay in conjunction with negative appraisals of game quality, the benefits and costs of play, and the potential for PTE scholarship models to be associated with exploitation. The results did, however, indicate awareness of potential consumer risks. The findings have implications for informing consumer education, regulation, as well as areas of focus in future quantitative research.},
	language = {en},
	urldate = {2022-09-12},
	journal = {International Journal of Mental Health and Addiction},
	author = {Delic, Amelia J. and Delfabbro, Paul H.},
	month = aug,
	year = {2022},
}

@misc{skymavis2022,
	type = {Whitepaper},
	title = {Axie {Infinity}: {Gameplay}},
	url = {https://whitepaper.axieinfinity.com/gameplay},
	urldate = {2022-09-12},
	journal = {Axie Infinity: Gameplay},
	author = {{Sky Mavis}},
	year = {2022},
}

@book{charmaz2006,
	address = {London ; Thousand Oaks, Calif},
	title = {Constructing grounded theory},
	isbn = {978-0-7619-7352-2 978-0-7619-7353-9},
	language = {en},
	publisher = {Sage Publications},
	author = {Charmaz, Kathy},
	year = {2006},
	keywords = {Grounded theory, Research Methodology, Social sciences},
}

@inproceedings{bilbow2022,
	address = {The University of Auckland, New Zealand},
	title = {Evaluating polaris{\textasciitilde} - {An} {Audiovisual} {Augmented} {Reality} {Experience} {Built} on {Open}-{Source} {Hardware} and {Software}},
	url = {https://nime.pubpub.org/pub/3o62rlch},
	doi = {10.21428/92fbeb44.8abb9ce6},
	abstract = {Augmented reality (AR) is increasingly being envisaged as a process of perceptual mediation or modulation, not only as a system that combines aligned and interactive virtual objects with a real environment. Within artistic practice, this reconceptualisation has led to a medium that emphasises this multisensory integration of virtual processes, leading to expressive, narrative-driven, and thought-provoking AR experiences. This paper outlines the development and evaluation of the polaris{\textasciitilde} experience. polaris{\textasciitilde} is built using a set of open-source hardware and software components that can be used to create privacy-respecting and cost-effective audiovisual AR experiences. Its wearable component is comprised of the open-source Project North Star AR headset and a pair of bone conduction headphones, providing simultaneous real and virtual visual and auditory elements. These elements are spatially aligned using Unity and PureData to the real space that they appear in and can be gesturally interacted with in a way that fosters artistic and musical expression. In order to evaluate the polaris{\textasciitilde}, 10 participants were recruited, who spent approximately 30 minutes each in the AR scene and were interviewed about their experience. Using grounded theory, the author extracted coded remarks from the transcriptions of these studies, that were then sorted into the categories of Sentiment, Learning, Adoption, Expression, and Immersion. In evaluating polaris{\textasciitilde} it was found that the experience engaged participants fruitfully, with many noting their ability to express themselves audiovisually in creative ways. The experience and the framework the author used to create it is available in a Github respository.},
	language = {en},
	urldate = {2022-09-27},
	booktitle = {{NIME} 2022},
	publisher = {PubPub},
	author = {Bilbow, Sam},
	month = jun,
	year = {2022},
}
